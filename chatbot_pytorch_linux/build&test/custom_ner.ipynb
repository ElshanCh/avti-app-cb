{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.training.example import Example\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "output_dir=Path(\"ner/\")\n",
    "n_iter=100\n",
    "\n",
    "#load the model\n",
    "\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe('ner', last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Opening JSON file\n",
    "f = open('training_data.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "\n",
    "x = json.load(f)\n",
    "dif = False\n",
    "# for key,i in enumerate(x): \n",
    "#     for key2,j in enumerate(i['annotations']):\n",
    "#         if j['word'] == 'None':\n",
    "#             continue\n",
    "#         else:\n",
    "#             dif = True\n",
    "#             start_index = i['text'].index(j['word'])\n",
    "#             end_index = start_index + len(j['word'])\n",
    "#             if j['start']!=start_index or j['end']!=end_index:\n",
    "#                 dif = True\n",
    "#                 # print(i)\n",
    "#                 # print(x[key]['annotations'])\n",
    "#                 x[key]['annotations'][key2]['start'] = start_index\n",
    "#                 x[key]['annotations'][key2]['end']=end_index\n",
    "# # Directly from dictionary\n",
    "# if dif is True:    \n",
    "#     with open('training_data.json', 'w') as outfile:\n",
    "#         json.dump(x, outfile)\n",
    "\n",
    "tr_d=[]\n",
    "TRAIN_DATA=[]\n",
    "for i in x:\n",
    "    training_data = {'entities':[]}\n",
    "    for j in i['annotations']:\n",
    "\n",
    "        training_data['entities'].append((j['start'], j['end'], j['label']))\n",
    "    # print(training_data)\n",
    "    TRAIN_DATA.append((i['text'],training_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:02<00:00, 38.08it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 63.90it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 59.83it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 60.89it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 59.90it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 63.86it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 65.01it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 66.09it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 65.31it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 64.67it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 65.45it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 66.44it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 65.37it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 64.61it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 59.83it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 63.31it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.22it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 40.44it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 47.56it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.61it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.11it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.98it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 50.36it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 50.75it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.87it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.31it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.31it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.61it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.73it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.18it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.71it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.03it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.36it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.55it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.82it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.73it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.32it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.56it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.24it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.63it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.55it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.16it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.72it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.70it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.74it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.29it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.24it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.86it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.43it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.93it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.23it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.06it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.82it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 57.03it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.25it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.15it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.46it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.87it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.75it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.71it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.37it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 57.27it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.45it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.31it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.63it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.40it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.53it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.15it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.84it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.10it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.08it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.58it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.89it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.02it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.81it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.52it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.43it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 55.99it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 54.30it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 57.14it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.03it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.66it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 51.67it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.81it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.13it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.57it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.16it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.41it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 51.86it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.32it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.09it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.75it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 52.49it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.88it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.36it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 57.62it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 51.64it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 56.90it/s]\n",
      "100%|██████████| 108/108 [00:02<00:00, 53.39it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 59.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# adding labels to ner\n",
    "model_run = False\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "example = []\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    model_run = True\n",
    "    optimizer = nlp.begin_training()\n",
    "    \n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update(\n",
    "                [example], \n",
    "                drop=0.5,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        # print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ner\n"
     ]
    }
   ],
   "source": [
    "if output_dir is not None and model_run is True:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    model_run = False\n",
    "    print(\"Saved model to\", output_dir)\n",
    "pickle.dump(nlp, open( \"models/model_custom_nlp.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE  ------>   in three days\n",
      "TRANSPORT  ------>   shared car\n",
      "LOC-FROM  ------>   via Paisiello 26\n",
      "LOC-TO  ------>   Viale Elvezia, 18\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"in three days i want to take a shared car from via Paisiello 26 to Viale Elvezia, 18\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_+ '  ------>   ' + ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbfb401fab630a94aee7d81a1570b56f66849326b379fbc34501169b58665998"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
