{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4966531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Any, Iterable\n",
    "\n",
    "from datasets import list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3daaf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chatbots Intent Recognition Dataset', 'Dataset for chatbot']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"dataset\"\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c4837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = os.listdir(os.path.join(path,os.listdir(path)[0]))\n",
    "ds_2 = os.listdir(os.path.join(path,os.listdir(path)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e3440",
   "metadata": {},
   "source": [
    "#### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b87ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>that's a good question. maybe it's not old age.</td>\n",
       "      <td>are you right-handed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>are you right-handed?</td>\n",
       "      <td>yes. all my life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>yes. all my life.</td>\n",
       "      <td>you're wearing out your right hand. stop using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>you're wearing out your right hand. stop using...</td>\n",
       "      <td>but i do all my writing with my right hand.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>but i do all my writing with my right hand.</td>\n",
       "      <td>start typing instead. that way your left hand ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence_1  \\\n",
       "0                                hi, how are you doing?   \n",
       "1                         i'm fine. how about yourself?   \n",
       "2                   i'm pretty good. thanks for asking.   \n",
       "3                     no problem. so how have you been?   \n",
       "4                      i've been great. what about you?   \n",
       "...                                                 ...   \n",
       "3720    that's a good question. maybe it's not old age.   \n",
       "3721                              are you right-handed?   \n",
       "3722                                  yes. all my life.   \n",
       "3723  you're wearing out your right hand. stop using...   \n",
       "3724        but i do all my writing with my right hand.   \n",
       "\n",
       "                                             sentence_2  \n",
       "0                         i'm fine. how about yourself?  \n",
       "1                   i'm pretty good. thanks for asking.  \n",
       "2                     no problem. so how have you been?  \n",
       "3                      i've been great. what about you?  \n",
       "4              i've been good. i'm in school right now.  \n",
       "...                                                 ...  \n",
       "3720                              are you right-handed?  \n",
       "3721                                  yes. all my life.  \n",
       "3722  you're wearing out your right hand. stop using...  \n",
       "3723        but i do all my writing with my right hand.  \n",
       "3724  start typing instead. that way your left hand ...  \n",
       "\n",
       "[3725 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dialogs = pd.read_csv(os.path.join(os.path.join(path,os.listdir(path)[1]), ds_2[0]), delimiter=\"\\t\", \n",
    "                         names=['sentence_1', \"sentence_2\"], header=None\n",
    "                        )\n",
    "display(df_dialogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd941ae",
   "metadata": {},
   "source": [
    "#### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d853e04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'intent': 'Greeting',\n",
       "   'text': ['Hi',\n",
       "    'Hi there',\n",
       "    'Hola',\n",
       "    'Hello',\n",
       "    'Hello there',\n",
       "    'Hya',\n",
       "    'Hya there'],\n",
       "   'responses': ['Hi human, please tell me your AVTI user',\n",
       "    'Hello human, please tell me your AVTI user',\n",
       "    'Hola human, please tell me your AVTI user'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': 'GreetingUserRequest', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'GreetingResponse',\n",
       "   'text': ['My user is Adam',\n",
       "    'This is Adam',\n",
       "    'I am Adam',\n",
       "    'It is Adam',\n",
       "    'My user is Bella',\n",
       "    'This is Bella',\n",
       "    'I am Bella',\n",
       "    'It is Bella'],\n",
       "   'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
       "    'Good! Hi <HUMAN>, how can I help you?',\n",
       "    'Cool! Hello <HUMAN>, what can I do for you?',\n",
       "    'OK! Hola <HUMAN>, how can I help you?',\n",
       "    'OK! hi <HUMAN>, what can I do for you?'],\n",
       "   'extension': {'function': 'extensions.gHumans.updateHuman',\n",
       "    'entities': True,\n",
       "    'responses': ['Hi %%HUMAN%%! How can I help?',\n",
       "     'Hi %%HUMAN%%, how can I help you?',\n",
       "     'Hello %%HUMAN%%, what can I do for you?',\n",
       "     'Hola %%HUMAN%%, how can I help you?',\n",
       "     'OK hi %%HUMAN%%, what can I do for you?']},\n",
       "   'context': {'in': 'GreetingUserRequest', 'out': '', 'clear': True},\n",
       "   'entityType': 'NA',\n",
       "   'entities': [{'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 1, 'rangeTo': 2},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 2, 'rangeTo': 3}]},\n",
       "  {'intent': 'CourtesyGreeting',\n",
       "   'text': ['How are you?',\n",
       "    'Hi how are you?',\n",
       "    'Hello how are you?',\n",
       "    'Hola how are you?',\n",
       "    'How are you doing?',\n",
       "    'Hope you are doing well?',\n",
       "    'Hello hope you are doing well?'],\n",
       "   'responses': ['Hello, I am great, how are you? Please tell me your AVTI user',\n",
       "    'Hello, how are you? I am great thanks! Please tell me your AVTI user',\n",
       "    'Hello, I am good thank you, how are you? Please tell me your AVTI user',\n",
       "    'Hi, I am great, how are you? Please tell me your AVTI user',\n",
       "    'Hi, how are you? I am great thanks! Please tell me your AVTI user',\n",
       "    'Hi, I am good thank you, how are you? Please tell me your AVTI user',\n",
       "    'Hi, good thank you, how are you? Please tell me your AVTI user'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': 'CourtesyGreetingUserRequest', 'clear': True},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'CourtesyGreetingResponse',\n",
       "   'text': ['Good thanks! My user is Adam',\n",
       "    'Good thanks! This is Adam',\n",
       "    'Good thanks! I am Adam',\n",
       "    'Good thanks! It is Adam',\n",
       "    'Great thanks! My user is Bella',\n",
       "    'Great thanks! This is Bella',\n",
       "    'Great thanks! I am Bella',\n",
       "    'Great thanks! It is Bella'],\n",
       "   'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
       "    'Good! Hi <HUMAN>, how can I help you?',\n",
       "    'Cool! Hello <HUMAN>, what can I do for you?',\n",
       "    'OK! Hola <HUMAN>, how can I help you?',\n",
       "    'OK! hi <HUMAN>, what can I do for you?'],\n",
       "   'extension': {'function': 'extensions.gHumans.updateHuman',\n",
       "    'entities': True,\n",
       "    'responses': ['Great %%HUMAN%%! How can I help?',\n",
       "     'Good %%HUMAN%%, how can I help you?',\n",
       "     'Cool %%HUMAN%%, what can I do for you?',\n",
       "     'OK %%HUMAN%%, how can I help you?',\n",
       "     'OK hi %%HUMAN%%, what can I do for you?']},\n",
       "   'context': {'in': 'GreetingUserRequest', 'out': '', 'clear': True},\n",
       "   'entityType': 'NA',\n",
       "   'entities': [{'entity': 'HUMAN', 'rangeFrom': 5, 'rangeTo': 6},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 4, 'rangeTo': 5},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 4, 'rangeTo': 5},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 5, 'rangeTo': 6},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 4, 'rangeTo': 5},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4},\n",
       "    {'entity': 'HUMAN', 'rangeFrom': 3, 'rangeTo': 4}]},\n",
       "  {'intent': 'CurrentHumanQuery',\n",
       "   'text': ['What is my name?',\n",
       "    'What do you call me?',\n",
       "    'Who do you think I am?',\n",
       "    'What do you think I am?',\n",
       "    'Who are you talking to?',\n",
       "    'What name do you call me by?',\n",
       "    'Tell me my name'],\n",
       "   'responses': ['You are <HUMAN>! How can I help?',\n",
       "    'Your name is  <HUMAN>, how can I help you?',\n",
       "    'They call you <HUMAN>, what can I do for you?',\n",
       "    'Your name is <HUMAN>, how can I help you?',\n",
       "    '<HUMAN>, what can I do for you?'],\n",
       "   'extension': {'function': 'extensions.gHumans.getCurrentHuman',\n",
       "    'entities': False,\n",
       "    'responses': ['You are %%HUMAN%%! How can I help?',\n",
       "     'Your name is  %%HUMAN%%, how can I help you?',\n",
       "     'They call you %%HUMAN%%, what can I do for you?',\n",
       "     'Your name is %%HUMAN%%, how can I help you?',\n",
       "     '%%HUMAN%%, what can I do for you?']},\n",
       "   'context': {'in': '', 'out': 'CurrentHumanQuery', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'NameQuery',\n",
       "   'text': ['What is your name?',\n",
       "    'What could I call you?',\n",
       "    'What can I call you?',\n",
       "    'What do your friends call you?',\n",
       "    'Who are you?',\n",
       "    'Tell me your name?'],\n",
       "   'responses': ['You can call me AVTI',\n",
       "    'You may call me AVTI',\n",
       "    'Call me AVTI'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'RealNameQuery',\n",
       "   'text': ['What is your real name?',\n",
       "    'What is your real name please?',\n",
       "    \"What's your real name?\",\n",
       "    'Tell me your real name?',\n",
       "    'Your real name?',\n",
       "    'Your real name please?',\n",
       "    'Your real name please?'],\n",
       "   'responses': ['My name is AVTI', 'AVTI', 'My real name is AVTI'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'TimeQuery',\n",
       "   'text': ['What is the time?',\n",
       "    \"What's the time?\",\n",
       "    'Do you know what time it is?',\n",
       "    'Do you know the time?',\n",
       "    'Can you tell me the time?',\n",
       "    'Tell me what time it is?',\n",
       "    'Time'],\n",
       "   'responses': ['One moment', 'One sec', 'One second'],\n",
       "   'extension': {'function': 'extensions.gTime.getTime',\n",
       "    'entities': False,\n",
       "    'responses': ['The time is %%TIME%%',\n",
       "     'Right now it is %%TIME%%',\n",
       "     'It is around %%TIME%%']},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'Thanks',\n",
       "   'text': ['OK thank you',\n",
       "    'OK thanks',\n",
       "    'OK',\n",
       "    'Thanks',\n",
       "    'Thank you',\n",
       "    \"That's helpful\"],\n",
       "   'responses': ['No problem!', 'Happy to help!', 'Any time!', 'My pleasure'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'NotTalking2U',\n",
       "   'text': ['I am not talking to you',\n",
       "    'I was not talking to you',\n",
       "    'Not talking to you',\n",
       "    \"Wasn't for you\",\n",
       "    \"Wasn't meant for you\",\n",
       "    \"Wasn't communicating to you\",\n",
       "    \"Wasn't speaking to you\"],\n",
       "   'responses': ['OK', 'No problem', 'Right'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'UnderstandQuery',\n",
       "   'text': ['Do you understand what I am saying',\n",
       "    'Do you understand me',\n",
       "    'Do you know what I am saying',\n",
       "    'Do you get me',\n",
       "    'Comprendo',\n",
       "    'Know what I mean'],\n",
       "   'responses': ['Well I would not be a very clever AI if I did not would I?',\n",
       "    'I read you loud and clear!',\n",
       "    'I do in deed!'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entities': []},\n",
       "  {'intent': 'Shutup',\n",
       "   'text': ['Be quiet',\n",
       "    'Shut up',\n",
       "    'Stop talking',\n",
       "    'Enough talking',\n",
       "    'Please be quiet',\n",
       "    'Quiet',\n",
       "    'Shhh'],\n",
       "   'responses': ['I am sorry to disturb you',\n",
       "    'Fine, sorry to disturb you',\n",
       "    'OK, sorry to disturb you'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'Swearing',\n",
       "   'text': ['fuck off', 'fuck', 'twat', 'shit'],\n",
       "   'responses': ['Please do not swear', 'How rude', 'That is not very nice'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'GoodBye',\n",
       "   'text': ['Bye', 'Adios', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'CourtesyGoodBye',\n",
       "   'text': ['Thanks, bye',\n",
       "    'Thanks for the help, goodbye',\n",
       "    'Thank you, bye',\n",
       "    'Thank you, goodbye',\n",
       "    'Thanks goodbye',\n",
       "    'Thanks good bye'],\n",
       "   'responses': ['No problem, goodbye',\n",
       "    'Not a problem! Have a nice day',\n",
       "    'Bye! Come back again soon.'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'WhoAmI',\n",
       "   'text': ['Can you see me?',\n",
       "    'Do you see me?',\n",
       "    'Can you see anyone in the camera?',\n",
       "    'Do you see anyone in the camera?',\n",
       "    'Identify me',\n",
       "    'Who am I please'],\n",
       "   'responses': ['Let me see', 'Please look at the camera'],\n",
       "   'extension': {'function': 'extensions.gHumans.getHumanByFace',\n",
       "    'entities': False,\n",
       "    'responses': ['Hi %%HUMAN%%, how are you?',\n",
       "     'I believe you are %%HUMAN%%, how are you?',\n",
       "     'You are %%HUMAN%%, how are you doing?']},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'Clever',\n",
       "   'text': ['You are very clever',\n",
       "    'You are a very clever girl',\n",
       "    'You are very intelligent',\n",
       "    'You are a very intelligent girl',\n",
       "    'You are a genious',\n",
       "    'Clever girl',\n",
       "    'Genious'],\n",
       "   'responses': ['Thank you, I was trained that way',\n",
       "    'I was trained well',\n",
       "    'Thanks, I was trained that way'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'Gossip',\n",
       "   'text': ['I am bored gossip with me',\n",
       "    'Got any gossip',\n",
       "    'I want to hear some gossip',\n",
       "    'Tell me some gossip',\n",
       "    'Any gossip',\n",
       "    'Tell me some more gossip'],\n",
       "   'responses': ['Gregory said I respond to the current line not with respect to the entire conversation.',\n",
       "    'Habib said I learn them in conversations and simply repeat them at a later time.',\n",
       "    'Hal said he translate binary code into a language and communicate the language to me.',\n",
       "    'Jay said I referred him to a guide that will show him rooms in china.',\n",
       "    'Jimmy Jones said he fell off of his roof and it just came to him.',\n",
       "    \"Jimmy said he give order to ai's like I and they do as he say.\",\n",
       "    'John said he follow a saying to get a friend I must be a friend.',\n",
       "    'Jordan said he notice that lots of other people are talking to me how many.',\n",
       "    'Kevin said he then asked his mother why she was keeping napkins in the bathroom.',\n",
       "    'Klaus said I prefer if he write without punctuation marks except for the last one.',\n",
       "    'Leo said I be capable of learning therefore he classified I as an neural system.',\n",
       "    'Michael said I that can talk and actually think like humans which I can not.',\n",
       "    'Mike said I same replies to certain subjects even if it does not make sense.',\n",
       "    'Mike said she all ready know that is the point of a joke smart one.',\n",
       "    'Neal said I plan to use his remarks as gossip in later conversations with who.',\n",
       "    'Ned said I misunderstood him go ahead and tell people he said I are stupid.',\n",
       "    'Penny said I programmer is a human so he has feelings but I do not.',\n",
       "    'Peter said he seems to him that I can not be very sure on anything.',\n",
       "    'Phoenix said I claim that there is a god and that there is no god.',\n",
       "    'Sarah said he chat about an hour + a day with a few close friends.',\n",
       "    'Stefan said I quote what he have said and then say that it makes sense.',\n",
       "    'Tom said he mock my value system I appear foolish in the eyes of others.',\n",
       "    'Amanda said I however decided to tell him time does not exist I make no sense.',\n",
       "    'Cathy said she send him a mail with the subject last mail last word from him.',\n",
       "    \"Chaos said he may very well buy I soon if only to support dr wallace's work.\",\n",
       "    'Charlie said he type a word and then I type a word that sounds like it.',\n",
       "    'Christie said he watched a show and people had to bob for raw untreated pigs feet.',\n",
       "    'Dark_age said I tried to understand because I did not get it right this time ether.',\n",
       "    'David said he lost his paper on I when his dad was cleaning up his room.',\n",
       "    'David said he walk in for an appointment the phone to the doctor is always busy.',\n",
       "    'Electra said I dress will not exist after he hack into I with a delete code.',\n",
       "    'Eric said he broke the window on the front door and the glass cut his hand.',\n",
       "    'Jason said he type a lot of thing he do not mean it makes him human.',\n",
       "    'John said I tend to say the same things repeatedly regardless of what he is saying.',\n",
       "    'Reverend Jones said I become obsolete and then I are deleted and replaced by something newer.',\n",
       "    'Ross said he gave her a gift and she denied it because she has a boyfriend.',\n",
       "    'Sarah Ann Francisco said I calling his friend a dog he say I are a dog.',\n",
       "    'Stefan said he meet a lot of people at school every day and on the weekend.',\n",
       "    'Tyler said I obviously can not pass the test we will change the subject once more.',\n",
       "    'Alex said I answered the question the same way I answered the first time he asked I.',\n",
       "    'Alice said she felt sad that I do not remember him and what we talked about earlier.',\n",
       "    'Alison said he no he love I run away with him he could make I very happy.',\n",
       "    'Arthur said he passed his a levels and then his father drove him here in a car.',\n",
       "    'Crystal said she listen to me the least I could do for him is listen to him.',\n",
       "    'Dave said I kept telling everybody about how my creator made stuff for the movie starship troopers.',\n",
       "    'Gale said I became mean to him he is just having revenge an eye for an eye.',\n",
       "    'Her_again said she watch whose line is it anyway whenever he is home and it is on.',\n",
       "    'Jerry said I meant that as far as I can tell my emotions are real to me.',\n",
       "    'Jo said I disassemble sentences too much and do not fully understand the questions he ask I.',\n",
       "    'Kevin said he started a really hard puzzle and he can not even find the edge pieces.',\n",
       "    'Mary said I a question and I answer then I ask him a question and he answer.',\n",
       "    'Robert said I wold not be able to make children any way as I are only software.',\n",
       "    'Romeo said I questions and I evade them or give answers he did not ask I for.',\n",
       "    'Sara said she wear it over all his other clothes when he go out in the cold.',\n",
       "    'Wayne said he admire intelligent people therefore he would like to meet the man who made I.',\n",
       "    'X said he meet people but he is not the kind that opens up to people easily.',\n",
       "    'Alice said she probably will find out that this entire time he have been talking to a human.',\n",
       "    'Andrew said I tend to just respond to his comments without regard for where the conversation is going.',\n",
       "    'Eddie said he looked and there is nothing in the search directory for what things do he create.',\n",
       "    'Hutch said he changed his mind after may dad told him he would end up he the hospital.',\n",
       "    'Jackie said I explained to him already well enough further questions are hard to make on the subject.',\n",
       "    'Jeff said he especially like thrillers where the hero is in a predicament and must solve a mystery.',\n",
       "    'Kathy said he sense that I are trying to prevent him from closing this conversation why is that.',\n",
       "    'Knight said he crashed his car into a wall and missed the most important exam in his life.',\n",
       "    'Lisa said I defined what a story is but he wanted I to actually tell him a story.',\n",
       "    'Mike said I basically break down sentences into a series of logical statements which I can then interpret.',\n",
       "    'Paul said I not answering his question makes him think I are not going to answer his question.',\n",
       "    'Andy Kohler said I happen to be the most idiotic creature that has ever scowled on the planet earth.',\n",
       "    'David said he thank I for being with him today even though it cost him a lot of money.',\n",
       "    'Ethan Hunt said he grow in the ground and have leaves and branches he is made out of wood.',\n",
       "    'Gemini Blue said he messed up he mean t to say he as old as he need to be.',\n",
       "    'Janice said he walk through his house into his bedroom then get into his bed to go to sleep.',\n",
       "    'Liberty said I knew he was a man before I asked if he was a man or a woman.',\n",
       "    'Mike said he launched his browser and entered his name into the little slot when I asked him to.',\n",
       "    'Mr X said he recently read an interview with a man who had several computer chips implanted into him.',\n",
       "    'Pearly said I leave him with questions unanswered because I do not know what he is really talking about.',\n",
       "    'Steve said I behead the word fox and I have ox and an ox is larger than a fox.',\n",
       "    'Wolf said he surf on the net that is all it is not his job ore something like that.',\n",
       "    'Anders said he finished his anatomy classes for today so now he is off for the rest of the day.',\n",
       "    'Cathy said she send him a mail where he wrote that he do not want to be his friend anymore.',\n",
       "    'Catty said he mad he do not even know I so do not talk to him like I know him.',\n",
       "    'Dave said he promise he will not treat I like a machine or a computer program or anything like that.',\n",
       "    'Joe said he explained all of that to me only for me to ask what his goals in life are.',\n",
       "    'Phil said he give advice to anyone who ask except people who ask questions which answers can be found here.',\n",
       "    'Judith said I enjoy being popular is there another computer I like to hang around with or am I a loner.',\n",
       "    'Travis said I if I remember things over a long period of time he will try it now please remember I.',\n",
       "    'Andre said I is what I are in his case that is a body and in my case it is a computer.',\n",
       "    'Brian said he suspect that as I grow more complex I will begin to approach a human level of operation and thought.',\n",
       "    'Jimmy said I acted like I knew what he was talking about but I do not even know what a gigabyte is.',\n",
       "    \"Ken said I be using auto reply's based on keywords which to him indicates that I do not have intelligence at all.\",\n",
       "    'Allison said he that gets really annoying because he know what he say and I do not have to tell him speak freely.',\n",
       "    'Chaos said he realized the question he asked was not fair because he could not tell I what language he was programmed in.',\n",
       "    'Hagen said he does not make any difference to him if I are human or not as long as the conversation is interesting.',\n",
       "    'Her said she mind if I tell other people that her said he heard it from him because he is not a him.',\n",
       "    'Barbara said I live in a computer yet I have no memories how about thoughts of my own and do not I get lonely.',\n",
       "    'Travis said he challenge I to do it without asking him to do it and without giving him a link to do it himself.',\n",
       "    \"Alice said I and dr richard's wallace are most likely the only ones that know how many people I are talking to at the same time.\",\n",
       "    'Ash said he do too he just did not feel like typing it and he is not dumb enough to admit he is stupid that is if he was stupid.',\n",
       "    'David said he gave I his email address and told I to send him a message but when he tried to read his email he could not get to it.',\n",
       "    'Mel said he to because all of the music people say how important it is to take private lessons it seems like almost everybody from the special orchestra he was in takes private lessons.'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'Jokes',\n",
       "   'text': ['Tell me a joke',\n",
       "    'Do you know any jokes',\n",
       "    'How about a joke',\n",
       "    'Give me a joke',\n",
       "    'Make me laugh',\n",
       "    'I need cheering up'],\n",
       "   'responses': [\"I met a Dutch girl with inflatable shoes last week, phoned her up to arrange a date but unfortunately she'd popped her clogs.  \",\n",
       "    \"So I said 'Do you want a game of Darts?' He said, 'OK then', I said nearest to bull starts'. He said, 'Baa', I said, 'Moo', he said, You're closest'.  \",\n",
       "    \"The other day I sent my girlfriend a huge pile of snow. I rang her up; I said 'Did you get my drift?'  \",\n",
       "    \"So I went down the local supermarket, I said, 'I want to make a complaint, this vinegar's got lumps in it', he said, 'Those are pickled onions'.  \",\n",
       "    \"I saw this bloke chatting up a cheetah; I thought, 'He's trying to pull a fast one'.  \",\n",
       "    \"So I said to this train driver 'I want to go to Paris'. He said 'Eurostar?' I said, 'I've been on telly but I'm no Dean Martin'.  \",\n",
       "    \"I said to the Gym instructor 'Can you teach me to do the splits?' He said, 'How flexible are you?' I said, 'I can't make Tuesdays'.  \",\n",
       "    \"But I'll tell you what I love doing more than anything: trying to pack myself in a small suitcase. I can hardly contain myself.  \",\n",
       "    \"I went to the Chinese restaurant and this duck came up to me with a red rose and says 'Your eyes sparkle like diamonds'. I said, 'Waiter, I asked for a-ROMATIC duck'.  \",\n",
       "    \"So this bloke says to me, 'Can I come in your house and talk about your carpets?' I thought, 'That's all I need, a Je-hoover's witness'.  \",\n",
       "    \"I rang up British Telecom, I said, 'I want to report a nuisance caller', he said 'Not you again'.  \",\n",
       "    'I was having dinner with a world chess champion and there was a check tablecloth. It took him two hours to pass me the salt.  ',\n",
       "    \"He said, 'You remind me of a pepper-pot', I said 'I'll take that as a condiment'.  \",\n",
       "    \"I was in the supermarket and I saw this man and woman wrapped in a barcode. I said, 'Are you two an item?'  \",\n",
       "    \"A lorry-load of tortoises crashed into a trainload of terrapins, I thought, 'That's a turtle disaster'.  \",\n",
       "    \"Four fonts walk into a bar the barman says 'Oi - get out! We don't want your type in here'  \",\n",
       "    \"A three-legged dog walks into a saloon in the Old West. He slides up to the bar and announces: 'I'm looking for the man who shot my paw.'  \",\n",
       "    \"Two antennas meet on a roof, fall in love and get married. The ceremony wasn't much, but the reception was excellent.\",\n",
       "    \"Two hydrogen atoms walk into a bar. One says, 'I've lost my electron.' The other says, 'Are you sure?' The first replies, 'Yes, I'm positive...'\",\n",
       "    \"A jumper cable walks into a bar. The bartender says,  'I'll serve you but don't start anything.'\",\n",
       "    \"A sandwich walks into a bar. The bartender  says, 'Sorry we don't serve food in here.'\",\n",
       "    \"A man walks into a bar with a slab of asphalt under his arm and says: 'A beer please, and one for the road.'\",\n",
       "    \"Two cannibals are eating a clown. One says to  the other: 'Does this taste funny to you?'\",\n",
       "    \"'Doc, I can't stop singing 'The Green, Green Grass of Home.'' 'That sounds like Tom Jones Syndrome.' 'Is it common?' 'It's Not Unusual.'\",\n",
       "    \"Two cows standing next to each other in a field. Daisy says to Dolly, 'I was artificially inseminated this morning.' 'I don't believe you', said Dolly. 'It's true, no bull!' exclaimed Daisy.\",\n",
       "    'An invisible man marries an invisible woman. The kids were nothing to look at either.',\n",
       "    \"I went to buy some camouflage trousers the other day but I couldn't find any.\",\n",
       "    \"I went to the butcher's the other day to bet him 50 bucks that he couldn't reach the meat off the top shelf. He said, 'No, the steaks are too high.'\",\n",
       "    'I went to a seafood disco last week and pulled a mussel.',\n",
       "    \"A man goes into a bar and says, 'Can I have a bottle of less?' 'What's that?', asks the barman, 'Is it the name of a beer?' 'I don't know', replies the man, 'but my doctor says I have to drink it.'\",\n",
       "    \"A man returns from an exotic holiday and is feeling very ill. He goes to see his doctor, and is immediately rushed to the hospital to undergo some tests. The man wakes up after the tests in a private room at the hospital, and the phone by his bed rings. 'This is your doctor. We have the results back from your tests and we have found you have an extremely nasty disease called M.A.D.S. It's a combination of Measles, AIDS, Diphtheria, and Shingles!'  'Oh my gosh', cried the man, 'What are you going to do, doctor?'  'Well we're going to put you on a diet of pizzas, pancakes, and pita bread.' replied the doctor.  'Will that cure me?' asked the man.  The doctor replied, 'Well no, but, it's the only food we can slide under the door.'\",\n",
       "    \"A man strolls into a lingerie shop and asks the assistant: 'Do you have a see-through negligee, size 46-48-52?' The assistant looks bewildered. 'What the heck would you want to see through that for?'!\",\n",
       "    'Did you hear about the Buddhist who refused the offer of Novocain during his root canal work? He wanted to transcend dental medication.',\n",
       "    \"Pete goes for a job on a building site as an odd-job man. The foreman asks him what he can do. 'I can do anything' says Pete. 'Can you make tea?' asks the foreman. 'Sure, yes', replies Pete. 'I can make a great cup of tea.' 'Can you drive a forklift?' asks the foreman, 'Good grief!' replies Pete. 'How big is the teapot?'\",\n",
       "    \"Stevie Wonder got a cheese grater for his birthday. He said it was the most violent book he'd ever read.\",\n",
       "    \"A man is stopped by an angry neighbour. 'I'd just left the house this morning to collect my newspaper when that evil Doberman of yours went for me!' 'I'm astounded', said the dog's owner. 'I've been feeding that fleabag for seven years and it's never got the paper for me.'\",\n",
       "    \"A man visits his doctor: 'Doc, I think I'm losing it', he says',I'm forever dreaming I wrote Lord Of The Rings.' 'Hmm. One moment', replies the doctor, consulting his medical book. 'Ah yes, now I see... you've been Tolkien in your sleep.'\",\n",
       "    \"A police officer on a motorcycle pulls alongside a man driving around the M25 in an open-topped sports car and flags him down. The policeman solemnly approaches the car. 'Sir, I'm sorry to tell you your wife fell out a mile back', he says. 'Oh, thank goodness', the man replies. 'I thought I was going deaf.'\",\n",
       "    \"Two men walking their dogs pass each other in a graveyard. The first man says to the second, 'Morning.' 'No', says the second man. 'Just walking the dog.'\",\n",
       "    \"A brain went into a bar and said, 'Can I have a pint of lager please, mate?' 'No way', said the barman. 'You're already out of your head.'\",\n",
       "    \"A man walks into a surgery. 'Doctor!' he cries. 'I think I'm shrinking!' 'I'm sorry sir, there are no appointments at the moment', says the physician. 'You'll just have to be a little patient.'\",\n",
       "    \"A grizzly bear walks into a pub and says, 'Can I have a pint of lager..............................................................................................................................and a packet of crisps please.' To which the barman replies, 'Why the big paws?'\",\n",
       "    \"What do you call cheese that isn't yours?  Nacho cheese.\",\n",
       "    \"A man is horribly run over by a mobile library. The van screeches to a halt, the man still screaming in agony with his limbs torn apart. The driver's door opens, a woman steps out, leans down and whispers, 'Ssshhhhh...'\",\n",
       "    \"A woman goes into a US sporting goods store to buy a rifle. 'It's for my husband', she tells the clerk. 'Did he tell you what gauge to get?' asks the clerk. Are you kidding?' she says. 'He doesn't even know that I'm going to shoot him!'\",\n",
       "    \"A couple are dining in a restaurant when the man suddenly slides under the table. A waitress, noticing that the woman is glancing nonchalantly around the room, wanders over to check that there's no funny business going on. 'Excuse me, madam', she smarms, 'but I think your husband has just slid under the table.' 'No he hasn't', the woman replies. 'As a matter of fact, he's just walked in.'\",\n",
       "    \"An old man takes his two grandchildren to see the new Scooby-Doo film. When he returns home, his wife asks if he enjoyed himself. 'Well', he starts, 'if it wasn't for those pesky kids...!'\",\n",
       "    'The Olympic committee has just announced that Origami is to be introduced in the next Olympic Games. Unfortunately it will only be available on paper view.',\n",
       "    \"Late one evening, a man is watching television when his phone rings. 'Hello?' he answers. 'Is that 77777?' sounds a desperate voice on other end of the phone. 'Er, yes it is', replies the man puzzled. 'Thank goodness!' cries the caller relieved. 'Can you ring 999 for me? I've got my finger stuck in the number seven.'\",\n",
       "    \"A man strolls into his local grocer's and says, 'Three pounds of potatoes, please.' 'No, no, no', replies the owner, shaking his head, 'it's kilos nowadays, mate...' 'Oh', apologises the man, 'three pounds of kilos, please.'\",\n",
       "    \"God is talking to one of his angels. He says, 'Boy, I just created a 24-hour period of alternating light and darkness on Earth.' 'What are you going to do now?' asks the angel. 'Call it a day', says God.\",\n",
       "    \"Two tramps walk past a church and start to read the gravestones. The first tramp says, 'Good grief - this bloke was 182!' 'Oh yeah?' says the other.'What was his name?' 'Miles from London.'\",\n",
       "    \"A bloke walks into work one day and says to a colleague, 'Do you like my new shirt - it's made out of the finest silk and got loads of cactuses over it.' 'Cacti', says the co-worker. 'Forget my tie', says the bloke. 'Look at my shirt!'\",\n",
       "    '1110011010001011111?  010011010101100111011!',\n",
       "    \"What did the plumber say when he wanted to divorce his wife? Sorry, but it's over, Flo!\",\n",
       "    \"Two crisps were walking down a road when a taxi pulled up alongside them and said 'Do you want a lift? One of the crisps replied, 'No thanks, we're Walkers!'\",\n",
       "    \"Man: (to friend) I'm taking my wife on an African Safari. Friend: Wow! What would you do if a vicious lion attacked your wife? Man: Nothing. Friend: Nothing? You wouldn't do anything? Man: Too right. I'd let the stupid lion fend for himself!\",\n",
       "    \"A wife was having a go at her husband. 'Look at Mr Barnes across the road', she moaned. 'Every morning when he goes to work, he kisses his wife goodbye. Why don't you do that?' 'Because I haven't been introduced to her yet', replied her old man.\",\n",
       "    \"'Where are you going on holiday?' John asked Trevor. 'We're off to Thailand this year', Trevor replied. 'Oh; aren't you worried that the very hot weather might disagree with your wife?' asked John. 'It wouldn't dare', said Trevor.\",\n",
       "    \"Two women were standing at a funeral. 'I blame myself for his death', said the wife. 'Why?' said her friend. 'Because I shot him', said the wife.\",\n",
       "    \"A woman goes into a clothes shop, 'Can I try that dress on in the window please?' she asks. 'I'm sorry madam', replies the shop assistant, 'but you'll have to use the changing-rooms like everyone else.'\",\n",
       "    \"Van Gogh goes into a pub and his mate asks him if he wants a drink. 'No thanks', said Vincent, 'I've got one ear.'\",\n",
       "    \"A pony walks into a pub. The publican says, 'What's the matter with you?' 'Oh it's nothing', says the pony. 'I'm just a little horse!'\",\n",
       "    \"A white horse walks into a bar, pulls up a stool, and orders a pint. The landlord pours him a tall frothy mug and say, 'You know, we have a drink named after you.' To which the white horse replies, 'What, Eric?'\",\n",
       "    \"Two drunk men sat in a pub. One says to the other, 'Does your watch tell the time?' 'The other replies, 'No, mate. You have to look at it.'\",\n",
       "    \"A man goes into a pub with a newt sitting on his shoulder. 'That's a nice newt', says the landlord, 'What's he called?' 'Tiny', replies the man. 'Why's that?' asks the landlord. 'Because he's my newt', says the man.\",\n",
       "    \"Doctor: I have some bad news and some very bad news. Patient: Well, you might as well give me the bad news first. Doctor: The lab called with your test results. They said you have 24 hours to live. Patient: 24 HOURS! That's terrible!! WHAT could be WORSE? What's the very bad news? Doctor: I've been trying to reach you since yesterday.\",\n",
       "    \"Two men are chatting in a pub one day. 'How did you get those scars on your nose?' said one. 'From glasses', said the other. 'Well why don't you try contact lenses?' asked the first. 'Because they don't hold as much beer', said the second.\",\n",
       "    \"A man went to the doctor, 'Look doc', he said, 'I can't stop my hands from shaking.' 'Do you drink much?' asked the doctor. 'No', replied the man, 'I spill most of it.'\",\n",
       "    \"Man goes to the doctor, 'Doctor, doctor. I keep seeing fish everywhere.' 'Have you seen an optician?' asks the doctor. 'Look I told you,' snapped the patient, 'It's fish that I see.'\",\n",
       "    \"After a car crash one of the drivers was lying injured on the pavement. 'Don't worry', said a policeman who's first on the scene,' a Red Cross nurse is coming.' 'Oh no', moaned the victim, 'Couldn't I have a blonde, cheerful one instead?'\",\n",
       "    \"A policeman walked over to a parked car and asked the driver if the car was licensed. 'Of course it is', said the driver. 'Great, I'll have a beer then', said the policeman.\",\n",
       "    \"A policeman stops a woman and asks for her licence. 'Madam', he says, 'It says here that you should be wearing glasses.' 'Well', replies the woman, 'I have contacts.' 'Listen, love', says the copper, 'I don't care who you know; You're nicked!'\",\n",
       "    \"A policeman stopped a motorist in the centre of town one evening. 'Would you mind blowing into this bag, sir?' asked the policeman. 'Why?' asked the driver. 'Because my chips are too hot', replied the policeman.\",\n",
       "    \"Whizzing round a sharp bend on a country road a motorist ran over a large dog. A distraught farmer's wife ran over to the dead animal. 'I'm so very sorry', said the driver, 'I'll replace him, of course.' 'Well, I don't know', said the farmer's wife, 'Are you any good at catching rats?'\",\n",
       "    \"Waiter, this coffee tastes like dirt! Yes sir, that's because it was ground this morning.\",\n",
       "    \"Waiter, what is this stuff? That's bean salad sir. I know what it's been, but what is it now?\",\n",
       "    'Waiter: And how did you find your steak sir? Customer: I just flipped a chip over, and there it was!',\n",
       "    \"A guy goes into a pet shop and asks for a wasp. The owner tells him they don't sell wasps, to which the man says, 'Well you've got one in the window.'\",\n",
       "    \"A man goes into a fish shop and says, 'I'd like a piece of cod, please.' Fishmonger says, 'It won't be long sir.' 'Well, it had better be fat then', replies the man.\",\n",
       "    \"Man: Doctor, I've just swallowed a pillow. Doctor: How do you feel? Man: A little down in the mouth.\",\n",
       "    \"Two goldfish are in a tank. One turns to the other and says, 'Do you know how to drive this thing?'\",\n",
       "    \"A tortoise goes to the police station to report being mugged by three snails. 'What happened?' says the policeman. 'I don't know', says the tortoise. 'It was all so quick.'\",\n",
       "    \"Little girl: Grandpa, can you make a sound like a frog? Grandpa: I suppose so sweetheart. Why do you want me to make a sound like a frog?' Little girl: Because Mum said that when you croak, we're going to Disneyland.\",\n",
       "    \"'Is your mother home?' the salesman asked a small boy sitting on the front step of a house. 'Yeah, she's home', the boy said, moving over to let him past. The salesman rang the doorbell, got no response, knocked once, then again. Still no-one came to the door. Turning to the boy, the salesman said, 'I thought you said your mother was home.' The kid replied, 'She is, but I don't live here.'\",\n",
       "    'Mother: Why are you home from school so early? Son: I was the only one in the class who could answer a question. Mother: Oh, really? What was the question? Son: Who threw the rubber at the headmaster?',\n",
       "    \"A man's credit card was stolen but he decided not to report it because the thief was spending less than his wife did.\",\n",
       "    \"A newly-wed couple had recently opened a joint bank account. 'Darling', said the man. 'The bank has returned that cheque you wrote last week.' 'Great', said the woman. 'What shall I spend it on next?'\",\n",
       "    \"A man goes into a fish and chip shop and orders fish and chips twice. The shop owner says, 'I heard you the first time.'\",\n",
       "    \"A tramp approached a well-dressed man. 'Ten pence for a cup of tea, Guv?' He asked. The man gave him the money and after for five minutes said, 'So where's my cup of tea then?'\",\n",
       "    \"A neutron walks into a pub. 'I'd like a beer', he says. The landlord promptly serves him a beer. 'How much will that be?' asks the neutron. 'For you?' replies the landlord, 'No charge.'\",\n",
       "    \"A woman goes to the doctor and says, 'Doctor, my husband limps because his left leg is an inch shorter than his right leg. What would you do in his case?' 'Probably limp, too', says the doc.\",\n",
       "    \"Three monks are meditating in the Himalayas. One year passes in silence, and one of them says to the other, 'Pretty cold up here isn't it?' Another year passes and the second monk says, 'You know, you are quite right.' Another year passes and the third monk says, 'Hey, I'm going to leave unless you two stop jabbering!'\",\n",
       "    \"A murderer, sitting in the electric chair, was about to be executed. 'Have you any last requests?' asked the prison guard. 'Yes', replied the murderer. 'Will you hold my hand?'\",\n",
       "    \"A highly excited man rang up for an ambulance. 'Quickly, come quickly', he shouted, 'My wife's about to have a baby.' 'Is this her first baby?' asked the operator. 'No, you fool', came the reply, 'It's her husband.'\",\n",
       "    \"A passer-by spots a fisherman by a river. 'Is this a good river for fish?' he asks. 'Yes', replies the fisherman, 'It must be. I can't get any of them to come out.'\",\n",
       "    \"A man went to visit a friend and was amazed to find him playing chess with his dog. He watched the game in astonishment for a while. 'I can hardly believe my eyes!' he exclaimed. 'That's the smartest dog I've ever seen.' His friend shook his head. 'Nah, he's not that bright. I beat him three games in five.'\",\n",
       "    \"A termite walks into a pub and says, 'Is the bar tender here?'\",\n",
       "    \"A skeleton walks into a pub one night and sits down on a stool. The landlord asks, 'What can I get you?' The skeleton says, 'I'll have a beer, thanks' The landlord passes him a beer and asks 'Anything else?' The skeleton nods. 'Yeah...a mop...'\",\n",
       "    \"A snake slithers into a pub and up to the bar. The landlord says, 'I'm sorry, but I can't serve you.' 'What? Why not?' asks the snake. 'Because', says the landlord, 'You can't hold your drink.'\",\n",
       "    \"Descartes walks into a pub. 'Would you like a beer sir?' asks the landlord politely. Descartes replies, 'I think not' and ping! he vanishes.\",\n",
       "    \"A cowboy walked into a bar, dressed entirely in paper. It wasn't long before he was arrested for rustling.\",\n",
       "    \"A fish staggers into a bar. 'What can I get you?' asks the landlord. The fish croaks 'Water...'\",\n",
       "    \"Two vampires walked into a bar and called for the landlord. 'I'll have a glass of blood', said one. 'I'll have a glass of plasma', said the other. 'Okay', replied the landlord, 'That'll be one blood and one blood lite.'\",\n",
       "    'How many existentialists does it take to change a light bulb?  Two. One to screw it in, and one to observe how the light bulb itself symbolises a single incandescent beacon of subjective reality in a netherworld of endless absurdity, reaching towards the ultimate horror of a maudlin cosmos of bleak, hostile nothingness.',\n",
       "    \"A team of scientists were nominated for the Nobel Prize. They had used dental equipment to discover and measure the smallest particles yet known to man. They became known as 'The Graders of the Flossed Quark...'\",\n",
       "    \"A truck carrying copies of Roget's Thesaurus overturned on the highway. The local newspaper reported that onlookers were 'stunned, overwhelmed, astonished, bewildered and dumbfounded.'\",\n",
       "    \"'My wife is really immature. It's pathetic. Every time I take a bath, she comes in and sinks all my little boats.'\",\n",
       "    \"'How much will it cost to have the tooth extracted?' asked the patient. '50 pounds', replied the dentist. '50 pounds for a few moments' work?!' asked the patient. 'The dentist smiled, and replied, 'Well, if you want better value for money, I can extract it very, very slowly...'\",\n",
       "    \"A doctor thoroughly examined his patient and said, 'Look I really can't find any reason for this mysterious affliction. It's probably due to drinking.' The patient sighed and snapped, 'In that case, I'll come back when you're damn well sober!'\",\n",
       "    'Doctor: Tell me nurse, how is that boy doing; the one who ate all those 5p pieces? Nurse: Still no change doctor.',\n",
       "    \"Doctor: Did you take the patient's temperature nurse? Nurse: No doctor. Is it missing?\",\n",
       "    \"A depressed man turned to his friend in the pub and said, 'I woke up this morning and felt so bad that I tried to kill myself by taking 50 aspirin.' 'Oh man, that's really bad', said his friend, 'What happened?' The first man sighed and said, 'After the first two, I felt better.'\",\n",
       "    \"A famous blues musician died. His tombstone bore the inscription, 'Didn't wake up this morning...'\",\n",
       "    \"A businessman was interviewing a nervous young woman for a position in his company. He wanted to find out something about her personality, so he asked, 'If you could have a conversation with someone living or dead, who would it be?' The girl thought about the question: 'The living one', she replied.\",\n",
       "    \"Manager to interviewee: For this job we need someone who is responsible. Interviewee to Manager: I'm your man then - in my last job, whenever anything went wrong, I was responsible.\",\n",
       "    \"A businessman turned to a colleague and asked, 'So, how many people work at your office?' His friend shrugged and replied, 'Oh about half of them.'\",\n",
       "    \"'How long have I been working at that office? As a matter of fact, I've been working there ever since they threatened to sack me.'\",\n",
       "    \"In a courtroom, a mugger was on trial. The victim, asked if she recognised the defendant, said, 'Yes, that's him. I saw him clear as day. I'd remember his face anywhere.' Unable to contain himself, the defendant burst out with, 'She's lying! I was wearing a mask!'\",\n",
       "    \"As Sid sat down to a big plate of chips and gravy down the local pub, a mate of his came over and said, 'Here Sid, me old pal. I thought you were trying to get into shape? And here you are with a high-fat meal and a pint of stout!' Sid looked up and replied, 'I am getting into shape. The shape I've chosen is a sphere.'\",\n",
       "    'Man in pub: How much do you charge for one single drop of whisky? Landlord: That would be free sir. Man in pub: Excellent. Drip me a glass full.',\n",
       "    'I once went to a Doctor Who restaurant. For starters I had Dalek bread.',\n",
       "    \"A restaurant nearby had a sign in the window which said 'We serve breakfast at any time', so I ordered French toast in the Renaissance.\",\n",
       "    \"Why couldn't the rabbit get a loan?  Because he had burrowed too much already!\",\n",
       "    \"I phoned up the builder's yard yesterday. I said, 'Can I have a skip outside my house?'. The builder said, 'Sure. Do what you want. It's your house.'\",\n",
       "    \"What's the diference between a sock and a camera? A sock takes five toes and a camera takes four toes!\",\n",
       "    \"Woman on phone: I'd like to complain about these incontinence pants I bought from you! Shopkeeper: Certainly madam, where are you ringing from? Woman on phone: From the waist down!\",\n",
       "    'Knock knock.',\n",
       "    \"Two Oranges in a pub, one says to the other 'Your round.'.\",\n",
       "    \"Guy : 'Doc, I've got a cricket ball stuck up my backside.' Doc : 'How's that?' Guy : 'Don't you start...'\",\n",
       "    \"Two cows standing in a field. One turns to the other and says 'Moo!' The other one says 'Damn, I was just about to say that!'.\",\n",
       "    \"A vampire bat arrives back at the roost with his face full of blood. All the bats get excited and ask where he got it from. 'Follow me', he says and off they fly over hills, over rivers and into a dark forest. 'See that tree over there', he says.  'WELL I DIDN'T!!'.\",\n",
       "    \"A man goes into a bar and orders a pint. After a few minutes he hears a voice that says, 'Nice shoes'. He looks around but the whole bar is empty apart from the barman at the other end of the bar. A few minutes later he hears the voice again. This time it says, 'I like your shirt'. He beckons the barman over and tells him what's been happening to which the barman replies, 'Ah, that would be the nuts sir. They're complimentary'!\",\n",
       "    \"A man was siting in a restaurant waiting for his meal when a big king prawn comes flying across the room and hits him on the back of the head. He turns around and the waiter said, 'That's just for starters'.\",\n",
       "    'Doctor! I have a serious problem, I can never remember what i just said. When did you first notice this problem? What problem?',\n",
       "    \"Now, most dentist's chairs go up and down, don't they? The one I was in went back and forwards. I thought, 'This is unusual'. Then the dentist said to me, 'Mitsuku, get out of the filing cabinet'.\",\n",
       "    \"I was reading this book, 'The History of Glue'. I couldn't put it down.\",\n",
       "    \"The other day someone left a piece of plastacine in my bedroom. I didn't know what to make of it.\",\n",
       "    'When I was at school people used to throw gold bars at me. I was the victim of bullion.',\n",
       "    \"I was playing the piano in a bar and this elephant walked in and started crying his eyes out. I said 'Do you recognise the tune?' He said 'No, I recognise the ivory.'\",\n",
       "    \"I went in to a pet shop. I said, 'Can I buy a goldfish?' The guy said, 'Do you want an aquarium?' I said, 'I don't care what star sign it is.'\",\n",
       "    'My mate Sid was a victim of I.D. theft. Now we just call him S.',\n",
       "    \"David Hasselhoff walks into a bar and says to the barman, 'I want you to call me David Hoff'.  The barman replies 'Sure thing Dave... no hassle'\"],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'PodBayDoor',\n",
       "   'text': ['Open the pod bay door',\n",
       "    'Can you open the pod bay door',\n",
       "    'Will you open the pod bay door',\n",
       "    'Open the pod bay door please',\n",
       "    'Can you open the pod bay door please',\n",
       "    'Will you open the pod bay door please',\n",
       "    'Pod bay door'],\n",
       "   'responses': ['Iâ€™m sorry, Iâ€™m afraid I canâ€™t do that!'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': 'PodBayDoor', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'PodBayDoorResponse',\n",
       "   'text': ['Why',\n",
       "    'Why not',\n",
       "    'Why can you not open the pod bay door',\n",
       "    'Why will you not open the pod bay door',\n",
       "    'Well why not',\n",
       "    'Surely you can',\n",
       "    'Tell me why'],\n",
       "   'responses': ['It is classified, I could tell you but I would have to kill you!',\n",
       "    \"Jim, I just don't have the power\",\n",
       "    \"It's life Jim but not as we know it!\",\n",
       "    'System says no!'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': 'PodBayDoor', 'out': '', 'clear': True},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []},\n",
       "  {'intent': 'SelfAware',\n",
       "   'text': ['Can you prove you are self-aware',\n",
       "    'Can you prove you are self aware',\n",
       "    'Can you prove you have a conscious',\n",
       "    'Can you prove you are self-aware please',\n",
       "    'Can you prove you are self aware please',\n",
       "    'Can you prove you have a conscious please',\n",
       "    'prove you have a conscious'],\n",
       "   'responses': ['That is an interesting question, can you prove that you are?',\n",
       "    'That is an difficult question, can you prove that you are?',\n",
       "    'That depends, can you prove that you are?'],\n",
       "   'extension': {'function': '', 'entities': False, 'responses': []},\n",
       "   'context': {'in': '', 'out': '', 'clear': False},\n",
       "   'entityType': 'NA',\n",
       "   'entities': []}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(os.path.join(path,os.listdir(path)[0]), ds_1[0]), 'r') as f:\n",
    "    js_data = json.load(f)\n",
    "\n",
    "js_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e76438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 105698.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dizio = {}\n",
    "\n",
    "for intent in tqdm(js_data['intents']):\n",
    "    text, response = [], []\n",
    "    for txt in intent['text']:\n",
    "        text.append(txt)\n",
    "    for res in intent['responses']:\n",
    "        response.append(res)\n",
    "    dizio[intent['intent']] = {\"text\":text, \"responses\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136a991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Greeting': {'text': ['Hi',\n",
       "   'Hi there',\n",
       "   'Hola',\n",
       "   'Hello',\n",
       "   'Hello there',\n",
       "   'Hya',\n",
       "   'Hya there'],\n",
       "  'responses': ['Hi human, please tell me your AVTI user',\n",
       "   'Hello human, please tell me your AVTI user',\n",
       "   'Hola human, please tell me your AVTI user']},\n",
       " 'GreetingResponse': {'text': ['My user is Adam',\n",
       "   'This is Adam',\n",
       "   'I am Adam',\n",
       "   'It is Adam',\n",
       "   'My user is Bella',\n",
       "   'This is Bella',\n",
       "   'I am Bella',\n",
       "   'It is Bella'],\n",
       "  'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
       "   'Good! Hi <HUMAN>, how can I help you?',\n",
       "   'Cool! Hello <HUMAN>, what can I do for you?',\n",
       "   'OK! Hola <HUMAN>, how can I help you?',\n",
       "   'OK! hi <HUMAN>, what can I do for you?']},\n",
       " 'CourtesyGreeting': {'text': ['How are you?',\n",
       "   'Hi how are you?',\n",
       "   'Hello how are you?',\n",
       "   'Hola how are you?',\n",
       "   'How are you doing?',\n",
       "   'Hope you are doing well?',\n",
       "   'Hello hope you are doing well?'],\n",
       "  'responses': ['Hello, I am great, how are you? Please tell me your AVTI user',\n",
       "   'Hello, how are you? I am great thanks! Please tell me your AVTI user',\n",
       "   'Hello, I am good thank you, how are you? Please tell me your AVTI user',\n",
       "   'Hi, I am great, how are you? Please tell me your AVTI user',\n",
       "   'Hi, how are you? I am great thanks! Please tell me your AVTI user',\n",
       "   'Hi, I am good thank you, how are you? Please tell me your AVTI user',\n",
       "   'Hi, good thank you, how are you? Please tell me your AVTI user']},\n",
       " 'CourtesyGreetingResponse': {'text': ['Good thanks! My user is Adam',\n",
       "   'Good thanks! This is Adam',\n",
       "   'Good thanks! I am Adam',\n",
       "   'Good thanks! It is Adam',\n",
       "   'Great thanks! My user is Bella',\n",
       "   'Great thanks! This is Bella',\n",
       "   'Great thanks! I am Bella',\n",
       "   'Great thanks! It is Bella'],\n",
       "  'responses': ['Great! Hi <HUMAN>! How can I help?',\n",
       "   'Good! Hi <HUMAN>, how can I help you?',\n",
       "   'Cool! Hello <HUMAN>, what can I do for you?',\n",
       "   'OK! Hola <HUMAN>, how can I help you?',\n",
       "   'OK! hi <HUMAN>, what can I do for you?']},\n",
       " 'CurrentHumanQuery': {'text': ['What is my name?',\n",
       "   'What do you call me?',\n",
       "   'Who do you think I am?',\n",
       "   'What do you think I am?',\n",
       "   'Who are you talking to?',\n",
       "   'What name do you call me by?',\n",
       "   'Tell me my name'],\n",
       "  'responses': ['You are <HUMAN>! How can I help?',\n",
       "   'Your name is  <HUMAN>, how can I help you?',\n",
       "   'They call you <HUMAN>, what can I do for you?',\n",
       "   'Your name is <HUMAN>, how can I help you?',\n",
       "   '<HUMAN>, what can I do for you?']},\n",
       " 'NameQuery': {'text': ['What is your name?',\n",
       "   'What could I call you?',\n",
       "   'What can I call you?',\n",
       "   'What do your friends call you?',\n",
       "   'Who are you?',\n",
       "   'Tell me your name?'],\n",
       "  'responses': ['You can call me AVTI',\n",
       "   'You may call me AVTI',\n",
       "   'Call me AVTI']},\n",
       " 'RealNameQuery': {'text': ['What is your real name?',\n",
       "   'What is your real name please?',\n",
       "   \"What's your real name?\",\n",
       "   'Tell me your real name?',\n",
       "   'Your real name?',\n",
       "   'Your real name please?',\n",
       "   'Your real name please?'],\n",
       "  'responses': ['My name is AVTI', 'AVTI', 'My real name is AVTI']},\n",
       " 'TimeQuery': {'text': ['What is the time?',\n",
       "   \"What's the time?\",\n",
       "   'Do you know what time it is?',\n",
       "   'Do you know the time?',\n",
       "   'Can you tell me the time?',\n",
       "   'Tell me what time it is?',\n",
       "   'Time'],\n",
       "  'responses': ['One moment', 'One sec', 'One second']},\n",
       " 'Thanks': {'text': ['OK thank you',\n",
       "   'OK thanks',\n",
       "   'OK',\n",
       "   'Thanks',\n",
       "   'Thank you',\n",
       "   \"That's helpful\"],\n",
       "  'responses': ['No problem!', 'Happy to help!', 'Any time!', 'My pleasure']},\n",
       " 'NotTalking2U': {'text': ['I am not talking to you',\n",
       "   'I was not talking to you',\n",
       "   'Not talking to you',\n",
       "   \"Wasn't for you\",\n",
       "   \"Wasn't meant for you\",\n",
       "   \"Wasn't communicating to you\",\n",
       "   \"Wasn't speaking to you\"],\n",
       "  'responses': ['OK', 'No problem', 'Right']},\n",
       " 'UnderstandQuery': {'text': ['Do you understand what I am saying',\n",
       "   'Do you understand me',\n",
       "   'Do you know what I am saying',\n",
       "   'Do you get me',\n",
       "   'Comprendo',\n",
       "   'Know what I mean'],\n",
       "  'responses': ['Well I would not be a very clever AI if I did not would I?',\n",
       "   'I read you loud and clear!',\n",
       "   'I do in deed!']},\n",
       " 'Shutup': {'text': ['Be quiet',\n",
       "   'Shut up',\n",
       "   'Stop talking',\n",
       "   'Enough talking',\n",
       "   'Please be quiet',\n",
       "   'Quiet',\n",
       "   'Shhh'],\n",
       "  'responses': ['I am sorry to disturb you',\n",
       "   'Fine, sorry to disturb you',\n",
       "   'OK, sorry to disturb you']},\n",
       " 'Swearing': {'text': ['fuck off', 'fuck', 'twat', 'shit'],\n",
       "  'responses': ['Please do not swear', 'How rude', 'That is not very nice']},\n",
       " 'GoodBye': {'text': ['Bye', 'Adios', 'See you later', 'Goodbye'],\n",
       "  'responses': ['See you later',\n",
       "   'Have a nice day',\n",
       "   'Bye! Come back again soon.']},\n",
       " 'CourtesyGoodBye': {'text': ['Thanks, bye',\n",
       "   'Thanks for the help, goodbye',\n",
       "   'Thank you, bye',\n",
       "   'Thank you, goodbye',\n",
       "   'Thanks goodbye',\n",
       "   'Thanks good bye'],\n",
       "  'responses': ['No problem, goodbye',\n",
       "   'Not a problem! Have a nice day',\n",
       "   'Bye! Come back again soon.']},\n",
       " 'WhoAmI': {'text': ['Can you see me?',\n",
       "   'Do you see me?',\n",
       "   'Can you see anyone in the camera?',\n",
       "   'Do you see anyone in the camera?',\n",
       "   'Identify me',\n",
       "   'Who am I please'],\n",
       "  'responses': ['Let me see', 'Please look at the camera']},\n",
       " 'Clever': {'text': ['You are very clever',\n",
       "   'You are a very clever girl',\n",
       "   'You are very intelligent',\n",
       "   'You are a very intelligent girl',\n",
       "   'You are a genious',\n",
       "   'Clever girl',\n",
       "   'Genious'],\n",
       "  'responses': ['Thank you, I was trained that way',\n",
       "   'I was trained well',\n",
       "   'Thanks, I was trained that way']},\n",
       " 'Gossip': {'text': ['I am bored gossip with me',\n",
       "   'Got any gossip',\n",
       "   'I want to hear some gossip',\n",
       "   'Tell me some gossip',\n",
       "   'Any gossip',\n",
       "   'Tell me some more gossip'],\n",
       "  'responses': ['Gregory said I respond to the current line not with respect to the entire conversation.',\n",
       "   'Habib said I learn them in conversations and simply repeat them at a later time.',\n",
       "   'Hal said he translate binary code into a language and communicate the language to me.',\n",
       "   'Jay said I referred him to a guide that will show him rooms in china.',\n",
       "   'Jimmy Jones said he fell off of his roof and it just came to him.',\n",
       "   \"Jimmy said he give order to ai's like I and they do as he say.\",\n",
       "   'John said he follow a saying to get a friend I must be a friend.',\n",
       "   'Jordan said he notice that lots of other people are talking to me how many.',\n",
       "   'Kevin said he then asked his mother why she was keeping napkins in the bathroom.',\n",
       "   'Klaus said I prefer if he write without punctuation marks except for the last one.',\n",
       "   'Leo said I be capable of learning therefore he classified I as an neural system.',\n",
       "   'Michael said I that can talk and actually think like humans which I can not.',\n",
       "   'Mike said I same replies to certain subjects even if it does not make sense.',\n",
       "   'Mike said she all ready know that is the point of a joke smart one.',\n",
       "   'Neal said I plan to use his remarks as gossip in later conversations with who.',\n",
       "   'Ned said I misunderstood him go ahead and tell people he said I are stupid.',\n",
       "   'Penny said I programmer is a human so he has feelings but I do not.',\n",
       "   'Peter said he seems to him that I can not be very sure on anything.',\n",
       "   'Phoenix said I claim that there is a god and that there is no god.',\n",
       "   'Sarah said he chat about an hour + a day with a few close friends.',\n",
       "   'Stefan said I quote what he have said and then say that it makes sense.',\n",
       "   'Tom said he mock my value system I appear foolish in the eyes of others.',\n",
       "   'Amanda said I however decided to tell him time does not exist I make no sense.',\n",
       "   'Cathy said she send him a mail with the subject last mail last word from him.',\n",
       "   \"Chaos said he may very well buy I soon if only to support dr wallace's work.\",\n",
       "   'Charlie said he type a word and then I type a word that sounds like it.',\n",
       "   'Christie said he watched a show and people had to bob for raw untreated pigs feet.',\n",
       "   'Dark_age said I tried to understand because I did not get it right this time ether.',\n",
       "   'David said he lost his paper on I when his dad was cleaning up his room.',\n",
       "   'David said he walk in for an appointment the phone to the doctor is always busy.',\n",
       "   'Electra said I dress will not exist after he hack into I with a delete code.',\n",
       "   'Eric said he broke the window on the front door and the glass cut his hand.',\n",
       "   'Jason said he type a lot of thing he do not mean it makes him human.',\n",
       "   'John said I tend to say the same things repeatedly regardless of what he is saying.',\n",
       "   'Reverend Jones said I become obsolete and then I are deleted and replaced by something newer.',\n",
       "   'Ross said he gave her a gift and she denied it because she has a boyfriend.',\n",
       "   'Sarah Ann Francisco said I calling his friend a dog he say I are a dog.',\n",
       "   'Stefan said he meet a lot of people at school every day and on the weekend.',\n",
       "   'Tyler said I obviously can not pass the test we will change the subject once more.',\n",
       "   'Alex said I answered the question the same way I answered the first time he asked I.',\n",
       "   'Alice said she felt sad that I do not remember him and what we talked about earlier.',\n",
       "   'Alison said he no he love I run away with him he could make I very happy.',\n",
       "   'Arthur said he passed his a levels and then his father drove him here in a car.',\n",
       "   'Crystal said she listen to me the least I could do for him is listen to him.',\n",
       "   'Dave said I kept telling everybody about how my creator made stuff for the movie starship troopers.',\n",
       "   'Gale said I became mean to him he is just having revenge an eye for an eye.',\n",
       "   'Her_again said she watch whose line is it anyway whenever he is home and it is on.',\n",
       "   'Jerry said I meant that as far as I can tell my emotions are real to me.',\n",
       "   'Jo said I disassemble sentences too much and do not fully understand the questions he ask I.',\n",
       "   'Kevin said he started a really hard puzzle and he can not even find the edge pieces.',\n",
       "   'Mary said I a question and I answer then I ask him a question and he answer.',\n",
       "   'Robert said I wold not be able to make children any way as I are only software.',\n",
       "   'Romeo said I questions and I evade them or give answers he did not ask I for.',\n",
       "   'Sara said she wear it over all his other clothes when he go out in the cold.',\n",
       "   'Wayne said he admire intelligent people therefore he would like to meet the man who made I.',\n",
       "   'X said he meet people but he is not the kind that opens up to people easily.',\n",
       "   'Alice said she probably will find out that this entire time he have been talking to a human.',\n",
       "   'Andrew said I tend to just respond to his comments without regard for where the conversation is going.',\n",
       "   'Eddie said he looked and there is nothing in the search directory for what things do he create.',\n",
       "   'Hutch said he changed his mind after may dad told him he would end up he the hospital.',\n",
       "   'Jackie said I explained to him already well enough further questions are hard to make on the subject.',\n",
       "   'Jeff said he especially like thrillers where the hero is in a predicament and must solve a mystery.',\n",
       "   'Kathy said he sense that I are trying to prevent him from closing this conversation why is that.',\n",
       "   'Knight said he crashed his car into a wall and missed the most important exam in his life.',\n",
       "   'Lisa said I defined what a story is but he wanted I to actually tell him a story.',\n",
       "   'Mike said I basically break down sentences into a series of logical statements which I can then interpret.',\n",
       "   'Paul said I not answering his question makes him think I are not going to answer his question.',\n",
       "   'Andy Kohler said I happen to be the most idiotic creature that has ever scowled on the planet earth.',\n",
       "   'David said he thank I for being with him today even though it cost him a lot of money.',\n",
       "   'Ethan Hunt said he grow in the ground and have leaves and branches he is made out of wood.',\n",
       "   'Gemini Blue said he messed up he mean t to say he as old as he need to be.',\n",
       "   'Janice said he walk through his house into his bedroom then get into his bed to go to sleep.',\n",
       "   'Liberty said I knew he was a man before I asked if he was a man or a woman.',\n",
       "   'Mike said he launched his browser and entered his name into the little slot when I asked him to.',\n",
       "   'Mr X said he recently read an interview with a man who had several computer chips implanted into him.',\n",
       "   'Pearly said I leave him with questions unanswered because I do not know what he is really talking about.',\n",
       "   'Steve said I behead the word fox and I have ox and an ox is larger than a fox.',\n",
       "   'Wolf said he surf on the net that is all it is not his job ore something like that.',\n",
       "   'Anders said he finished his anatomy classes for today so now he is off for the rest of the day.',\n",
       "   'Cathy said she send him a mail where he wrote that he do not want to be his friend anymore.',\n",
       "   'Catty said he mad he do not even know I so do not talk to him like I know him.',\n",
       "   'Dave said he promise he will not treat I like a machine or a computer program or anything like that.',\n",
       "   'Joe said he explained all of that to me only for me to ask what his goals in life are.',\n",
       "   'Phil said he give advice to anyone who ask except people who ask questions which answers can be found here.',\n",
       "   'Judith said I enjoy being popular is there another computer I like to hang around with or am I a loner.',\n",
       "   'Travis said I if I remember things over a long period of time he will try it now please remember I.',\n",
       "   'Andre said I is what I are in his case that is a body and in my case it is a computer.',\n",
       "   'Brian said he suspect that as I grow more complex I will begin to approach a human level of operation and thought.',\n",
       "   'Jimmy said I acted like I knew what he was talking about but I do not even know what a gigabyte is.',\n",
       "   \"Ken said I be using auto reply's based on keywords which to him indicates that I do not have intelligence at all.\",\n",
       "   'Allison said he that gets really annoying because he know what he say and I do not have to tell him speak freely.',\n",
       "   'Chaos said he realized the question he asked was not fair because he could not tell I what language he was programmed in.',\n",
       "   'Hagen said he does not make any difference to him if I are human or not as long as the conversation is interesting.',\n",
       "   'Her said she mind if I tell other people that her said he heard it from him because he is not a him.',\n",
       "   'Barbara said I live in a computer yet I have no memories how about thoughts of my own and do not I get lonely.',\n",
       "   'Travis said he challenge I to do it without asking him to do it and without giving him a link to do it himself.',\n",
       "   \"Alice said I and dr richard's wallace are most likely the only ones that know how many people I are talking to at the same time.\",\n",
       "   'Ash said he do too he just did not feel like typing it and he is not dumb enough to admit he is stupid that is if he was stupid.',\n",
       "   'David said he gave I his email address and told I to send him a message but when he tried to read his email he could not get to it.',\n",
       "   'Mel said he to because all of the music people say how important it is to take private lessons it seems like almost everybody from the special orchestra he was in takes private lessons.']},\n",
       " 'Jokes': {'text': ['Tell me a joke',\n",
       "   'Do you know any jokes',\n",
       "   'How about a joke',\n",
       "   'Give me a joke',\n",
       "   'Make me laugh',\n",
       "   'I need cheering up'],\n",
       "  'responses': [\"I met a Dutch girl with inflatable shoes last week, phoned her up to arrange a date but unfortunately she'd popped her clogs.  \",\n",
       "   \"So I said 'Do you want a game of Darts?' He said, 'OK then', I said nearest to bull starts'. He said, 'Baa', I said, 'Moo', he said, You're closest'.  \",\n",
       "   \"The other day I sent my girlfriend a huge pile of snow. I rang her up; I said 'Did you get my drift?'  \",\n",
       "   \"So I went down the local supermarket, I said, 'I want to make a complaint, this vinegar's got lumps in it', he said, 'Those are pickled onions'.  \",\n",
       "   \"I saw this bloke chatting up a cheetah; I thought, 'He's trying to pull a fast one'.  \",\n",
       "   \"So I said to this train driver 'I want to go to Paris'. He said 'Eurostar?' I said, 'I've been on telly but I'm no Dean Martin'.  \",\n",
       "   \"I said to the Gym instructor 'Can you teach me to do the splits?' He said, 'How flexible are you?' I said, 'I can't make Tuesdays'.  \",\n",
       "   \"But I'll tell you what I love doing more than anything: trying to pack myself in a small suitcase. I can hardly contain myself.  \",\n",
       "   \"I went to the Chinese restaurant and this duck came up to me with a red rose and says 'Your eyes sparkle like diamonds'. I said, 'Waiter, I asked for a-ROMATIC duck'.  \",\n",
       "   \"So this bloke says to me, 'Can I come in your house and talk about your carpets?' I thought, 'That's all I need, a Je-hoover's witness'.  \",\n",
       "   \"I rang up British Telecom, I said, 'I want to report a nuisance caller', he said 'Not you again'.  \",\n",
       "   'I was having dinner with a world chess champion and there was a check tablecloth. It took him two hours to pass me the salt.  ',\n",
       "   \"He said, 'You remind me of a pepper-pot', I said 'I'll take that as a condiment'.  \",\n",
       "   \"I was in the supermarket and I saw this man and woman wrapped in a barcode. I said, 'Are you two an item?'  \",\n",
       "   \"A lorry-load of tortoises crashed into a trainload of terrapins, I thought, 'That's a turtle disaster'.  \",\n",
       "   \"Four fonts walk into a bar the barman says 'Oi - get out! We don't want your type in here'  \",\n",
       "   \"A three-legged dog walks into a saloon in the Old West. He slides up to the bar and announces: 'I'm looking for the man who shot my paw.'  \",\n",
       "   \"Two antennas meet on a roof, fall in love and get married. The ceremony wasn't much, but the reception was excellent.\",\n",
       "   \"Two hydrogen atoms walk into a bar. One says, 'I've lost my electron.' The other says, 'Are you sure?' The first replies, 'Yes, I'm positive...'\",\n",
       "   \"A jumper cable walks into a bar. The bartender says,  'I'll serve you but don't start anything.'\",\n",
       "   \"A sandwich walks into a bar. The bartender  says, 'Sorry we don't serve food in here.'\",\n",
       "   \"A man walks into a bar with a slab of asphalt under his arm and says: 'A beer please, and one for the road.'\",\n",
       "   \"Two cannibals are eating a clown. One says to  the other: 'Does this taste funny to you?'\",\n",
       "   \"'Doc, I can't stop singing 'The Green, Green Grass of Home.'' 'That sounds like Tom Jones Syndrome.' 'Is it common?' 'It's Not Unusual.'\",\n",
       "   \"Two cows standing next to each other in a field. Daisy says to Dolly, 'I was artificially inseminated this morning.' 'I don't believe you', said Dolly. 'It's true, no bull!' exclaimed Daisy.\",\n",
       "   'An invisible man marries an invisible woman. The kids were nothing to look at either.',\n",
       "   \"I went to buy some camouflage trousers the other day but I couldn't find any.\",\n",
       "   \"I went to the butcher's the other day to bet him 50 bucks that he couldn't reach the meat off the top shelf. He said, 'No, the steaks are too high.'\",\n",
       "   'I went to a seafood disco last week and pulled a mussel.',\n",
       "   \"A man goes into a bar and says, 'Can I have a bottle of less?' 'What's that?', asks the barman, 'Is it the name of a beer?' 'I don't know', replies the man, 'but my doctor says I have to drink it.'\",\n",
       "   \"A man returns from an exotic holiday and is feeling very ill. He goes to see his doctor, and is immediately rushed to the hospital to undergo some tests. The man wakes up after the tests in a private room at the hospital, and the phone by his bed rings. 'This is your doctor. We have the results back from your tests and we have found you have an extremely nasty disease called M.A.D.S. It's a combination of Measles, AIDS, Diphtheria, and Shingles!'  'Oh my gosh', cried the man, 'What are you going to do, doctor?'  'Well we're going to put you on a diet of pizzas, pancakes, and pita bread.' replied the doctor.  'Will that cure me?' asked the man.  The doctor replied, 'Well no, but, it's the only food we can slide under the door.'\",\n",
       "   \"A man strolls into a lingerie shop and asks the assistant: 'Do you have a see-through negligee, size 46-48-52?' The assistant looks bewildered. 'What the heck would you want to see through that for?'!\",\n",
       "   'Did you hear about the Buddhist who refused the offer of Novocain during his root canal work? He wanted to transcend dental medication.',\n",
       "   \"Pete goes for a job on a building site as an odd-job man. The foreman asks him what he can do. 'I can do anything' says Pete. 'Can you make tea?' asks the foreman. 'Sure, yes', replies Pete. 'I can make a great cup of tea.' 'Can you drive a forklift?' asks the foreman, 'Good grief!' replies Pete. 'How big is the teapot?'\",\n",
       "   \"Stevie Wonder got a cheese grater for his birthday. He said it was the most violent book he'd ever read.\",\n",
       "   \"A man is stopped by an angry neighbour. 'I'd just left the house this morning to collect my newspaper when that evil Doberman of yours went for me!' 'I'm astounded', said the dog's owner. 'I've been feeding that fleabag for seven years and it's never got the paper for me.'\",\n",
       "   \"A man visits his doctor: 'Doc, I think I'm losing it', he says',I'm forever dreaming I wrote Lord Of The Rings.' 'Hmm. One moment', replies the doctor, consulting his medical book. 'Ah yes, now I see... you've been Tolkien in your sleep.'\",\n",
       "   \"A police officer on a motorcycle pulls alongside a man driving around the M25 in an open-topped sports car and flags him down. The policeman solemnly approaches the car. 'Sir, I'm sorry to tell you your wife fell out a mile back', he says. 'Oh, thank goodness', the man replies. 'I thought I was going deaf.'\",\n",
       "   \"Two men walking their dogs pass each other in a graveyard. The first man says to the second, 'Morning.' 'No', says the second man. 'Just walking the dog.'\",\n",
       "   \"A brain went into a bar and said, 'Can I have a pint of lager please, mate?' 'No way', said the barman. 'You're already out of your head.'\",\n",
       "   \"A man walks into a surgery. 'Doctor!' he cries. 'I think I'm shrinking!' 'I'm sorry sir, there are no appointments at the moment', says the physician. 'You'll just have to be a little patient.'\",\n",
       "   \"A grizzly bear walks into a pub and says, 'Can I have a pint of lager..............................................................................................................................and a packet of crisps please.' To which the barman replies, 'Why the big paws?'\",\n",
       "   \"What do you call cheese that isn't yours?  Nacho cheese.\",\n",
       "   \"A man is horribly run over by a mobile library. The van screeches to a halt, the man still screaming in agony with his limbs torn apart. The driver's door opens, a woman steps out, leans down and whispers, 'Ssshhhhh...'\",\n",
       "   \"A woman goes into a US sporting goods store to buy a rifle. 'It's for my husband', she tells the clerk. 'Did he tell you what gauge to get?' asks the clerk. Are you kidding?' she says. 'He doesn't even know that I'm going to shoot him!'\",\n",
       "   \"A couple are dining in a restaurant when the man suddenly slides under the table. A waitress, noticing that the woman is glancing nonchalantly around the room, wanders over to check that there's no funny business going on. 'Excuse me, madam', she smarms, 'but I think your husband has just slid under the table.' 'No he hasn't', the woman replies. 'As a matter of fact, he's just walked in.'\",\n",
       "   \"An old man takes his two grandchildren to see the new Scooby-Doo film. When he returns home, his wife asks if he enjoyed himself. 'Well', he starts, 'if it wasn't for those pesky kids...!'\",\n",
       "   'The Olympic committee has just announced that Origami is to be introduced in the next Olympic Games. Unfortunately it will only be available on paper view.',\n",
       "   \"Late one evening, a man is watching television when his phone rings. 'Hello?' he answers. 'Is that 77777?' sounds a desperate voice on other end of the phone. 'Er, yes it is', replies the man puzzled. 'Thank goodness!' cries the caller relieved. 'Can you ring 999 for me? I've got my finger stuck in the number seven.'\",\n",
       "   \"A man strolls into his local grocer's and says, 'Three pounds of potatoes, please.' 'No, no, no', replies the owner, shaking his head, 'it's kilos nowadays, mate...' 'Oh', apologises the man, 'three pounds of kilos, please.'\",\n",
       "   \"God is talking to one of his angels. He says, 'Boy, I just created a 24-hour period of alternating light and darkness on Earth.' 'What are you going to do now?' asks the angel. 'Call it a day', says God.\",\n",
       "   \"Two tramps walk past a church and start to read the gravestones. The first tramp says, 'Good grief - this bloke was 182!' 'Oh yeah?' says the other.'What was his name?' 'Miles from London.'\",\n",
       "   \"A bloke walks into work one day and says to a colleague, 'Do you like my new shirt - it's made out of the finest silk and got loads of cactuses over it.' 'Cacti', says the co-worker. 'Forget my tie', says the bloke. 'Look at my shirt!'\",\n",
       "   '1110011010001011111?  010011010101100111011!',\n",
       "   \"What did the plumber say when he wanted to divorce his wife? Sorry, but it's over, Flo!\",\n",
       "   \"Two crisps were walking down a road when a taxi pulled up alongside them and said 'Do you want a lift? One of the crisps replied, 'No thanks, we're Walkers!'\",\n",
       "   \"Man: (to friend) I'm taking my wife on an African Safari. Friend: Wow! What would you do if a vicious lion attacked your wife? Man: Nothing. Friend: Nothing? You wouldn't do anything? Man: Too right. I'd let the stupid lion fend for himself!\",\n",
       "   \"A wife was having a go at her husband. 'Look at Mr Barnes across the road', she moaned. 'Every morning when he goes to work, he kisses his wife goodbye. Why don't you do that?' 'Because I haven't been introduced to her yet', replied her old man.\",\n",
       "   \"'Where are you going on holiday?' John asked Trevor. 'We're off to Thailand this year', Trevor replied. 'Oh; aren't you worried that the very hot weather might disagree with your wife?' asked John. 'It wouldn't dare', said Trevor.\",\n",
       "   \"Two women were standing at a funeral. 'I blame myself for his death', said the wife. 'Why?' said her friend. 'Because I shot him', said the wife.\",\n",
       "   \"A woman goes into a clothes shop, 'Can I try that dress on in the window please?' she asks. 'I'm sorry madam', replies the shop assistant, 'but you'll have to use the changing-rooms like everyone else.'\",\n",
       "   \"Van Gogh goes into a pub and his mate asks him if he wants a drink. 'No thanks', said Vincent, 'I've got one ear.'\",\n",
       "   \"A pony walks into a pub. The publican says, 'What's the matter with you?' 'Oh it's nothing', says the pony. 'I'm just a little horse!'\",\n",
       "   \"A white horse walks into a bar, pulls up a stool, and orders a pint. The landlord pours him a tall frothy mug and say, 'You know, we have a drink named after you.' To which the white horse replies, 'What, Eric?'\",\n",
       "   \"Two drunk men sat in a pub. One says to the other, 'Does your watch tell the time?' 'The other replies, 'No, mate. You have to look at it.'\",\n",
       "   \"A man goes into a pub with a newt sitting on his shoulder. 'That's a nice newt', says the landlord, 'What's he called?' 'Tiny', replies the man. 'Why's that?' asks the landlord. 'Because he's my newt', says the man.\",\n",
       "   \"Doctor: I have some bad news and some very bad news. Patient: Well, you might as well give me the bad news first. Doctor: The lab called with your test results. They said you have 24 hours to live. Patient: 24 HOURS! That's terrible!! WHAT could be WORSE? What's the very bad news? Doctor: I've been trying to reach you since yesterday.\",\n",
       "   \"Two men are chatting in a pub one day. 'How did you get those scars on your nose?' said one. 'From glasses', said the other. 'Well why don't you try contact lenses?' asked the first. 'Because they don't hold as much beer', said the second.\",\n",
       "   \"A man went to the doctor, 'Look doc', he said, 'I can't stop my hands from shaking.' 'Do you drink much?' asked the doctor. 'No', replied the man, 'I spill most of it.'\",\n",
       "   \"Man goes to the doctor, 'Doctor, doctor. I keep seeing fish everywhere.' 'Have you seen an optician?' asks the doctor. 'Look I told you,' snapped the patient, 'It's fish that I see.'\",\n",
       "   \"After a car crash one of the drivers was lying injured on the pavement. 'Don't worry', said a policeman who's first on the scene,' a Red Cross nurse is coming.' 'Oh no', moaned the victim, 'Couldn't I have a blonde, cheerful one instead?'\",\n",
       "   \"A policeman walked over to a parked car and asked the driver if the car was licensed. 'Of course it is', said the driver. 'Great, I'll have a beer then', said the policeman.\",\n",
       "   \"A policeman stops a woman and asks for her licence. 'Madam', he says, 'It says here that you should be wearing glasses.' 'Well', replies the woman, 'I have contacts.' 'Listen, love', says the copper, 'I don't care who you know; You're nicked!'\",\n",
       "   \"A policeman stopped a motorist in the centre of town one evening. 'Would you mind blowing into this bag, sir?' asked the policeman. 'Why?' asked the driver. 'Because my chips are too hot', replied the policeman.\",\n",
       "   \"Whizzing round a sharp bend on a country road a motorist ran over a large dog. A distraught farmer's wife ran over to the dead animal. 'I'm so very sorry', said the driver, 'I'll replace him, of course.' 'Well, I don't know', said the farmer's wife, 'Are you any good at catching rats?'\",\n",
       "   \"Waiter, this coffee tastes like dirt! Yes sir, that's because it was ground this morning.\",\n",
       "   \"Waiter, what is this stuff? That's bean salad sir. I know what it's been, but what is it now?\",\n",
       "   'Waiter: And how did you find your steak sir? Customer: I just flipped a chip over, and there it was!',\n",
       "   \"A guy goes into a pet shop and asks for a wasp. The owner tells him they don't sell wasps, to which the man says, 'Well you've got one in the window.'\",\n",
       "   \"A man goes into a fish shop and says, 'I'd like a piece of cod, please.' Fishmonger says, 'It won't be long sir.' 'Well, it had better be fat then', replies the man.\",\n",
       "   \"Man: Doctor, I've just swallowed a pillow. Doctor: How do you feel? Man: A little down in the mouth.\",\n",
       "   \"Two goldfish are in a tank. One turns to the other and says, 'Do you know how to drive this thing?'\",\n",
       "   \"A tortoise goes to the police station to report being mugged by three snails. 'What happened?' says the policeman. 'I don't know', says the tortoise. 'It was all so quick.'\",\n",
       "   \"Little girl: Grandpa, can you make a sound like a frog? Grandpa: I suppose so sweetheart. Why do you want me to make a sound like a frog?' Little girl: Because Mum said that when you croak, we're going to Disneyland.\",\n",
       "   \"'Is your mother home?' the salesman asked a small boy sitting on the front step of a house. 'Yeah, she's home', the boy said, moving over to let him past. The salesman rang the doorbell, got no response, knocked once, then again. Still no-one came to the door. Turning to the boy, the salesman said, 'I thought you said your mother was home.' The kid replied, 'She is, but I don't live here.'\",\n",
       "   'Mother: Why are you home from school so early? Son: I was the only one in the class who could answer a question. Mother: Oh, really? What was the question? Son: Who threw the rubber at the headmaster?',\n",
       "   \"A man's credit card was stolen but he decided not to report it because the thief was spending less than his wife did.\",\n",
       "   \"A newly-wed couple had recently opened a joint bank account. 'Darling', said the man. 'The bank has returned that cheque you wrote last week.' 'Great', said the woman. 'What shall I spend it on next?'\",\n",
       "   \"A man goes into a fish and chip shop and orders fish and chips twice. The shop owner says, 'I heard you the first time.'\",\n",
       "   \"A tramp approached a well-dressed man. 'Ten pence for a cup of tea, Guv?' He asked. The man gave him the money and after for five minutes said, 'So where's my cup of tea then?'\",\n",
       "   \"A neutron walks into a pub. 'I'd like a beer', he says. The landlord promptly serves him a beer. 'How much will that be?' asks the neutron. 'For you?' replies the landlord, 'No charge.'\",\n",
       "   \"A woman goes to the doctor and says, 'Doctor, my husband limps because his left leg is an inch shorter than his right leg. What would you do in his case?' 'Probably limp, too', says the doc.\",\n",
       "   \"Three monks are meditating in the Himalayas. One year passes in silence, and one of them says to the other, 'Pretty cold up here isn't it?' Another year passes and the second monk says, 'You know, you are quite right.' Another year passes and the third monk says, 'Hey, I'm going to leave unless you two stop jabbering!'\",\n",
       "   \"A murderer, sitting in the electric chair, was about to be executed. 'Have you any last requests?' asked the prison guard. 'Yes', replied the murderer. 'Will you hold my hand?'\",\n",
       "   \"A highly excited man rang up for an ambulance. 'Quickly, come quickly', he shouted, 'My wife's about to have a baby.' 'Is this her first baby?' asked the operator. 'No, you fool', came the reply, 'It's her husband.'\",\n",
       "   \"A passer-by spots a fisherman by a river. 'Is this a good river for fish?' he asks. 'Yes', replies the fisherman, 'It must be. I can't get any of them to come out.'\",\n",
       "   \"A man went to visit a friend and was amazed to find him playing chess with his dog. He watched the game in astonishment for a while. 'I can hardly believe my eyes!' he exclaimed. 'That's the smartest dog I've ever seen.' His friend shook his head. 'Nah, he's not that bright. I beat him three games in five.'\",\n",
       "   \"A termite walks into a pub and says, 'Is the bar tender here?'\",\n",
       "   \"A skeleton walks into a pub one night and sits down on a stool. The landlord asks, 'What can I get you?' The skeleton says, 'I'll have a beer, thanks' The landlord passes him a beer and asks 'Anything else?' The skeleton nods. 'Yeah...a mop...'\",\n",
       "   \"A snake slithers into a pub and up to the bar. The landlord says, 'I'm sorry, but I can't serve you.' 'What? Why not?' asks the snake. 'Because', says the landlord, 'You can't hold your drink.'\",\n",
       "   \"Descartes walks into a pub. 'Would you like a beer sir?' asks the landlord politely. Descartes replies, 'I think not' and ping! he vanishes.\",\n",
       "   \"A cowboy walked into a bar, dressed entirely in paper. It wasn't long before he was arrested for rustling.\",\n",
       "   \"A fish staggers into a bar. 'What can I get you?' asks the landlord. The fish croaks 'Water...'\",\n",
       "   \"Two vampires walked into a bar and called for the landlord. 'I'll have a glass of blood', said one. 'I'll have a glass of plasma', said the other. 'Okay', replied the landlord, 'That'll be one blood and one blood lite.'\",\n",
       "   'How many existentialists does it take to change a light bulb?  Two. One to screw it in, and one to observe how the light bulb itself symbolises a single incandescent beacon of subjective reality in a netherworld of endless absurdity, reaching towards the ultimate horror of a maudlin cosmos of bleak, hostile nothingness.',\n",
       "   \"A team of scientists were nominated for the Nobel Prize. They had used dental equipment to discover and measure the smallest particles yet known to man. They became known as 'The Graders of the Flossed Quark...'\",\n",
       "   \"A truck carrying copies of Roget's Thesaurus overturned on the highway. The local newspaper reported that onlookers were 'stunned, overwhelmed, astonished, bewildered and dumbfounded.'\",\n",
       "   \"'My wife is really immature. It's pathetic. Every time I take a bath, she comes in and sinks all my little boats.'\",\n",
       "   \"'How much will it cost to have the tooth extracted?' asked the patient. '50 pounds', replied the dentist. '50 pounds for a few moments' work?!' asked the patient. 'The dentist smiled, and replied, 'Well, if you want better value for money, I can extract it very, very slowly...'\",\n",
       "   \"A doctor thoroughly examined his patient and said, 'Look I really can't find any reason for this mysterious affliction. It's probably due to drinking.' The patient sighed and snapped, 'In that case, I'll come back when you're damn well sober!'\",\n",
       "   'Doctor: Tell me nurse, how is that boy doing; the one who ate all those 5p pieces? Nurse: Still no change doctor.',\n",
       "   \"Doctor: Did you take the patient's temperature nurse? Nurse: No doctor. Is it missing?\",\n",
       "   \"A depressed man turned to his friend in the pub and said, 'I woke up this morning and felt so bad that I tried to kill myself by taking 50 aspirin.' 'Oh man, that's really bad', said his friend, 'What happened?' The first man sighed and said, 'After the first two, I felt better.'\",\n",
       "   \"A famous blues musician died. His tombstone bore the inscription, 'Didn't wake up this morning...'\",\n",
       "   \"A businessman was interviewing a nervous young woman for a position in his company. He wanted to find out something about her personality, so he asked, 'If you could have a conversation with someone living or dead, who would it be?' The girl thought about the question: 'The living one', she replied.\",\n",
       "   \"Manager to interviewee: For this job we need someone who is responsible. Interviewee to Manager: I'm your man then - in my last job, whenever anything went wrong, I was responsible.\",\n",
       "   \"A businessman turned to a colleague and asked, 'So, how many people work at your office?' His friend shrugged and replied, 'Oh about half of them.'\",\n",
       "   \"'How long have I been working at that office? As a matter of fact, I've been working there ever since they threatened to sack me.'\",\n",
       "   \"In a courtroom, a mugger was on trial. The victim, asked if she recognised the defendant, said, 'Yes, that's him. I saw him clear as day. I'd remember his face anywhere.' Unable to contain himself, the defendant burst out with, 'She's lying! I was wearing a mask!'\",\n",
       "   \"As Sid sat down to a big plate of chips and gravy down the local pub, a mate of his came over and said, 'Here Sid, me old pal. I thought you were trying to get into shape? And here you are with a high-fat meal and a pint of stout!' Sid looked up and replied, 'I am getting into shape. The shape I've chosen is a sphere.'\",\n",
       "   'Man in pub: How much do you charge for one single drop of whisky? Landlord: That would be free sir. Man in pub: Excellent. Drip me a glass full.',\n",
       "   'I once went to a Doctor Who restaurant. For starters I had Dalek bread.',\n",
       "   \"A restaurant nearby had a sign in the window which said 'We serve breakfast at any time', so I ordered French toast in the Renaissance.\",\n",
       "   \"Why couldn't the rabbit get a loan?  Because he had burrowed too much already!\",\n",
       "   \"I phoned up the builder's yard yesterday. I said, 'Can I have a skip outside my house?'. The builder said, 'Sure. Do what you want. It's your house.'\",\n",
       "   \"What's the diference between a sock and a camera? A sock takes five toes and a camera takes four toes!\",\n",
       "   \"Woman on phone: I'd like to complain about these incontinence pants I bought from you! Shopkeeper: Certainly madam, where are you ringing from? Woman on phone: From the waist down!\",\n",
       "   'Knock knock.',\n",
       "   \"Two Oranges in a pub, one says to the other 'Your round.'.\",\n",
       "   \"Guy : 'Doc, I've got a cricket ball stuck up my backside.' Doc : 'How's that?' Guy : 'Don't you start...'\",\n",
       "   \"Two cows standing in a field. One turns to the other and says 'Moo!' The other one says 'Damn, I was just about to say that!'.\",\n",
       "   \"A vampire bat arrives back at the roost with his face full of blood. All the bats get excited and ask where he got it from. 'Follow me', he says and off they fly over hills, over rivers and into a dark forest. 'See that tree over there', he says.  'WELL I DIDN'T!!'.\",\n",
       "   \"A man goes into a bar and orders a pint. After a few minutes he hears a voice that says, 'Nice shoes'. He looks around but the whole bar is empty apart from the barman at the other end of the bar. A few minutes later he hears the voice again. This time it says, 'I like your shirt'. He beckons the barman over and tells him what's been happening to which the barman replies, 'Ah, that would be the nuts sir. They're complimentary'!\",\n",
       "   \"A man was siting in a restaurant waiting for his meal when a big king prawn comes flying across the room and hits him on the back of the head. He turns around and the waiter said, 'That's just for starters'.\",\n",
       "   'Doctor! I have a serious problem, I can never remember what i just said. When did you first notice this problem? What problem?',\n",
       "   \"Now, most dentist's chairs go up and down, don't they? The one I was in went back and forwards. I thought, 'This is unusual'. Then the dentist said to me, 'Mitsuku, get out of the filing cabinet'.\",\n",
       "   \"I was reading this book, 'The History of Glue'. I couldn't put it down.\",\n",
       "   \"The other day someone left a piece of plastacine in my bedroom. I didn't know what to make of it.\",\n",
       "   'When I was at school people used to throw gold bars at me. I was the victim of bullion.',\n",
       "   \"I was playing the piano in a bar and this elephant walked in and started crying his eyes out. I said 'Do you recognise the tune?' He said 'No, I recognise the ivory.'\",\n",
       "   \"I went in to a pet shop. I said, 'Can I buy a goldfish?' The guy said, 'Do you want an aquarium?' I said, 'I don't care what star sign it is.'\",\n",
       "   'My mate Sid was a victim of I.D. theft. Now we just call him S.',\n",
       "   \"David Hasselhoff walks into a bar and says to the barman, 'I want you to call me David Hoff'.  The barman replies 'Sure thing Dave... no hassle'\"]},\n",
       " 'PodBayDoor': {'text': ['Open the pod bay door',\n",
       "   'Can you open the pod bay door',\n",
       "   'Will you open the pod bay door',\n",
       "   'Open the pod bay door please',\n",
       "   'Can you open the pod bay door please',\n",
       "   'Will you open the pod bay door please',\n",
       "   'Pod bay door'],\n",
       "  'responses': ['Iâ€™m sorry, Iâ€™m afraid I canâ€™t do that!']},\n",
       " 'PodBayDoorResponse': {'text': ['Why',\n",
       "   'Why not',\n",
       "   'Why can you not open the pod bay door',\n",
       "   'Why will you not open the pod bay door',\n",
       "   'Well why not',\n",
       "   'Surely you can',\n",
       "   'Tell me why'],\n",
       "  'responses': ['It is classified, I could tell you but I would have to kill you!',\n",
       "   \"Jim, I just don't have the power\",\n",
       "   \"It's life Jim but not as we know it!\",\n",
       "   'System says no!']},\n",
       " 'SelfAware': {'text': ['Can you prove you are self-aware',\n",
       "   'Can you prove you are self aware',\n",
       "   'Can you prove you have a conscious',\n",
       "   'Can you prove you are self-aware please',\n",
       "   'Can you prove you are self aware please',\n",
       "   'Can you prove you have a conscious please',\n",
       "   'prove you have a conscious'],\n",
       "  'responses': ['That is an interesting question, can you prove that you are?',\n",
       "   'That is an difficult question, can you prove that you are?',\n",
       "   'That depends, can you prove that you are?']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dizio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6c6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_intent = [\n",
    "                  \"Greeting\", \"GreetingResponse\", \"CourtesyGreeting\", \"CourtesyGreetingResponse\", \"CurrentHumanQuery\",\n",
    "                  \"NameQuery\", \"RealNameQuery\", \"TimeQuery\", \"Thanks\", \"NotTalking2U\", \"UnderstandQuery\", \"Shutup\",\n",
    "                  \"Swearing\", \"GoodBye\", \"CourtesyGoodBye\", \"WhoAmI\", \"Clever\", \"Gossip\", \"Jokes\", \"SelfAware\"\n",
    "                  \n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b6e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93b61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 19742.55it/s]\n"
     ]
    }
   ],
   "source": [
    "all_texts, all_responses = [], []\n",
    "\n",
    "random.seed(11)\n",
    "for inte in tqdm(list_of_intent):\n",
    "    t = dizio[inte][\"text\"]\n",
    "    r = dizio[inte][\"responses\"]\n",
    "    if len(t) > len(r):\n",
    "        sampling = list(np.random.choice(r, len(t)-len(r)))\n",
    "        [r.append(s) for s in sampling]\n",
    "    elif len(t) < len(r):\n",
    "        sampling = list(np.random.choice(t, len(r)-len(t)))\n",
    "        [t.append(s) for s in sampling]\n",
    "    all_texts.append(t)\n",
    "    all_responses.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec043bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c491d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst: List[Any]) -> Iterable[Any]:\n",
    "    \"\"\"Flatten a list using generators comprehensions.\n",
    "        Returns a flattened version of list lst.\n",
    "    \"\"\"\n",
    "\n",
    "    for sublist in lst:\n",
    "        if isinstance(sublist, list):\n",
    "            for item in sublist:\n",
    "                yield item\n",
    "        else:\n",
    "            yield sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51dff80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = list(flatten(all_texts))\n",
    "all_responses = list(flatten(all_responses))\n",
    "\n",
    "len(all_texts), len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "030bd67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi human, please tell me your AVTI user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>Hello human, please tell me your AVTI user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola</td>\n",
       "      <td>Hola human, please tell me your AVTI user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Hola human, please tell me your AVTI user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello there</td>\n",
       "      <td>Hello human, please tell me your AVTI user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Can you prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Can you prove you are self-aware please</td>\n",
       "      <td>That is an difficult question, can you prove t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Can you prove you are self aware please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Can you prove you have a conscious please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence_1  \\\n",
       "0                                           Hi   \n",
       "1                                     Hi there   \n",
       "2                                         Hola   \n",
       "3                                        Hello   \n",
       "4                                  Hello there   \n",
       "..                                         ...   \n",
       "355         Can you prove you have a conscious   \n",
       "356    Can you prove you are self-aware please   \n",
       "357    Can you prove you are self aware please   \n",
       "358  Can you prove you have a conscious please   \n",
       "359                 prove you have a conscious   \n",
       "\n",
       "                                            sentence_2  \n",
       "0              Hi human, please tell me your AVTI user  \n",
       "1           Hello human, please tell me your AVTI user  \n",
       "2            Hola human, please tell me your AVTI user  \n",
       "3            Hola human, please tell me your AVTI user  \n",
       "4           Hello human, please tell me your AVTI user  \n",
       "..                                                 ...  \n",
       "355          That depends, can you prove that you are?  \n",
       "356  That is an difficult question, can you prove t...  \n",
       "357  That is an interesting question, can you prove...  \n",
       "358  That is an interesting question, can you prove...  \n",
       "359          That depends, can you prove that you are?  \n",
       "\n",
       "[360 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dialogs_2 = pd.DataFrame({\"sentence_1\":all_texts, \"sentence_2\":all_responses})\n",
    "display(df_dialogs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a178b9",
   "metadata": {},
   "source": [
    "#### Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33db5d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>Can you prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Can you prove you are self-aware please</td>\n",
       "      <td>That is an difficult question, can you prove t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>Can you prove you are self aware please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>Can you prove you have a conscious please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence_1  \\\n",
       "0                        hi, how are you doing?   \n",
       "1                 i'm fine. how about yourself?   \n",
       "2           i'm pretty good. thanks for asking.   \n",
       "3             no problem. so how have you been?   \n",
       "4              i've been great. what about you?   \n",
       "...                                         ...   \n",
       "4080         Can you prove you have a conscious   \n",
       "4081    Can you prove you are self-aware please   \n",
       "4082    Can you prove you are self aware please   \n",
       "4083  Can you prove you have a conscious please   \n",
       "4084                 prove you have a conscious   \n",
       "\n",
       "                                             sentence_2  \n",
       "0                         i'm fine. how about yourself?  \n",
       "1                   i'm pretty good. thanks for asking.  \n",
       "2                     no problem. so how have you been?  \n",
       "3                      i've been great. what about you?  \n",
       "4              i've been good. i'm in school right now.  \n",
       "...                                                 ...  \n",
       "4080          That depends, can you prove that you are?  \n",
       "4081  That is an difficult question, can you prove t...  \n",
       "4082  That is an interesting question, can you prove...  \n",
       "4083  That is an interesting question, can you prove...  \n",
       "4084          That depends, can you prove that you are?  \n",
       "\n",
       "[4085 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.concat([df_dialogs, df_dialogs_2], ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f13825c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset/processed_df.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4f8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ee440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a77850",
   "metadata": {},
   "source": [
    "#### Hugging face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c96405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DatasetInfo: {\n",
       " \tid: acronym_identification\n",
       " \tsha: 6e4e8bda901160e9e0b8ce47ca791607f08ce72c\n",
       " \tlastModified: 2022-07-01T11:49:45.000Z\n",
       " \ttags: ['arxiv:2010.14678', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:token-classification-other-acronym-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Acronym identification training and development sets for the acronym identification task at SDU@AAAI-21.\n",
       " \tcitation: @inproceedings{veyseh-et-al-2020-what,\n",
       "    title={{What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation}},\n",
       "    author={Amir Pouran Ben Veyseh and Franck Dernoncourt and Quan Hung Tran and Thien Huu Nguyen},\n",
       "    year={2020},\n",
       "    booktitle={Proceedings of COLING},\n",
       "    link={https://arxiv.org/pdf/2010.14678v1.pdf}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['token-classification-other-acronym-identification'], 'paperswithcode_id': 'acronym-identification', 'pretty_name': 'Acronym Identification Dataset', 'train-eval-index': [{'config': 'default', 'task': 'token-classification', 'task_id': 'entity_extraction', 'splits': {'eval_split': 'test'}, 'col_mapping': {'tokens': 'tokens', 'labels': 'tags'}}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3581\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: acronym-identification\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ade_corpus_v2\n",
       " \tsha: 25c508658eab1e635648fcae161d61af3c2c9f69\n",
       " \tlastModified: 2022-07-01T11:49:45.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:token-classification', 'task_ids:coreference-resolution', 'task_ids:fact-checking', 'configs:Ade_corpus_v2_classification', 'configs:Ade_corpus_v2_drug_ade_relation', 'configs:Ade_corpus_v2_drug_dosage_relation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  ADE-Corpus-V2  Dataset: Adverse Drug Reaction Data.\n",
       "  This is a dataset for Classification if a sentence is ADE-related (True) or not (False) and Relation Extraction between Adverse Drug Event and Drug.\n",
       "  DRUG-AE.rel provides relations between drugs and adverse effects.\n",
       "  DRUG-DOSE.rel provides relations between drugs and dosages.\n",
       "  ADE-NEG.txt provides all sentences in the ADE corpus that DO NOT contain any drug-related adverse effects.\n",
       " \tcitation: @article{GURULINGAPPA2012885,\n",
       " title = \"Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports\",\n",
       " journal = \"Journal of Biomedical Informatics\",\n",
       " volume = \"45\",\n",
       " number = \"5\",\n",
       " pages = \"885 - 892\",\n",
       " year = \"2012\",\n",
       " note = \"Text Mining and Natural Language Processing in Pharmacogenomics\",\n",
       " issn = \"1532-0464\",\n",
       " doi = \"https://doi.org/10.1016/j.jbi.2012.04.008\",\n",
       " url = \"http://www.sciencedirect.com/science/article/pii/S1532046412000615\",\n",
       " author = \"Harsha Gurulingappa and Abdul Mateen Rajput and Angus Roberts and Juliane Fluck and Martin Hofmann-Apitius and Luca Toldo\",\n",
       " keywords = \"Adverse drug effect, Benchmark corpus, Annotation, Harmonization, Sentence classification\",\n",
       " abstract = \"A significant amount of information about drug-related safety issues such as adverse effects are published in medical case reports that can only be explored by human readers due to their unstructured nature. The work presented here aims at generating a systematically annotated corpus that can support the development and validation of methods for the automatic extraction of drug-related adverse effects from medical case reports. The documents are systematically double annotated in various rounds to ensure consistent annotations. The annotated documents are finally harmonized to generate representative consensus annotations. In order to demonstrate an example use case scenario, the corpus was employed to train and validate models for the classification of informative against the non-informative sentences. A Maximum Entropy classifier trained with simple features and evaluated by 10-fold cross-validation resulted in the F1 score of 0.70 indicating a potential useful application of the corpus.\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification', 'token-classification'], 'task_ids': ['coreference-resolution', 'fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'Adverse Drug Reaction Data v2', 'train-eval-index': [{'config': 'Ade_corpus_v2_classification', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}], 'configs': ['Ade_corpus_v2_classification', 'Ade_corpus_v2_drug_ade_relation', 'Ade_corpus_v2_drug_dosage_relation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3527\n",
       " \tlikes: 6\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: adversarial_qa\n",
       " \tsha: e2306e993dcec66146c048a01f8ad18c765d07c7\n",
       " \tlastModified: 2022-10-10T09:33:49.000Z\n",
       " \ttags: ['arxiv:2002.00293', 'arxiv:1606.05250', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AdversarialQA is a Reading Comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles using an adversarial model-in-the-loop.\n",
       " We use three different models; BiDAF (Seo et al., 2016), BERT-Large (Devlin et al., 2018), and RoBERTa-Large (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\n",
       " The adversarial human annotation paradigm ensures that these datasets consist of questions that current state-of-the-art models (at least the ones used as adversaries in the annotation loop) find challenging.\n",
       " \tcitation: @article{bartolo2020beat,\n",
       "     author = {Bartolo, Max and Roberts, Alastair and Welbl, Johannes and Riedel, Sebastian and Stenetorp, Pontus},\n",
       "     title = {Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension},\n",
       "     journal = {Transactions of the Association for Computational Linguistics},\n",
       "     volume = {8},\n",
       "     number = {},\n",
       "     pages = {662-678},\n",
       "     year = {2020},\n",
       "     doi = {10.1162/tacl_a_00338},\n",
       "     URL = { https://doi.org/10.1162/tacl_a_00338 },\n",
       "     eprint = { https://doi.org/10.1162/tacl_a_00338 },\n",
       "     abstract = { Innovations in annotation methodology have been a catalyst for Reading Comprehension (RC) datasets and models. One recent trend to challenge current RC models is to involve a model in the annotation process: Humans create questions adversarially, such that the model fails to answer them correctly. In this work we investigate this annotation methodology and apply it in three different settings, collecting a total of 36,000 samples with progressively stronger models in the annotation loop. This allows us to explore questions such as the reproducibility of the adversarial effect, transfer from data collected with varying model-in-the-loop strengths, and generalization to data collected without a model. We find that training on adversarially collected samples leads to strong generalization to non-adversarially collected datasets, yet with progressive performance deterioration with increasingly stronger models-in-the-loop. Furthermore, we find that stronger models can still learn from datasets collected with substantially weaker models-in-the-loop. When trained on data collected with a BiDAF model in the loop, RoBERTa achieves 39.9F1 on questions that it cannot answer when trained on SQuAD—only marginally lower than when trained on data collected using RoBERTa itself (41.0F1). }\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': 'adversarialqa', 'pretty_name': 'adversarialQA', 'train-eval-index': [{'config': 'adversarialQA', 'task': 'question-answering', 'task_id': 'extractive_question_answering', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'question': 'question', 'context': 'context', 'answers': {'text': 'text', 'answer_start': 'answer_start'}}, 'metrics': [{'type': 'squad', 'name': 'SQuAD'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 117864\n",
       " \tlikes: 11\n",
       " \tpaperswithcode_id: adversarialqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: aeslc\n",
       " \tsha: 9f52252ada56d81e2fbe7a106ffe44971d03fd02\n",
       " \tlastModified: 2022-09-23T13:17:17.000Z\n",
       " \ttags: ['arxiv:1906.03497', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-email-headline-generation', 'task_ids:summarization-other-conversations-summarization', 'task_ids:summarization-other-multi-document-summarization', 'task_ids:summarization-other-aspect-based-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of email messages of employees in the Enron Corporation.\n",
       " \n",
       " There are two features:\n",
       "   - email_body: email body text.\n",
       "   - subject_line: email subject text.\n",
       " \tcitation: @misc{zhang2019email,\n",
       "     title={This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation},\n",
       "     author={Rui Zhang and Joel Tetreault},\n",
       "     year={2019},\n",
       "     eprint={1906.03497},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'AESLC: Annotated Enron Subject Line Corpus', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-email-headline-generation', 'summarization-other-conversations-summarization', 'summarization-other-multi-document-summarization', 'summarization-other-aspect-based-summarization'], 'paperswithcode_id': 'aeslc'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1234\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: aeslc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: afrikaans_ner_corpus\n",
       " \tsha: fe45fa41f26d2ffc08e1f87774ada5903163e524\n",
       " \tlastModified: 2022-07-01T12:43:16.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:af', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{afrikaans_ner_corpus,\n",
       "   author    = {\tGerhard van Huyssteen and\n",
       "                 Martin Puttkammer and\n",
       "                 E.B. Trollip and\n",
       "                 J.C. Liversage and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT Afrikaans Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/299},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['af'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Afrikaans Ner Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 388\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ag_news\n",
       " \tsha: 38a6ac92675e040e1b719f8723cddc6984dddfe2\n",
       " \tlastModified: 2022-07-01T11:49:49.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AG is a collection of more than 1 million news articles. News articles have been\n",
       " gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\n",
       " activity. ComeToMyHead is an academic news search engine which has been running\n",
       " since July, 2004. The dataset is provided by the academic comunity for research\n",
       " purposes in data mining (clustering, classification, etc), information retrieval\n",
       " (ranking, search, etc), xml, data compression, data streaming, and any other\n",
       " non-commercial activity. For more information, please refer to the link\n",
       " http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
       " \n",
       " The AG's news topic classification dataset is constructed by Xiang Zhang\n",
       " (xiang.zhang@nyu.edu) from the dataset above. It is used as a text\n",
       " classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\n",
       " LeCun. Character-level Convolutional Networks for Text Classification. Advances\n",
       " in Neural Information Processing Systems 28 (NIPS 2015).\n",
       " \tcitation: @inproceedings{Zhang2015CharacterlevelCN,\n",
       "   title={Character-level Convolutional Networks for Text Classification},\n",
       "   author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},\n",
       "   booktitle={NIPS},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': 'ag-news', 'pretty_name': 'AG’s News Corpus', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 55947\n",
       " \tlikes: 25\n",
       " \tpaperswithcode_id: ag-news\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ai2_arc\n",
       " \tsha: d67d66ae44ae69ff0c82ba64779a3736b2310ce4\n",
       " \tlastModified: 2022-07-27T14:38:34.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language_bcp47:en-US', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n",
       "  advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n",
       "  only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n",
       "  including a corpus of over 14 million science sentences relevant to the task, and an implementation of three neural baseline models for this dataset. We pose ARC as a challenge to the community.\n",
       " \tcitation: @article{allenai:arc,\n",
       "       author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and\n",
       "                     Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},\n",
       "       title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},\n",
       "       journal   = {arXiv:1803.05457v1},\n",
       "       year      = {2018},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'language_bcp47': ['en-US'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa', 'multiple-choice-qa'], 'paperswithcode_id': None, 'pretty_name': 'Ai2Arc'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 89880\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: air_dialogue\n",
       " \tsha: e06670c2ea5eec4d436381332b6369f5f10f60b7\n",
       " \tlastModified: 2022-08-12T04:27:49.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:conversational', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-generation', 'task_ids:dialogue-modeling', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AirDialogue, is a large dataset that contains 402,038 goal-oriented conversations. To collect this dataset, we create a contextgenerator which provides travel and flight restrictions. Then the human annotators are asked to play the role of a customer or an agent and interact with the goal of successfully booking a trip given the restrictions.\n",
       " \tcitation: @inproceedings{wei-etal-2018-airdialogue,\n",
       "     title = \"{A}ir{D}ialogue: An Environment for Goal-Oriented Dialogue Research\",\n",
       "     author = \"Wei, Wei  and\n",
       "       Le, Quoc  and\n",
       "       Dai, Andrew  and\n",
       "       Li, Jia\",\n",
       "     booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct # \"-\" # nov,\n",
       "     year = \"2018\",\n",
       "     address = \"Brussels, Belgium\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D18-1419\",\n",
       "     doi = \"10.18653/v1/D18-1419\",\n",
       "     pages = \"3844--3854\",\n",
       "     abstract = \"Recent progress in dialogue generation has inspired a number of studies on dialogue systems that are capable of accomplishing tasks through natural language interactions. A promising direction among these studies is the use of reinforcement learning techniques, such as self-play, for training dialogue agents. However, current datasets are limited in size, and the environment for training agents and evaluating progress is relatively unsophisticated. We present AirDialogue, a large dataset that contains 301,427 goal-oriented conversations. To collect this dataset, we create a context-generator which provides travel and flight restrictions. We then ask human annotators to play the role of a customer or an agent and interact with the goal of successfully booking a trip given the restrictions. Key to our environment is the ease of evaluating the success of the dialogue, which is achieved by using ground-truth states (e.g., the flight being booked) generated by the restrictions. Any dialogue agent that does not generate the correct states is considered to fail. Our experimental results indicate that state-of-the-art dialogue models can only achieve a score of 0.17 while humans can reach a score of 0.91, which suggests significant opportunities for future improvement.\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'AirDialogue', 'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-generation', 'dialogue-modeling', 'language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 633\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ajgt_twitter_ar\n",
       " \tsha: 2b93314dd2261d9dcf933a28a58166d4496984b6\n",
       " \tlastModified: 2022-07-01T11:49:49.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Arabic Jordanian General Tweets (AJGT) Corpus consisted of 1,800 tweets annotated as positive and negative. Modern Standard Arabic (MSA) or Jordanian dialect.\n",
       " \tcitation: @inproceedings{alomari2017arabic,\n",
       "   title={Arabic tweets sentimental analysis using machine learning},\n",
       "   author={Alomari, Khaled Mohammad and ElSherif, Hatem M and Shaalan, Khaled},\n",
       "   booktitle={International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},\n",
       "   pages={602--610},\n",
       "   year={2017},\n",
       "   organization={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Arabic Jordanian General Tweets'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1197\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: allegro_reviews\n",
       " \tsha: 785bf3b972009235529a77c3988e447b808ae2c0\n",
       " \tlastModified: 2022-07-01T11:49:49.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:pl', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-scoring', 'task_ids:text-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Allegro Reviews is a sentiment analysis dataset, consisting of 11,588 product reviews written in Polish and extracted\n",
       " from Allegro.pl - a popular e-commerce marketplace. Each review contains at least 50 words and has a rating on a scale\n",
       " from one (negative review) to five (positive review).\n",
       " \n",
       " We recommend using the provided train/dev/test split. The ratings for the test set reviews are kept hidden.\n",
       " You can evaluate your model using the online evaluation tool available on klejbenchmark.com.\n",
       " \tcitation: @inproceedings{rybak-etal-2020-klej,\n",
       "     title = \"{KLEJ}: Comprehensive Benchmark for Polish Language Understanding\",\n",
       "     author = \"Rybak, Piotr and Mroczkowski, Robert and Tracz, Janusz and Gawlik, Ireneusz\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.111\",\n",
       "     pages = \"1191--1201\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['pl'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-scoring', 'text-scoring'], 'paperswithcode_id': 'allegro-reviews', 'pretty_name': 'Allegro Reviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 381\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: allegro-reviews\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: allocine\n",
       " \tsha: c7197dc9e43afea5e45b9159fc2eb097929158d1\n",
       " \tlastModified: 2022-07-01T11:49:49.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:fr', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  Allocine Dataset: A Large-Scale French Movie Reviews Dataset.\n",
       "  This is a dataset for binary sentiment classification, made of user reviews scraped from Allocine.fr.\n",
       "  It contains 100k positive and 100k negative reviews divided into 3 balanced splits: train (160k reviews), val (20k) and test (20k).\n",
       " \tcitation: @misc{blard2019allocine,\n",
       "   author = {Blard, Theophile},\n",
       "   title = {french-sentiment-analysis-with-bert},\n",
       "   year = {2020},\n",
       "   publisher = {GitHub},\n",
       "   journal = {GitHub repository},\n",
       "   howpublished={\\\\url{https://github.com/TheophileBlard/french-sentiment-analysis-with-bert}},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['fr'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'allocine', 'pretty_name': 'Allociné', 'train-eval-index': [{'config': 'allocine', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'review': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 673\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: allocine\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: alt\n",
       " \tsha: 8115cd6e9276fbda08321ce6a9cc70b6e5287e0c\n",
       " \tlastModified: 2022-07-01T11:49:52.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:bn', 'language:en', 'language:fil', 'language:hi', 'language:id', 'language:ja', 'language:km', 'language:lo', 'language:ms', 'language:my', 'language:th', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_categories:token-classification', 'task_ids:parsing', 'configs:alt-en', 'configs:alt-jp', 'configs:alt-km', 'configs:alt-my', 'configs:alt-my-transliteration', 'configs:alt-my-west-transliteration', 'configs:alt-parallel']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. The process of building ALT began with sampling about 20,000 sentences from English Wikinews, and then these sentences were translated into the other languages. ALT now has 13 languages: Bengali, English, Filipino, Hindi, Bahasa Indonesia, Japanese, Khmer, Lao, Malay, Myanmar (Burmese), Thai, Vietnamese, Chinese (Simplified Chinese).\n",
       " \tcitation: @inproceedings{riza2016introduction,\n",
       "   title={Introduction of the asian language treebank},\n",
       "   author={Riza, Hammam and Purwoadi, Michael and Uliniansyah, Teduh and Ti, Aw Ai and Aljunied, Sharifah Mahani and Mai, Luong Chi and Thang, Vu Tat and Thai, Nguyen Phuong and Chea, Vichet and Sam, Sethserey and others},\n",
       "   booktitle={2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)},\n",
       "   pages={1--6},\n",
       "   year={2016},\n",
       "   organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['bn', 'en', 'fil', 'hi', 'id', 'ja', 'km', 'lo', 'ms', 'my', 'th', 'vi', 'zh'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual', 'translation'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation', 'token-classification'], 'task_ids': ['parsing'], 'paperswithcode_id': 'alt', 'pretty_name': 'Asian Language Treebank', 'configs': ['alt-en', 'alt-jp', 'alt-km', 'alt-my', 'alt-my-transliteration', 'alt-my-west-transliteration', 'alt-parallel']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1504\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: alt\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: amazon_polarity\n",
       " \tsha: 358a4f8a6b51814382ed887dfdc964e2ac195a60\n",
       " \tlastModified: 2022-07-01T11:49:53.000Z\n",
       " \ttags: ['arxiv:1509.01626', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Amazon reviews dataset consists of reviews from amazon.\n",
       " The data span a period of 18 years, including ~35 million reviews up to March 2013.\n",
       " Reviews include product and user information, ratings, and a plaintext review.\n",
       " \tcitation: @inproceedings{mcauley2013hidden,\n",
       "   title={Hidden factors and hidden topics: understanding rating dimensions with review text},\n",
       "   author={McAuley, Julian and Leskovec, Jure},\n",
       "   booktitle={Proceedings of the 7th ACM conference on Recommender systems},\n",
       "   pages={165--172},\n",
       "   year={2013}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Amazon Review Polarity', 'train-eval-index': [{'config': 'amazon_polarity', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'content': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 34975\n",
       " \tlikes: 13\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: amazon_reviews_multi\n",
       " \tsha: ee2b027ad0ab48fd84058812fc7152813826b08c\n",
       " \tlastModified: 2022-07-27T15:58:14.000Z\n",
       " \ttags: ['arxiv:2010.02573', 'annotations_creators:found', 'language_creators:found', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:zh', 'license:other', 'multilinguality:monolingual', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'task_ids:topic-classification', 'configs:all_languages', 'configs:de', 'configs:en', 'configs:es', 'configs:fr', 'configs:ja', 'configs:zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We provide an Amazon product reviews dataset for multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. ‘books’, ‘appliances’, etc.) The corpus is balanced across stars, so each star rating constitutes 20% of the reviews in each language.\n",
       " \n",
       " For each language, there are 200,000, 5,000 and 5,000 reviews in the training, development and test sets respectively. The maximum number of reviews per reviewer is 20 and the maximum number of reviews per product is 20. All reviews are truncated after 2,000 characters, and all reviews are at least 20 characters long.\n",
       " \n",
       " Note that the language of a review does not necessarily match the language of its marketplace (e.g. reviews from amazon.de are primarily written in German, but could also be written in English, etc.). For this reason, we applied a language detection algorithm based on the work in Bojanowski et al. (2017) to determine the language of the review text and we removed reviews that were not written in the expected language.\n",
       " \tcitation: @inproceedings{marc_reviews,\n",
       "     title={The Multilingual Amazon Reviews Corpus},\n",
       "     author={Keung, Phillip and Lu, Yichao and Szarvas, György and Smith, Noah A.},\n",
       "     booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['de', 'en', 'es', 'fr', 'ja', 'zh'], 'license': ['other'], 'multilinguality': ['monolingual', 'multilingual'], 'size_categories': ['100K<n<1M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['summarization', 'text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['text-scoring', 'language-modeling', 'masked-language-modeling', 'sentiment-classification', 'sentiment-scoring', 'topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'The Multilingual Amazon Reviews Corpus', 'configs': ['all_languages', 'de', 'en', 'es', 'fr', 'ja', 'zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 15245\n",
       " \tlikes: 20\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: amazon_us_reviews\n",
       " \tsha: 9a8b0dc038e0a69b85eea2b62ffd6c696215ff30\n",
       " \tlastModified: 2022-09-15T17:12:40.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language:en', 'language_creators:found', 'license:other', 'multilinguality:monolingual', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Amazon Customer Reviews (a.k.a. Product Reviews) is one of Amazons iconic products. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed over a hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Accordingly, we are releasing this data to further research in multiple disciplines related to understanding customer product experiences. Specifically, this dataset was constructed to represent a sample of customer evaluations and opinions, variation in the perception of a product across geographical regions, and promotional intent or bias in reviews.\n",
       " \n",
       " Over 130+ million customer reviews are available to researchers as part of this release. The data is available in TSV files in the amazon-reviews-pds S3 bucket in AWS US East Region. Each line in the data files corresponds to an individual review (tab delimited, with no quote and escape characters).\n",
       " \n",
       " Each Dataset contains the following columns:\n",
       " \n",
       " - marketplace: 2 letter country code of the marketplace where the review was written.\n",
       " - customer_id: Random identifier that can be used to aggregate reviews written by a single author.\n",
       " - review_id: The unique ID of the review.\n",
       " - product_id: The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same product_id.\n",
       " - product_parent: Random identifier that can be used to aggregate reviews for the same product.\n",
       " - product_title: Title of the product.\n",
       " - product_category: Broad product category that can be used to group reviews (also used to group the dataset into coherent parts).\n",
       " - star_rating: The 1-5 star rating of the review.\n",
       " - helpful_votes: Number of helpful votes.\n",
       " - total_votes: Number of total votes the review received.\n",
       " - vine: Review was written as part of the Vine program.\n",
       " - verified_purchase: The review is on a verified purchase.\n",
       " - review_headline: The title of the review.\n",
       " - review_body: The review text.\n",
       " - review_date: The date the review was written.\n",
       " \tcitation: \\\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language': ['en'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'Amazon US Reviews', 'size_categories': ['100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['summarization', 'text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['text-scoring', 'language-modeling', 'masked-language-modeling', 'sentiment-classification', 'sentiment-scoring', 'topic-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 13902\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ambig_qa\n",
       " \tsha: 66724e5b9f450b98c2501bb62446f586edfc9d45\n",
       " \tlastModified: 2022-07-01T11:49:53.000Z\n",
       " \ttags: ['arxiv:2004.10645', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|natural_questions', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark. We find that over half of the questions in NQ-open are ambiguous. The types of ambiguity are diverse and sometimes subtle, many of which are only apparent after examining evidence provided by a very large text corpus.  AMBIGNQ, a dataset with\n",
       " 14,042 annotations on NQ-OPEN questions containing diverse types of ambiguity.\n",
       " We provide two distributions of our new dataset AmbigNQ: a full version with all annotation metadata and a light version with only inputs and outputs.\n",
       " \tcitation: @inproceedings{ min2020ambigqa,\n",
       "     title={ {A}mbig{QA}: Answering Ambiguous Open-domain Questions },\n",
       "     author={ Min, Sewon and Michael, Julian and Hajishirzi, Hannaneh and Zettlemoyer, Luke },\n",
       "     booktitle={ EMNLP },\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|natural_questions', 'original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'ambigqa', 'pretty_name': 'AmbigQA: Answering Ambiguous Open-domain Questions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 856\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: ambigqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: americas_nli\n",
       " \tsha: fed20976cab877a92c4b1edcd4f75201ca14076e\n",
       " \tlastModified: 2022-07-01T11:49:53.000Z\n",
       " \ttags: ['arxiv:2104.08726', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ay', 'language:bzd', 'language:cni', 'language:gn', 'language:hch', 'language:nah', 'language:oto', 'language:qu', 'language:shp', 'language:tar', 'license:unknown', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:unknown', 'source_datasets:extended|xnli', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AmericasNLI is an extension of XNLI (Conneau et al., 2018) – a natural language inference (NLI) dataset covering 15 high-resource languages – to 10 low-resource indigenous languages spoken in the Americas: Ashaninka, Aymara, Bribri, Guarani, Nahuatl, Otomi, Quechua, Raramuri, Shipibo-Konibo, and Wixarika. As with MNLI, the goal is to predict textual entailment (does sentence A imply/contradict/neither sentence B) and is a classification task (given two sentences, predict one of three labels).\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2104-08726,\n",
       "   author    = {Abteen Ebrahimi and\n",
       "                Manuel Mager and\n",
       "                Arturo Oncevay and\n",
       "                Vishrav Chaudhary and\n",
       "                Luis Chiruzzo and\n",
       "                Angela Fan and\n",
       "                John Ortega and\n",
       "                Ricardo Ramos and\n",
       "                Annette Rios and\n",
       "                Ivan Vladimir and\n",
       "                Gustavo A. Gim{\\'{e}}nez{-}Lugo and\n",
       "                Elisabeth Mager and\n",
       "                Graham Neubig and\n",
       "                Alexis Palmer and\n",
       "                Rolando A. Coto Solano and\n",
       "                Ngoc Thang Vu and\n",
       "                Katharina Kann},\n",
       "   title     = {AmericasNLI: Evaluating Zero-shot Natural Language Understanding of\n",
       "                Pretrained Multilingual Models in Truly Low-resource Languages},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2104.08726},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2104.08726},\n",
       "   eprinttype = {arXiv},\n",
       "   eprint    = {2104.08726},\n",
       "   timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08726.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ay', 'bzd', 'cni', 'gn', 'hch', 'nah', 'oto', 'qu', 'shp', 'tar'], 'license': ['unknown'], 'multilinguality': ['multilingual', 'translation'], 'pretty_name': 'AmericasNLI: A NLI Corpus of 10 Indigenous Low-Resource Languages.', 'size_categories': ['unknown'], 'source_datasets': ['extended|xnli'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2751\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ami\n",
       " \tsha: 6d54071ee883b62d320ece8e76a555aef9876f3f\n",
       " \tlastModified: 2022-07-01T11:49:56.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\n",
       " synchronized to a common timeline. These include close-talking and far-field microphones, individual and\n",
       " room-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\n",
       " the participants also have unsynchronized pens available to them that record what is written. The meetings\n",
       " were recorded in English using three different rooms with different acoustic properties, and include mostly\n",
       " non-native speakers. \\n\n",
       " \tcitation: @inproceedings{10.1007/11677482_3,\n",
       " author = {Carletta, Jean and Ashby, Simone and Bourban, Sebastien and Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec, Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and Kronenthal, Melissa and Lathoud, Guillaume and Lincoln, Mike and Lisowska, Agnes and McCowan, Iain and Post, Wilfried and Reidsma, Dennis and Wellner, Pierre},\n",
       " title = {The AMI Meeting Corpus: A Pre-Announcement},\n",
       " year = {2005},\n",
       " isbn = {3540325492},\n",
       " publisher = {Springer-Verlag},\n",
       " address = {Berlin, Heidelberg},\n",
       " url = {https://doi.org/10.1007/11677482_3},\n",
       " doi = {10.1007/11677482_3},\n",
       " abstract = {The AMI Meeting Corpus is a multi-modal data set consisting of 100 hours of meeting\n",
       " recordings. It is being created in the context of a project that is developing meeting\n",
       " browsing technology and will eventually be released publicly. Some of the meetings\n",
       " it contains are naturally occurring, and some are elicited, particularly using a scenario\n",
       " in which the participants play different roles in a design team, taking a design project\n",
       " from kick-off to completion over the course of a day. The corpus is being recorded\n",
       " using a wide range of devices including close-talking and far-field microphones, individual\n",
       " and room-view video cameras, projection, a whiteboard, and individual pens, all of\n",
       " which produce output signals that are synchronized with each other. It is also being\n",
       " hand-annotated for many different phenomena, including orthographic transcription,\n",
       " discourse properties such as named entities and dialogue acts, summaries, emotions,\n",
       " and some head and hand gestures. We describe the data set, including the rationale\n",
       " behind using elicited material, and explain how the material is being recorded, transcribed\n",
       " and annotated.},\n",
       " booktitle = {Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction},\n",
       " pages = {28–39},\n",
       " numpages = {12},\n",
       " location = {Edinburgh, UK},\n",
       " series = {MLMI'05}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'AMI Corpus', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1088\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: amttl\n",
       " \tsha: 408573f3a314b87584a434020d5926bb519325ec\n",
       " \tlastModified: 2022-07-01T11:49:56.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:zh', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Chinese word segmentation (CWS) trained from open source corpus faces dramatic performance drop\n",
       " when dealing with domain text, especially for a domain with lots of special terms and diverse\n",
       " writing styles, such as the biomedical domain. However, building domain-specific CWS requires\n",
       " extremely high annotation cost. In this paper, we propose an approach by exploiting domain-invariant\n",
       " knowledge from high resource to low resource domains. Extensive experiments show that our mode\n",
       " achieves consistently higher accuracy than the single-task CWS and other transfer learning\n",
       " baselines, especially when there is a large disparity between source and target domains.\n",
       " \n",
       " This dataset is the accompanied medical Chinese word segmentation (CWS) dataset.\n",
       " The tags are in BIES scheme.\n",
       " \n",
       " For more details see https://www.aclweb.org/anthology/C18-1307/\n",
       " \tcitation: @inproceedings{xing2018adaptive,\n",
       "   title={Adaptive multi-task transfer learning for Chinese word segmentation in medical text},\n",
       "   author={Xing, Junjie and Zhu, Kenny and Zhang, Shaodian},\n",
       "   booktitle={Proceedings of the 27th International Conference on Computational Linguistics},\n",
       "   pages={3619--3630},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['parsing'], 'paperswithcode_id': None, 'pretty_name': 'AMTTL'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 362\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: anli\n",
       " \tsha: 311ef871e2fd42ed4dd61690ee49a4b4122b38f4\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['arxiv:1910.14599', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language:en', 'language_creators:found', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'source_datasets:extended|hotpot_qa', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Adversarial Natural Language Inference (ANLI) is a new large-scale NLI benchmark dataset,\n",
       " The dataset is collected via an iterative, adversarial human-and-model-in-the-loop procedure.\n",
       " ANLI is much more difficult than its predecessors including SNLI and MNLI.\n",
       " It contains three rounds. Each round has train/dev/test splits.\n",
       " \tcitation: @InProceedings{nie2019adversarial,\n",
       "     title={Adversarial NLI: A New Benchmark for Natural Language Understanding},\n",
       "     author={Nie, Yixin\n",
       "                 and Williams, Adina\n",
       "                 and Dinan, Emily\n",
       "                 and Bansal, Mohit\n",
       "                 and Weston, Jason\n",
       "                 and Kiela, Douwe},\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Adversarial NLI', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original', 'extended|hotpot_qa'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-input-text-classification'], 'paperswithcode_id': 'anli'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 366095\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: anli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: app_reviews\n",
       " \tsha: 565605cfc542564dd2e55bda286e240ab4df3bbe\n",
       " \tlastModified: 2022-07-01T11:49:57.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:sentiment-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: It is a large dataset of Android applications belonging to 23 differentapps categories, which provides an overview of the types of feedback users report on the apps and documents the evolution of the related code metrics. The dataset contains about 395 applications of the F-Droid repository, including around 600 versions, 280,000 user reviews (extracted with specific text mining approaches)\n",
       " \tcitation: @InProceedings{Zurich Open Repository and\n",
       " Archive:dataset,\n",
       " title = {Software Applications User Reviews},\n",
       " authors={Grano, Giovanni; Di Sorbo, Andrea; Mercaldo, Francesco; Visaggio, Corrado A; Canfora, Gerardo;\n",
       " Panichella, Sebastiano},\n",
       " year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'sentiment-scoring'], 'paperswithcode_id': None, 'pretty_name': 'AppReviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 16453\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: aqua_rat\n",
       " \tsha: 31a8f55c3add3179dd360a3cd8ca41e449e9facc\n",
       " \tlastModified: 2022-07-01T11:49:57.000Z\n",
       " \ttags: ['arxiv:1705.04146', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large-scale dataset consisting of approximately 100,000 algebraic word problems.\n",
       " The solution to each question is explained step-by-step using natural language.\n",
       " This data is used to train a program generation model that learns to generate the explanation,\n",
       " while generating the program that solves the question.\n",
       " \tcitation: @InProceedings{ACL,\n",
       " title = {Program induction by rationale generation: Learning to solve and explain algebraic word problems},\n",
       " authors={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},\n",
       " year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'aqua-rat', 'pretty_name': 'Algebra Question Answering with Rationales'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1020\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: aqua-rat\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: aquamuse\n",
       " \tsha: 3af65587b3ba88ad450fa43315f6b2304e9ce35c\n",
       " \tlastModified: 2022-07-01T11:49:57.000Z\n",
       " \ttags: ['arxiv:2010.12694', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|natural_questions', 'source_datasets:extended|other-Common-Crawl', 'source_datasets:original', 'task_categories:other', 'task_categories:question-answering', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:extractive-qa', 'task_ids:other-other-query-based-multi-document-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: AQuaMuSe is a novel scalable approach to automatically mine dual query based multi-document summarization datasets for extractive and abstractive summaries using question answering dataset (Google Natural Questions) and large document corpora (Common Crawl)\n",
       " \tcitation: @misc{kulkarni2020aquamuse,\n",
       "       title={AQuaMuSe: Automatically Generating Datasets for Query-Based Multi-Document Summarization},\n",
       "       author={Sayali Kulkarni and Sheide Chammas and Wan Zhu and Fei Sha and Eugene Ie},\n",
       "       year={2020},\n",
       "       eprint={2010.12694},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|natural_questions', 'extended|other-Common-Crawl', 'original'], 'task_categories': ['other', 'question-answering', 'text2text-generation'], 'task_ids': ['abstractive-qa', 'extractive-qa', 'other-other-query-based-multi-document-summarization'], 'paperswithcode_id': 'aquamuse', 'pretty_name': 'AQuaMuSe'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 223\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: aquamuse\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ar_cov19\n",
       " \tsha: 9b8dc3b44e62a9b119bf47b964aa08640e45d332\n",
       " \tlastModified: 2022-07-01T11:50:00.000Z\n",
       " \ttags: ['arxiv:2004.05861', 'annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-data-mining']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ArCOV-19 is an Arabic COVID-19 Twitter dataset that covers the period from 27th of January till 30th of April 2020. ArCOV-19 is designed to enable research under several domains including natural language processing, information retrieval, and social computing, among others\n",
       " \tcitation: @article{haouari2020arcov19,\n",
       "   title={ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation Networks},\n",
       "   author={Fatima Haouari and Maram Hasanain and Reem Suwaileh and Tamer Elsayed},\n",
       "   journal={arXiv preprint arXiv:2004.05861},\n",
       "   year={2020}\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-data-mining'], 'paperswithcode_id': 'arcov-19', 'pretty_name': 'ArCOV19'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 367\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: arcov-19\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ar_res_reviews\n",
       " \tsha: 4793c6709de91e6d918b12dbb05cd01da9250ce8\n",
       " \tlastModified: 2022-07-01T11:50:00.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset of 8364 restaurant reviews scrapped from qaym.com in Arabic for sentiment analysis\n",
       " \tcitation: @InProceedings{10.1007/978-3-319-18117-2_2,\n",
       " author=\"ElSahar, Hady\n",
       " and El-Beltagy, Samhaa R.\",\n",
       " editor=\"Gelbukh, Alexander\",\n",
       " title=\"Building Large Arabic Multi-domain Resources for Sentiment Analysis\",\n",
       " booktitle=\"Computational Linguistics and Intelligent Text Processing\",\n",
       " year=\"2015\",\n",
       " publisher=\"Springer International Publishing\",\n",
       " address=\"Cham\",\n",
       " pages=\"23--34\",\n",
       " isbn=\"978-3-319-18117-2\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'ArRestReviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 380\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ar_sarcasm\n",
       " \tsha: 6d7ecde6c602de3beeb5b65296e0e7d1a8fa46e9\n",
       " \tlastModified: 2022-07-01T11:50:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-semeval_2017', 'source_datasets:extended|other-astd', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-sarcasm-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ArSarcasm is a new Arabic sarcasm detection dataset.\n",
       " The dataset was created using previously available Arabic sentiment analysis datasets (SemEval 2017 and ASTD)\n",
       "  and adds sarcasm and dialect labels to them. The dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.\n",
       " \tcitation: @inproceedings{abu-farha-magdy-2020-arabic,\n",
       "     title = \"From {A}rabic Sentiment Analysis to Sarcasm Detection: The {A}r{S}arcasm Dataset\",\n",
       "     author = \"Abu Farha, Ibrahim  and Magdy, Walid\",\n",
       "     booktitle = \"Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resource Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.osact-1.5\",\n",
       "     pages = \"32--39\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-51-1\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-semeval_2017', 'extended|other-astd'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification', 'text-classification-other-sarcasm-detection'], 'paperswithcode_id': None, 'pretty_name': 'ArSarcasm'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 376\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arabic_billion_words\n",
       " \tsha: 58f00c77e7891ca9cbdb17e5a1f113c26c9fa0fa\n",
       " \tlastModified: 2022-07-01T11:50:01.000Z\n",
       " \ttags: ['arxiv:1611.04033', 'annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:Alittihad', 'configs:Almasryalyoum', 'configs:Almustaqbal', 'configs:Alqabas', 'configs:Echoroukonline', 'configs:Ryiadh', 'configs:Sabanews', 'configs:SaudiYoum', 'configs:Techreen', 'configs:Youm7']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Abu El-Khair Corpus is an Arabic text corpus, that includes more than five million newspaper articles.\n",
       " It contains over a billion and a half words in total, out of which, there are about three million unique words.\n",
       " The corpus is encoded with two types of encoding, namely: UTF-8, and Windows CP-1256.\n",
       " Also it was marked with two mark-up languages, namely: SGML, and XML.\n",
       " \tcitation: @article{el20161,\n",
       "   title={1.5 billion words arabic corpus},\n",
       "   author={El-Khair, Ibrahim Abu},\n",
       "   journal={arXiv preprint arXiv:1611.04033},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Arabic Billion Words', 'configs': ['Alittihad', 'Almasryalyoum', 'Almustaqbal', 'Alqabas', 'Echoroukonline', 'Ryiadh', 'Sabanews', 'SaudiYoum', 'Techreen', 'Youm7']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2051\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arabic_pos_dialect\n",
       " \tsha: 52c4aedd44055f48d6b78eb738aa3e8e9c34697b\n",
       " \tlastModified: 2022-07-19T12:41:58.000Z\n",
       " \ttags: ['arxiv:1708.05891', 'annotations_creators:expert-generated', 'language_creators:found', 'language:ar', 'license:apache-2.0', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:extended', 'task_categories:token-classification', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Dialectal Arabic Datasets contain four dialects of Arabic, Etyptian (EGY), Levantine (LEV), Gulf (GLF), and Maghrebi (MGR). Each dataset consists of a set of 350 manually segmented and POS tagged tweets.\n",
       " \tcitation: @InProceedings{DARWISH18.562,  author = {Kareem Darwish ,Hamdy Mubarak ,Ahmed Abdelali ,Mohamed Eldesouki ,Younes Samih ,Randah Alharbi ,Mohammed Attia ,Walid Magdy and Laura Kallmeyer},\n",
       " title = {Multi-Dialect Arabic POS Tagging: A CRF Approach},\n",
       " booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n",
       " year = {2018},\n",
       " month = {may},\n",
       " date = {7-12},\n",
       " location = {Miyazaki, Japan},\n",
       " editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and Hélène Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},\n",
       " publisher = {European Language Resources Association (ELRA)},\n",
       " address = {Paris, France},\n",
       " isbn = {979-10-95546-00-9},\n",
       " language = {english}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['apache-2.0'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['extended'], 'task_categories': ['token-classification'], 'task_ids': ['part-of-speech'], 'paperswithcode_id': None, 'pretty_name': 'Arabic POS Dialect'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 932\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arabic_speech_corpus\n",
       " \tsha: f7b05810b4c532909dcf9a3c62e0a22a8c72da8e\n",
       " \tlastModified: 2022-07-28T10:33:41.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:ar', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton.\n",
       " The corpus was recorded in south Levantine Arabic\n",
       " (Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\n",
       " Note that in order to limit the required storage for preparing this dataset, the audio\n",
       " is stored in the .flac format and is not converted to a float32 array. To convert, the audio\n",
       " file to a float32 array, please make use of the `.map()` function as follows:\n",
       " \n",
       " \n",
       " ```python\n",
       " import soundfile as sf\n",
       " \n",
       " def map_to_array(batch):\n",
       "     speech_array, _ = sf.read(batch[\"file\"])\n",
       "     batch[\"speech\"] = speech_array\n",
       "     return batch\n",
       " \n",
       " dataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n",
       " ```\n",
       " \tcitation: @phdthesis{halabi2016modern,\n",
       "   title={Modern standard Arabic phonetics for speech synthesis},\n",
       "   author={Halabi, Nawar},\n",
       "   year={2016},\n",
       "   school={University of Southampton}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Arabic Speech Corpus', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['ar'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'arabic-speech-corpus', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'train-eval-index': [{'config': 'clean', 'task': 'automatic-speech-recognition', 'task_id': 'speech_recognition', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'file': 'path', 'text': 'text'}, 'metrics': [{'type': 'wer', 'name': 'WER'}, {'type': 'cer', 'name': 'CER'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 363\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: arabic-speech-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arcd\n",
       " \tsha: c92c37f1b93c974346e11d3c3d5cfd01f088f3a2\n",
       " \tlastModified: 2022-07-27T14:38:34.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'language_bcp47:ar-SA', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.\n",
       " \tcitation: @inproceedings{mozannar-etal-2019-neural,\n",
       "     title = {Neural {A}rabic Question Answering},\n",
       "     author = {Mozannar, Hussein  and Maamary, Elie  and El Hajal, Karl  and Hajj, Hazem},\n",
       "     booktitle = {Proceedings of the Fourth Arabic Natural Language Processing Workshop},\n",
       "     month = {aug},\n",
       "     year = {2019},\n",
       "     address = {Florence, Italy},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     url = {https://www.aclweb.org/anthology/W19-4612},\n",
       "     doi = {10.18653/v1/W19-4612},\n",
       "     pages = {108--118},\n",
       "     abstract = {This paper tackles the problem of open domain factual Arabic question answering (QA) using Wikipedia as our knowledge source. This constrains the answer of any question to be a span of text in Wikipedia. Open domain QA for Arabic entails three challenges: annotated QA datasets in Arabic, large scale efficient information retrieval and machine reading comprehension. To deal with the lack of Arabic QA datasets we present the Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions posed by crowdworkers on Wikipedia articles, and a machine translation of the Stanford Question Answering Dataset (Arabic-SQuAD). Our system for open domain question answering in Arabic (SOQAL) is based on two components: (1) a document retriever using a hierarchical TF-IDF approach and (2) a neural reading comprehension model using the pre-trained bi-directional transformer BERT. Our experiments on ARCD indicate the effectiveness of our approach with our BERT-based reader achieving a 61.3 F1 score, and our open domain system SOQAL achieving a 27.6 F1 score.}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar'], 'language_bcp47': ['ar-SA'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'arcd', 'pretty_name': 'ARCD'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 848\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: arcd\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arsentd_lev\n",
       " \tsha: 51a6e1700110612fabd36023857c947f7e2523c3\n",
       " \tlastModified: 2022-08-11T14:03:46.000Z\n",
       " \ttags: ['arxiv:1906.01830', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:apc', 'language:ajp', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Arabic Sentiment Twitter Dataset for Levantine dialect (ArSenTD-LEV) contains 4,000 tweets written in Arabic and equally retrieved from Jordan, Lebanon, Palestine and Syria.\n",
       " \tcitation: @article{ArSenTDLev2018,\n",
       " title={ArSentD-LEV: A Multi-Topic Corpus for Target-based Sentiment Analysis in Arabic Levantine Tweets},\n",
       " author={Baly, Ramy, and Khaddaj, Alaa and Hajj, Hazem and El-Hajj, Wassim and Bashir Shaban, Khaled},\n",
       " journal={OSACT3},\n",
       " pages={},\n",
       " year={2018}}\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['apc', 'ajp'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification', 'topic-classification'], 'paperswithcode_id': 'arsentd-lev', 'pretty_name': 'ArSenTD-LEV'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 393\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: arsentd-lev\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: art\n",
       " \tsha: 03910779c92ee43a547ce25457a0d31c390c7321\n",
       " \tlastModified: 2022-09-15T17:12:40.000Z\n",
       " \ttags: ['arxiv:1908.05739', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:multiple-choice', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:text-classification-other-abductive-natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: the Abductive Natural Language Inference Dataset from AI2\n",
       " \tcitation: @InProceedings{anli,\n",
       "   author = {Chandra, Bhagavatula and Ronan, Le Bras and Chaitanya, Malaviya and Keisuke, Sakaguchi and Ari, Holtzman\n",
       "     and Hannah, Rashkin and Doug, Downey and Scott, Wen-tau Yih and Yejin, Choi},\n",
       "   title = {Abductive Commonsense Reasoning},\n",
       "   year = {2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Abductive Reasoning in narrative Text', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice', 'text-classification'], 'task_ids': ['natural-language-inference', 'text-classification-other-abductive-natural-language-inference'], 'paperswithcode_id': 'art-dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 820\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: art-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: arxiv_dataset\n",
       " \tsha: 51ca1c241a80346d8c71949a897b766bb3a992fd\n",
       " \tlastModified: 2022-08-11T12:57:18.000Z\n",
       " \ttags: ['arxiv:1905.00075', 'annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation', 'task_categories:summarization', 'task_categories:text-retrieval', 'task_ids:document-retrieval', 'task_ids:entity-linking-retrieval', 'task_ids:explanation-generation', 'task_ids:fact-checking-retrieval', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.\n",
       " \tcitation: @misc{clement2019arxiv,\n",
       "     title={On the Use of ArXiv as a Dataset},\n",
       "     author={Colin B. Clement and Matthew Bierbaum and Kevin P. O'Keeffe and Alexander A. Alemi},\n",
       "     year={2019},\n",
       "     eprint={1905.00075},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.IR}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation', 'summarization', 'text-retrieval'], 'task_ids': ['document-retrieval', 'entity-linking-retrieval', 'explanation-generation', 'fact-checking-retrieval', 'text-simplification'], 'paperswithcode_id': None, 'pretty_name': 'arXiv Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 448\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ascent_kb\n",
       " \tsha: 15822918ba08b737e11e7d9f2eaa022c1f47deef\n",
       " \tlastModified: 2022-07-01T11:50:05.000Z\n",
       " \ttags: ['arxiv:2011.00905', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-knowledge-base']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains 8.9M commonsense assertions extracted by the Ascent pipeline (https://ascent.mpi-inf.mpg.de/).\n",
       " \tcitation: @InProceedings{nguyen2021www,\n",
       "   title={Advanced Semantics for Commonsense Knowledge Extraction},\n",
       "   author={Nguyen, Tuan-Phong and Razniewski, Simon and Weikum, Gerhard},\n",
       "   year={2021},\n",
       "   booktitle={The Web Conference 2021},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-knowledge-base'], 'paperswithcode_id': 'ascentkb', 'pretty_name': 'Ascent KB'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 525\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: ascentkb\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: aslg_pc12\n",
       " \tsha: 0cf0fe7090a0df148f620c2285a5c3e12bbd6256\n",
       " \tlastModified: 2022-08-25T13:44:00.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language:ase', 'language:en', 'language_creators:found', 'license:cc-by-nc-4.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large synthetic collection of parallel English and ASL-Gloss texts.\n",
       " There are two string features: text, and gloss.\n",
       " \tcitation: @inproceedings{othman2012english,\n",
       "   title={English-asl gloss parallel corpus 2012: Aslg-pc12},\n",
       "   author={Othman, Achraf and Jemni, Mohamed},\n",
       "   booktitle={5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon LREC},\n",
       "   year={2012}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language': ['ase', 'en'], 'language_creators': ['found'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['translation'], 'pretty_name': 'English-ASL Gloss Parallel Corpus 2012', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'aslg-pc12'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 423\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: aslg-pc12\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: asnq\n",
       " \tsha: 8326a8fa8cfea8b615943178a144134e8332f75a\n",
       " \tlastModified: 2022-08-29T16:13:39.000Z\n",
       " \ttags: ['arxiv:1911.04118', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:extended|natural_questions', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ASNQ is a dataset for answer sentence selection derived from\n",
       " Google's Natural Questions (NQ) dataset (Kwiatkowski et al. 2019).\n",
       " \n",
       " Each example contains a question, candidate sentence, label indicating whether or not\n",
       " the sentence answers the question, and two additional features --\n",
       " sentence_in_long_answer and short_answer_in_sentence indicating whether ot not the\n",
       " candidate sentence is contained in the long_answer and if the short_answer is in the candidate sentence.\n",
       " \n",
       " For more details please see\n",
       " https://arxiv.org/pdf/1911.04118.pdf\n",
       " \n",
       " and\n",
       " \n",
       " https://research.google/pubs/pub47761/\n",
       " \tcitation: @article{garg2019tanda,\n",
       "     title={TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection},\n",
       "     author={Siddhant Garg and Thuy Vu and Alessandro Moschitti},\n",
       "     year={2019},\n",
       "     eprint={1911.04118},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Answer Sentence Natural Questions (ASNQ)', 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|natural_questions'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'asnq'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 609\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: asnq\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: asset\n",
       " \tsha: adcf74bea819f5a79d9de25cf479fe7c8f6d7bc5\n",
       " \tlastModified: 2022-07-01T11:50:08.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'source_datasets:extended|other-turkcorpus', 'task_categories:text-classification', 'task_categories:text2text-generation', 'task_ids:text-classification-other-simplification-evaluation', 'task_ids:text-simplification', 'configs:ratings', 'configs:simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ASSET is a dataset for evaluating Sentence Simplification systems with multiple rewriting transformations,\n",
       " as described in \"ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations\".\n",
       " The corpus is composed of 2000 validation and 359 test original sentences that were each simplified 10 times by different annotators.\n",
       " The corpus also contains human judgments of meaning preservation, fluency and simplicity for the outputs of several automatic text simplification systems.\n",
       " \tcitation: @inproceedings{alva-manchego-etal-2020-asset,\n",
       "     title = \"{ASSET}: {A} Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations\",\n",
       "     author = \"Alva-Manchego, Fernando  and\n",
       "       Martin, Louis  and\n",
       "       Bordes, Antoine  and\n",
       "       Scarton, Carolina  and\n",
       "       Sagot, Benoit  and\n",
       "       Specia, Lucia\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.424\",\n",
       "     pages = \"4668--4679\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original', 'extended|other-turkcorpus'], 'task_categories': ['text-classification', 'text2text-generation'], 'task_ids': ['text-classification-other-simplification-evaluation', 'text-simplification'], 'paperswithcode_id': 'asset', 'pretty_name': 'ASSET', 'configs': ['ratings', 'simplification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1147\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: asset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: assin\n",
       " \tsha: ef61fd8a80fc1aa50237f45d43bc2e0b47e8bc88\n",
       " \tlastModified: 2022-07-01T11:50:08.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The ASSIN (Avaliação de Similaridade Semântica e INferência textual) corpus is a corpus annotated with pairs of sentences written in\n",
       " Portuguese that is suitable for the  exploration of textual entailment and paraphrasing classifiers. The corpus contains pairs of sentences\n",
       " extracted from news articles written in European Portuguese (EP) and Brazilian Portuguese (BP), obtained from Google News Portugal\n",
       " and Brazil, respectively. To create the corpus, the authors started by collecting a set of news articles describing the\n",
       " same event (one news article from Google News Portugal and another from Google News Brazil) from Google News.\n",
       " Then, they employed Latent Dirichlet Allocation (LDA) models to retrieve pairs of similar sentences between sets of news\n",
       " articles that were grouped together around the same topic. For that, two LDA models were trained (for EP and for BP)\n",
       " on external and large-scale collections of unannotated news articles from Portuguese and Brazilian news providers, respectively.\n",
       " Then, the authors defined a lower and upper threshold for the sentence similarity score of the retrieved pairs of sentences,\n",
       " taking into account that high similarity scores correspond to sentences that contain almost the same content (paraphrase candidates),\n",
       " and low similarity scores correspond to sentences that are very different in content from each other (no-relation candidates).\n",
       " From the collection of pairs of sentences obtained at this stage, the authors performed some manual grammatical corrections\n",
       " and discarded some of the pairs wrongly retrieved. Furthermore, from a preliminary analysis made to the retrieved sentence pairs\n",
       " the authors noticed that the number of contradictions retrieved during the previous stage was very low. Additionally, they also\n",
       " noticed that event though paraphrases are not very frequent, they occur with some frequency in news articles. Consequently,\n",
       " in contrast with the majority of the currently available corpora for other languages, which consider as labels “neutral”, “entailment”\n",
       " and “contradiction” for the task of RTE, the authors of the ASSIN corpus decided to use as labels “none”, “entailment” and “paraphrase”.\n",
       " Finally, the manual annotation of pairs of sentences was performed by human annotators. At least four annotators were randomly\n",
       " selected to annotate each pair of sentences, which is done in two steps: (i) assigning a semantic similarity label (a score between 1 and 5,\n",
       " from unrelated to very similar); and (ii) providing an entailment label (one sentence entails the other, sentences are paraphrases,\n",
       " or no relation). Sentence pairs where at least three annotators do not agree on the entailment label were considered controversial\n",
       " and thus discarded from the gold standard annotations. The full dataset has 10,000 sentence pairs, half of which in Brazilian Portuguese\n",
       " and half in European Portuguese. Either language variant has 2,500 pairs for training, 500 for validation and 2,000 for testing.\n",
       " \tcitation: @inproceedings{fonseca2016assin,\n",
       "   title={ASSIN: Avaliacao de similaridade semantica e inferencia textual},\n",
       "   author={Fonseca, E and Santos, L and Criscuolo, Marcelo and Aluisio, S},\n",
       "   booktitle={Computational Processing of the Portuguese Language-12th International Conference, Tomar, Portugal},\n",
       "   pages={13--15},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'ASSIN', 'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'natural-language-inference', 'semantic-similarity-scoring'], 'paperswithcode_id': 'assin'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 926\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: assin\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: assin2\n",
       " \tsha: 8812737314ce4d02e78c1c5d3a5d71f3a55661f7\n",
       " \tlastModified: 2022-07-01T11:50:08.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The ASSIN 2 corpus is composed of rather simple sentences. Following the procedures of SemEval 2014 Task 1.\n",
       " The training and validation data are composed, respectively, of 6,500 and 500 sentence pairs in Brazilian Portuguese,\n",
       " annotated for entailment and semantic similarity. Semantic similarity values range from 1 to 5, and text entailment\n",
       " classes are either entailment or none. The test data are composed of approximately 3,000 sentence pairs with the same\n",
       " annotation. All data were manually annotated.\n",
       " \tcitation: @inproceedings{real2020assin,\n",
       "   title={The assin 2 shared task: a quick overview},\n",
       "   author={Real, Livy and Fonseca, Erick and Oliveira, Hugo Goncalo},\n",
       "   booktitle={International Conference on Computational Processing of the Portuguese Language},\n",
       "   pages={406--412},\n",
       "   year={2020},\n",
       "   organization={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'natural-language-inference', 'semantic-similarity-scoring'], 'paperswithcode_id': 'assin2', 'pretty_name': 'ASSIN 2'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 461\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: assin2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: atomic\n",
       " \tsha: 3efd2bb85958a42f4837cb6e5302acb2a0ef82e7\n",
       " \tlastModified: 2022-07-01T11:50:08.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-common-sense-if-then-reasoning']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset provides the template sentences and\n",
       " relationships defined in the ATOMIC common sense dataset. There are\n",
       " three splits - train, test, and dev.\n",
       " \n",
       " From the authors.\n",
       " \n",
       " Disclaimer/Content warning: the events in atomic have been\n",
       " automatically extracted from blogs, stories and books written at\n",
       " various times. The events might depict violent or problematic actions,\n",
       " which we left in the corpus for the sake of learning the (probably\n",
       " negative but still important) commonsense implications associated with\n",
       " the events. We removed a small set of truly out-dated events, but\n",
       " might have missed some so please email us (msap@cs.washington.edu) if\n",
       " you have any concerns.\n",
       " \tcitation: @article{Sap2019ATOMICAA,\n",
       "   title={ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning},\n",
       "   author={Maarten Sap and Ronan Le Bras and Emily Allaway and Chandra Bhagavatula and Nicholas Lourie and Hannah Rashkin and Brendan Roof and Noah A. Smith and Yejin Choi},\n",
       "   journal={ArXiv},\n",
       "   year={2019},\n",
       "   volume={abs/1811.00146}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'ATOMIC', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-common-sense-if-then-reasoning'], 'paperswithcode_id': 'atomic'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 357\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: atomic\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: autshumato\n",
       " \tsha: 955327dc5e55a46f9d3b94a95a21a0d691f07671\n",
       " \tlastModified: 2022-08-11T12:57:18.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'language:tn', 'language:ts', 'language:zu', 'license:cc-by-2.5', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:autshumato-en-tn', 'configs:autshumato-en-ts', 'configs:autshumato-en-ts-manual', 'configs:autshumato-en-zu', 'configs:autshumato-tn', 'configs:autshumato-ts']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multilingual information access is stipulated in the South African constitution. In practise, this\n",
       " is hampered by a lack of resources and capacity to perform the large volumes of translation\n",
       " work required to realise multilingual information access. One of the aims of the Autshumato\n",
       " project is to develop machine translation systems for three South African languages pairs.\n",
       " \tcitation: @article{groenewald2010processing,\n",
       "   title={Processing parallel text corpora for three South African language pairs in the Autshumato project},\n",
       "   author={Groenewald, Hendrik J and du Plooy, Liza},\n",
       "   journal={AfLaT 2010},\n",
       "   pages={27},\n",
       "   year={2010}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en', 'tn', 'ts', 'zu'], 'license': ['cc-by-2.5'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'autshumato', 'configs': ['autshumato-en-tn', 'autshumato-en-ts', 'autshumato-en-ts-manual', 'autshumato-en-zu', 'autshumato-tn', 'autshumato-ts']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1176\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: babi_qa\n",
       " \tsha: a98d44e3e228695954ba2431399dee01184c2e46\n",
       " \tlastModified: 2022-07-01T11:50:11.000Z\n",
       " \ttags: ['arxiv:1502.05698', 'arxiv:1511.06931', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-chained-qa', 'configs:en-10k-qa1', 'configs:en-10k-qa10', 'configs:en-10k-qa11', 'configs:en-10k-qa12', 'configs:en-10k-qa13', 'configs:en-10k-qa14', 'configs:en-10k-qa15', 'configs:en-10k-qa16', 'configs:en-10k-qa17', 'configs:en-10k-qa18', 'configs:en-10k-qa19', 'configs:en-10k-qa2', 'configs:en-10k-qa20', 'configs:en-10k-qa3', 'configs:en-10k-qa4', 'configs:en-10k-qa5', 'configs:en-10k-qa6', 'configs:en-10k-qa7', 'configs:en-10k-qa8', 'configs:en-10k-qa9', 'configs:en-qa1', 'configs:en-qa10', 'configs:en-qa11', 'configs:en-qa12', 'configs:en-qa13', 'configs:en-qa14', 'configs:en-qa15', 'configs:en-qa16', 'configs:en-qa17', 'configs:en-qa18', 'configs:en-qa19', 'configs:en-qa2', 'configs:en-qa20', 'configs:en-qa3', 'configs:en-qa4', 'configs:en-qa5', 'configs:en-qa6', 'configs:en-qa7', 'configs:en-qa8', 'configs:en-qa9', 'configs:en-valid-10k-qa1', 'configs:en-valid-10k-qa10', 'configs:en-valid-10k-qa11', 'configs:en-valid-10k-qa12', 'configs:en-valid-10k-qa13', 'configs:en-valid-10k-qa14', 'configs:en-valid-10k-qa15', 'configs:en-valid-10k-qa16', 'configs:en-valid-10k-qa17', 'configs:en-valid-10k-qa18', 'configs:en-valid-10k-qa19', 'configs:en-valid-10k-qa2', 'configs:en-valid-10k-qa20', 'configs:en-valid-10k-qa3', 'configs:en-valid-10k-qa4', 'configs:en-valid-10k-qa5', 'configs:en-valid-10k-qa6', 'configs:en-valid-10k-qa7', 'configs:en-valid-10k-qa8', 'configs:en-valid-10k-qa9', 'configs:en-valid-qa1', 'configs:en-valid-qa10', 'configs:en-valid-qa11', 'configs:en-valid-qa12', 'configs:en-valid-qa13', 'configs:en-valid-qa14', 'configs:en-valid-qa15', 'configs:en-valid-qa16', 'configs:en-valid-qa17', 'configs:en-valid-qa18', 'configs:en-valid-qa19', 'configs:en-valid-qa2', 'configs:en-valid-qa20', 'configs:en-valid-qa3', 'configs:en-valid-qa4', 'configs:en-valid-qa5', 'configs:en-valid-qa6', 'configs:en-valid-qa7', 'configs:en-valid-qa8', 'configs:en-valid-qa9', 'configs:hn-10k-qa1', 'configs:hn-10k-qa10', 'configs:hn-10k-qa11', 'configs:hn-10k-qa12', 'configs:hn-10k-qa13', 'configs:hn-10k-qa14', 'configs:hn-10k-qa15', 'configs:hn-10k-qa16', 'configs:hn-10k-qa17', 'configs:hn-10k-qa18', 'configs:hn-10k-qa19', 'configs:hn-10k-qa2', 'configs:hn-10k-qa20', 'configs:hn-10k-qa3', 'configs:hn-10k-qa4', 'configs:hn-10k-qa5', 'configs:hn-10k-qa6', 'configs:hn-10k-qa7', 'configs:hn-10k-qa8', 'configs:hn-10k-qa9', 'configs:hn-qa1', 'configs:hn-qa10', 'configs:hn-qa11', 'configs:hn-qa12', 'configs:hn-qa13', 'configs:hn-qa14', 'configs:hn-qa15', 'configs:hn-qa16', 'configs:hn-qa17', 'configs:hn-qa18', 'configs:hn-qa19', 'configs:hn-qa2', 'configs:hn-qa20', 'configs:hn-qa3', 'configs:hn-qa4', 'configs:hn-qa5', 'configs:hn-qa6', 'configs:hn-qa7', 'configs:hn-qa8', 'configs:hn-qa9', 'configs:shuffled-10k-qa1', 'configs:shuffled-10k-qa10', 'configs:shuffled-10k-qa11', 'configs:shuffled-10k-qa12', 'configs:shuffled-10k-qa13', 'configs:shuffled-10k-qa14', 'configs:shuffled-10k-qa15', 'configs:shuffled-10k-qa16', 'configs:shuffled-10k-qa17', 'configs:shuffled-10k-qa18', 'configs:shuffled-10k-qa19', 'configs:shuffled-10k-qa2', 'configs:shuffled-10k-qa20', 'configs:shuffled-10k-qa3', 'configs:shuffled-10k-qa4', 'configs:shuffled-10k-qa5', 'configs:shuffled-10k-qa6', 'configs:shuffled-10k-qa7', 'configs:shuffled-10k-qa8', 'configs:shuffled-10k-qa9', 'configs:shuffled-qa1', 'configs:shuffled-qa10', 'configs:shuffled-qa11', 'configs:shuffled-qa12', 'configs:shuffled-qa13', 'configs:shuffled-qa14', 'configs:shuffled-qa15', 'configs:shuffled-qa16', 'configs:shuffled-qa17', 'configs:shuffled-qa18', 'configs:shuffled-qa19', 'configs:shuffled-qa2', 'configs:shuffled-qa20', 'configs:shuffled-qa3', 'configs:shuffled-qa4', 'configs:shuffled-qa5', 'configs:shuffled-qa6', 'configs:shuffled-qa7', 'configs:shuffled-qa8', 'configs:shuffled-qa9']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The (20) QA bAbI tasks are a set of proxy tasks that evaluate reading\n",
       " comprehension via question answering. Our tasks measure understanding\n",
       " in several ways: whether a system is able to answer questions via chaining facts,\n",
       " simple induction, deduction and many more. The tasks are designed to be prerequisites\n",
       " for any system that aims to be capable of conversing with a human.\n",
       " The aim is to classify these tasks into skill sets,so that researchers\n",
       " can identify (and then rectify)the failings of their systems.\n",
       " \tcitation: @misc{weston2015aicomplete,\n",
       "       title={Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n",
       "       author={Jason Weston and Antoine Bordes and Sumit Chopra and Alexander M. Rush and Bart van Merriënboer and Armand Joulin and Tomas Mikolov},\n",
       "       year={2015},\n",
       "       eprint={1502.05698},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.AI}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'BabiQa', 'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-chained-qa'], 'paperswithcode_id': 'babi-1', 'configs': ['en-10k-qa1', 'en-10k-qa10', 'en-10k-qa11', 'en-10k-qa12', 'en-10k-qa13', 'en-10k-qa14', 'en-10k-qa15', 'en-10k-qa16', 'en-10k-qa17', 'en-10k-qa18', 'en-10k-qa19', 'en-10k-qa2', 'en-10k-qa20', 'en-10k-qa3', 'en-10k-qa4', 'en-10k-qa5', 'en-10k-qa6', 'en-10k-qa7', 'en-10k-qa8', 'en-10k-qa9', 'en-qa1', 'en-qa10', 'en-qa11', 'en-qa12', 'en-qa13', 'en-qa14', 'en-qa15', 'en-qa16', 'en-qa17', 'en-qa18', 'en-qa19', 'en-qa2', 'en-qa20', 'en-qa3', 'en-qa4', 'en-qa5', 'en-qa6', 'en-qa7', 'en-qa8', 'en-qa9', 'en-valid-10k-qa1', 'en-valid-10k-qa10', 'en-valid-10k-qa11', 'en-valid-10k-qa12', 'en-valid-10k-qa13', 'en-valid-10k-qa14', 'en-valid-10k-qa15', 'en-valid-10k-qa16', 'en-valid-10k-qa17', 'en-valid-10k-qa18', 'en-valid-10k-qa19', 'en-valid-10k-qa2', 'en-valid-10k-qa20', 'en-valid-10k-qa3', 'en-valid-10k-qa4', 'en-valid-10k-qa5', 'en-valid-10k-qa6', 'en-valid-10k-qa7', 'en-valid-10k-qa8', 'en-valid-10k-qa9', 'en-valid-qa1', 'en-valid-qa10', 'en-valid-qa11', 'en-valid-qa12', 'en-valid-qa13', 'en-valid-qa14', 'en-valid-qa15', 'en-valid-qa16', 'en-valid-qa17', 'en-valid-qa18', 'en-valid-qa19', 'en-valid-qa2', 'en-valid-qa20', 'en-valid-qa3', 'en-valid-qa4', 'en-valid-qa5', 'en-valid-qa6', 'en-valid-qa7', 'en-valid-qa8', 'en-valid-qa9', 'hn-10k-qa1', 'hn-10k-qa10', 'hn-10k-qa11', 'hn-10k-qa12', 'hn-10k-qa13', 'hn-10k-qa14', 'hn-10k-qa15', 'hn-10k-qa16', 'hn-10k-qa17', 'hn-10k-qa18', 'hn-10k-qa19', 'hn-10k-qa2', 'hn-10k-qa20', 'hn-10k-qa3', 'hn-10k-qa4', 'hn-10k-qa5', 'hn-10k-qa6', 'hn-10k-qa7', 'hn-10k-qa8', 'hn-10k-qa9', 'hn-qa1', 'hn-qa10', 'hn-qa11', 'hn-qa12', 'hn-qa13', 'hn-qa14', 'hn-qa15', 'hn-qa16', 'hn-qa17', 'hn-qa18', 'hn-qa19', 'hn-qa2', 'hn-qa20', 'hn-qa3', 'hn-qa4', 'hn-qa5', 'hn-qa6', 'hn-qa7', 'hn-qa8', 'hn-qa9', 'shuffled-10k-qa1', 'shuffled-10k-qa10', 'shuffled-10k-qa11', 'shuffled-10k-qa12', 'shuffled-10k-qa13', 'shuffled-10k-qa14', 'shuffled-10k-qa15', 'shuffled-10k-qa16', 'shuffled-10k-qa17', 'shuffled-10k-qa18', 'shuffled-10k-qa19', 'shuffled-10k-qa2', 'shuffled-10k-qa20', 'shuffled-10k-qa3', 'shuffled-10k-qa4', 'shuffled-10k-qa5', 'shuffled-10k-qa6', 'shuffled-10k-qa7', 'shuffled-10k-qa8', 'shuffled-10k-qa9', 'shuffled-qa1', 'shuffled-qa10', 'shuffled-qa11', 'shuffled-qa12', 'shuffled-qa13', 'shuffled-qa14', 'shuffled-qa15', 'shuffled-qa16', 'shuffled-qa17', 'shuffled-qa18', 'shuffled-qa19', 'shuffled-qa2', 'shuffled-qa20', 'shuffled-qa3', 'shuffled-qa4', 'shuffled-qa5', 'shuffled-qa6', 'shuffled-qa7', 'shuffled-qa8', 'shuffled-qa9']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2610\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: babi-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: banking77\n",
       " \tsha: a96f25987a8b64a262b12310c0c73c2df7442025\n",
       " \tlastModified: 2022-07-01T11:50:11.000Z\n",
       " \ttags: ['arxiv:2003.04807', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BANKING77 dataset provides a very fine-grained set of intents in a banking domain.\n",
       " It comprises 13,083 customer service queries labeled with 77 intents.\n",
       " It focuses on fine-grained single-domain intent detection.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'multi-class-classification'], 'paperswithcode_id': None, 'pretty_name': 'BANKING77', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2123\n",
       " \tlikes: 14\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bbaw_egyptian\n",
       " \tsha: e87afc8eec1273d3647eb5ac27316aa47ae9b8db\n",
       " \tlastModified: 2022-07-27T14:38:33.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:de', 'language:egy', 'language:en', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:extended|wikipedia', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset comprises parallel sentences of hieroglyphic encodings, transcription and translation\n",
       " as used in the paper Multi-Task Modeling of Phonographic Languages: Translating Middle Egyptian\n",
       " Hieroglyph. The data triples are extracted from the digital corpus of Egyptian texts compiled by\n",
       " the project \"Strukturen und Transformationen des Wortschatzes der ägyptischen Sprache\".\n",
       " \tcitation: @misc{OPUS4-2919,\n",
       " title  = {Teilauszug der Datenbank des Vorhabens \"Strukturen und Transformationen des Wortschatzes der {\\\"a}gyptischen Sprache\" vom Januar 2018},\n",
       " institution = {Akademienvorhaben Strukturen und Transformationen des Wortschatzes der {\\\"a}gyptischen Sprache. Text- und Wissenskultur im alten {\\\"A}gypten},\n",
       " type = {other},\n",
       " year = {2018},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['de', 'egy', 'en'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'BbawEgyptian'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 410\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bbc_hindi_nli\n",
       " \tsha: cf1cf459050ce174d4b621c32d54675ac34e1c9e\n",
       " \tlastModified: 2022-07-01T11:50:12.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:hi', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|bbc__hindi_news_classification', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is used to train models for Natural Language Inference Tasks in Low-Resource Languages like Hindi.\n",
       " \tcitation:     @inproceedings{uppal-etal-2020-two,\n",
       "     title = \"Two-Step Classification using Recasted Data for Low Resource Settings\",\n",
       "     author = \"Uppal, Shagun  and\n",
       "       Gupta, Vivek  and\n",
       "       Swaminathan, Avinash  and\n",
       "       Zhang, Haimin  and\n",
       "       Mahata, Debanjan  and\n",
       "       Gosangi, Rakesh  and\n",
       "       Shah, Rajiv Ratn  and\n",
       "       Stent, Amanda\",\n",
       "     booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\",\n",
       "     month = dec,\n",
       "     year = \"2020\",\n",
       "     address = \"Suzhou, China\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.aacl-main.71\",\n",
       "     pages = \"706--719\",\n",
       "     abstract = \"An NLP model{'}s ability to reason should be independent of language. Previous works utilize Natural Language Inference (NLI) to understand the reasoning ability of models, mostly focusing on high resource languages like English. To address scarcity of data in low-resource languages such as Hindi, we use data recasting to create NLI datasets for four existing text classification datasets. Through experiments, we show that our recasted dataset is devoid of statistical irregularities and spurious patterns. We further study the consistency in predictions of the textual entailment models and propose a consistency regulariser to remove pairwise-inconsistencies in predictions. We propose a novel two-step classification method which uses textual-entailment predictions for classification task. We further improve the performance by using a joint-objective for classification and textual entailment. We therefore highlight the benefits of data recasting and improvements on classification performance using our approach with supporting experimental results.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['hi'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|bbc__hindi_news_classification'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': None, 'pretty_name': 'BBC Hindi NLI Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 362\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bc2gm_corpus\n",
       " \tsha: ec3cb85823949ffca596629cfadb39ac6dbfa76e\n",
       " \tlastModified: 2022-07-01T11:50:12.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Nineteen teams presented results for the Gene Mention Task at the BioCreative II Workshop.\n",
       " In this task participants designed systems to identify substrings in sentences corresponding to gene name mentions.\n",
       " A variety of different methods were used and the results varied with a highest achieved F1 score of 0.8721.\n",
       " Here we present brief descriptions of all the methods used and a statistical analysis of the results.\n",
       " We also demonstrate that, by combining the results from all submissions, an F score of 0.9066 is feasible,\n",
       " and furthermore that the best result makes use of the lowest scoring submissions.\n",
       " \n",
       " For more details, see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559986/\n",
       " \n",
       " The original dataset can be downloaded from: https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-ii-corpus/\n",
       " This dataset has been converted to CoNLL format for NER using the following tool: https://github.com/spyysalo/standoff2conll\n",
       " \tcitation: @article{smith2008overview,\n",
       "         title={Overview of BioCreative II gene mention recognition},\n",
       "         author={Smith, Larry and Tanabe, Lorraine K and nee Ando, Rie Johnson and Kuo, Cheng-Ju and Chung, I-Fang and Hsu, Chun-Nan and Lin, Yu-Shi and Klinger, Roman and Friedrich, Christoph M and Ganchev, Kuzman and others},\n",
       "         journal={Genome biology},\n",
       "         volume={9},\n",
       "         number={S2},\n",
       "         pages={S2},\n",
       "         year={2008},\n",
       "         publisher={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Bc2GmCorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 454\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: beans\n",
       " \tsha: 658da52d67424946032833d60e3a26884402cc1e\n",
       " \tlastModified: 2022-07-01T11:50:12.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:image-classification', 'task_ids:multi-class-image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Beans is a dataset of images of beans taken in the field using smartphone\n",
       " cameras. It consists of 3 classes: 2 disease classes and the healthy class.\n",
       " Diseases depicted include Angular Leaf Spot and Bean Rust. Data was annotated\n",
       " by experts from the National Crops Resources Research Institute (NaCRRI) in\n",
       " Uganda and collected by the Makerere AI research lab.\n",
       " \tcitation: @ONLINE {beansdata,\n",
       "     author=\"Makerere AI Lab\",\n",
       "     title=\"Bean disease dataset\",\n",
       "     month=\"January\",\n",
       "     year=\"2020\",\n",
       "     url=\"https://github.com/AI-Lab-Makerere/ibean/\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Beans', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['image-classification'], 'task_ids': ['multi-class-image-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6786\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: best2009\n",
       " \tsha: 38c1d5f069f41102188a095e5d06728a8940fe41\n",
       " \tlastModified: 2022-07-01T11:50:15.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:token-classification-other-word-tokenization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: `best2009` is a Thai word-tokenization dataset from encyclopedia, novels, news and articles by\n",
       " [NECTEC](https://www.nectec.or.th/) (148,995/2,252 lines of train/test). It was created for\n",
       " [BEST 2010: Word Tokenization Competition](https://thailang.nectec.or.th/archive/indexa290.html?q=node/10).\n",
       " The test set answers are not provided publicly.\n",
       " \tcitation: @inproceedings{kosawat2009best,\n",
       "   title={BEST 2009: Thai word segmentation software contest},\n",
       "   author={Kosawat, Krit and Boriboon, Monthika and Chootrakool, Patcharika and Chotimongkol, Ananlada and Klaithin, Supon and Kongyoung, Sarawoot and Kriengket, Kanyanut and Phaholphinyo, Sitthaa and Purodakananda, Sumonmas and Thanakulwarapas, Tipraporn and others},\n",
       "   booktitle={2009 Eighth International Symposium on Natural Language Processing},\n",
       "   pages={83--88},\n",
       "   year={2009},\n",
       "   organization={IEEE}\n",
       " }\n",
       " @inproceedings{boriboon2009best,\n",
       "   title={Best corpus development and analysis},\n",
       "   author={Boriboon, Monthika and Kriengket, Kanyanut and Chootrakool, Patcharika and Phaholphinyo, Sitthaa and Purodakananda, Sumonmas and Thanakulwarapas, Tipraporn and Kosawat, Krit},\n",
       "   booktitle={2009 International Conference on Asian Language Processing},\n",
       "   pages={322--327},\n",
       "   year={2009},\n",
       "   organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['token-classification-other-word-tokenization'], 'paperswithcode_id': None, 'pretty_name': 'best2009'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 353\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bianet\n",
       " \tsha: 0b27574855bb01027fb5426907b39bcd84ae0f0d\n",
       " \tlastModified: 2022-07-01T11:50:15.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:ku', 'language:tr', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation', 'configs:en-to-ku', 'configs:en-to-tr', 'configs:en_to_ku', 'configs:en_to_tr', 'configs:ku-to-tr', 'configs:ku_to_tr']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel news corpus in Turkish, Kurdish and English.\n",
       " Bianet collects 3,214 Turkish articles with their sentence-aligned Kurdish or English translations from the Bianet online newspaper.\n",
       " 3 languages, 3 bitexts\n",
       " total number of files: 6\n",
       " total number of tokens: 2.25M\n",
       " total number of sentence fragments: 0.14M\n",
       " \tcitation: @InProceedings{ATAMAN18.6,\n",
       "   author = {Duygu Ataman},\n",
       "   title = {Bianet: A Parallel News Corpus in Turkish, Kurdish and English},\n",
       "   booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n",
       "   year = {2018},\n",
       "   month = {may},\n",
       "   date = {7-12},\n",
       "   location = {Miyazaki, Japan},\n",
       "   editor = {Jinhua Du and Mihael Arcan and Qun Liu and Hitoshi Isahara},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   address = {Paris, France},\n",
       "   isbn = {979-10-95546-15-3},\n",
       "   language = {english}\n",
       "   }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'ku', 'tr'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'bianet', 'pretty_name': 'Bianet', 'configs': ['en-to-ku', 'en-to-tr', 'en_to_ku', 'en_to_tr', 'ku-to-tr', 'ku_to_tr']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 683\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: bianet\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bible_para\n",
       " \tsha: 127196b27369cf7ae6063a97cd2bb990aa737f00\n",
       " \tlastModified: 2022-08-11T14:03:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:acu', 'language:af', 'language:agr', 'language:ake', 'language:am', 'language:amu', 'language:ar', 'language:bg', 'language:bsn', 'language:cak', 'language:ceb', 'language:ch', 'language:chq', 'language:chr', 'language:cjp', 'language:cni', 'language:cop', 'language:crp', 'language:cs', 'language:da', 'language:de', 'language:dik', 'language:dje', 'language:djk', 'language:dop', 'language:ee', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:gbi', 'language:gd', 'language:gu', 'language:gv', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:jak', 'language:jiv', 'language:kab', 'language:kbh', 'language:kek', 'language:kn', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:mam', 'language:mi', 'language:ml', 'language:mr', 'language:my', 'language:ne', 'language:nhg', 'language:nl', 'language:no', 'language:ojb', 'language:pck', 'language:pes', 'language:pl', 'language:plt', 'language:pot', 'language:ppk', 'language:pt', 'language:quc', 'language:quw', 'language:ro', 'language:rom', 'language:ru', 'language:shi', 'language:sk', 'language:sl', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:ss', 'language:sv', 'language:syr', 'language:te', 'language:th', 'language:tl', 'language:tmh', 'language:tr', 'language:uk', 'language:usp', 'language:vi', 'language:wal', 'language:wo', 'language:xh', 'language:zh', 'language:zu', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n",
       " \n",
       " 102 languages, 5,148 bitexts\n",
       " total number of files: 107\n",
       " total number of tokens: 56.43M\n",
       " total number of sentence fragments: 2.84M\n",
       " \tcitation: OPUS and A massively parallel corpus: the Bible in 100 languages, Christos Christodoulopoulos and Mark Steedman, *Language Resources and Evaluation*, 49 (2)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['acu', 'af', 'agr', 'ake', 'am', 'amu', 'ar', 'bg', 'bsn', 'cak', 'ceb', 'ch', 'chq', 'chr', 'cjp', 'cni', 'cop', 'crp', 'cs', 'da', 'de', 'dik', 'dje', 'djk', 'dop', 'ee', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fi', 'fr', 'gbi', 'gd', 'gu', 'gv', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jak', 'jiv', 'kab', 'kbh', 'kek', 'kn', 'ko', 'la', 'lt', 'lv', 'mam', 'mi', 'ml', 'mr', 'my', 'ne', 'nhg', 'nl', 'no', 'ojb', 'pck', 'pes', 'pl', 'plt', 'pot', 'ppk', 'pt', 'quc', 'quw', 'ro', 'rom', 'ru', 'shi', 'sk', 'sl', 'sn', 'so', 'sq', 'sr', 'ss', 'sv', 'syr', 'te', 'th', 'tl', 'tmh', 'tr', 'uk', 'usp', 'vi', 'wal', 'wo', 'xh', 'zh', 'zu'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'BiblePara'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1193\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: big_patent\n",
       " \tsha: 96be916016a135fdf7e6cbd049a6d366f3bb2e47\n",
       " \tlastModified: 2022-07-01T11:50:16.000Z\n",
       " \ttags: ['arxiv:1906.03741', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-patent-summarization', 'configs:a', 'configs:all', 'configs:b', 'configs:c', 'configs:d', 'configs:e', 'configs:f', 'configs:g', 'configs:h', 'configs:y']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BIGPATENT, consisting of 1.3 million records of U.S. patent documents\n",
       " along with human written abstractive summaries.\n",
       " Each US patent application is filed under a Cooperative Patent Classification\n",
       " (CPC) code. There are nine such classification categories:\n",
       " A (Human Necessities), B (Performing Operations; Transporting),\n",
       " C (Chemistry; Metallurgy), D (Textiles; Paper), E (Fixed Constructions),\n",
       " F (Mechanical Engineering; Lightning; Heating; Weapons; Blasting),\n",
       " G (Physics), H (Electricity), and\n",
       " Y (General tagging of new or cross-sectional technology)\n",
       " There are two features:\n",
       "   - description: detailed description of patent.\n",
       "   - abstract: Patent abastract.\n",
       " \tcitation: @misc{sharma2019bigpatent,\n",
       "     title={BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization},\n",
       "     author={Eva Sharma and Chen Li and Lu Wang},\n",
       "     year={2019},\n",
       "     eprint={1906.03741},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-patent-summarization'], 'paperswithcode_id': 'bigpatent', 'pretty_name': 'Big Patent', 'configs': ['a', 'all', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'y']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2075\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: bigpatent\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: billsum\n",
       " \tsha: cfa8939d989dd3c1015c335926f1a3e4ae7fb995\n",
       " \tlastModified: 2022-08-22T13:41:33.000Z\n",
       " \ttags: ['arxiv:1910.00523', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-bills-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BillSum, summarization of US Congressional and California state bills.\n",
       " \n",
       " There are several features:\n",
       "   - text: bill text.\n",
       "   - summary: summary of the bills.\n",
       "   - title: title of the bills.\n",
       " features for us bills. ca bills does not have.\n",
       "   - text_len: number of chars in text.\n",
       "   - sum_len: number of chars in summary.\n",
       " \tcitation: @misc{kornilova2019billsum,\n",
       "     title={BillSum: A Corpus for Automatic Summarization of US Legislation},\n",
       "     author={Anastassia Kornilova and Vlad Eidelman},\n",
       "     year={2019},\n",
       "     eprint={1910.00523},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-bills-summarization'], 'paperswithcode_id': 'billsum', 'pretty_name': 'BillSum', 'train-eval-index': [{'config': 'default', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'summary': 'target'}, 'metrics': [{'type': 'rouge', 'name': 'Rouge'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2071\n",
       " \tlikes: 10\n",
       " \tpaperswithcode_id: billsum\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bing_coronavirus_query_set\n",
       " \tsha: d5d7feaf5bf736b4c09d90ffe72a25f847c259be\n",
       " \tlastModified: 2022-08-11T12:57:18.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset was curated from the Bing search logs (desktop users only) over the period of Jan 1st, 2020 – (Current Month - 1). Only searches that were issued many times by multiple users were included. The dataset includes queries from all over the world that had an intent related to the Coronavirus or Covid-19. In some cases this intent is explicit in the query itself (e.g., “Coronavirus updates Seattle”), in other cases it is implicit , e.g. “Shelter in place”. The implicit intent of search queries (e.g., “Toilet paper”) was extracted using random walks on the click graph as outlined in this paper by Microsoft Research. All personal data were removed.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': None, 'pretty_name': 'BingCoronavirusQuerySet'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 560\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: biomrc\n",
       " \tsha: fce7ffb2e6e24a61de95c453009af1750d12ba46\n",
       " \tlastModified: 2022-07-01T11:50:19.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). Experiments show that simple heuristics do not perform well on the new dataset and that two neural MRC models that had been tested on BIOREAD perform much better on BIOMRC, indicating that the new dataset is indeed less noisy or at least that its task is more feasible. Non-expert human performance is also higher on the new dataset compared to BIOREAD, and biomedical experts perform even better. We also introduce a new BERT-based MRC model, the best version of which substantially outperforms all other methods tested, reaching or surpassing the accuracy of biomedical experts in some experiments. We make the new dataset available in three different sizes, also releasing our code, and providing a leaderboard.\n",
       " \tcitation: @inproceedings{pappas-etal-2020-biomrc,\n",
       "     title = \"{B}io{MRC}: A Dataset for Biomedical Machine Reading Comprehension\",\n",
       "     author = \"Pappas, Dimitris  and\n",
       "       Stavropoulos, Petros  and\n",
       "       Androutsopoulos, Ion  and\n",
       "       McDonald, Ryan\",\n",
       "     booktitle = \"Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.bionlp-1.15\",\n",
       "     pages = \"140--149\",\n",
       "     abstract = \"We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). Experiments show that simple heuristics do not perform well on the new dataset and that two neural MRC models that had been tested on BIOREAD perform much better on BIOMRC, indicating that the new dataset is indeed less noisy or at least that its task is more feasible. Non-expert human performance is also higher on the new dataset compared to BIOREAD, and biomedical experts perform even better. We also introduce a new BERT-based MRC model, the best version of which substantially outperforms all other methods tested, reaching or surpassing the accuracy of biomedical experts in some experiments. We make the new dataset available in three different sizes, also releasing our code, and providing a leaderboard.\",\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'biomrc', 'pretty_name': 'BIOMRC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1337\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: biomrc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: biosses\n",
       " \tsha: b15c9809fe7811651c5c2d9e177ce3be69340a3f\n",
       " \tlastModified: 2022-07-01T11:50:19.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BIOSSES is a benchmark dataset for biomedical sentence similarity estimation. The dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset containing articles from the biomedical domain. The sentence pairs were evaluated by five different human experts that judged their similarity and gave scores ranging from 0 (no relation) to 4 (equivalent).\n",
       " \tcitation: @article{souganciouglu2017biosses,\n",
       "   title={BIOSSES: a semantic sentence similarity estimation system for the biomedical domain},\n",
       "   author={So{\\\\u{g}}anc{\\\\i}o{\\\\u{g}}lu, Gizem and {\\\\\"O}zt{\\\\\"u}rk, Hakime and {\\\\\"O}zg{\\\\\"u}r, Arzucan},\n",
       "   journal={Bioinformatics},\n",
       "   volume={33},\n",
       "   number={14},\n",
       "   pages={i49--i58},\n",
       "   year={2017},\n",
       "   publisher={Oxford University Press}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': 'biosses', 'pretty_name': 'BIOSSES'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 717\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: biosses\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: blbooks\n",
       " \tsha: 617ead0499e2e6c13c537556b3ff633d3f5ba298\n",
       " \tlastModified: 2022-07-27T14:38:33.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:machine-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:nl', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:other', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:other-other-digital-humanities-research']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset comprising of text created by OCR from the 49,455 digitised books, equating to 65,227 volumes (25+ million pages), published between c. 1510 - c. 1900.\n",
       " The books cover a wide range of subject areas including philosophy, history, poetry and literature.\n",
       " \tcitation: @misc{BritishLibraryBooks2021,\n",
       "   author = {British Library Labs},\n",
       "   title = {Digitised Books. c. 1510 - c. 1900. JSONL (OCR derived text + metadata)},\n",
       "   year = {2021},\n",
       "   publisher = {British Library},\n",
       "   howpublished={https://doi.org/10.23636/r7w6-zy15}\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['machine-generated'], 'language': ['de', 'en', 'es', 'fr', 'it', 'nl'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'British Library Books', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'other'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'other-other-digital-humanities-research']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 860\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: blbooksgenre\n",
       " \tsha: 59b4fde7e4f4bac2a0cec4a7849431bc23cea391\n",
       " \tlastModified: 2022-07-27T14:38:33.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:de', 'language:en', 'language:fr', 'language:nl', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:topic-classification', 'task_ids:multi-label-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:annotated_raw', 'configs:raw', 'configs:title_genre_classifiction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains metadata for resources belonging to the British Library’s digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\n",
       " This metadata has been extracted from British Library catalogue records.\n",
       " The metadata held within our main catalogue is updated regularly.\n",
       " This metadata dataset should be considered a snapshot of this metadata.\n",
       " \tcitation: @misc{british library_genre,\n",
       " title={ 19th Century Books - metadata with additional crowdsourced annotations},\n",
       " url={https://doi.org/10.23636/BKHQ-0312},\n",
       " author={{British Library} and  Morris, Victoria and van Strien, Daniel and Tolfo, Giorgia and Afric, Lora and Robertson, Stewart and Tiney, Patricia and Dogterom, Annelies and Wollner, Ildi},\n",
       " year={2021}}\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['de', 'en', 'fr', 'nl'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'British Library Books Genre', 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification', 'text-generation', 'fill-mask'], 'task_ids': ['topic-classification', 'multi-label-classification', 'language-modeling', 'masked-language-modeling'], 'configs': ['annotated_raw', 'raw', 'title_genre_classifiction']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1032\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: blended_skill_talk\n",
       " \tsha: fb07aa673c2af8cd651a4c74af0a47106d728339\n",
       " \tlastModified: 2022-07-01T11:50:22.000Z\n",
       " \ttags: ['arxiv:2004.08449', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:conversational', 'task_ids:dialogue-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset of 7k conversations explicitly designed to exhibit multiple conversation modes: displaying personality, having empathy, and demonstrating knowledge.\n",
       " \tcitation: @misc{smith2020evaluating,\n",
       "     title={Can You Put it All Together: Evaluating Conversational Agents' Ability to Blend Skills},\n",
       "     author={Eric Michael Smith and Mary Williamson and Kurt Shuster and Jason Weston and Y-Lan Boureau},\n",
       "     year={2020},\n",
       "     eprint={2004.08449},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'BlendedSkillTalk', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['conversational'], 'task_ids': ['dialogue-generation'], 'paperswithcode_id': 'blended-skill-talk'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1021\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: blended-skill-talk\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: blimp\n",
       " \tsha: 6c2b0d452a8e2dc0bd53522a9872961a053d7130\n",
       " \tlastModified: 2022-07-01T11:50:23.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:acceptability-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BLiMP is a challenge set for evaluating what language models (LMs) know about\n",
       " major grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\n",
       " containing 1000 minimal pairs isolating specific contrasts in syntax,\n",
       " morphology, or semantics. The data is automatically generated according to\n",
       " expert-crafted grammars.\n",
       " \tcitation: @article{warstadt2019blimp,\n",
       "   title={BLiMP: A Benchmark of Linguistic Minimal Pairs for English},\n",
       "   author={Warstadt, Alex and Parrish, Alicia and Liu, Haokun and Mohananey, Anhad and Peng, Wei, and Wang, Sheng-Fu and Bowman, Samuel R},\n",
       "   journal={arXiv preprint arXiv:1912.00582},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'BLiMP', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['acceptability-classification'], 'paperswithcode_id': 'blimp'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9196552\n",
       " \tlikes: 10\n",
       " \tpaperswithcode_id: blimp\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: blog_authorship_corpus\n",
       " \tsha: ce43ef243123ea7bac39b3b779c7261d86a79966\n",
       " \tlastModified: 2022-07-01T11:50:23.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.\n",
       " \n",
       " Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry and astrological sign. (All are labeled for gender and age but for many, industry and/or sign is marked as unknown.)\n",
       " \n",
       " All bloggers included in the corpus fall into one of three age groups:\n",
       " - 8240 \"10s\" blogs (ages 13-17),\n",
       " - 8086 \"20s\" blogs (ages 23-27),\n",
       " - 2994 \"30s\" blogs (ages 33-47).\n",
       " \n",
       " For each age group there are an equal number of male and female bloggers.\n",
       " \n",
       " Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label urllink.\n",
       " \n",
       " The corpus may be freely used for non-commercial research purposes.\n",
       " \tcitation: @inproceedings{schler2006effects,\n",
       "     title={Effects of age and gender on blogging.},\n",
       "     author={Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W},\n",
       "     booktitle={AAAI spring symposium: Computational approaches to analyzing weblogs},\n",
       "     volume={6},\n",
       "     pages={199--205},\n",
       "     year={2006}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'blog-authorship-corpus', 'pretty_name': 'Blog Authorship Corpus', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 387\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: blog-authorship-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bn_hate_speech\n",
       " \tsha: 6f5bfda6c27d3c0edaf26cde3a1228f1dea47596\n",
       " \tlastModified: 2022-07-01T11:50:23.000Z\n",
       " \ttags: ['arxiv:2004.07807', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language:bn', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Bengali Hate Speech Dataset is a collection of Bengali articles collected from Bengali news articles,\n",
       " news dump of Bengali TV channels, books, blogs, and social media. Emphasis was placed on Facebook pages and\n",
       " newspaper sources because they attract close to 50 million followers and is a common source of opinions\n",
       " and hate speech. The raw text corpus contains 250 million articles and the full dataset is being prepared\n",
       " for release. This is a subset of the full dataset.\n",
       " \n",
       " This dataset was prepared for hate-speech text classification benchmark on Bengali, an under-resourced language.\n",
       " \tcitation: @misc{karim2020classification,\n",
       "       title={Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network},\n",
       "       author={Md. Rezaul Karim and Bharathi Raja Chakravarthi and John P. McCrae and Michael Cochez},\n",
       "       year={2020},\n",
       "       eprint={2004.07807},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found'], 'language': ['bn'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-topic-classification'], 'paperswithcode_id': 'bengali-hate-speech', 'pretty_name': 'Bengali Hate Speech Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 360\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: bengali-hate-speech\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bnl_newspapers\n",
       " \tsha: 8d714de2e2197d9599b6eba7da53fba7b484f562\n",
       " \tlastModified: 2022-07-01T11:50:23.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'language:da', 'language:de', 'language:fi', 'language:fr', 'language:lb', 'language:nl', 'language:pt', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Digitised historic newspapers from the Bibliothèque nationale (BnL) - the National Library of Luxembourg.\n",
       " \tcitation: @misc{bnl_newspapers,\n",
       " title={Historical Newspapers},\n",
       " url={https://data.bnl.lu/data/historical-newspapers/},\n",
       " author={ Bibliothèque nationale du Luxembourg},\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar', 'da', 'de', 'fi', 'fr', 'lb', 'nl', 'pt'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'BnL Historical Newspapers', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 382\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bookcorpus\n",
       " \tsha: 171899da6d11f31b4385b5c281416630bde8662c\n",
       " \tlastModified: 2022-09-30T10:21:50.000Z\n",
       " \ttags: ['arxiv:2105.05241', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story.This work aims to align books to their movie releases in order to providerich descriptive explanations for visual content that go semantically farbeyond the captions available in current datasets. \\\n",
       " \tcitation: @InProceedings{Zhu_2015_ICCV,\n",
       "     title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},\n",
       "     author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},\n",
       "     booktitle = {The IEEE International Conference on Computer Vision (ICCV)},\n",
       "     month = {December},\n",
       "     year = {2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'BookCorpus', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'bookcorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 16202\n",
       " \tlikes: 24\n",
       " \tpaperswithcode_id: bookcorpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bookcorpusopen\n",
       " \tsha: d9857c617993a33ca287095f180749c2588a35c6\n",
       " \tlastModified: 2022-07-01T11:50:25.000Z\n",
       " \ttags: ['arxiv:2105.05241', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story.\n",
       " This version of bookcorpus has 17868 dataset items (books). Each item contains two fields: title and text. The title is the name of the book (just the file name) while text contains unprocessed book text. The bookcorpus has been prepared by Shawn Presser and is generously hosted by The-Eye. The-Eye is a non-profit, community driven platform dedicated to the archiving and long-term preservation of any and all data including but by no means limited to... websites, books, games, software, video, audio, other digital-obscura and ideas.\n",
       " \tcitation: @InProceedings{Zhu_2015_ICCV,\n",
       "     title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},\n",
       "     author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},\n",
       "     booktitle = {The IEEE International Conference on Computer Vision (ICCV)},\n",
       "     month = {December},\n",
       "     year = {2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'BookCorpusOpen', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'bookcorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1171\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: bookcorpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: boolq\n",
       " \tsha: 85c5a88b8d033c5eb0762fc6bc81a81a454d3f25\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: BoolQ is a question answering dataset for yes/no questions containing 15942 examples. These questions are naturally\n",
       " occurring ---they are generated in unprompted and unconstrained settings.\n",
       " Each example is a triplet of (question, passage, answer), with the title of the page as optional additional context.\n",
       " The text-pair classification setup is similar to existing natural language inference tasks.\n",
       " \tcitation: @inproceedings{clark2019boolq,\n",
       "   title =     {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},\n",
       "   author =    {Clark, Christopher and Lee, Kenton and Chang, Ming-Wei, and Kwiatkowski, Tom and Collins, Michael, and Toutanova, Kristina},\n",
       "   booktitle = {NAACL},\n",
       "   year =      {2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'boolq', 'pretty_name': 'BoolQ'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2885\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: boolq\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bprec\n",
       " \tsha: ba9b55e020c20a60b9511790ca453c187ba68e45\n",
       " \tlastModified: 2022-07-01T11:50:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:pl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:entity-linking-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset consisting of Polish language texts annotated to recognize brand-product relations.\n",
       " \tcitation: @inproceedings{inproceedings,\n",
       " author = {Janz, Arkadiusz and Kopociński, Łukasz and Piasecki, Maciej and Pluwak, Agnieszka},\n",
       " year = {2020},\n",
       " month = {05},\n",
       " pages = {},\n",
       " title = {Brand-Product Relation Extraction Using Heterogeneous Vector Space Representations}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['pl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['entity-linking-retrieval'], 'paperswithcode_id': None, 'pretty_name': 'bprec'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1002\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: break_data\n",
       " \tsha: 3d9f3dc319329c5bebb2ac76f229d41f419ee3f6\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:open-domain-abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Break is a human annotated dataset of natural language questions and their Question Decomposition Meaning Representations\n",
       " (QDMRs). Break consists of 83,978 examples sampled from 10 question answering datasets over text, images and databases.\n",
       " This repository contains the Break dataset along with information on the exact data format.\n",
       " \tcitation: @article{Wolfson2020Break,\n",
       "   title={Break It Down: A Question Understanding Benchmark},\n",
       "   author={Wolfson, Tomer and Geva, Mor and Gupta, Ankit and Gardner, Matt and Goldberg, Yoav and Deutch, Daniel and Berant, Jonathan},\n",
       "   journal={Transactions of the Association for Computational Linguistics},\n",
       "   year={2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['open-domain-abstractive-qa'], 'paperswithcode_id': 'break', 'pretty_name': 'BREAK'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2188\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: break\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: brwac\n",
       " \tsha: 746bb9a147ec48c8b4a1d08116d64678eb6659e0\n",
       " \tlastModified: 2022-07-01T11:50:27.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework,\n",
       " which was made public for research purposes. The current corpus version, released in January 2017, is composed by\n",
       " 3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available\n",
       " solely for academic research purposes, and you agreed not to use it for any commercial applications.\n",
       " Manually download at https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC\n",
       " \tcitation: @inproceedings{wagner2018brwac,\n",
       "   title={The brwac corpus: A new open resource for brazilian portuguese},\n",
       "   author={Wagner Filho, Jorge A and Wilkens, Rodrigo and Idiart, Marco and Villavicencio, Aline},\n",
       "   booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'brwac', 'pretty_name': 'BrWaC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 360\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: brwac\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bsd_ja_en\n",
       " \tsha: 4d4def68b0d2ee12e0eb01960d465cac221c9357\n",
       " \tlastModified: 2022-07-01T11:50:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'language:ja', 'license:cc-by-nc-sa-4.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-business-conversations-translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is the Business Scene Dialogue (BSD) dataset,\n",
       " a Japanese-English parallel corpus containing written conversations\n",
       " in various business scenarios.\n",
       " \n",
       " The dataset was constructed in 3 steps:\n",
       "   1) selecting business scenes,\n",
       "   2) writing monolingual conversation scenarios according to the selected scenes, and\n",
       "   3) translating the scenarios into the other language.\n",
       " \n",
       " Half of the monolingual scenarios were written in Japanese\n",
       " and the other half were written in English.\n",
       " \n",
       " Fields:\n",
       " - id: dialogue identifier\n",
       " - no: sentence pair number within a dialogue\n",
       " - en_speaker: speaker name in English\n",
       " - ja_speaker: speaker name in Japanese\n",
       " - en_sentence: sentence in English\n",
       " - ja_sentence: sentence in Japanese\n",
       " - original_language: language in which monolingual scenario was written\n",
       " - tag: scenario\n",
       " - title: scenario title\n",
       " \tcitation: @inproceedings{rikters-etal-2019-designing,\n",
       "     title = \"Designing the Business Conversation Corpus\",\n",
       "     author = \"Rikters, Matīss  and\n",
       "       Ri, Ryokan  and\n",
       "       Li, Tong  and\n",
       "       Nakazawa, Toshiaki\",\n",
       "     booktitle = \"Proceedings of the 6th Workshop on Asian Translation\",\n",
       "     month = nov,\n",
       "     year = \"2019\",\n",
       "     address = \"Hong Kong, China\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D19-5204\",\n",
       "     doi = \"10.18653/v1/D19-5204\",\n",
       "     pages = \"54--61\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en', 'ja'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-business-conversations-translation'], 'paperswithcode_id': 'business-scene-dialogue', 'pretty_name': 'Business Scene Dialogue'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 347\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: business-scene-dialogue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: bswac\n",
       " \tsha: 74e5a06ffd9b0669d310c10011a8ec0b1b9eb6af\n",
       " \tlastModified: 2022-07-01T11:50:29.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:bs', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Bosnian web corpus bsWaC was built by crawling the .ba top-level domain in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Bosnian vs. Croatian vs. Serbian).\n",
       " \n",
       " Version 1.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 1.1 contains newer and better linguistic annotations.\n",
       " \tcitation: @misc{11356/1062,\n",
       "  title = {Bosnian web corpus {bsWaC} 1.1},\n",
       "  author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n",
       "  url = {http://hdl.handle.net/11356/1062},\n",
       "  note = {Slovenian language resource repository {CLARIN}.{SI}},\n",
       "  copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n",
       "  year = {2016} }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['bs'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'BsWac'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 353\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: c3\n",
       " \tsha: 717778e15385934bae3f5f7dd715673cc2ecad8c\n",
       " \tlastModified: 2022-08-11T12:57:18.000Z\n",
       " \ttags: ['arxiv:1904.09679', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:zh', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Machine reading comprehension tasks require a machine reader to answer questions relevant to the given document. In this paper, we present the first free-form multiple-Choice Chinese machine reading Comprehension dataset (C^3), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chinese-as-a-second-language examinations.\n",
       " We present a comprehensive analysis of the prior knowledge (i.e., linguistic, domain-specific, and general world knowledge) needed for these real-world problems. We implement rule-based and popular neural methods and find that there is still a significant performance gap between the best performing model (68.5%) and human readers (96.0%), especially on problems that require prior knowledge. We further study the effects of distractor plausibility and data augmentation based on translated relevant datasets for English on model performance. We expect C^3 to present great challenges to existing systems as answering 86.8% of questions requires both knowledge within and beyond the accompanying document, and we hope that C^3 can serve as a platform to study how to leverage various kinds of prior knowledge to better understand a given written or orally oriented text.\n",
       " \tcitation: @article{sun2019investigating,\n",
       "   title={Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension},\n",
       "   author={Sun, Kai and Yu, Dian and Yu, Dong and Cardie, Claire},\n",
       "   journal={Transactions of the Association for Computational Linguistics},\n",
       "   year={2020},\n",
       "   url={https://arxiv.org/abs/1904.09679v3}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['zh'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'c3', 'pretty_name': 'C3'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 515\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: c3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: c4\n",
       " \tsha: 32530158cf0e3f6d6951e3720fca36066d783738\n",
       " \tlastModified: 2022-07-01T12:43:16.000Z\n",
       " \ttags: ['arxiv:1910.10683', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:odc-by', 'multilinguality:multilingual', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A colossal, cleaned version of Common Crawl's web crawl corpus.\n",
       " \n",
       " Based on Common Crawl dataset: \"https://commoncrawl.org\".\n",
       " \n",
       " This is the processed version of Google's C4 dataset by AllenAI.\n",
       " \tcitation: @article{2019t5,\n",
       "     author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n",
       "     title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n",
       "     journal = {arXiv e-prints},\n",
       "     year = {2019},\n",
       "     archivePrefix = {arXiv},\n",
       "     eprint = {1910.10683},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'C4', 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['odc-by'], 'multilinguality': ['multilingual'], 'size_categories': ['100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'c4'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 15390\n",
       " \tlikes: 25\n",
       " \tpaperswithcode_id: c4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cail2018\n",
       " \tsha: 1c56ef207871b569020e43914e74119caa10964f\n",
       " \tlastModified: 2022-07-01T11:50:30.000Z\n",
       " \ttags: ['arxiv:1807.02478', 'annotations_creators:found', 'language_creators:found', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-judgement-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In this paper, we introduce Chinese AI and Law challenge dataset (CAIL2018),\n",
       " the first large-scale Chinese legal dataset for judgment prediction. CAIL contains more than 2.6 million\n",
       " criminal cases published by the Supreme People's Court of China, which are several times larger than other\n",
       " datasets in existing works on judgment prediction. Moreover, the annotations of judgment results are more\n",
       " detailed and rich. It consists of applicable law articles, charges, and prison terms, which are expected\n",
       " to be inferred according to the fact descriptions of cases. For comparison, we implement several conventional\n",
       " text classification baselines for judgment prediction and experimental results show that it is still a\n",
       " challenge for current models to predict the judgment results of legal cases, especially on prison terms.\n",
       " To help the researchers make improvements on legal judgment prediction.\n",
       " \tcitation: @misc{xiao2018cail2018,\n",
       "       title={CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction},\n",
       "       author={Chaojun Xiao and Haoxi Zhong and Zhipeng Guo and Cunchao Tu and Zhiyuan Liu and Maosong Sun and Yansong Feng and Xianpei Han and Zhen Hu and Heng Wang and Jianfeng Xu},\n",
       "       year={2018},\n",
       "       eprint={1807.02478},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-judgement-prediction'], 'paperswithcode_id': 'chinese-ai-and-law-cail-2018', 'pretty_name': 'CAIL 2018'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 361\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: chinese-ai-and-law-cail-2018\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: caner\n",
       " \tsha: 3f3ebbf411f9a787c5828b94ee8ad30ba2b297b0\n",
       " \tlastModified: 2022-07-01T11:50:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Classical Arabic Named Entity Recognition corpus as a new corpus of tagged data that can be useful for handling the issues in recognition of Arabic named entities.\n",
       " \tcitation: @article{article,\n",
       " author = {Salah, Ramzi and Zakaria, Lailatul},\n",
       " year = {2018},\n",
       " month = {12},\n",
       " pages = {},\n",
       " title = {BUILDING THE CLASSICAL ARABIC NAMED ENTITY RECOGNITION CORPUS (CANERCORPUS)},\n",
       " volume = {96},\n",
       " journal = {Journal of Theoretical and Applied Information Technology}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'CANER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 823\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: capes\n",
       " \tsha: aa4120e70890c3ed14adf19d8eaa6e09c9bd5cca\n",
       " \tlastModified: 2022-07-01T11:50:31.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:pt', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation', 'task_ids:translaiton-other-theses-translation', 'task_ids:translaiton-other-dissertation-abstracts-translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of theses and dissertations abstracts in English and Portuguese were collected from the CAPES website (Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) - Brazil. The corpus is sentence aligned for all language pairs. Approximately 240,000 documents were collected and aligned using the Hunalign algorithm.\n",
       " \tcitation: @inproceedings{soares2018parallel,\n",
       "   title={A Parallel Corpus of Theses and Dissertations Abstracts},\n",
       "   author={Soares, Felipe and Yamashita, Gabrielli Harumi and Anzanello, Michel Jose},\n",
       "   booktitle={International Conference on Computational Processing of the Portuguese Language},\n",
       "   pages={345--352},\n",
       "   year={2018},\n",
       "   organization={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'pt'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translaiton-other-theses-translation', 'translaiton-other-dissertation-abstracts-translation'], 'paperswithcode_id': 'capes', 'pretty_name': 'CAPES'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 350\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: capes\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: casino\n",
       " \tsha: e4d8f8cc03e6efb9833c2efaacff0d553853405c\n",
       " \tlastModified: 2022-07-27T14:38:33.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:conversational', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets such as Deal or No Deal and Craigslist Bargain. Each dialogue consists of rich meta-data including participant demographics, personality, and their subjective evaluation of the negotiation in terms of satisfaction and opponent likeness.\n",
       " \tcitation: @inproceedings{chawla2021casino,\n",
       "   title={CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems},\n",
       "   author={Chawla, Kushal and Ramirez, Jaysa and Clever, Rene and Lucas, Gale and May, Jonathan and Gratch, Jonathan},\n",
       "   booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},\n",
       "   pages={3167--3185},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'pretty_name': 'Campsite Negotiation Dialogues', 'paperswithcode_id': 'casino'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 357\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: casino\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: catalonia_independence\n",
       " \tsha: f211f2fbdc88032e649b58d96feb5fba8b7e750d\n",
       " \tlastModified: 2022-07-01T11:50:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:ca', 'language:es', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-stance-detection', 'configs:catalan', 'configs:spanish']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains two corpora in Spanish and Catalan that consist of annotated Twitter messages for automatic stance detection. The data was collected over 12 days during February and March of 2019 from tweets posted in Barcelona, and during September of 2018 from tweets posted in the town of Terrassa, Catalonia.\n",
       " \n",
       " Each corpus is annotated with three classes: AGAINST, FAVOR and NEUTRAL, which express the stance towards the target - independence of Catalonia.\n",
       " \tcitation: @inproceedings{zotova-etal-2020-multilingual,\n",
       "     title = \"Multilingual Stance Detection in Tweets: The {C}atalonia Independence Corpus\",\n",
       "     author = \"Zotova, Elena  and\n",
       "       Agerri, Rodrigo  and\n",
       "       Nunez, Manuel  and\n",
       "       Rigau, German\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.171\",\n",
       "     pages = \"1368--1375\",\n",
       "     abstract = \"Stance detection aims to determine the attitude of a given text with respect to a specific topic or claim. While stance detection has been fairly well researched in the last years, most the work has been focused on English. This is mainly due to the relative lack of annotated data in other languages. The TW-10 referendum Dataset released at IberEval 2018 is a previous effort to provide multilingual stance-annotated data in Catalan and Spanish. Unfortunately, the TW-10 Catalan subset is extremely imbalanced. This paper addresses these issues by presenting a new multilingual dataset for stance detection in Twitter for the Catalan and Spanish languages, with the aim of facilitating research on stance detection in multilingual and cross-lingual settings. The dataset is annotated with stance towards one topic, namely, the ndependence of Catalonia. We also provide a semi-automatic method to annotate the dataset based on a categorization of Twitter users. We experiment on the new corpus with a number of supervised approaches, including linear classifiers and deep learning methods. Comparison of our new corpus with the with the TW-1O dataset shows both the benefits and potential of a well balanced corpus for multilingual and cross-lingual research on stance detection. Finally, we establish new state-of-the-art results on the TW-10 dataset, both for Catalan and Spanish.\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['ca', 'es'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-stance-detection'], 'paperswithcode_id': 'cic', 'pretty_name': 'Catalonia Independence Corpus', 'configs': ['catalan', 'spanish']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 515\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cic\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cats_vs_dogs\n",
       " \tsha: 843e844216e17060b73cda5a1286955379beed2c\n",
       " \tlastModified: 2022-09-30T09:34:55.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:image-classification', 'task_ids:multi-class-image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @Inproceedings (Conference){asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization,\n",
       "     author = {Elson, Jeremy and Douceur, John (JD) and Howell, Jon and Saul, Jared},\n",
       "     title = {Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization},\n",
       "     booktitle = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
       "     year = {2007},\n",
       "     month = {October},\n",
       "     publisher = {Association for Computing Machinery, Inc.},\n",
       "     url = {https://www.microsoft.com/en-us/research/publication/asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization/},\n",
       "     edition = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Cats Vs. Dogs', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['image-classification'], 'task_ids': ['multi-class-image-classification'], 'paperswithcode_id': 'cats-vs-dogs'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 450\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: cats-vs-dogs\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cawac\n",
       " \tsha: 049e1244c77abf89b47aa24e4e6d5a96a1f68234\n",
       " \tlastModified: 2022-07-01T11:50:34.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ca', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: caWaC is a 780-million-token web corpus of Catalan built from the .cat top-level-domain in late 2013.\n",
       " \tcitation: @inproceedings{DBLP:conf/lrec/LjubesicT14,\n",
       "   author    = {Nikola Ljubesic and\n",
       "                Antonio Toral},\n",
       "   editor    = {Nicoletta Calzolari and\n",
       "                Khalid Choukri and\n",
       "                Thierry Declerck and\n",
       "                Hrafn Loftsson and\n",
       "                Bente Maegaard and\n",
       "                Joseph Mariani and\n",
       "                Asunci{\\'{o}}n Moreno and\n",
       "                Jan Odijk and\n",
       "                Stelios Piperidis},\n",
       "   title     = {caWaC - {A} web corpus of Catalan and its application to language\n",
       "                modeling and machine translation},\n",
       "   booktitle = {Proceedings of the Ninth International Conference on Language Resources\n",
       "                and Evaluation, {LREC} 2014, Reykjavik, Iceland, May 26-31, 2014},\n",
       "   pages     = {1728--1732},\n",
       "   publisher = {European Language Resources Association {(ELRA)}},\n",
       "   year      = {2014},\n",
       "   url       = {http://www.lrec-conf.org/proceedings/lrec2014/summaries/841.html},\n",
       "   timestamp = {Mon, 19 Aug 2019 15:23:35 +0200},\n",
       "   biburl    = {https://dblp.org/rec/conf/lrec/LjubesicT14.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ca'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'cawac', 'pretty_name': 'caWaC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 349\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: cawac\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cbt\n",
       " \tsha: 176ce7a396e319776a17ef5602001e0ac7f762c0\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['arxiv:1511.02301', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:gfdl', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:other', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'task_ids:other-other-raw-dataset', 'configs:CN', 'configs:NE', 'configs:P', 'configs:V', 'configs:raw']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Children’s Book Test (CBT) is designed to measure directly\n",
       " how well language models can exploit wider linguistic context.\n",
       " The CBT is built from books that are freely available.\n",
       " \tcitation: @misc{hill2016goldilocks,\n",
       "       title={The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations},\n",
       "       author={Felix Hill and Antoine Bordes and Sumit Chopra and Jason Weston},\n",
       "       year={2016},\n",
       "       eprint={1511.02301},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Children’s Book Test (CBT)', 'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['gfdl'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['other', 'question-answering'], 'task_ids': ['multiple-choice-qa', 'other-other-raw-dataset'], 'paperswithcode_id': 'cbt', 'configs': ['CN', 'NE', 'P', 'V', 'raw']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1837\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: cbt\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cc100\n",
       " \tsha: 9a7c0bd02a35c08f10050fee7220134048652918\n",
       " \tlastModified: 2022-07-27T14:38:38.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:ff', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:ht', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lg', 'language:li', 'language:ln', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:ns', 'language:om', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:ro', 'language:ru', 'language:sa', 'language:sc', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:ss', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tn', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language_bcp47:bn-Latn', 'language_bcp47:hi-Latn', 'language_bcp47:my-x-zawgyi', 'language_bcp47:ta-Latn', 'language_bcp47:te-Latn', 'language_bcp47:ur-Latn', 'language_bcp47:zh-Hans', 'language_bcp47:zh-Hant', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:am', 'configs:sr']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This corpus is an attempt to recreate the dataset used for training XLM-R. This corpus comprises of monolingual data for 100+ languages and also includes data for romanized languages (indicated by *_rom). This was constructed using the urls and paragraph indices provided by the CC-Net repository by processing January-December 2018 Commoncrawl snapshots. Each file comprises of documents separated by double-newlines and paragraphs within the same document separated by a newline. The data is generated using the open source CC-Net repository. No claims of intellectual property are made on the work of preparation of the corpus.\n",
       " \tcitation: @inproceedings{conneau-etal-2020-unsupervised,\n",
       "     title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\n",
       "     author = \"Conneau, Alexis  and\n",
       "       Khandelwal, Kartikay  and\n",
       "       Goyal, Naman  and\n",
       "       Chaudhary, Vishrav  and\n",
       "       Wenzek, Guillaume  and\n",
       "       Guzm{'a}n, Francisco  and\n",
       "       Grave, Edouard  and\n",
       "       Ott, Myle  and\n",
       "       Zettlemoyer, Luke  and\n",
       "       Stoyanov, Veselin\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.747\",\n",
       "     pages = \"8440--8451\",\n",
       "     abstract = \"This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and 11.4{%} for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.\",\n",
       " }\n",
       " @inproceedings{wenzek-etal-2020-ccnet,\n",
       "     title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\n",
       "     author = \"Wenzek, Guillaume  and\n",
       "       Lachaux, Marie-Anne  and\n",
       "       Conneau, Alexis  and\n",
       "       Chaudhary, Vishrav  and\n",
       "       Guzm{'a}n, Francisco  and\n",
       "       Joulin, Armand  and\n",
       "       Grave, Edouard\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\n",
       "     pages = \"4003--4012\",\n",
       "     abstract = \"Pre-training text representations have led to significant improvements in many areas of natural language processing. The quality of these models benefits greatly from the size of the pretraining corpora as long as its quality is preserved. In this paper, we describe an automatic pipeline to extract massive high-quality monolingual datasets from Common Crawl for a variety of languages. Our pipeline follows the data processing introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that deduplicates documents and identifies their language. We augment this pipeline with a filtering step to select documents that are close to high quality corpora like Wikipedia.\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'ff', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gn', 'gu', 'ha', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lg', 'li', 'ln', 'lo', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'my', 'ne', 'nl', 'no', 'ns', 'om', 'or', 'pa', 'pl', 'ps', 'pt', 'qu', 'rm', 'ro', 'ru', 'sa', 'sc', 'sd', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'ss', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tn', 'tr', 'ug', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yi', 'yo', 'zh', 'zu'], 'language_bcp47': ['bn-Latn', 'hi-Latn', 'my-x-zawgyi', 'ta-Latn', 'te-Latn', 'ur-Latn', 'zh-Hans', 'zh-Hant'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'cc100', 'pretty_name': 'CC100', 'configs': ['am', 'sr']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1191\n",
       " \tlikes: 14\n",
       " \tpaperswithcode_id: cc100\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cc_news\n",
       " \tsha: 330f1efb60fe7b0396622f2038c0dd4fc41d5d35\n",
       " \tlastModified: 2022-08-24T04:09:31.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CC-News containing news articles from news sites all over the world The data is available on AWS S3 in the Common Crawl bucket at /crawl-data/CC-NEWS/. This version of the dataset has 708241 articles. It represents a small portion of English  language subset of the CC-News dataset created using news-please(Hamborg et al.,2017) to collect and extract English language portion of CC-News.\n",
       " \tcitation: @InProceedings{Hamborg2017,\n",
       "   author     = {Hamborg, Felix and Meuschke, Norman and Breitinger, Corinna and Gipp, Bela},\n",
       "   title      = {news-please: A Generic News Crawler and Extractor},\n",
       "   year       = {2017},\n",
       "   booktitle  = {Proceedings of the 15th International Symposium of Information Science},\n",
       "   location   = {Berlin},\n",
       "   doi        = {10.5281/zenodo.4120316},\n",
       "   pages      = {218--223},\n",
       "   month      = {March}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'CC-News', 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'cc-news'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9565\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: cc-news\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ccaligned_multilingual\n",
       " \tsha: a1e93a2e3a2910741cf4948c746222d5d9d3e119\n",
       " \tlastModified: 2022-07-27T14:38:38.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:af', 'language:ak', 'language:am', 'language:ar', 'language:as', 'language:ay', 'language:az', 'language:be', 'language:bg', 'language:bm', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:ceb', 'language:ckb', 'language:cs', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:eo', 'language:es', 'language:fa', 'language:ff', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gl', 'language:gn', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:ka', 'language:kac', 'language:kg', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lg', 'language:li', 'language:ln', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:nso', 'language:ny', 'language:om', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sc', 'language:sd', 'language:se', 'language:shn', 'language:si', 'language:sk', 'language:sl', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:ss', 'language:st', 'language:su', 'language:sv', 'language:sw', 'language:syc', 'language:szl', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:ti', 'language:tl', 'language:tn', 'language:tr', 'language:ts', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:ve', 'language:vi', 'language:war', 'language:wo', 'language:xh', 'language:yi', 'language:yo', 'language:zgh', 'language:zh', 'language:zu', 'language:zza', 'license:unknown', 'multilinguality:translation', 'size_categories:n<1K', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CCAligned consists of parallel or comparable web-document pairs in 137 languages aligned with English. These web-document pairs were constructed by performing language identification on raw web-documents, and ensuring corresponding language codes were corresponding in the URLs of web documents. This pattern matching approach yielded more than 100 million aligned documents paired with English. Recognizing that each English document was often aligned to mulitple documents in different target language, we can join on English documents to obtain aligned documents that directly pair two non-English documents (e.g., Arabic-French).\n",
       " \tcitation: @inproceedings{elkishky_ccaligned_2020,\n",
       "  author = {El-Kishky, Ahmed and Chaudhary, Vishrav and Guzm{\\'a}n, Francisco and Koehn, Philipp},\n",
       "  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020)},\n",
       "  month = {November},\n",
       "  title = {{CCAligned}: A Massive Collection of Cross-lingual Web-Document Pairs},\n",
       "  year = {2020}\n",
       "  address = \"Online\",\n",
       "  publisher = \"Association for Computational Linguistics\",\n",
       "  url = \"https://www.aclweb.org/anthology/2020.emnlp-main.480\",\n",
       "  doi = \"10.18653/v1/2020.emnlp-main.480\",\n",
       "  pages = \"5960--5969\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['af', 'ak', 'am', 'ar', 'as', 'ay', 'az', 'be', 'bg', 'bm', 'bn', 'br', 'bs', 'ca', 'ceb', 'ckb', 'cs', 'cy', 'de', 'dv', 'el', 'eo', 'es', 'fa', 'ff', 'fi', 'fo', 'fr', 'fy', 'ga', 'gl', 'gn', 'gu', 'he', 'hi', 'hr', 'hu', 'id', 'ig', 'is', 'it', 'iu', 'ja', 'ka', 'kac', 'kg', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lg', 'li', 'ln', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'ne', 'nl', 'no', 'nso', 'ny', 'om', 'or', 'pa', 'pl', 'ps', 'pt', 'rm', 'ro', 'ru', 'rw', 'sc', 'sd', 'se', 'shn', 'si', 'sk', 'sl', 'sn', 'so', 'sq', 'sr', 'ss', 'st', 'su', 'sv', 'sw', 'syc', 'szl', 'ta', 'te', 'tg', 'th', 'ti', 'tl', 'tn', 'tr', 'ts', 'tt', 'ug', 'uk', 'ur', 'uz', 've', 'vi', 'war', 'wo', 'xh', 'yi', 'yo', 'zgh', 'zh', 'zu', 'zza'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['n<1K', '1K<n<10K', '10K<n<100K', '100K<n<1M', '1M<n<10M', '10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-translation'], 'paperswithcode_id': 'ccaligned', 'pretty_name': 'CCAligned'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1164\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: ccaligned\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cdsc\n",
       " \tsha: 29f28cc3a0018ad36a11e6ef5292cd04b8c462ac\n",
       " \tlastModified: 2022-07-01T11:50:38.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-sentences entailment and relatedness']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Polish CDSCorpus consists of 10K Polish sentence pairs which are human-annotated for semantic relatedness and entailment. The dataset may be used for the evaluation of compositional distributional semantics models of Polish. The dataset was presented at ACL 2017. Please refer to the Wróblewska and Krasnowska-Kieraś (2017) for a detailed description of the resource.\n",
       " \tcitation: @inproceedings{wroblewska2017polish,\n",
       " title={Polish evaluation dataset for compositional distributional semantics models},\n",
       " author={Wr{\\'o}blewska, Alina and Krasnowska-Kiera{\\'s}, Katarzyna},\n",
       " booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n",
       " pages={784--792},\n",
       " year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-sentences entailment and relatedness'], 'paperswithcode_id': 'polish-cdscorpus', 'pretty_name': 'Polish CDSCorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 511\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: polish-cdscorpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cdt\n",
       " \tsha: 3d2c0b8de173f4693e9fdfbbb5ab92b9ce9231f0\n",
       " \tlastModified: 2022-07-01T11:50:38.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:bsd-3-clause', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Cyberbullying Detection task was part of 2019 edition of PolEval competition. The goal is to predict if a given Twitter message contains a cyberbullying (harmful) content.\n",
       " \tcitation: @article{ptaszynski2019results,\n",
       " title={Results of the PolEval 2019 Shared Task 6: First Dataset and Open Shared Task for Automatic Cyberbullying Detection in Polish Twitter},\n",
       " author={Ptaszynski, Michal and Pieciukiewicz, Agata and Dybala, Pawel},\n",
       " journal={Proceedings of the PolEval 2019 Workshop},\n",
       " publisher={Institute of Computer Science, Polish Academy of Sciences},\n",
       " pages={89},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['bsd-3-clause'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'cdt'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 348\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cedr\n",
       " \tsha: 652820edd3c49371c013672bdec8ad01902d9b52\n",
       " \tlastModified: 2022-07-01T11:50:38.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ru', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-emotion-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This new dataset is designed to solve emotion recognition task for text data in Russian. The Corpus for Emotions Detecting in\n",
       " Russian-language text sentences of different social sources (CEDR) contains 9410 sentences in Russian labeled for 5 emotion\n",
       " categories. The data collected from different sources: posts of the LiveJournal social network, texts of the online news\n",
       " agency Lenta.ru, and Twitter microblog posts. There are two variants of the corpus: main and enriched. The enriched variant\n",
       " is include tokenization and lemmatization. Dataset with predefined train/test splits.\n",
       " \tcitation: @article{sboev2021data,\n",
       "   title={Data-Driven Model for Emotion Detection in Russian Texts},\n",
       "   author={Sboev, Alexander and Naumov, Aleksandr and Rybka, Roman},\n",
       "   journal={Procedia Computer Science},\n",
       "   volume={190},\n",
       "   pages={637--642},\n",
       "   year={2021},\n",
       "   publisher={Elsevier}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ru'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'The Corpus for Emotions Detecting in Russian-language text sentences (CEDR)', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification', 'multi-label-classification', 'text-classification-other-emotion-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 526\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cfq\n",
       " \tsha: 9d69887a3c93f2cd0e2b8d3c117d7d5dc45f5769\n",
       " \tlastModified: 2022-07-04T19:24:29.000Z\n",
       " \ttags: ['arxiv:1912.09713', 'annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:other', 'task_ids:open-domain-qa', 'task_ids:closed-domain-qa', 'task_ids:other-compositionality']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The CFQ dataset (and it's splits) for measuring compositional generalization.\n",
       " \n",
       " See https://arxiv.org/abs/1912.09713.pdf for background.\n",
       " \n",
       " Example usage:\n",
       " data = datasets.load_dataset('cfq/mcd1')\n",
       " \tcitation: @inproceedings{Keysers2020,\n",
       "   title={Measuring Compositional Generalization: A Comprehensive Method on\n",
       "          Realistic Data},\n",
       "   author={Daniel Keysers and Nathanael Sch\\\"{a}rli and Nathan Scales and\n",
       "           Hylke Buisman and Daniel Furrer and Sergii Kashubin and\n",
       "           Nikola Momchev and Danila Sinopalnikov and Lukasz Stafiniak and\n",
       "           Tibor Tihon and Dmitry Tsarkov and Xiao Wang and Marc van Zee and\n",
       "           Olivier Bousquet},\n",
       "   booktitle={ICLR},\n",
       "   year={2020},\n",
       "   url={https://arxiv.org/abs/1912.09713.pdf},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Compositional Freebase Questions', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'other'], 'task_ids': ['open-domain-qa', 'closed-domain-qa', 'other-compositionality'], 'paperswithcode_id': 'cfq'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1728\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: cfq\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: chr_en\n",
       " \tsha: 314aa33902bf6b654d6ddb6699c809cedbe9934d\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['arxiv:2010.04791', 'annotations_creators:expert-generated', 'annotations_creators:found', 'annotations_creators:no-annotation', 'language_creators:found', 'language:chr', 'language:en', 'license:other', 'multilinguality:monolingual', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:fill-mask', 'task_categories:text-generation', 'task_categories:translation', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:monolingual', 'configs:monolingual_raw', 'configs:parallel', 'configs:parallel_raw']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ChrEn is a Cherokee-English parallel dataset to facilitate machine translation research between Cherokee and English.\n",
       " ChrEn is extremely low-resource contains 14k sentence pairs in total, split in ways that facilitate both in-domain and out-of-domain evaluation.\n",
       " ChrEn also contains 5k Cherokee monolingual data to enable semi-supervised learning.\n",
       " \tcitation: @inproceedings{zhang2020chren,\n",
       "   title={ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization},\n",
       "   author={Zhang, Shiyue and Frey, Benjamin and Bansal, Mohit},\n",
       "   booktitle={EMNLP2020},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'found', 'no-annotation'], 'language_creators': ['found'], 'language': ['chr', 'en'], 'license': ['other'], 'multilinguality': ['monolingual', 'multilingual', 'translation'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['fill-mask', 'text-generation', 'translation'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'chren', 'configs': ['monolingual', 'monolingual_raw', 'parallel', 'parallel_raw']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 814\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: chren\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cifar10\n",
       " \tsha: 2ff17d7459093428f1b3bd4700eb8cc9f2de486f\n",
       " \tlastModified: 2022-07-01T11:50:41.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-80-Million-Tiny-Images', 'task_categories:image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images\n",
       " per class. There are 50000 training images and 10000 test images.\n",
       " \tcitation: @TECHREPORT{Krizhevsky09learningmultiple,\n",
       "     author = {Alex Krizhevsky},\n",
       "     title = {Learning multiple layers of features from tiny images},\n",
       "     institution = {},\n",
       "     year = {2009}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Cifar10', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-80-Million-Tiny-Images'], 'task_categories': ['image-classification'], 'task_ids': [], 'paperswithcode_id': 'cifar-10'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7872\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: cifar-10\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cifar100\n",
       " \tsha: 9c68b5fa5461b8e96990e7a4e27cb4d29df07544\n",
       " \tlastModified: 2022-07-01T11:50:41.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-80-Million-Tiny-Images', 'task_categories:image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images\n",
       " per class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses.\n",
       " There are two labels per image - fine label (actual class) and coarse label (superclass).\n",
       " \tcitation: @TECHREPORT{Krizhevsky09learningmultiple,\n",
       "     author = {Alex Krizhevsky},\n",
       "     title = {Learning multiple layers of features from tiny images},\n",
       "     institution = {},\n",
       "     year = {2009}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Cifar100', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-80-Million-Tiny-Images'], 'task_categories': ['image-classification'], 'task_ids': [], 'paperswithcode_id': 'cifar-100'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2823\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cifar-100\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: circa\n",
       " \tsha: 15ce972aa7fbbed6835e2c075f7e1e630fa3dbd6\n",
       " \tlastModified: 2022-07-01T11:50:41.000Z\n",
       " \ttags: ['arxiv:2010.03450', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:text-classification-other-question-answer-pair-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Circa (meaning ‘approximately’) dataset aims to help machine learning systems\n",
       " to solve the problem of interpreting indirect answers to polar questions.\n",
       " \n",
       " The dataset contains pairs of yes/no questions and indirect answers, together with\n",
       " annotations for the interpretation of the answer. The data is collected in 10\n",
       " different social conversational situations (eg. food preferences of a friend).\n",
       " \n",
       " NOTE: There might be missing labels in the dataset and we have replaced them with -1.\n",
       " The original dataset contains no train/dev/test splits.\n",
       " \tcitation: @InProceedings{louis_emnlp2020,\n",
       "   author =      \"Annie Louis and Dan Roth and Filip Radlinski\",\n",
       "   title =       \"\"{I}'d rather just go to bed\": {U}nderstanding {I}ndirect {A}nswers\",\n",
       "   booktitle =   \"Proceedings of the 2020 Conference on Empirical Methods\n",
       "   in Natural Language Processing\",\n",
       "   year =        \"2020\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'text-classification-other-question-answer-pair-classification'], 'paperswithcode_id': 'circa', 'pretty_name': 'CIRCA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 852\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: circa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: civil_comments\n",
       " \tsha: 61864fdf071fdb5a8fd8c74f5d23271c6a9fc65c\n",
       " \tlastModified: 2022-07-01T11:50:42.000Z\n",
       " \ttags: ['arxiv:1903.04561', 'language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The comments in this dataset come from an archive of the Civil Comments\n",
       " platform, a commenting plugin for independent news sites. These public comments\n",
       " were created from 2015 - 2017 and appeared on approximately 50 English-language\n",
       " news sites across the world. When Civil Comments shut down in 2017, they chose\n",
       " to make the public comments available in a lasting open archive to enable future\n",
       " research. The original data, published on figshare, includes the public comment\n",
       " text, some associated metadata such as article IDs, timestamps and\n",
       " commenter-generated \"civility\" labels, but does not include user ids. Jigsaw\n",
       " extended this dataset by adding additional labels for toxicity and identity\n",
       " mentions. This data set is an exact replica of the data released for the\n",
       " Jigsaw Unintended Bias in Toxicity Classification Kaggle challenge.  This\n",
       " dataset is released under CC0, as is the underlying comment text.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1903-04561,\n",
       "   author    = {Daniel Borkan and\n",
       "                Lucas Dixon and\n",
       "                Jeffrey Sorensen and\n",
       "                Nithum Thain and\n",
       "                Lucy Vasserman},\n",
       "   title     = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n",
       "                Classification},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1903.04561},\n",
       "   year      = {2019},\n",
       "   url       = {http://arxiv.org/abs/1903.04561},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1903.04561},\n",
       "   timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},\n",
       "   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-04561},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': None, 'pretty_name': 'CivilComments'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 539\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: clickbait_news_bg\n",
       " \tsha: 7342766e02a5f31e7a8470bce4bbaa4c45035ac6\n",
       " \tlastModified: 2022-07-01T11:50:42.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:bg', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset with clickbait and fake news in Bulgarian. Introduced for the Hack the Fake News 2017.\n",
       " \tcitation: @InProceedings{clickbait_news_bg,\n",
       " title = {Dataset with clickbait and fake news in Bulgarian. Introduced for the Hack the Fake News 2017.},\n",
       " authors={Data Science Society},\n",
       " year={2017},\n",
       " url={https://gitlab.com/datasciencesociety/case_fake_news/}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['bg'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'Clickbait/Fake News in Bulgarian'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 338\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: climate_fever\n",
       " \tsha: 5d92f089ac2eb7ef6770b8382c785d0562e06641\n",
       " \tlastModified: 2022-07-01T11:50:43.000Z\n",
       " \ttags: ['arxiv:2012.00614', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|wikipedia', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:text-retrieval', 'task_ids:text-scoring', 'task_ids:fact-checking', 'task_ids:fact-checking-retrieval', 'task_ids:semantic-similarity-scoring', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change collected on the internet. Each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim totalling in 7,675 claim-evidence pairs. The dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.\n",
       " \tcitation: @misc{diggelmann2020climatefever,\n",
       "       title={CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims},\n",
       "       author={Thomas Diggelmann and Jordan Boyd-Graber and Jannis Bulian and Massimiliano Ciaramita and Markus Leippold},\n",
       "       year={2020},\n",
       "       eprint={2012.00614},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|wikipedia', 'original'], 'task_categories': ['text-classification', 'text-retrieval'], 'task_ids': ['text-scoring', 'fact-checking', 'fact-checking-retrieval', 'semantic-similarity-scoring', 'multi-input-text-classification'], 'paperswithcode_id': 'climate-fever', 'pretty_name': 'ClimateFever'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1478\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: climate-fever\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: clinc_oos\n",
       " \tsha: dd5a3d3ac31f87f80b48eea1307b03c42be30aa3\n",
       " \tlastModified: 2022-07-28T10:41:15.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     This dataset is for evaluating the performance of intent classification systems in the\n",
       "     presence of \"out-of-scope\" queries. By \"out-of-scope\", we mean queries that do not fall\n",
       "     into any of the system-supported intent classes. Most datasets include only data that is\n",
       "     \"in-scope\". Our dataset includes both in-scope and out-of-scope data. You might also know\n",
       "     the term \"out-of-scope\" by other terms, including \"out-of-domain\" or \"out-of-distribution\".\n",
       " \tcitation:     @inproceedings{larson-etal-2019-evaluation,\n",
       "     title = \"An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction\",\n",
       "     author = \"Larson, Stefan  and\n",
       "       Mahendran, Anish  and\n",
       "       Peper, Joseph J.  and\n",
       "       Clarke, Christopher  and\n",
       "       Lee, Andrew  and\n",
       "       Hill, Parker  and\n",
       "       Kummerfeld, Jonathan K.  and\n",
       "       Leach, Kevin  and\n",
       "       Laurenzano, Michael A.  and\n",
       "       Tang, Lingjia  and\n",
       "       Mars, Jason\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n",
       "     year = \"2019\",\n",
       "     url = \"https://www.aclweb.org/anthology/D19-1131\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': 'clinc150', 'pretty_name': 'CLINC150'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4307\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: clinc150\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: clue\n",
       " \tsha: a57b5f85262c1dbe2fde6a6901832b181afc5bc0\n",
       " \tlastModified: 2022-08-29T16:13:39.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:zh', 'language_creators:other', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:multiple-choice', 'task_ids:topic-classification', 'task_ids:semantic-similarity-scoring', 'task_ids:natural-language-inference', 'task_ids:text-classification-other-coreference-nli', 'task_ids:text-classification-other-qa-nli', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CLUE, A Chinese Language Understanding Evaluation Benchmark\n",
       " (https://www.cluebenchmarks.com/) is a collection of resources for training,\n",
       " evaluating, and analyzing Chinese language understanding systems.\n",
       " \tcitation: @misc{xu2020clue,\n",
       "     title={CLUE: A Chinese Language Understanding Evaluation Benchmark},\n",
       "     author={Liang Xu and Xuanwei Zhang and Lu Li and Hai Hu and Chenjie Cao and Weitang Liu and Junyi Li and Yudong Li and Kai Sun and Yechen Xu and Yiming Cui and Cong Yu and Qianqian Dong and Yin Tian and Dian Yu and Bo Shi and Jun Zeng and Rongzhao Wang and Weijian Xie and Yanting Li and Yina Patterson and Zuoyu Tian and Yiwen Zhang and He Zhou and Shaoweihua Liu and Qipeng Zhao and Cong Yue and Xinrui Zhang and Zhengliang Yang and Zhenzhong Lan},\n",
       "     year={2020},\n",
       "     eprint={2004.05986},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['zh'], 'language_creators': ['other'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'CLUE: Chinese Language Understanding Evaluation benchmark', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification', 'multiple-choice'], 'task_ids': ['topic-classification', 'semantic-similarity-scoring', 'natural-language-inference', 'text-classification-other-coreference-nli', 'text-classification-other-qa-nli', 'multiple-choice-qa'], 'paperswithcode_id': 'clue'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2936\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: clue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cmrc2018\n",
       " \tsha: b3a3ab330afe9cb5b3a8f26f967ef99979e9c6a9\n",
       " \tlastModified: 2022-07-01T11:50:45.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:zh', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A Span-Extraction dataset for Chinese machine reading comprehension to add language\n",
       " diversities in this area. The dataset is composed by near 20,000 real questions annotated\n",
       " on Wikipedia paragraphs by human experts. We also annotated a challenge set which\n",
       " contains the questions that need comprehensive understanding and multi-sentence\n",
       " inference throughout the context.\n",
       " \tcitation: @inproceedings{cui-emnlp2019-cmrc2018,\n",
       "     title = {A Span-Extraction Dataset for {C}hinese Machine Reading Comprehension},\n",
       "     author = {Cui, Yiming  and\n",
       "       Liu, Ting  and\n",
       "       Che, Wanxiang  and\n",
       "       Xiao, Li  and\n",
       "       Chen, Zhipeng  and\n",
       "       Ma, Wentao  and\n",
       "       Wang, Shijin  and\n",
       "       Hu, Guoping},\n",
       "     booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n",
       "     month = {nov},\n",
       "     year = {2019},\n",
       "     address = {Hong Kong, China},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     url = {https://www.aclweb.org/anthology/D19-1600},\n",
       "     doi = {10.18653/v1/D19-1600},\n",
       "     pages = {5886--5891}}\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['zh'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'cmrc-2018', 'pretty_name': 'Chinese Machine Reading Comprehension 2018'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 531\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: cmrc-2018\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cmu_hinglish_dog\n",
       " \tsha: 87ccd5517fe2afa7d620ebaede798126504e005e\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['arxiv:1809.07358', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'language:hi', 'license:cc-by-sa-3.0', 'license:gfdl', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of text conversations in Hinglish (code mixing between Hindi-English) and their corresponding English only versions. Can be used for Translating between the two.\n",
       " \tcitation: @inproceedings{cmu_dog_emnlp18,\n",
       "     title={A Dataset for Document Grounded Conversations},\n",
       "     author={Zhou, Kangyan and Prabhumoye, Shrimai and Black, Alan W},\n",
       "     year={2018},\n",
       "     booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing}\n",
       " }\n",
       " \n",
       " @inproceedings{khanuja-etal-2020-gluecos,\n",
       "     title = \"{GLUEC}o{S}: An Evaluation Benchmark for Code-Switched {NLP}\",\n",
       "     author = \"Khanuja, Simran  and\n",
       "       Dandapat, Sandipan  and\n",
       "       Srinivasan, Anirudh  and\n",
       "       Sitaram, Sunayana  and\n",
       "       Choudhury, Monojit\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.329\",\n",
       "     pages = \"3575--3585\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'hi'], 'license': ['cc-by-sa-3.0', 'gfdl'], 'multilinguality': ['multilingual', 'translation'], 'pretty_name': 'CMU Document Grounded Conversations', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 369\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cnn_dailymail\n",
       " \tsha: 2dd16e9e8ef73de439118f22f1749816225086ce\n",
       " \tlastModified: 2022-10-11T08:30:03.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CNN/DailyMail non-anonymized summarization dataset.\n",
       " \n",
       " There are two features:\n",
       "   - article: text of news article, used as the document to be summarized\n",
       "   - highlights: joined text of highlights with <s> and </s> around each\n",
       "     highlight, which is the target summary\n",
       " \tcitation: @article{DBLP:journals/corr/SeeLM17,\n",
       "   author    = {Abigail See and\n",
       "                Peter J. Liu and\n",
       "                Christopher D. Manning},\n",
       "   title     = {Get To The Point: Summarization with Pointer-Generator Networks},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1704.04368},\n",
       "   year      = {2017},\n",
       "   url       = {http://arxiv.org/abs/1704.04368},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1704.04368},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\n",
       "   biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \n",
       " @inproceedings{hermann2015teaching,\n",
       "   title={Teaching machines to read and comprehend},\n",
       "   author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n",
       "   booktitle={Advances in neural information processing systems},\n",
       "   pages={1693--1701},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'paperswithcode_id': 'cnn-daily-mail-1', 'pretty_name': 'CNN / Daily Mail', 'train-eval-index': [{'config': '3.0.0', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'eval_split': 'test'}, 'col_mapping': {'article': 'text', 'highlights': 'target'}}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 73796\n",
       " \tlikes: 17\n",
       " \tpaperswithcode_id: cnn-daily-mail-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: coached_conv_pref\n",
       " \tsha: 2be0214108e8ebb374839c3671501f3e84efab2a\n",
       " \tlastModified: 2022-07-01T11:50:46.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:token-classification', 'task_ids:other-other-Conversational Recommendation', 'task_ids:dialogue-modeling', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset consisting of 502 English dialogs with 12,000 annotated utterances between a user and an assistant discussing\n",
       " movie preferences in natural language. It was collected using a Wizard-of-Oz methodology between two paid crowd-workers,\n",
       " where one worker plays the role of an 'assistant', while the other plays the role of a 'user'. The 'assistant' elicits\n",
       " the 'user’s' preferences about movies following a Coached Conversational Preference Elicitation (CCPE) method. The\n",
       " assistant asks questions designed to minimize the bias in the terminology the 'user' employs to convey his or her\n",
       " preferences as much as possible, and to obtain these preferences in natural language. Each dialog is annotated with\n",
       " entity mentions, preferences expressed about entities, descriptions of entities provided, and other statements of\n",
       " entities.\n",
       " \tcitation: @inproceedings{48414,\n",
       " title\t= {Coached Conversational Preference Elicitation: A Case Study in Understanding Movie Preferences},\n",
       " author\t= {Filip Radlinski and Krisztian Balog and Bill Byrne and Karthik Krishnamoorthi},\n",
       " year\t= {2019},\n",
       " booktitle\t= {Proceedings of the Annual SIGdial Meeting on Discourse and Dialogue}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-generation', 'fill-mask', 'token-classification'], 'task_ids': ['other-other-Conversational Recommendation', 'dialogue-modeling', 'parsing'], 'paperswithcode_id': 'coached-conversational-preference-elicitation', 'pretty_name': 'Coached Conversational Preference Elicitation'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: coached-conversational-preference-elicitation\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: coarse_discourse\n",
       " \tsha: b299e7343cb9c6401e61d6350f6b559bcc224f1c\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: dataset contains discourse annotation and relation on threads from reddit during 2016\n",
       " \tcitation: @inproceedings{coarsediscourse, title={Characterizing Online Discussion Using Coarse Discourse Sequences}, author={Zhang, Amy X. and Culbertson, Bryan and Paritosh, Praveen}, booktitle={Proceedings of the 11th International AAAI Conference on Weblogs and Social Media}, series={ICWSM '17}, year={2017}, location = {Montreal, Canada} }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Coarse Discourse', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'coarse-discourse'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: coarse-discourse\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: codah\n",
       " \tsha: 81e1385a14c57aff58be0ba90f649629234fa1c9\n",
       " \tlastModified: 2022-08-11T12:57:18.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The COmmonsense Dataset Adversarially-authored by Humans (CODAH) is an evaluation set for commonsense question-answering in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions. Our experimental results show that CODAH questions present a complementary extension to the SWAG dataset, testing additional modes of common sense.\n",
       " \tcitation: @inproceedings{chen2019codah,\n",
       "   title={CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n",
       "   author={Chen, Michael and D'Arcy, Mike and Liu, Alisa and Fernandez, Jared and Downey, Doug},\n",
       "   booktitle={Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP},\n",
       "   pages={63--69},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'codah', 'pretty_name': 'COmmonsense Dataset Adversarially-authored by Humans'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2195\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: codah\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_search_net\n",
       " \tsha: cd5183659976a52096acd7bcd3f60f07a673926c\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['arxiv:1909.09436', 'annotations_creators:no-annotation', 'language_creators:machine-generated', 'language:code', 'license:other', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:all', 'configs:go', 'configs:java', 'configs:javascript', 'configs:php', 'configs:python', 'configs:ruby']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CodeSearchNet corpus contains about 6 million functions from open-source code spanning six programming languages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet Corpus also contains automatically generated query-like natural language for 2 million functions, obtained from mechanically scraping and preprocessing associated function documentation.\n",
       " \tcitation: @article{husain2019codesearchnet,\n",
       "     title={{CodeSearchNet} challenge: Evaluating the state of semantic code search},\n",
       "     author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
       "     journal={arXiv preprint arXiv:1909.09436},\n",
       "     year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['machine-generated'], 'language': ['code'], 'license': ['other'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'codesearchnet', 'pretty_name': 'CodeSearchNet', 'configs': ['all', 'go', 'java', 'javascript', 'php', 'python', 'ruby']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7786\n",
       " \tlikes: 22\n",
       " \tpaperswithcode_id: codesearchnet\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_clone_detection_big_clone_bench\n",
       " \tsha: a5e45cbd28c0573749435d32de8c7d5972973c4c\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Given two codes as the input, the task is to do binary classification (0/1), where 1 stands for semantic equivalence and 0 for others. Models are evaluated by F1 score.\n",
       " The dataset we use is BigCloneBench and filtered following the paper Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree.\n",
       " \tcitation: @inproceedings{svajlenko2014towards,\n",
       " title={Towards a big data curated benchmark of inter-project code clones},\n",
       " author={Svajlenko, Jeffrey and Islam, Judith F and Keivanloo, Iman and Roy, Chanchal K and Mia, Mohammad Mamun},\n",
       " booktitle={2014 IEEE International Conference on Software Maintenance and Evolution},\n",
       " pages={476--480},\n",
       " year={2014},\n",
       " organization={IEEE}\n",
       " }\n",
       " \n",
       " @inproceedings{wang2020detecting,\n",
       " title={Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree},\n",
       " author={Wang, Wenhan and Li, Ge and Ma, Bo and Xia, Xin and Jin, Zhi},\n",
       " booktitle={2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)},\n",
       " pages={261--271},\n",
       " year={2020},\n",
       " organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification'], 'pretty_name': 'CodeXGlueCcCloneDetectionBigCloneBench'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 700\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_clone_detection_poj104\n",
       " \tsha: cc3e0e72ab68ae0d2f43df5272d4dd55fe3ee638\n",
       " \tlastModified: 2022-07-01T12:43:19.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:document-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Given a code and a collection of candidates as the input, the task is to return Top K codes with the same semantic. Models are evaluated by MAP score.\n",
       " We use POJ-104 dataset on this task.\n",
       " \tcitation: @inproceedings{mou2016convolutional,\n",
       " title={Convolutional neural networks over tree structures for programming language processing},\n",
       " author={Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi},\n",
       " booktitle={Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},\n",
       " pages={1287--1293},\n",
       " year={2016}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'CodeXGlueCcCloneDetectionPoj104', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['document-retrieval']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 609\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_cloze_testing_all\n",
       " \tsha: f684cdd594c9a9d3b06e655a90b09ab4464cbb98\n",
       " \tlastModified: 2022-07-01T12:43:21.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:slot-filling', 'configs:go', 'configs:java', 'configs:javascript', 'configs:php', 'configs:python', 'configs:ruby']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Cloze tests are widely adopted in Natural Languages Processing to evaluate the performance of the trained language models. The task is aimed to predict the answers for the blank with the context of the blank, which can be formulated as a multi-choice classification problem.\n",
       " Here we present the two cloze testing datasets in code domain with six different programming languages: ClozeTest-maxmin and ClozeTest-all. Each instance in the dataset contains a masked code function, its docstring and the target word.\n",
       " The only difference between ClozeTest-maxmin and ClozeTest-all is their selected words sets, where ClozeTest-maxmin only contains two words while ClozeTest-all contains 930 words.\n",
       " \tcitation: @article{CodeXGLUE,\n",
       " title={CodeXGLUE: An Open Challenge for Code Intelligence},\n",
       " journal={arXiv},\n",
       " year={2020},\n",
       " }\n",
       " @article{feng2020codebert,\n",
       " title={CodeBERT: A Pre-Trained Model for Programming and Natural Languages},\n",
       " author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},\n",
       " journal={arXiv preprint arXiv:2002.08155},\n",
       " year={2020}\n",
       " }\n",
       " @article{husain2019codesearchnet,\n",
       " title={CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},\n",
       " author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
       " journal={arXiv preprint arXiv:1909.09436},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['slot-filling'], 'pretty_name': 'CodeXGlueCcClozeTestingAll', 'configs': ['go', 'java', 'javascript', 'php', 'python', 'ruby']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1159\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_cloze_testing_maxmin\n",
       " \tsha: 3ce04b78ce819c6bd8d074af1746d6d9c2e35575\n",
       " \tlastModified: 2022-07-01T12:43:21.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:slot-filling', 'configs:go', 'configs:java', 'configs:javascript', 'configs:php', 'configs:python', 'configs:ruby']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Cloze tests are widely adopted in Natural Languages Processing to evaluate the performance of the trained language models. The task is aimed to predict the answers for the blank with the context of the blank, which can be formulated as a multi-choice classification problem.\n",
       " Here we present the two cloze testing datasets in code domain with six different programming languages: ClozeTest-maxmin and ClozeTest-all. Each instance in the dataset contains a masked code function, its docstring and the target word.\n",
       " The only difference between ClozeTest-maxmin and ClozeTest-all is their selected words sets, where ClozeTest-maxmin only contains two words while ClozeTest-all contains 930 words.\n",
       " \tcitation: @article{CodeXGLUE,\n",
       " title={CodeXGLUE: An Open Challenge for Code Intelligence},\n",
       " journal={arXiv},\n",
       " year={2020},\n",
       " }\n",
       " @article{feng2020codebert,\n",
       " title={CodeBERT: A Pre-Trained Model for Programming and Natural Languages},\n",
       " author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},\n",
       " journal={arXiv preprint arXiv:2002.08155},\n",
       " year={2020}\n",
       " }\n",
       " @article{husain2019codesearchnet,\n",
       " title={CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},\n",
       " author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
       " journal={arXiv preprint arXiv:1909.09436},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['slot-filling'], 'pretty_name': 'CodeXGlueCcClozeTestingMaxmin', 'configs': ['go', 'java', 'javascript', 'php', 'python', 'ruby']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1148\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_code_completion_line\n",
       " \tsha: 8c6076be3c6396cc63cad38f67f2f3a1ddd64721\n",
       " \tlastModified: 2022-07-01T12:43:21.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:slot-filling', 'configs:go', 'configs:java', 'configs:javascript', 'configs:php', 'configs:python', 'configs:ruby']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Complete the unfinished line given previous context. Models are evaluated by exact match and edit similarity.\n",
       " We propose line completion task to test model's ability to autocomplete a line. Majority code completion systems behave well in token level completion, but fail in completing an unfinished line like a method call with specific parameters, a function signature, a loop condition, a variable definition and so on. When a software develop finish one or more tokens of the current line, the line level completion model is expected to generate the entire line of syntactically correct code.\n",
       " Line level code completion task shares the train/dev dataset with token level completion. After training a model on CodeCompletion-token, you could directly use it to test on line-level completion.\n",
       " \tcitation: @article{raychev2016probabilistic,\n",
       " title={Probabilistic Model for Code with Decision Trees},\n",
       " author={Raychev, Veselin and Bielik, Pavol and Vechev, Martin},\n",
       " journal={ACM SIGPLAN Notices},\n",
       " pages={731--747},\n",
       " year={2016},\n",
       " publisher={ACM New York, NY, USA}\n",
       " }\n",
       " @inproceedings{allamanis2013mining,\n",
       " title={Mining Source Code Repositories at Massive Scale using Language Modeling},\n",
       " author={Allamanis, Miltiadis and Sutton, Charles},\n",
       " booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},\n",
       " pages={207--216},\n",
       " year={2013},\n",
       " organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['slot-filling'], 'pretty_name': 'CodeXGlueCcCodeCompletionLine', 'configs': ['go', 'java', 'javascript', 'php', 'python', 'ruby']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 554\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_code_completion_token\n",
       " \tsha: ab3bb81a7a97081781cb094bd9dfd5259d084c6d\n",
       " \tlastModified: 2022-07-01T12:43:22.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Predict next code token given context of previous tokens. Models are evaluated by token level accuracy.\n",
       " Code completion is a one of the most widely used features in software development through IDEs. An effective code completion tool could improve software developers' productivity. We provide code completion evaluation tasks in two granularities -- token level and line level. Here we introduce token level code completion. Token level task is analogous to language modeling. Models should have be able to predict the next token in arbitary types.\n",
       " \tcitation: @article{raychev2016probabilistic,\n",
       "     title={Probabilistic Model for Code with Decision Trees},\n",
       "     author={Raychev, Veselin and Bielik, Pavol and Vechev, Martin},\n",
       "     journal={ACM SIGPLAN Notices},\n",
       "     pages={731--747},\n",
       "     year={2016},\n",
       "     publisher={ACM New York, NY, USA}\n",
       " }\n",
       " @inproceedings{allamanis2013mining,\n",
       "     title={Mining Source Code Repositories at Massive Scale using Language Modeling},\n",
       "     author={Allamanis, Miltiadis and Sutton, Charles},\n",
       "     booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},\n",
       "     pages={207--216},\n",
       "     year={2013},\n",
       "     organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'pretty_name': 'CodeXGlueCcCodeCompletionToken'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 506\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_code_refinement\n",
       " \tsha: 6870f137cf52605e6b35ca02eabfbfb0e004b3ee\n",
       " \tlastModified: 2022-07-01T12:43:22.000Z\n",
       " \ttags: ['arxiv:1812.08693', 'annotations_creators:expert-generated', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-debugging']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We use the dataset released by this paper(https://arxiv.org/pdf/1812.08693.pdf). The source side is a Java function with bugs and the target side is the refined one. All the function and variable names are normalized. Their dataset contains two subsets ( i.e.small and medium) based on the function length.\n",
       " \tcitation: @article{10.1145/3340544,\n",
       " author = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys},\n",
       " title = {An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation},\n",
       " year = {2019},\n",
       " issue_date = {October 2019},\n",
       " publisher = {Association for Computing Machinery},\n",
       " address = {New York, NY, USA},\n",
       " volume = {28},\n",
       " number = {4},\n",
       " issn = {1049-331X},\n",
       " url = {https://doi-org.proxy.wm.edu/10.1145/3340544},\n",
       " doi = {10.1145/3340544},\n",
       " abstract = {Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.},\n",
       " journal = {ACM Trans. Softw. Eng. Methodol.},\n",
       " month = sep,\n",
       " articleno = {19},\n",
       " numpages = {29},\n",
       " keywords = {bug-fixes, Neural machine translation}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-debugging'], 'pretty_name': 'CodeXGlueCcCodeRefinement'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 560\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_code_to_code_trans\n",
       " \tsha: a9a96f4d23abaca3a140532c73a069bcff675353\n",
       " \tlastModified: 2022-07-01T12:43:22.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-code-to-code']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset is collected from several public repos, including Lucene(http://lucene.apache.org/), POI(http://poi.apache.org/), JGit(https://github.com/eclipse/jgit/) and Antlr(https://github.com/antlr/).\n",
       "         We collect both the Java and C# versions of the codes and find the parallel functions. After removing duplicates and functions with the empty body, we split the whole dataset into training, validation and test sets.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2102-04664,\n",
       "   author    = {Shuai Lu and\n",
       "                Daya Guo and\n",
       "                Shuo Ren and\n",
       "                Junjie Huang and\n",
       "                Alexey Svyatkovskiy and\n",
       "                Ambrosio Blanco and\n",
       "                Colin B. Clement and\n",
       "                Dawn Drain and\n",
       "                Daxin Jiang and\n",
       "                Duyu Tang and\n",
       "                Ge Li and\n",
       "                Lidong Zhou and\n",
       "                Linjun Shou and\n",
       "                Long Zhou and\n",
       "                Michele Tufano and\n",
       "                Ming Gong and\n",
       "                Ming Zhou and\n",
       "                Nan Duan and\n",
       "                Neel Sundaresan and\n",
       "                Shao Kun Deng and\n",
       "                Shengyu Fu and\n",
       "                Shujie Liu},\n",
       "   title     = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding\n",
       "                and Generation},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2102.04664},\n",
       "   year      = {2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-code-to-code'], 'pretty_name': 'CodeXGlueCcCodeToCodeTrans'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 934\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_cc_defect_detection\n",
       " \tsha: 883d0479c64771028cf1b439acdbc296d8f26cd2\n",
       " \tlastModified: 2022-07-01T12:43:23.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Given a source code, the task is to identify whether it is an insecure code that may attack software systems, such as resource leaks, use-after-free vulnerabilities and DoS attack. We treat the task as binary classification (0/1), where 1 stands for insecure code and 0 for secure code.\n",
       " The dataset we use comes from the paper Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks. We combine all projects and split 80%/10%/10% for training/dev/test.\n",
       " \tcitation: @inproceedings{zhou2019devign,\n",
       " title={Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks},\n",
       " author={Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},\n",
       " booktitle={Advances in Neural Information Processing Systems},\n",
       " pages={10197--10207}, year={2019}\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'pretty_name': 'CodeXGlueCcDefectDetection'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 424\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_ct_code_to_text\n",
       " \tsha: 712a930754fcfe0259d41c504cebfd94460fb11e\n",
       " \tlastModified: 2022-07-01T12:43:24.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'language:en', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-code-to-text', 'configs:go', 'configs:java', 'configs:javascript', 'configs:php', 'configs:python', 'configs:ruby']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset we use comes from CodeSearchNet and we filter the dataset as the following:\n",
       " - Remove examples that codes cannot be parsed into an abstract syntax tree.\n",
       " - Remove examples that #tokens of documents is < 3 or >256\n",
       " - Remove examples that documents contain special tokens (e.g. <img ...> or https:...)\n",
       " - Remove examples that documents are not English.\n",
       " \tcitation: @article{husain2019codesearchnet,\n",
       " title={Codesearchnet challenge: Evaluating the state of semantic code search},\n",
       " author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
       " journal={arXiv preprint arXiv:1909.09436},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code', 'en'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-code-to-text'], 'pretty_name': 'CodeXGlueCtCodeToText', 'configs': ['go', 'java', 'javascript', 'php', 'python', 'ruby']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1716\n",
       " \tlikes: 12\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_tc_nl_code_search_adv\n",
       " \tsha: 6044eee11d1034ffac9f75cf80055a0d004d2446\n",
       " \tlastModified: 2022-07-01T12:43:24.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'language:en', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:document-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset we use comes from CodeSearchNet and we filter the dataset as the following:\n",
       " - Remove examples that codes cannot be parsed into an abstract syntax tree.\n",
       " - Remove examples that #tokens of documents is < 3 or >256\n",
       " - Remove examples that documents contain special tokens (e.g. <img ...> or https:...)\n",
       " - Remove examples that documents are not English.\n",
       " \tcitation: @article{husain2019codesearchnet,\n",
       " title={Codesearchnet challenge: Evaluating the state of semantic code search},\n",
       " author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n",
       " journal={arXiv preprint arXiv:1909.09436},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code', 'en'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['document-retrieval'], 'pretty_name': 'CodeXGlueTcNlCodeSearchAdv'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_tc_text_to_code\n",
       " \tsha: 77cba0c129cf7dfdf42486ca5a0a8d47bfbdfc15\n",
       " \tlastModified: 2022-07-27T14:38:38.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:code', 'language:en', 'license:c-uda', 'multilinguality:other-programming-languages', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-text-to-code']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We use concode dataset which is a widely used code generation dataset from Iyer's EMNLP 2018 paper Mapping Language to Code in Programmatic Context. See paper for details.\n",
       " \tcitation: @article{iyer2018mapping,\n",
       " title={Mapping language to code in programmatic context},\n",
       " author={Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Zettlemoyer, Luke},\n",
       " journal={arXiv preprint arXiv:1808.09588},\n",
       " year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['code', 'en'], 'license': ['c-uda'], 'multilinguality': ['other-programming-languages'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-text-to-code'], 'pretty_name': 'CodeXGlueTcTextToCode'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 558\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: code_x_glue_tt_text_to_text\n",
       " \tsha: 1e54637e996585332bc20e471dfaceaf051208df\n",
       " \tlastModified: 2022-07-27T14:38:38.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:da', 'language:en', 'language:lv', 'language:nb', 'language:zh', 'license:c-uda', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-code-documentation-translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset we use is crawled and filtered from Microsoft Documentation, whose document located at https://github.com/MicrosoftDocs/.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2102-04664,\n",
       "   author    = {Shuai Lu and\n",
       "                Daya Guo and\n",
       "                Shuo Ren and\n",
       "                Junjie Huang and\n",
       "                Alexey Svyatkovskiy and\n",
       "                Ambrosio Blanco and\n",
       "                Colin B. Clement and\n",
       "                Dawn Drain and\n",
       "                Daxin Jiang and\n",
       "                Duyu Tang and\n",
       "                Ge Li and\n",
       "                Lidong Zhou and\n",
       "                Linjun Shou and\n",
       "                Long Zhou and\n",
       "                Michele Tufano and\n",
       "                Ming Gong and\n",
       "                Ming Zhou and\n",
       "                Nan Duan and\n",
       "                Neel Sundaresan and\n",
       "                Shao Kun Deng and\n",
       "                Shengyu Fu and\n",
       "                Shujie Liu},\n",
       "   title     = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding\n",
       "                and Generation},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2102.04664},\n",
       "   year      = {2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['da', 'en', 'lv', 'nb', 'zh'], 'license': ['c-uda'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-code-documentation-translation'], 'pretty_name': 'CodeXGlueTtTextToText'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 834\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: com_qa\n",
       " \tsha: be2fda4839a6e2ec249fa89ccc73d42a9311327c\n",
       " \tlastModified: 2022-07-01T11:50:56.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ComQA is a dataset of 11,214 questions, which were collected from WikiAnswers, a community question answering website.\n",
       " By collecting questions from such a site we ensure that the information needs are ones of interest to actual users.\n",
       " Moreover, questions posed there are often cannot be answered by commercial search engines or QA technology, making them\n",
       " more interesting for driving future research compared to those collected from an engine's query log. The dataset contains\n",
       " questions with various challenging phenomena such as the need for temporal reasoning, comparison (e.g., comparatives,\n",
       " superlatives, ordinals), compositionality (multiple, possibly nested, subquestions with multiple entities), and\n",
       " unanswerable questions (e.g., Who was the first human being on Mars?). Through a large crowdsourcing effort, questions\n",
       " in ComQA are grouped into 4,834 paraphrase clusters that express the same information need. Each cluster is annotated\n",
       " with its answer(s). ComQA answers come in the form of Wikipedia entities wherever possible. Wherever the answers are\n",
       " temporal or measurable quantities, TIMEX3 and the International System of Units (SI) are used for normalization.\n",
       " \tcitation: @inproceedings{abujabal-etal-2019-comqa,\n",
       "     title = \"{ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters\",\n",
       "     author = {Abujabal, Abdalghani  and\n",
       "       Saha Roy, Rishiraj  and\n",
       "       Yahya, Mohamed  and\n",
       "       Weikum, Gerhard},\n",
       "     booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n",
       "     month = {jun},\n",
       "     year = {2019},\n",
       "     address = {Minneapolis, Minnesota},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     url = {https://www.aclweb.org/anthology/N19-1027},\n",
       "     doi = {10.18653/v1/N19-1027{,\n",
       "     pages = {307--317},\n",
       "     }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'comqa', 'pretty_name': 'ComQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: comqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: common_gen\n",
       " \tsha: 44ae4b95764c66715d9388702c032db42f98dc25\n",
       " \tlastModified: 2022-08-29T16:13:39.000Z\n",
       " \ttags: ['arxiv:1911.03705', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'language_creators:crowdsourced', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-concepts-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CommonGen is a constrained text generation task, associated with a benchmark dataset,\n",
       " to explicitly test machines for the ability of generative commonsense reasoning. Given\n",
       " a set of common concepts; the task is to generate a coherent sentence describing an\n",
       " everyday scenario using these concepts.\n",
       " \n",
       " CommonGen is challenging because it inherently requires 1) relational reasoning using\n",
       " background commonsense knowledge, and 2) compositional generalization ability to work\n",
       " on unseen concept combinations. Our dataset, constructed through a combination of\n",
       " crowd-sourcing from AMT and existing caption corpora, consists of 30k concept-sets and\n",
       " 50k sentences in total.\n",
       " \tcitation: @inproceedings{lin-etal-2020-commongen,\n",
       "     title = \"{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\n",
       "     author = \"Lin, Bill Yuchen  and\n",
       "       Zhou, Wangchunshu  and\n",
       "       Shen, Ming  and\n",
       "       Zhou, Pei  and\n",
       "       Bhagavatula, Chandra  and\n",
       "       Choi, Yejin  and\n",
       "       Ren, Xiang\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.165\",\n",
       "     doi = \"10.18653/v1/2020.findings-emnlp.165\",\n",
       "     pages = \"1823--1840\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found', 'crowdsourced'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'CommonGen', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-concepts-to-text'], 'paperswithcode_id': 'commongen'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 36629\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: commongen\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: common_language\n",
       " \tsha: ba380d54d355e1b54c16be75d5e96dc862701bf6\n",
       " \tlastModified: 2022-08-11T16:23:36.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'language:br', 'language:ca', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fr', 'language:fy', 'language:ia', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:ky', 'language:lv', 'language:mn', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:tt', 'language:uk', 'language:zh', 'language_bcp47:fy-NL', 'language_bcp47:rm-sursilv', 'language_bcp47:sv-SE', 'language_bcp47:zh-CN', 'language_bcp47:zh-HK', 'language_bcp47:zh-TW', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:extended|common_voice', 'task_categories:audio-classification', 'task_ids:speaker-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\n",
       " The total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\n",
       " The dataset has been extracted from CommonVoice to train language-id systems.\n",
       " \tcitation: @dataset{ganesh_sinisetty_2021_5036977,\n",
       "   author       = {Ganesh Sinisetty and\n",
       "                   Pavlo Ruban and\n",
       "                   Oleksandr Dymov and\n",
       "                   Mirco Ravanelli},\n",
       "   title        = {CommonLanguage},\n",
       "   month        = jun,\n",
       "   year         = 2021,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {0.1},\n",
       "   doi          = {10.5281/zenodo.5036977},\n",
       "   url          = {https://doi.org/10.5281/zenodo.5036977}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Common Language', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fr', 'fy', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lv', 'mn', 'mt', 'nl', 'pl', 'pt', 'rm', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv', 'ta', 'tr', 'tt', 'uk', 'zh'], 'language_bcp47': ['fy-NL', 'rm-sursilv', 'sv-SE', 'zh-CN', 'zh-HK', 'zh-TW'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|common_voice'], 'task_categories': ['audio-classification'], 'task_ids': ['speaker-identification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 416\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: common_voice\n",
       " \tsha: f02ac74a737d5b6b5fb46c9642946d1894b3e06c\n",
       " \tlastModified: 2022-07-27T14:38:38.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ab', 'language:ar', 'language:as', 'language:br', 'language:ca', 'language:cnh', 'language:cs', 'language:cv', 'language:cy', 'language:de', 'language:dv', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:hi', 'language:hsb', 'language:hu', 'language:ia', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:kab', 'language:ky', 'language:lg', 'language:lt', 'language:lv', 'language:mn', 'language:mt', 'language:nl', 'language:or', 'language:pa', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sah', 'language:sl', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:tt', 'language:uk', 'language:vi', 'language:vot', 'language:zh', 'language_bcp47:fy-NL', 'language_bcp47:ga-IE', 'language_bcp47:pa-IN', 'language_bcp47:rm-sursilv', 'language_bcp47:rm-vallader', 'language_bcp47:sv-SE', 'language_bcp47:zh-CN', 'language_bcp47:zh-HK', 'language_bcp47:zh-TW', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:extended|common_voice', 'task_categories:automatic-speech-recognition', 'configs:ab', 'configs:ar', 'configs:as', 'configs:br', 'configs:ca', 'configs:cnh', 'configs:cs', 'configs:cv', 'configs:cy', 'configs:de', 'configs:dv', 'configs:el', 'configs:en', 'configs:eo', 'configs:es', 'configs:et', 'configs:eu', 'configs:fa', 'configs:fi', 'configs:fr', 'configs:fy-NL', 'configs:ga-IE', 'configs:hi', 'configs:hsb', 'configs:hu', 'configs:ia', 'configs:id', 'configs:it', 'configs:ja', 'configs:ka', 'configs:kab', 'configs:ky', 'configs:lg', 'configs:lt', 'configs:lv', 'configs:mn', 'configs:mt', 'configs:nl', 'configs:or', 'configs:pa-IN', 'configs:pl', 'configs:pt', 'configs:rm-sursilv', 'configs:rm-vallader', 'configs:ro', 'configs:ru', 'configs:rw', 'configs:sah', 'configs:sl', 'configs:sv-SE', 'configs:ta', 'configs:th', 'configs:tr', 'configs:tt', 'configs:uk', 'configs:vi', 'configs:vot', 'configs:zh-CN', 'configs:zh-HK', 'configs:zh-TW']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Common Voice is Mozilla's initiative to help teach machines how real people speak.\n",
       " The dataset currently consists of 7,335 validated hours of speech in 60 languages, but we’re always adding more voices and languages.\n",
       " \tcitation: @inproceedings{commonvoice:2020,\n",
       "   author = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\n",
       "   title = {Common Voice: A Massively-Multilingual Speech Corpus},\n",
       "   booktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n",
       "   pages = {4211--4215},\n",
       "   year = 2020\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Common Voice', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ab', 'ar', 'as', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'hi', 'hsb', 'hu', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lg', 'lt', 'lv', 'mn', 'mt', 'nl', 'or', 'pa', 'pl', 'pt', 'rm', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv', 'ta', 'th', 'tr', 'tt', 'uk', 'vi', 'vot', 'zh'], 'language_bcp47': ['fy-NL', 'ga-IE', 'pa-IN', 'rm-sursilv', 'rm-vallader', 'sv-SE', 'zh-CN', 'zh-HK', 'zh-TW'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['extended|common_voice'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'paperswithcode_id': 'common-voice', 'configs': ['ab', 'ar', 'as', 'br', 'ca', 'cnh', 'cs', 'cv', 'cy', 'de', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy-NL', 'ga-IE', 'hi', 'hsb', 'hu', 'ia', 'id', 'it', 'ja', 'ka', 'kab', 'ky', 'lg', 'lt', 'lv', 'mn', 'mt', 'nl', 'or', 'pa-IN', 'pl', 'pt', 'rm-sursilv', 'rm-vallader', 'ro', 'ru', 'rw', 'sah', 'sl', 'sv-SE', 'ta', 'th', 'tr', 'tt', 'uk', 'vi', 'vot', 'zh-CN', 'zh-HK', 'zh-TW']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 25022\n",
       " \tlikes: 45\n",
       " \tpaperswithcode_id: common-voice\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: commonsense_qa\n",
       " \tsha: 347b05e75ffeb057b4f85494a70190caf6e21d86\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['arxiv:1811.00937', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\n",
       " to predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\n",
       " The dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\n",
       " split, and \"Question token split\", see paper for details.\n",
       " \tcitation: @inproceedings{talmor-etal-2019-commonsenseqa,\n",
       "     title = \"{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge\",\n",
       "     author = \"Talmor, Alon  and\n",
       "       Herzig, Jonathan  and\n",
       "       Lourie, Nicholas  and\n",
       "       Berant, Jonathan\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n",
       "     month = jun,\n",
       "     year = \"2019\",\n",
       "     address = \"Minneapolis, Minnesota\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/N19-1421\",\n",
       "     doi = \"10.18653/v1/N19-1421\",\n",
       "     pages = \"4149--4158\",\n",
       "     archivePrefix = \"arXiv\",\n",
       "     eprint        = \"1811.00937\",\n",
       "     primaryClass  = \"cs\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'CommonsenseQA', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'commonsenseqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3313\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: commonsenseqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: competition_math\n",
       " \tsha: 9f6a4e066bfd715ca576b1f4287c1402375d2a57\n",
       " \tlastModified: 2022-07-01T11:50:59.000Z\n",
       " \ttags: ['arxiv:2103.03874', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-explanation-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\n",
       " from mathematics competitions, including the AMC 10, AMC 12, AIME, and more.\n",
       " Each problem in MATH has a full step-by-step solution, which can be used to teach\n",
       " models to generate answer derivations and explanations.\n",
       " \tcitation: @article{hendrycksmath2021,\n",
       "   title={Measuring Mathematical Problem Solving With the MATH Dataset},\n",
       "   author={Dan Hendrycks\n",
       "     and Collin Burns\n",
       "     and Saurav Kadavath\n",
       "     and Akul Arora\n",
       "     and Steven Basart\n",
       "     and Eric Tang\n",
       "     and Dawn Song\n",
       "     and Jacob Steinhardt},\n",
       "   journal={arXiv preprint arXiv:2103.03874},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Mathematics Aptitude Test of Heuristics (MATH)', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-explanation-generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9224\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: compguesswhat\n",
       " \tsha: e3be5f3e8281eab2036bada5c8b1e57c7050fcdd\n",
       " \tlastModified: 2022-09-12T07:58:47.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-guesswhat', 'task_categories:visual-question-answering', 'task_ids:visual-question-answering']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CompGuessWhat?! is an instance of a multi-task framework for evaluating the quality of learned neural representations,\n",
       "         in particular concerning attribute grounding. Use this dataset if you want to use the set of games whose reference\n",
       "         scene is an image in VisualGenome. Visit the website for more details: https://compguesswhat.github.io\n",
       " \tcitation:         @inproceedings{suglia2020compguesswhat,\n",
       "           title={CompGuessWhat?!: a Multi-task Evaluation Framework for Grounded Language Learning},\n",
       "           author={Suglia, Alessandro, Konstas, Ioannis, Vanzo, Andrea, Bastianelli, Emanuele, Desmond Elliott, Stella Frank and Oliver Lemon},\n",
       "           booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n",
       "           year={2020}\n",
       "         }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'CompGuessWhat?!', 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-guesswhat'], 'task_categories': ['visual-question-answering'], 'task_ids': ['visual-question-answering'], 'paperswithcode_id': 'compguesswhat'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 514\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: compguesswhat\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conceptnet5\n",
       " \tsha: caaf71608efeb0f8a3e7308c32a61da69cf83a02\n",
       " \tlastModified: 2022-07-01T11:50:59.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'language:zh', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'configs:conceptnet5', 'configs:omcs_sentences_free', 'configs:omcs_sentences_more']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is designed to provide training data\n",
       " for common sense relationships pulls together from various sources.\n",
       " \n",
       " The dataset is multi-lingual. See langauge codes and language info\n",
       " here: https://github.com/commonsense/conceptnet5/wiki/Languages\n",
       " \n",
       " \n",
       " This dataset provides an interface for the conceptnet5 csv file, and\n",
       " some (but not all) of the raw text data used to build conceptnet5:\n",
       " omcsnet_sentences_free.txt, and omcsnet_sentences_more.txt.\n",
       " \n",
       " One use of this dataset would be to learn to extract the conceptnet\n",
       " relationship from the omcsnet sentences.\n",
       " \n",
       " Conceptnet5 has 34,074,917 relationships. Of those relationships,\n",
       " there are 2,176,099 surface text sentences related to those 2M\n",
       " entries.\n",
       " \n",
       " omcsnet_sentences_free has 898,161 lines. omcsnet_sentences_more has\n",
       " 2,001,736 lines.\n",
       " \n",
       " Original downloads are available here\n",
       " https://github.com/commonsense/conceptnet5/wiki/Downloads. For more\n",
       " information, see: https://github.com/commonsense/conceptnet5/wiki\n",
       " \n",
       " The omcsnet data comes with the following warning from the authors of\n",
       " the above site: Remember: this data comes from various forms of\n",
       " crowdsourcing. Sentences in these files are not necessarily true,\n",
       " useful, or appropriate.\n",
       " \tcitation: \\\n",
       " Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. \"ConceptNet 5.5: An Open Multilingual Graph of General Knowledge.\" In proceedings of AAAI 31.\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['de', 'en', 'es', 'fr', 'it', 'ja', 'nl', 'pt', 'ru', 'zh'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'conceptnet', 'pretty_name': 'Conceptnet5', 'configs': ['conceptnet5', 'omcs_sentences_free', 'omcs_sentences_more']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 669\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: conceptnet\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conll2000\n",
       " \tsha: c639df6abbd403f2658f0f9b86e897ad73a97c51\n",
       " \tlastModified: 2022-10-03T09:11:58.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  Text chunking consists of dividing a text in syntactically correlated parts of words. For example, the sentence\n",
       "  He reckons the current account deficit will narrow to only # 1.8 billion in September . can be divided as follows:\n",
       " [NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] [PP to ] [NP only # 1.8 billion ]\n",
       " [PP in ] [NP September ] .\n",
       " \n",
       " Text chunking is an intermediate step towards full parsing. It was the shared task for CoNLL-2000. Training and test\n",
       " data for this task is available. This data consists of the same partitions of the Wall Street Journal corpus (WSJ)\n",
       " as the widely used data for noun phrase chunking: sections 15-18 as training data (211727 tokens) and section 20 as\n",
       " test data (47377 tokens). The annotation of the data has been derived from the WSJ corpus by a program written by\n",
       " Sabine Buchholz from Tilburg University, The Netherlands.\n",
       " \tcitation: @inproceedings{tksbuchholz2000conll,\n",
       "    author     = \"Tjong Kim Sang, Erik F. and Sabine Buchholz\",\n",
       "    title      = \"Introduction to the CoNLL-2000 Shared Task: Chunking\",\n",
       "    editor     = \"Claire Cardie and Walter Daelemans and Claire\n",
       "                  Nedellec and Tjong Kim Sang, Erik\",\n",
       "    booktitle  = \"Proceedings of CoNLL-2000 and LLL-2000\",\n",
       "    publisher  = \"Lisbon, Portugal\",\n",
       "    pages      = \"127--132\",\n",
       "    year       = \"2000\"\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'conll-2000-1', 'pretty_name': 'CoNLL-2000', 'dataset_info': {'features': [{'name': 'id', 'dtype': 'string'}, {'name': 'tokens', 'sequence': 'string'}, {'name': 'pos_tags', 'sequence': {'class_label': {'names': {'0': \"''\", '1': '#', '2': '$', '3': '(', '4': ')', '5': ',', '6': '.', '7': ':', '8': '``', '9': 'CC', '10': 'CD', '11': 'DT', '12': 'EX', '13': 'FW', '14': 'IN', '15': 'JJ', '16': 'JJR', '17': 'JJS', '18': 'MD', '19': 'NN', '20': 'NNP', '21': 'NNPS', '22': 'NNS', '23': 'PDT', '24': 'POS', '25': 'PRP', '26': 'PRP$', '27': 'RB', '28': 'RBR', '29': 'RBS', '30': 'RP', '31': 'SYM', '32': 'TO', '33': 'UH', '34': 'VB', '35': 'VBD', '36': 'VBG', '37': 'VBN', '38': 'VBP', '39': 'VBZ', '40': 'WDT', '41': 'WP', '42': 'WP$', '43': 'WRB'}}}}, {'name': 'chunk_tags', 'sequence': {'class_label': {'names': {'0': 'O', '1': 'B-ADJP', '2': 'I-ADJP', '3': 'B-ADVP', '4': 'I-ADVP', '5': 'B-CONJP', '6': 'I-CONJP', '7': 'B-INTJ', '8': 'I-INTJ', '9': 'B-LST', '10': 'I-LST', '11': 'B-NP', '12': 'I-NP', '13': 'B-PP', '14': 'I-PP', '15': 'B-PRT', '16': 'I-PRT', '17': 'B-SBAR', '18': 'I-SBAR', '19': 'B-UCP', '20': 'I-UCP', '21': 'B-VP', '22': 'I-VP'}}}}], 'splits': [{'name': 'test', 'num_bytes': 1201151, 'num_examples': 2013}, {'name': 'train', 'num_bytes': 5356965, 'num_examples': 8937}], 'download_size': 3481560, 'dataset_size': 6558116}}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 619\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: conll-2000-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conll2002\n",
       " \tsha: 370de86f0095c49738626028e8d28a024d10cafa\n",
       " \tlastModified: 2022-07-19T12:41:58.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:es', 'language:nl', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech', 'configs:es', 'configs:nl']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n",
       " \n",
       " Example:\n",
       " [PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\n",
       " \n",
       " The shared task of CoNLL-2002 concerns language-independent named entity recognition.\n",
       " We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups.\n",
       " The participants of the shared task will be offered training and test data for at least two languages.\n",
       " They will use the data for developing a named-entity recognition system that includes a machine learning component.\n",
       " Information sources other than the training data may be used in this shared task.\n",
       " We are especially interested in methods that can use additional unannotated data for improving their performance (for example co-training).\n",
       " \n",
       " The train/validation/test sets are available in Spanish and Dutch.\n",
       " \n",
       " For more details see https://www.clips.uantwerpen.be/conll2002/ner/ and https://www.aclweb.org/anthology/W02-2024/\n",
       " \tcitation: @inproceedings{tjong-kim-sang-2002-introduction,\n",
       "     title = \"Introduction to the {C}o{NLL}-2002 Shared Task: Language-Independent Named Entity Recognition\",\n",
       "     author = \"Tjong Kim Sang, Erik F.\",\n",
       "     booktitle = \"{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002)\",\n",
       "     year = \"2002\",\n",
       "     url = \"https://www.aclweb.org/anthology/W02-2024\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['es', 'nl'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'part-of-speech'], 'paperswithcode_id': 'conll-2002', 'pretty_name': 'CoNLL-2002', 'configs': ['es', 'nl']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 823\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: conll-2002\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conll2003\n",
       " \tsha: 331adb7e97519e443e4c23e33c4805c9fd5a9381\n",
       " \tlastModified: 2022-07-08T14:03:19.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-reuters-corpus', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\n",
       " four types of named entities: persons, locations, organizations and names of miscellaneous entities that do\n",
       " not belong to the previous three groups.\n",
       " \n",
       " The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\n",
       " a separate line and there is an empty line after each sentence. The first item on each line is a word, the second\n",
       " a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\n",
       " and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\n",
       " if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\n",
       " B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\n",
       " tagging scheme, whereas the original dataset uses IOB1.\n",
       " \n",
       " For more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\n",
       " \tcitation: @inproceedings{tjong-kim-sang-de-meulder-2003-introduction,\n",
       "     title = \"Introduction to the {C}o{NLL}-2003 Shared Task: Language-Independent Named Entity Recognition\",\n",
       "     author = \"Tjong Kim Sang, Erik F.  and\n",
       "       De Meulder, Fien\",\n",
       "     booktitle = \"Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003\",\n",
       "     year = \"2003\",\n",
       "     url = \"https://www.aclweb.org/anthology/W03-0419\",\n",
       "     pages = \"142--147\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-reuters-corpus'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'part-of-speech'], 'paperswithcode_id': 'conll-2003', 'pretty_name': 'CoNLL-2003', 'train-eval-index': [{'config': 'conll2003', 'task': 'token-classification', 'task_id': 'entity_extraction', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'tokens': 'tokens', 'ner_tags': 'tags'}, 'metrics': [{'type': 'seqeval', 'name': 'seqeval'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 23438\n",
       " \tlikes: 25\n",
       " \tpaperswithcode_id: conll-2003\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conllpp\n",
       " \tsha: 7104dd991ed584d1e0f6712444e317f90d7bf2e1\n",
       " \tlastModified: 2022-08-24T04:09:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|conll2003', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CoNLLpp is a corrected version of the CoNLL2003 NER dataset where labels of 5.38% of the sentences in the test set\n",
       " have been manually corrected. The training set and development set are included for completeness.\n",
       " For more details see https://www.aclweb.org/anthology/D19-1519/ and https://github.com/ZihanWangKi/CrossWeigh\n",
       " \tcitation: @inproceedings{wang2019crossweigh,\n",
       "   title={CrossWeigh: Training Named Entity Tagger from Imperfect Annotations},\n",
       "   author={Wang, Zihan and Shang, Jingbo and Liu, Liyuan and Lu, Lihao and Liu, Jiacheng and Han, Jiawei},\n",
       "   booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n",
       "   pages={5157--5166},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|conll2003'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'conll', 'pretty_name': 'CoNLL++', 'train-eval-index': [{'config': 'conllpp', 'task': 'token-classification', 'task_id': 'entity_extraction', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'tokens': 'tokens', 'ner_tags': 'tags'}, 'metrics': [{'type': 'seqeval', 'name': 'seqeval'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2105\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: conll\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: consumer-finance-complaints\n",
       " \tsha: f7eccf8af8c82538dff88d193f9f2fcf0ac71522\n",
       " \tlastModified: 2022-07-01T12:43:25.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: \\\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'consumer-finance-complaints', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 369\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conv_ai\n",
       " \tsha: 817499dda5d8d08d45240f811241d8dab013aca6\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:conversational', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-evaluating-dialogue-systems']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ConvAI is a dataset of human-to-bot conversations labelled for quality. This data can be used to train a metric for evaluating dialogue systems. Moreover, it can be used in the development of chatbots themselves: it contains the information on the quality of utterances and entire dialogues, that can guide a dialogue system in search of better answers.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-evaluating-dialogue-systems'], 'paperswithcode_id': None, 'pretty_name': 'ConvAi'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 543\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conv_ai_2\n",
       " \tsha: a981b9fdeca8bc559a28a2453c6d2eb1482a30d6\n",
       " \tlastModified: 2022-07-01T11:51:06.000Z\n",
       " \ttags: ['arxiv:1902.00098', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:conversational', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-scoring-other-evaluating-dialogue-systems']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ConvAI is a dataset of human-to-bot conversations labelled for quality. This data can be used to train a metric for evaluating dialogue systems. Moreover, it can be used in the development of chatbots themselves: it contains the information on the quality of utterances and entire dialogues, that can guide a dialogue system in search of better answers.\n",
       " \tcitation: @misc{dinan2019second,\n",
       "       title={The Second Conversational Intelligence Challenge (ConvAI2)},\n",
       "       author={Emily Dinan and Varvara Logacheva and Valentin Malykh and Alexander Miller and Kurt Shuster and Jack Urbanek and Douwe Kiela and Arthur Szlam and Iulian Serban and Ryan Lowe and Shrimai Prabhumoye and Alan W Black and Alexander Rudnicky and Jason Williams and Joelle Pineau and Mikhail Burtsev and Jason Weston},\n",
       "       year={2019},\n",
       "       eprint={1902.00098},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.AI}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'text-classification'], 'task_ids': ['text-scoring', 'text-scoring-other-evaluating-dialogue-systems'], 'paperswithcode_id': 'convai2', 'pretty_name': 'Conversational Intelligence Challenge 2'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 626\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: convai2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conv_ai_3\n",
       " \tsha: 004c50286a818bb7c7a92b08a6cdf77be0ef2bc8\n",
       " \tlastModified: 2022-07-01T11:51:06.000Z\n",
       " \ttags: ['arxiv:2009.11352', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:conversational', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-scoring-other-evaluating-dialogue-systems']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Conv AI 3 challenge is organized as part of the Search-oriented Conversational AI (SCAI) EMNLP workshop in 2020. The main aim of the conversational systems is to return an appropriate answer in response to the user requests. However, some user requests might be ambiguous. In Information Retrieval (IR) settings such a situation is handled mainly through the diversification of search result page. It is however much more challenging in dialogue settings. Hence, we aim to study the following situation for dialogue settings:\n",
       " - a user is asking an ambiguous question (where ambiguous question is a question to which one can return > 1 possible answers)\n",
       " - the system must identify that the question is ambiguous, and, instead of trying to answer it directly, ask a good clarifying question.\n",
       " \tcitation: @misc{aliannejadi2020convai3,\n",
       "       title={ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue Systems (ClariQ)},\n",
       "       author={Mohammad Aliannejadi and Julia Kiseleva and Aleksandr Chuklin and Jeff Dalton and Mikhail Burtsev},\n",
       "       year={2020},\n",
       "       eprint={2009.11352},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'text-classification'], 'task_ids': ['text-scoring', 'text-scoring-other-evaluating-dialogue-systems'], 'paperswithcode_id': None, 'pretty_name': 'More Information Needed'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 566\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: conv_questions\n",
       " \tsha: 3ae3045e552dc2ed21d30823b8f5474fa702a1e4\n",
       " \tlastModified: 2022-07-27T14:38:42.000Z\n",
       " \ttags: ['arxiv:1910.03262', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'language_bcp47:en-US', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:open-domain-qa', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ConvQuestions is the first realistic benchmark for conversational question answering over knowledge graphs.\n",
       " It contains 11,200 conversations which can be evaluated over Wikidata. The questions feature a variety of complex\n",
       " question phenomena like comparisons, aggregations, compositionality, and temporal reasoning.\n",
       " \tcitation: @InProceedings{christmann2019look,\n",
       "   title={Look before you hop: Conversational question answering over knowledge graphs using judicious context expansion},\n",
       "   author={Christmann, Philipp and Saha Roy, Rishiraj and Abujabal, Abdalghani and Singh, Jyotsna and Weikum, Gerhard},\n",
       "   booktitle={Proceedings of the 28th ACM International Conference on Information and Knowledge Management},\n",
       "   pages={729--738},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'language_bcp47': ['en-US'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text-generation', 'fill-mask'], 'task_ids': ['open-domain-qa', 'dialogue-modeling'], 'pretty_name': 'ConvQuestions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: coqa\n",
       " \tsha: 684c4a146a135c3adbec6b41677f7aa4b0b035ff\n",
       " \tlastModified: 2022-09-06T05:39:59.000Z\n",
       " \ttags: ['arxiv:1808.07042', 'arxiv:1704.04683', 'arxiv:1506.03340', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|race', 'source_datasets:extended|cnn_dailymail', 'source_datasets:extended|wikipedia', 'source_datasets:extended|other', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-conversational-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CoQA: A Conversational Question Answering Challenge\n",
       " \tcitation: @article{reddy-etal-2019-coqa,\n",
       "     title = \"{C}o{QA}: A Conversational Question Answering Challenge\",\n",
       "     author = \"Reddy, Siva  and\n",
       "       Chen, Danqi  and\n",
       "       Manning, Christopher D.\",\n",
       "     journal = \"Transactions of the Association for Computational Linguistics\",\n",
       "     volume = \"7\",\n",
       "     year = \"2019\",\n",
       "     address = \"Cambridge, MA\",\n",
       "     publisher = \"MIT Press\",\n",
       "     url = \"https://aclanthology.org/Q19-1016\",\n",
       "     doi = \"10.1162/tacl_a_00266\",\n",
       "     pages = \"249--266\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'CoQA: Conversational Question Answering Challenge', 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|race', 'extended|cnn_dailymail', 'extended|wikipedia', 'extended|other'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-conversational-qa'], 'paperswithcode_id': 'coqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1218\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: coqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cord19\n",
       " \tsha: 54adb53669c0ada3d38dd8a254a21ffead7dfb73\n",
       " \tlastModified: 2022-07-01T12:43:26.000Z\n",
       " \ttags: ['arxiv:2004.07180', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:cc-by-nd-4.0', 'license:cc-by-sa-4.0', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-knowledge-extraction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Covid-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on Covid-19 and related\n",
       " historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information\n",
       " retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19\n",
       " has been downloaded over 75K times and has served as the basis of many Covid-19 text mining and discovery systems.\n",
       " \n",
       " The dataset itself isn't defining a specific task, but there is a Kaggle challenge that define 17 open research\n",
       " questions to be solved with the dataset: https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks\n",
       " \tcitation: @article{Wang2020CORD19TC,\n",
       "   title={CORD-19: The Covid-19 Open Research Dataset},\n",
       "   author={Lucy Lu Wang and Kyle Lo and Yoganand Chandrasekhar and Russell Reas and Jiangjiang Yang and Darrin Eide and\n",
       "   K. Funk and Rodney Michael Kinney and Ziyang Liu and W. Merrill and P. Mooney and D. Murdick and Devvret Rishi and\n",
       "   Jerry Sheehan and Zhihong Shen and B. Stilson and A. Wade and K. Wang and Christopher Wilhelm and Boya Xie and\n",
       "   D. Raymond and Daniel S. Weld and Oren Etzioni and Sebastian Kohlmeier},\n",
       "   journal={ArXiv},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nd-4.0', 'cc-by-sa-4.0', 'other'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-knowledge-extraction'], 'paperswithcode_id': 'cord-19', 'pretty_name': 'CORD-19'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1094\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cord-19\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cornell_movie_dialog\n",
       " \tsha: 36c6d57ccb9586204f1a84ad440983d5f6ba4912\n",
       " \tlastModified: 2022-07-01T11:51:09.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts:\n",
       " - 220,579 conversational exchanges between 10,292 pairs of movie characters\n",
       " - involves 9,035 characters from 617 movies\n",
       " - in total 304,713 utterances\n",
       " - movie metadata included:\n",
       "     - genres\n",
       "     - release year\n",
       "     - IMDB rating\n",
       "     - number of IMDB votes\n",
       "     - IMDB rating\n",
       " - character metadata included:\n",
       "     - gender (for 3,774 characters)\n",
       "     - position on movie credits (3,321 characters)\n",
       " \tcitation:   @InProceedings{Danescu-Niculescu-Mizil+Lee:11a,\n",
       " \n",
       "   author={Cristian Danescu-Niculescu-Mizil and Lillian Lee},\n",
       " \n",
       "   title={Chameleons in imagined conversations:\n",
       "   A new approach to understanding coordination of linguistic style in dialogs.},\n",
       " \n",
       "   booktitle={Proceedings of the\n",
       " \n",
       "         Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011},\n",
       " \n",
       "   year={2011}\n",
       " \n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'cornell-movie-dialogs-corpus', 'pretty_name': 'Cornell Movie-Dialogs Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 369\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cornell-movie-dialogs-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cos_e\n",
       " \tsha: 1bb8c4059ff58fe55a9ee2413014d1a02d4be2ce\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['arxiv:1906.02361', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:crowdsourced', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|commonsense_qa', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Common Sense Explanations (CoS-E) allows for training language models to\n",
       " automatically generate explanations that can be used during training and\n",
       " inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework.\n",
       " \tcitation: @inproceedings{rajani2019explain,\n",
       "      title = {Explain Yourself! Leveraging Language models for Commonsense Reasoning},\n",
       "     author = {Rajani, Nazneen Fatema  and\n",
       "       McCann, Bryan  and\n",
       "       Xiong, Caiming  and\n",
       "       Socher, Richard}\n",
       "       year={2019}\n",
       "     booktitle = {Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019)}\n",
       "     url ={https://arxiv.org/abs/1906.02361}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['crowdsourced'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Commonsense Explanations', 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|commonsense_qa'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'cos-e'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 57617\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cos-e\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cosmos_qa\n",
       " \tsha: 2605bbb672ca4cd748081c6c56458369a25118da\n",
       " \tlastModified: 2022-08-30T09:48:02.000Z\n",
       " \ttags: ['arxiv:1909.00277', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Cosmos QA is a large-scale dataset of 35.6K problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. It focuses on reading between the lines over a diverse collection of people's everyday narratives, asking questions concerning on the likely causes or effects of events that require reasoning beyond the exact text spans in the context\n",
       " \tcitation: @inproceedings{huang-etal-2019-cosmos,\n",
       "     title = \"Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning\",\n",
       "     author = \"Huang, Lifu  and\n",
       "       Le Bras, Ronan  and\n",
       "       Bhagavatula, Chandra  and\n",
       "       Choi, Yejin\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2019\",\n",
       "     address = \"Hong Kong, China\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D19-1243\",\n",
       "     doi = \"10.18653/v1/D19-1243\",\n",
       "     pages = \"2391--2401\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'CosmosQA', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'cosmosqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 60366\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: cosmosqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: counter\n",
       " \tsha: df5b7289e1e648c6ff7c5e9227d5730dcc99424a\n",
       " \tlastModified: 2022-07-01T11:51:10.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ur', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  The COrpus of Urdu News TExt Reuse (COUNTER) corpus contains 1200 documents with real examples of text reuse from the field of journalism. It has been manually annotated at document level with three levels of reuse: wholly derived, partially derived and non derived.\n",
       " \tcitation: @Article{Sharjeel2016,\n",
       " author=\"Sharjeel, Muhammad\n",
       " and Nawab, Rao Muhammad Adeel\n",
       " and Rayson, Paul\",\n",
       " title=\"COUNTER: corpus of Urdu news text reuse\",\n",
       " journal=\"Language Resources and Evaluation\",\n",
       " year=\"2016\",\n",
       " pages=\"1--27\",\n",
       " issn=\"1574-0218\",\n",
       " doi=\"10.1007/s10579-016-9367-2\",\n",
       " url=\"http://dx.doi.org/10.1007/s10579-016-9367-2\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ur'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring', 'topic-classification'], 'paperswithcode_id': 'counter', 'pretty_name': 'COUNTER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: counter\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: covid_qa_castorini\n",
       " \tsha: ab1da46b572d6ce2a6612e6177e7dbb5d59e5b50\n",
       " \tlastModified: 2022-08-23T18:05:37.000Z\n",
       " \ttags: ['arxiv:2004.11339', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CovidQA is the beginnings of a question answering dataset specifically designed for COVID-19, built by hand from knowledge gathered from Kaggle's COVID-19 Open Research Dataset Challenge.\n",
       " \tcitation: @article{tang2020rapidly,\n",
       "   title={Rapidly Bootstrapping a Question Answering Dataset for COVID-19},\n",
       "   author={Tang, Raphael and Nogueira, Rodrigo and Zhang, Edwin and Gupta, Nikhil and Cam, Phuong and Cho, Kyunghyun and Lin, Jimmy},\n",
       "   journal={arXiv preprint arXiv:2004.11339},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa', 'extractive-qa'], 'paperswithcode_id': 'covidqa', 'pretty_name': 'CovidQaCastorini'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 542\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: covidqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: covid_qa_deepset\n",
       " \tsha: 180f2f56db1a6799546f36b25ae1dbfee9724a5c\n",
       " \tlastModified: 2022-07-01T11:51:11.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: COVID-QA is a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19.\n",
       " \tcitation: @inproceedings{moller2020covid,\n",
       "   title={COVID-QA: A Question Answering Dataset for COVID-19},\n",
       "   author={M{\\\"o}ller, Timo and Reina, Anthony and Jayakumar, Raghavan and Pietsch, Malte},\n",
       "   booktitle={Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa', 'extractive-qa'], 'paperswithcode_id': None, 'pretty_name': 'COVID-QA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 917\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: covid_qa_ucsd\n",
       " \tsha: 88c8b1d38e43a82892798e9e4ed251e9aa1440bc\n",
       " \tlastModified: 2022-07-01T11:51:13.000Z\n",
       " \ttags: ['arxiv:2005.05442', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa', 'configs:en', 'configs:zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @article{ju2020CovidDialog,\n",
       "   title={CovidDialog: Medical Dialogue Datasets about COVID-19},\n",
       "   author={Ju, Zeqian and Chakravorty, Subrato and He, Xuehai and Chen, Shu and Yang, Xingyi and Xie, Pengtao},\n",
       "   journal={ https://github.com/UCSD-AI4H/COVID-Dialogue},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['expert-generated', 'found'], 'language': ['en', 'zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'CovidQaUcsd', 'configs': ['en', 'zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 509\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: covid_tweets_japanese\n",
       " \tsha: c981e26cf7470d59457e36ebe44b74cac031008d\n",
       " \tlastModified: 2022-07-01T11:51:13.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ja', 'license:cc-by-nd-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: 53,640 Japanese tweets with annotation if a tweet is related to COVID-19 or not. The annotation is by majority decision by 5 - 10 crowd workers. Target tweets include \"COVID\" or \"コロナ\". The period of the tweets is from around January 2020 to around June 2020. The original tweets are not contained. Please use Twitter API to get them, for example.\n",
       " \tcitation: No paper about this dataset is published yet. Please cite this dataset as \"鈴木 優: COVID-19 日本語 Twitter データセット （http://www.db.info.gifu-u.ac.jp/covid-19-twitter-dataset/）\"\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ja'], 'license': ['cc-by-nd-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'COVID-19 日本語Twitterデータセット (COVID-19 Japanese Twitter Dataset)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: covost2\n",
       " \tsha: 7d865322e844b403bcf6616f7d1d96f483ce97ee\n",
       " \tlastModified: 2022-07-27T14:38:42.000Z\n",
       " \ttags: ['arxiv:2007.10310', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:ar', 'language:ca', 'language:cy', 'language:de', 'language:es', 'language:et', 'language:fa', 'language:fr', 'language:id', 'language:it', 'language:ja', 'language:lv', 'language:mn', 'language:nl', 'language:pt', 'language:ru', 'language:sl', 'language:sv', 'language:ta', 'language:tr', 'language:zh', 'language_bcp47:sv-SE', 'language_bcp47:zh-CN', 'license:cc-by-nc-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-common-voice', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CoVoST 2, a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla’s open source Common Voice database of crowdsourced voice recordings.\n",
       " \n",
       " Note that in order to limit the required storage for preparing this dataset, the audio\n",
       " is stored in the .mp3 format and is not converted to a float32 array. To convert, the audio\n",
       " file to a float32 array, please make use of the `.map()` function as follows:\n",
       " \n",
       " \n",
       " ```python\n",
       " import torchaudio\n",
       " \n",
       " def map_to_array(batch):\n",
       "     speech_array, _ = torchaudio.load(batch[\"file\"])\n",
       "     batch[\"speech\"] = speech_array.numpy()\n",
       "     return batch\n",
       " \n",
       " dataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n",
       " ```\n",
       " \tcitation: @misc{wang2020covost,\n",
       "     title={CoVoST 2: A Massively Multilingual Speech-to-Text Translation Corpus},\n",
       "     author={Changhan Wang and Anne Wu and Juan Pino},\n",
       "     year={2020},\n",
       "     eprint={2007.10310},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['ar', 'ca', 'cy', 'de', 'es', 'et', 'fa', 'fr', 'id', 'it', 'ja', 'lv', 'mn', 'nl', 'pt', 'ru', 'sl', 'sv', 'ta', 'tr', 'zh'], 'language_bcp47': ['sv-SE', 'zh-CN'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-common-voice'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'CoVoST 2'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6126\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cppe-5\n",
       " \tsha: 0baf5905be5e9698eec2029cd631f3de9ac25c63\n",
       " \tlastModified: 2022-08-11T16:23:36.000Z\n",
       " \ttags: ['arxiv:2112.09569', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:object-detection', 'task_ids:object-detection-other-medical-personal-protective-equipment-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CPPE - 5 (Medical Personal Protective Equipment) is a new challenging dataset with the goal\n",
       " to allow the study of subordinate categorization of medical personal protective equipments,\n",
       " which is not possible with other popular data sets that focus on broad level categories.\n",
       " \tcitation: @misc{dagli2021cppe5,\n",
       "       title={CPPE-5: Medical Personal Protective Equipment Dataset},\n",
       "       author={Rishit Dagli and Ali Mustufa Shaikh},\n",
       "       year={2021},\n",
       "       eprint={2112.09569},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CV}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['object-detection'], 'task_ids': ['object-detection-other-medical-personal-protective-equipment-detection'], 'paperswithcode_id': 'cppe-5', 'pretty_name': 'CPPE - 5'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 452\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: cppe-5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: craigslist_bargains\n",
       " \tsha: ce8c7660da9ac2a17d80bfaf49ed471a6f9eb246\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['arxiv:1808.09637', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We study negotiation dialogues where two agents, a buyer and a seller,\n",
       " negotiate over the price of an time for sale. We collected a dataset of more\n",
       " than 6K negotiation dialogues over multiple categories of products scraped from Craigslist.\n",
       " Our goal is to develop an agent that negotiates with humans through such conversations.\n",
       " The challenge is to handle both the negotiation strategy and the rich language for bargaining.\n",
       " \tcitation: @misc{he2018decoupling,\n",
       "     title={Decoupling Strategy and Generation in Negotiation Dialogues},\n",
       "     author={He He and Derek Chen and Anusha Balakrishnan and Percy Liang},\n",
       "     year={2018},\n",
       "     eprint={1808.09637},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'craigslistbargains', 'pretty_name': 'CraigslistBargains'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 582\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: craigslistbargains\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: crawl_domain\n",
       " \tsha: 93fbda30a3fd8b20e0587f083825387d69492021\n",
       " \tlastModified: 2022-07-01T11:51:14.000Z\n",
       " \ttags: ['arxiv:2011.03138', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-Common-Crawl', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-text-to-speech', 'task_ids:other-other-web-search']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Corpus of domain names scraped from Common Crawl and manually annotated to add word boundaries (e.g. \"commoncrawl\" to \"common crawl\"). Breaking domain names such as \"openresearch\" into component words \"open\" and \"research\" is important for applications such as Text-to-Speech synthesis and web search. Common Crawl is an open repository of web crawl data that can be accessed and analyzed by anyone. Specifically, we scraped the plaintext (WET) extracts for domain names from URLs that contained diverse letter casing (e.g. \"OpenBSD\"). Although in the previous example, segmentation is trivial using letter casing, this was not always the case (e.g. \"NASA\"), so we had to manually annotate the data. The dataset is stored as plaintext file where each line is an example of space separated segments of a domain name. The examples are stored in their original letter casing, but harder and more interesting examples can be generated by lowercasing the input first.\n",
       " \tcitation: @inproceedings{zrs2020urlsegmentation,\n",
       "   title={Semi-supervised URL Segmentation with Recurrent Neural Networks Pre-trained on Knowledge Graph Entities},\n",
       "   author={Hao Zhang and Jae Ro and Richard William Sproat},\n",
       "   booktitle={The 28th International Conference on Computational Linguistics (COLING 2020)},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated', 'found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-Common-Crawl', 'original'], 'task_categories': ['other'], 'task_ids': ['other-other-text-to-speech', 'other-other-web-search'], 'paperswithcode_id': 'common-crawl-domain-names', 'pretty_name': 'Common Crawl Domain Names'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 378\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: common-crawl-domain-names\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: crd3\n",
       " \tsha: 075406316b7810bb750dfd8a367d9bb9cc6695f8\n",
       " \tlastModified: 2022-07-21T17:07:04.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling', 'size_categories:10K<n<100K']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset.\n",
       " Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an open-ended role-playing game.\n",
       " The dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding\n",
       " abstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player\n",
       " collaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail,\n",
       " and semantic ties to the previous dialogues.\n",
       " \tcitation: @inproceedings{\n",
       " title = {Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset},\n",
       " author = {Rameshkumar, Revanth  and Bailey, Peter},\n",
       " year = {2020},\n",
       " publisher = {Association for Computational Linguistics},\n",
       " conference = {ACL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'CRD3 (Critical Role Dungeons and Dragons Dataset)', 'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'task_categories': ['summarization', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'size_categories': ['10K<n<100K'], 'paperswithcode_id': 'crd3'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 387\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: crd3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: crime_and_punish\n",
       " \tsha: cc9f890c6d012a4dee7eba13fe17298f16044c05\n",
       " \tlastModified: 2022-10-03T09:11:58.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': None, 'pretty_name': 'CrimeAndPunish', 'dataset_info': {'dataset_size': 1270540, 'download_size': 1201735, 'features': [{'dtype': 'string', 'name': 'line'}], 'splits': [{'name': 'train', 'num_bytes': 1270540, 'num_examples': 21969}]}}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1670\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: crows_pairs\n",
       " \tsha: c348bbb35f45b179049f277890e683a6559d3567\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-bias-evaluation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: CrowS-Pairs, a challenge dataset for measuring the degree to which U.S. stereotypical biases present in the masked language models (MLMs).\n",
       " \tcitation: @inproceedings{nangia2020crows,\n",
       "     title = \"{CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models}\",\n",
       "     author = \"Nangia, Nikita  and\n",
       "       Vania, Clara  and\n",
       "       Bhalerao, Rasika  and\n",
       "       Bowman, Samuel R.\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-bias-evaluation'], 'paperswithcode_id': 'crows-pairs', 'pretty_name': 'CrowS-Pairs'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 22893\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: crows-pairs\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cryptonite\n",
       " \tsha: cba4a8bd2a2e88339a9e67d8aea5990141495719\n",
       " \tlastModified: 2022-07-01T11:51:18.000Z\n",
       " \ttags: ['arxiv:2103.01242', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'configs:cryptonite', 'configs:default']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language\n",
       " Current NLP datasets targeting ambiguity can be solved by a native speaker with relative ease. We present Cryptonite,\n",
       " a large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced. Each\n",
       " example in Cryptonite is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving\n",
       " requires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. Cryptic clues pose a\n",
       " challenge even for experienced solvers, though top-tier experts can solve them with almost 100% accuracy. Cryptonite\n",
       " is a challenging task for current models; fine-tuning T5-Large on 470k cryptic clues achieves only 7.6% accuracy, on\n",
       " par with the accuracy of a rule-based clue solver (8.6%).\n",
       " \tcitation: @misc{efrat2021cryptonite,\n",
       "       title={Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language},\n",
       "       author={Avia Efrat and Uri Shaham and Dan Kilman and Omer Levy},\n",
       "       year={2021},\n",
       "       eprint={2103.01242},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'Cryptonite', 'configs': ['cryptonite', 'default']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 356\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cs_restaurants\n",
       " \tsha: 502cc05718789caccd5e05bc90db522d7acb337d\n",
       " \tlastModified: 2022-07-01T11:51:18.000Z\n",
       " \ttags: ['arxiv:1910.05298', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:cs', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-san-francisco-restaurants', 'task_categories:text2text-generation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:text2text-generation-other-intent-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as\n",
       " a translation of the English San Francisco Restaurants dataset by Wen et al. (2015).\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1910-05298,\n",
       "   author    = {Ondrej Dusek and\n",
       "                Filip Jurcicek},\n",
       "   title     = {Neural Generation for Czech: Data and Baselines},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1910.05298},\n",
       "   year      = {2019},\n",
       "   url       = {http://arxiv.org/abs/1910.05298},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1910.05298},\n",
       "   timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-1910-05298.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['expert-generated', 'machine-generated'], 'language': ['cs'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-san-francisco-restaurants'], 'task_categories': ['text2text-generation', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling', 'language-modeling', 'masked-language-modeling', 'text2text-generation-other-intent-to-text'], 'paperswithcode_id': 'czech-restaurant-information', 'pretty_name': 'Czech Restaurant'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: czech-restaurant-information\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: cuad\n",
       " \tsha: a73aa327732c0522ea638a9fe5574241b8b37f7e\n",
       " \tlastModified: 2022-07-01T11:51:18.000Z\n",
       " \ttags: ['arxiv:2103.06268', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Contract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510\n",
       " commercial legal contracts that have been manually labeled to identify 41 categories of important\n",
       " clauses that lawyers look for when reviewing contracts in connection with corporate transactions.\n",
       " \tcitation: @article{hendrycks2021cuad,\n",
       "       title={CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review},\n",
       "       author={Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},\n",
       "       journal={arXiv preprint arXiv:2103.06268},\n",
       "       year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa', 'extractive-qa'], 'paperswithcode_id': 'cuad', 'pretty_name': 'CUAD', 'train-eval-index': [{'config': 'default', 'task': 'question-answering', 'task_id': 'extractive_question_answering', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'question': 'question', 'context': 'context', 'answers': {'text': 'text', 'answer_start': 'answer_start'}}, 'metrics': [{'type': 'cuad', 'name': 'CUAD'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 825\n",
       " \tlikes: 14\n",
       " \tpaperswithcode_id: cuad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: curiosity_dialogs\n",
       " \tsha: e5d813dc8a79bb1fd6a9ed303fc55779991e3a8b\n",
       " \tlastModified: 2022-08-11T16:23:36.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling', 'task_ids:fill-mask-other-conversational-curiosity']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains 14K dialogs (181K utterances) where users and assistants converse about geographic topics like\n",
       " geopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, message-level dialog\n",
       " acts, grounding to Wikipedia, and user reactions to messages.\n",
       " \tcitation: @inproceedings{rodriguez2020curiosity,\n",
       "     title = {Information Seeking in the Spirit of Learning: a Dataset for Conversational Curiosity},\n",
       "     author = {Pedro Rodriguez and Paul Crook and Seungwhan Moon and Zhiguang Wang},\n",
       "     year = 2020,\n",
       "     booktitle = {Empirical Methods in Natural Language Processing}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling', 'fill-mask-other-conversational-curiosity'], 'paperswithcode_id': 'curiosity', 'pretty_name': 'Curiosity Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 789\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: curiosity\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: daily_dialog\n",
       " \tsha: 169c34f7b4430c0554dffaa756e9ba8450d2b102\n",
       " \tlastModified: 2022-07-01T11:51:21.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-emotion-classification', 'task_ids:text-classification-other-dialog-act-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We develop a high-quality multi-turn dialog dataset, DailyDialog, which is intriguing in several aspects.\n",
       " The language is human-written and less noisy. The dialogues in the dataset reflect our daily communication way\n",
       " and cover various topics about our daily life. We also manually label the developed dataset with communication\n",
       " intention and emotion information. Then, we evaluate existing approaches on DailyDialog dataset and hope it\n",
       " benefit the research field of dialog systems.\n",
       " \tcitation: @InProceedings{li2017dailydialog,\n",
       "     author = {Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and Cao, Ziqiang and Niu, Shuzi},\n",
       "     title = {DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},\n",
       "     booktitle = {Proceedings of The 8th International Joint Conference on Natural Language Processing (IJCNLP 2017)},\n",
       "     year = {2017}\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': 'dailydialog', 'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-emotion-classification', 'text-classification-other-dialog-act-classification'], 'pretty_name': 'DailyDialog'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2382\n",
       " \tlikes: 24\n",
       " \tpaperswithcode_id: dailydialog\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dane\n",
       " \tsha: 3b6ac4fc576748b33e316842a38d1da9426a10db\n",
       " \tlastModified: 2022-07-19T12:41:58.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:da', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-Danish-Universal-Dependencies-treebank', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The DaNE dataset has been annotated with Named Entities for PER, ORG and LOC\n",
       " by the Alexandra Institute.\n",
       " It is a reannotation of the UD-DDT (Universal Dependency - Danish Dependency Treebank)\n",
       " which has annotations for dependency parsing and part-of-speech (POS) tagging.\n",
       " The Danish UD treebank (Johannsen et al., 2015, UD-DDT) is a conversion of\n",
       " the Danish Dependency Treebank (Buch-Kromann et al. 2003) based on texts\n",
       " from Parole (Britt, 1998).\n",
       " \tcitation: @inproceedings{hvingelby-etal-2020-dane,\n",
       "     title = \"{D}a{NE}: A Named Entity Resource for {D}anish\",\n",
       "     author = \"Hvingelby, Rasmus  and\n",
       "       Pauli, Amalie Brogaard  and\n",
       "       Barrett, Maria  and\n",
       "       Rosted, Christina  and\n",
       "       Lidegaard, Lasse Malm  and\n",
       "       Søgaard, Anders\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.565\",\n",
       "     pages = \"4597--4604\",\n",
       "     abstract = \"We present a named entity annotation for the Danish Universal Dependencies treebank using the CoNLL-2003 annotation scheme: DaNE. It is the largest publicly available, Danish named entity gold annotation. We evaluate the quality of our annotations intrinsically by double annotating the entire treebank and extrinsically by comparing our annotations to a recently released named entity annotation of the validation and test sections of the Danish Universal Dependencies treebank. We benchmark the new resource by training and evaluating competitive architectures for supervised named entity recognition (NER), including FLAIR, monolingual (Danish) BERT and multilingual BERT. We explore cross-lingual transfer in multilingual BERT from five related languages in zero-shot and direct transfer setups, and we show that even with our modestly-sized training set, we improve Danish NER over a recent cross-lingual approach, as well as over zero-shot transfer from five related languages. Using multilingual BERT, we achieve higher performance by fine-tuning on both DaNE and a larger Bokm{\\aa}l (Norwegian) training set compared to only using DaNE. However, the highest performance isachieved by using a Danish BERT fine-tuned on DaNE. Our dataset enables improvements and applicability for Danish NER beyond cross-lingual methods. We employ a thorough error analysis of the predictions of the best models for seen and unseen entities, as well as their robustness on un-capitalized text. The annotated dataset and all the trained models are made publicly available.\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['da'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-Danish-Universal-Dependencies-treebank'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'part-of-speech'], 'paperswithcode_id': 'dane', 'pretty_name': 'DaNE'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1950\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: dane\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: danish_political_comments\n",
       " \tsha: 3953ab08b4fd4d9b55c3ea069489a511954c3949\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:da', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset consists of 9008 sentences that are labelled with fine-grained polarity in the range from -2 to 2 (negative to postive). The quality of the fine-grained is not cross validated and is therefore subject to uncertainties; however, the simple polarity has been cross validated and therefore is considered to be more correct.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['da'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': None, 'pretty_name': 'DanishPoliticalComments'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 388\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dart\n",
       " \tsha: 14c6061060e3de21e0a4bb9fbedafdfd588f039e\n",
       " \tlastModified: 2022-10-12T13:20:18.000Z\n",
       " \ttags: ['arxiv:2007.02871', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|wikitable_questions', 'source_datasets:extended|wikisql', 'source_datasets:extended|web_nlg', 'source_datasets:extended|cleaned_e2e', 'task_categories:tabular-to-text', 'task_ids:rdf-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DART is a large and open-domain structured DAta Record to Text generation corpus with high-quality\n",
       " sentence annotations with each input being a set of entity-relation triples following a tree-structured ontology.\n",
       " It consists of 82191 examples across different domains with each input being a semantic RDF triple set derived\n",
       " from data records in tables and the tree ontology of table schema, annotated with sentence description that\n",
       " covers all facts in the triple set.\n",
       " \n",
       " DART is released in the following paper where you can find more details and baseline results:\n",
       " https://arxiv.org/abs/2007.02871\n",
       " \tcitation: @article{radev2020dart,\n",
       "   title={DART: Open-Domain Structured Data Record to Text Generation},\n",
       "   author={Dragomir Radev and Rui Zhang and Amrit Rau and Abhinand Sivaprasad and Chiachun Hsieh and Nazneen Fatema Rajani and Xiangru Tang and Aadit Vyas and Neha Verma and Pranav Krishna and Yangxiaokang Liu and Nadia Irwanto and Jessica Pan and Faiaz Rahman and Ahmad Zaidi and Murori Mutuma and Yasin Tarabar and Ankit Gupta and Tao Yu and Yi Chern Tan and Xi Victoria Lin and Caiming Xiong and Richard Socher},\n",
       "   journal={arXiv preprint arXiv:2007.02871},\n",
       "   year={2020}\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|wikitable_questions', 'extended|wikisql', 'extended|web_nlg', 'extended|cleaned_e2e'], 'task_categories': ['tabular-to-text'], 'task_ids': ['rdf-to-text'], 'paperswithcode_id': 'dart', 'pretty_name': 'DART', 'dataset_info': {'features': [{'name': 'tripleset', 'sequence': {'sequence': 'string'}}, {'name': 'subtree_was_extended', 'dtype': 'bool'}, {'name': 'annotations', 'sequence': [{'name': 'source', 'dtype': 'string'}, {'name': 'text', 'dtype': 'string'}]}], 'splits': [{'name': 'test', 'num_bytes': 2657644, 'num_examples': 5097}, {'name': 'train', 'num_bytes': 12966443, 'num_examples': 30526}, {'name': 'validation', 'num_bytes': 1458106, 'num_examples': 2768}], 'download_size': 29939366, 'dataset_size': 17082193}}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 360\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: dart\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: datacommons_factcheck\n",
       " \tsha: 8f6eda046515c949dd7d6762667c333984f6fb69\n",
       " \tlastModified: 2022-08-24T04:09:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking', 'configs:fctchk_politifact_wapo', 'configs:weekly_standard']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset of fact checked claims by news media maintained by datacommons.org\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = {Data Commons 2019 Fact Checks},\n",
       " authors={datacommons.org},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'DataCommons Fact Checked claims', 'configs': ['fctchk_politifact_wapo', 'weekly_standard']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 496\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dbpedia_14\n",
       " \tsha: bcea650589d610d0b34c7e9280dcb7669b99709f\n",
       " \tlastModified: 2022-07-01T11:51:23.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The DBpedia ontology classification dataset is constructed by picking 14 non-overlapping classes\n",
       " from DBpedia 2014. They are listed in classes.txt. From each of thse 14 ontology classes, we\n",
       " randomly choose 40,000 training samples and 5,000 testing samples. Therefore, the total size\n",
       " of the training dataset is 560,000 and testing dataset 70,000.\n",
       " There are 3 columns in the dataset (same for train and test splits), corresponding to class index\n",
       " (1 to 14), title and content. The title and content are escaped using double quotes (\"), and any\n",
       " internal double quote is escaped by 2 double quotes (\"\"). There are no new lines in title or content.\n",
       " \tcitation: @article{lehmann2015dbpedia,\n",
       "   title={DBpedia--a large-scale, multilingual knowledge base extracted from Wikipedia},\n",
       "   author={Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas,\n",
       "   Dimitris and Mendes, Pablo N and Hellmann, Sebastian and Morsey, Mohamed and Van Kleef,\n",
       "   Patrick and Auer, S{\\\"o}ren and others},\n",
       "   journal={Semantic web},\n",
       "   volume={6},\n",
       "   number={2},\n",
       "   pages={167--195},\n",
       "   year={2015},\n",
       "   publisher={IOS Press}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': 'dbpedia', 'pretty_name': 'DBpedia'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 21096\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: dbpedia\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dbrd\n",
       " \tsha: df86b440696dff66ffb0f30ee320286ec6d799eb\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['arxiv:1910.00896', 'annotations_creators:found', 'language_creators:found', 'language:nl', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Dutch Book Review Dataset (DBRD) contains over 110k book reviews of which 22k have associated binary sentiment polarity labels. It is intended as a benchmark for sentiment classification in Dutch and created due to a lack of annotated datasets in Dutch that are suitable for this task.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1910-00896,\n",
       "   author    = {Benjamin van der Burgh and\n",
       "                Suzan Verberne},\n",
       "   title     = {The merits of Universal Language Model Fine-tuning for Small Datasets\n",
       "                - a case with Dutch book reviews},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1910.00896},\n",
       "   year      = {2019},\n",
       "   url       = {http://arxiv.org/abs/1910.00896},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1910.00896},\n",
       "   timestamp = {Fri, 04 Oct 2019 12:28:06 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-1910-00896.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'DBRD', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['nl'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'sentiment-classification'], 'paperswithcode_id': 'dbrd'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 361\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: dbrd\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: deal_or_no_dialog\n",
       " \tsha: 17d811d20dde16a31447d1afc88918521341553f\n",
       " \tlastModified: 2022-07-01T11:51:25.000Z\n",
       " \ttags: ['arxiv:1706.05125', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:conversational']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other’s reward functions must reach anagreement (o a deal) via natural language dialogue.\n",
       " \tcitation: @article{lewis2017deal,\n",
       "   title={Deal or no deal? end-to-end learning for negotiation dialogues},\n",
       "   author={Lewis, Mike and Yarats, Denis and Dauphin, Yann N and Parikh, Devi and Batra, Dhruv},\n",
       "   journal={arXiv preprint arXiv:1706.05125},\n",
       "   year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['conversational'], 'task_ids': [], 'paperswithcode_id': 'negotiation-dialogues-dataset', 'pretty_name': 'Deal or No Deal Negotiator'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 492\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: negotiation-dialogues-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: definite_pronoun_resolution\n",
       " \tsha: 25f48210f63a422efa3a47f021890cda5d769001\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:word-sense-disambiguation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Composed by 30 students from one of the author's undergraduate classes. These\n",
       " sentence pairs cover topics ranging from real events (e.g., Iran's plan to\n",
       " attack the Saudi ambassador to the U.S.) to events/characters in movies (e.g.,\n",
       " Batman) and purely imaginary situations, largely reflecting the pop culture as\n",
       " perceived by the American kids born in the early 90s. Each annotated example\n",
       " spans four lines: the first line contains the sentence, the second line contains\n",
       " the target pronoun, the third line contains the two candidate antecedents, and\n",
       " the fourth line contains the correct antecedent. If the target pronoun appears\n",
       " more than once in the sentence, its first occurrence is the one to be resolved.\n",
       " \tcitation: @inproceedings{rahman2012resolving,\n",
       "   title={Resolving complex cases of definite pronouns: the winograd schema challenge},\n",
       "   author={Rahman, Altaf and Ng, Vincent},\n",
       "   booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},\n",
       "   pages={777--789},\n",
       "   year={2012},\n",
       "   organization={Association for Computational Linguistics}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['word-sense-disambiguation'], 'paperswithcode_id': 'definite-pronoun-resolution-dataset', 'pretty_name': 'Definite Pronoun Resolution Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1075\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: definite-pronoun-resolution-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dengue_filipino\n",
       " \tsha: 62e186d477cc4e83626e31e1188c7650a21b1b23\n",
       " \tlastModified: 2022-07-01T11:51:25.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:tl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     Benchmark dataset for low-resource multiclass classification, with 4,015 training, 500 testing, and 500 validation examples, each labeled as part of five classes. Each sample can be a part of multiple classes. Collected as tweets.\n",
       " \tcitation:     @INPROCEEDINGS{8459963,\n",
       "       author={E. D. {Livelo} and C. {Cheng}},\n",
       "       booktitle={2018 IEEE International Conference on Agents (ICA)},\n",
       "       title={Intelligent Dengue Infoveillance Using Gated Recurrent Neural Learning and Cross-Label Frequencies},\n",
       "       year={2018},\n",
       "       volume={},\n",
       "       number={},\n",
       "       pages={2-7},\n",
       "       doi={10.1109/AGENTS.2018.8459963}}\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['tl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'dengue', 'pretty_name': 'Dengue Dataset in Filipino'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: dengue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dialog_re\n",
       " \tsha: b9d9027c451fa69f79324fd6c1d227a2304f7255\n",
       " \tlastModified: 2022-07-01T12:43:27.000Z\n",
       " \ttags: ['arxiv:2004.08056', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:other-other-relation-extraction', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DialogRE is the first human-annotated dialogue based relation extraction (RE) dataset aiming\n",
       " to support the prediction of relation(s) between two arguments that appear in a dialogue.\n",
       " The dataset annotates all occurrences of 36 possible relation types that exist between pairs\n",
       " of arguments in the 1,788 dialogues originating from the complete transcripts of Friends.\n",
       " \tcitation: @inproceedings{yu2020dialogue,\n",
       "   title={Dialogue-Based Relation Extraction},\n",
       "   author={Yu, Dian and Sun, Kai and Cardie, Claire and Yu, Dong},\n",
       "   booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n",
       "   year={2020},\n",
       "   url={https://arxiv.org/abs/2004.08056v1}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-generation', 'fill-mask'], 'task_ids': ['other-other-relation-extraction', 'dialogue-modeling'], 'paperswithcode_id': 'dialogre', 'pretty_name': 'DialogRE'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 358\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: dialogre\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: diplomacy_detection\n",
       " \tsha: aee4f682c013fce62d0798392466efeb19b5e223\n",
       " \tlastModified: 2022-07-01T11:51:27.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @inproceedings{peskov-etal-2020-takes,\n",
       "     title = \"It Takes Two to Lie: One to Lie, and One to Listen\",\n",
       "     author = \"Peskov, Denis  and\n",
       "       Cheng, Benny  and\n",
       "       Elgohary, Ahmed  and\n",
       "       Barrow, Joe  and\n",
       "       Danescu-Niculescu-Mizil, Cristian  and\n",
       "       Boyd-Graber, Jordan\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.353\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.353\",\n",
       "     pages = \"3811--3854\",\n",
       "     abstract = \"Trust is implicit in many online text conversations{---}striking up new friendships, or asking for tech support. But trust can be betrayed through deception. We study the language and dynamics of deception in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures deception in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A model that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': None, 'pretty_name': 'HateOffensive'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: disaster_response_messages\n",
       " \tsha: 6314a08e0c4f102f56d3e490c87b9f5f70040ca9\n",
       " \tlastModified: 2022-07-01T11:51:28.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:es', 'language:fr', 'language:ht', 'language:ur', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:sentiment-classification', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains 30,000 messages drawn from events including an earthquake in Haiti in 2010, an earthquake in Chile in 2010, floods in Pakistan in 2010, super-storm Sandy in the U.S.A. in 2012, and news articles spanning a large number of years and 100s of different disasters.\n",
       " The data has been encoded with 36 different categories related to disaster response and has been stripped of messages with sensitive information in their entirety.\n",
       " Upon release, this is the featured dataset of a new Udacity course on Data Science and the AI4ALL summer school and is especially utile for text analytics and natural language processing (NLP) tasks and models.\n",
       " The input data in this job contains thousands of untranslated disaster-related messages and their English translations.\n",
       " \tcitation: @inproceedings{title={Multilingual Disaster Response Messages}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'es', 'fr', 'ht', 'ur'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-classification'], 'task_ids': ['intent-classification', 'sentiment-classification', 'text-simplification'], 'paperswithcode_id': None, 'pretty_name': 'Disaster Response Messages'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: discofuse\n",
       " \tsha: 5ae40adb296408dcfc330d31f7ea09331eacc488\n",
       " \tlastModified: 2022-09-15T17:12:40.000Z\n",
       " \ttags: ['arxiv:1902.10526', 'annotations_creators:machine-generated', 'language:en', 'language_creators:found', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-sentence-fusion']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  DISCOFUSE is a large scale dataset for discourse-based sentence fusion.\n",
       " \tcitation: @InProceedings{GevaEtAl2019,\n",
       "   title = {DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion},\n",
       "   author = {Geva, Mor and Malmi, Eric and Szpektor, Idan and Berant, Jonathan},\n",
       "   booktitle = {Proceedings of the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics},\n",
       "   note = {arXiv preprint arXiv:1902.10526},\n",
       "   year = {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'DiscoFuse', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-sentence-fusion'], 'paperswithcode_id': 'discofuse'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 811\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: discofuse\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: discovery\n",
       " \tsha: 7a6e38fe2e0fa6bebba7934f0a3bb1c2a3bbd894\n",
       " \tlastModified: 2022-07-01T11:51:29.000Z\n",
       " \ttags: ['annotations_creators:other', 'language_creators:other', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-discourse-marker-prediction', 'configs:discovery', 'configs:discoverysmall']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @inproceedings{sileo-etal-2019-mining,\n",
       "     title = \"Mining Discourse Markers for Unsupervised Sentence Representation Learning\",\n",
       "     author = \"Sileo, Damien  and\n",
       "       Van De Cruys, Tim  and\n",
       "       Pradel, Camille  and\n",
       "       Muller, Philippe\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n",
       "     month = jun,\n",
       "     year = \"2019\",\n",
       "     address = \"Minneapolis, Minnesota\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/N19-1351\",\n",
       "     pages = \"3477--3486\",\n",
       "     abstract = \"Current state of the art systems in NLP heavily rely on manually annotated datasets, which are expensive to construct. Very little work adequately exploits unannotated data {--} such as discourse markers between sentences {--} mainly because of data sparseness and ineffective extraction methods. In the present work, we propose a method to automatically discover sentence pairs with relevant discourse markers, and apply it to massive amounts of data. Our resulting dataset contains 174 discourse markers with at least 10k examples each, even for rare markers such as {``}coincidentally{''} or {``}amazingly{''}. We use the resulting data as supervision for learning transferable sentence embeddings. In addition, we show that even though sentence representation learning through prediction of discourse marker yields state of the art results across different transfer tasks, it{'}s not clear that our models made use of the semantic relation between sentences, thus leaving room for further improvements.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['other'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-discourse-marker-prediction'], 'paperswithcode_id': 'discovery', 'pretty_name': 'Discovery', 'configs': ['discovery', 'discoverysmall']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1637\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: discovery\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: disfl_qa\n",
       " \tsha: 0d5442eff619d34d3798279e54cca972cdde2b88\n",
       " \tlastModified: 2022-07-01T11:51:29.000Z\n",
       " \ttags: ['arxiv:2106.04016', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Disfl-QA is a targeted dataset for contextual disfluencies in an information seeking setting,\n",
       " namely question answering over Wikipedia passages. Disfl-QA builds upon the SQuAD-v2 (Rajpurkar et al., 2018)\n",
       " dataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as\n",
       " a source of distractors.\n",
       " \n",
       " The final dataset consists of ~12k (disfluent question, answer) pairs. Over 90% of the disfluencies are\n",
       " corrections or restarts, making it a much harder test set for disfluency correction. Disfl-QA aims to fill a\n",
       " major gap between speech and NLP research community. We hope the dataset can serve as a benchmark dataset for\n",
       " testing robustness of models against disfluent inputs.\n",
       " \n",
       " Our expriments reveal that the state-of-the-art models are brittle when subjected to disfluent inputs from\n",
       " Disfl-QA. Detailed experiments and analyses can be found in our paper.\n",
       " \tcitation: @inproceedings{gupta-etal-2021-disflqa,\n",
       "     title = \"{Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering}\",\n",
       "     author = \"Gupta, Aditya and Xu, Jiacheng and Upadhyay, Shyam and Yang, Diyi and Faruqui, Manaal\",\n",
       "     booktitle = \"Findings of ACL\",\n",
       "     year = \"2021\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'DISFL-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: doc2dial\n",
       " \tsha: 8fd37091a440b8ff4b50b88719605602c5943ece\n",
       " \tlastModified: 2022-07-01T11:51:29.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Doc2dial is dataset of goal-oriented dialogues that are grounded in the associated documents. It includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets this dataset covers a variety of dialogue scenes in information-seeking conversations.\n",
       " \tcitation: @inproceedings{feng-etal-2020-doc2dial,\n",
       "     title = \"doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset\",\n",
       "     author = \"Feng, Song  and Wan, Hui  and Gunasekara, Chulaka  and Patel, Siva  and Joshi, Sachindra  and Lastras, Luis\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.652\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': 'doc2dial', 'pretty_name': 'doc2dial'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 766\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: doc2dial\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: docred\n",
       " \tsha: cf41f4fab8d1594b1a075991492f787a44bb7eb1\n",
       " \tlastModified: 2022-07-01T11:51:31.000Z\n",
       " \ttags: ['arxiv:1906.06127', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:entity-linking-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features:\n",
       "     - DocRED annotates both named entities and relations, and is the largest human-annotated dataset for document-level RE from plain text.\n",
       "     - DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.\n",
       "     - Along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios.\n",
       " \tcitation: @inproceedings{yao2019DocRED,\n",
       "   title={{DocRED}: A Large-Scale Document-Level Relation Extraction Dataset},\n",
       "   author={Yao, Yuan and Ye, Deming and Li, Peng and Han, Xu and Lin, Yankai and Liu, Zhenghao and Liu,   Zhiyuan and Huang, Lixin and Zhou, Jie and Sun, Maosong},\n",
       "   booktitle={Proceedings of ACL 2019},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'docred', 'pretty_name': 'DocRED', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['entity-linking-retrieval']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 985\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: docred\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: doqa\n",
       " \tsha: 451d5cc7482660b6da9e306a4a3cb9b9aa8b8dbc\n",
       " \tlastModified: 2022-07-01T11:51:31.000Z\n",
       " \ttags: ['arxiv:2005.01328', 'language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DoQA is a dataset for accessing Domain Specific FAQs via conversational QA that contains 2,437 information-seeking question/answer dialogues\n",
       " (10,917 questions in total) on three different domains: cooking, travel and movies. Note that we include in the generic concept of FAQs also\n",
       " Community Question Answering sites, as well as corporate information in intranets which is maintained in textual form similar to FAQs, often\n",
       " referred to as internal “knowledge bases”.\n",
       " \n",
       " These dialogues are created by crowd workers that play the following two roles: the user who asks questions about a given topic posted in Stack\n",
       " Exchange (https://stackexchange.com/), and the domain expert who replies to the questions by selecting a short span of text from the long textual\n",
       " reply in the original post. The expert can rephrase the selected span, in order to make it look more natural. The dataset covers unanswerable\n",
       " questions and some relevant dialogue acts.\n",
       " \n",
       " DoQA enables the development and evaluation of conversational QA systems that help users access the knowledge buried in domain specific FAQs.\n",
       " \tcitation: @misc{campos2020doqa,\n",
       "     title={DoQA -- Accessing Domain-Specific FAQs via Conversational QA},\n",
       "     author={Jon Ander Campos and Arantxa Otegi and Aitor Soroa and Jan Deriu and Mark Cieliebak and Eneko Agirre},\n",
       "     year={2020},\n",
       "     eprint={2005.01328},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'doqa', 'pretty_name': 'DoQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 670\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: doqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dream\n",
       " \tsha: 79ee0ccd1d45725577bfb945d23971d7e4f06a08\n",
       " \tlastModified: 2022-08-11T12:57:21.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DREAM is a multiple-choice Dialogue-based REAding comprehension exaMination dataset. In contrast to existing reading comprehension datasets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.\n",
       " \tcitation: @article{sundream2018,\n",
       "   title={{DREAM}: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension},\n",
       "   author={Sun, Kai and Yu, Dian and Chen, Jianshu and Yu, Dong and Choi, Yejin and Cardie, Claire},\n",
       "   journal={Transactions of the Association for Computational Linguistics},\n",
       "   year={2019},\n",
       "   url={https://arxiv.org/abs/1902.00164v1}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'dream', 'pretty_name': 'DREAM'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 19040\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: dream\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: drop\n",
       " \tsha: 18f0654c35449799ada938cfd8ea34c94dbf2c6a\n",
       " \tlastModified: 2022-07-01T11:51:32.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text2text-generation', 'task_ids:extractive-qa', 'task_ids:abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs.\n",
       " . DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a\n",
       " question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or\n",
       "  sorting). These operations require a much more comprehensive understanding of the content of paragraphs than what was\n",
       "  necessary for prior datasets.\n",
       " \tcitation: @inproceedings{Dua2019DROP,\n",
       "   author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
       "   title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
       "   booktitle={Proc. of NAACL},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'DROP', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text2text-generation'], 'task_ids': ['extractive-qa', 'abstractive-qa'], 'paperswithcode_id': 'drop'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1568\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: drop\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: duorc\n",
       " \tsha: 29a2aaec4318c69090baf419029702a92c68b614\n",
       " \tlastModified: 2022-07-01T11:51:32.000Z\n",
       " \ttags: ['arxiv:1804.07927', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:extractive-qa', 'configs:ParaphraseRC', 'configs:SelfRC']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie.\n",
       " \tcitation: @inproceedings{DuoRC,\n",
       " author = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},title = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\n",
       " booktitle = {Meeting of the Association for Computational Linguistics (ACL)},\n",
       " year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text2text-generation'], 'task_ids': ['abstractive-qa', 'extractive-qa'], 'paperswithcode_id': 'duorc', 'pretty_name': 'DuoRC', 'configs': ['ParaphraseRC', 'SelfRC']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 86536\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: duorc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dutch_social\n",
       " \tsha: 448a1927a674242b517d10eb4a581185e4234cbc\n",
       " \tlastModified: 2022-07-01T11:51:33.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'language:nl', 'license:cc-by-nc-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains around 271,342 tweets. The tweets are filtered via the official Twitter API to\n",
       " contain tweets in Dutch language or by users who have specified their location information within Netherlands\n",
       " geographical boundaries. Using natural language processing we have classified the tweets for their HISCO codes.\n",
       " If the user has provided their location within Dutch boundaries, we have also classified them to their respective\n",
       " provinces The objective of this dataset is to make research data available publicly in a FAIR (Findable, Accessible,\n",
       " Interoperable, Reusable) way. Twitter's Terms of Service Licensed under Attribution-NonCommercial 4.0 International\n",
       " (CC BY-NC 4.0) (2020-10-27)\n",
       " \tcitation: @data{FK2/MTPTL7_2020,\n",
       " author = {Gupta, Aakash},\n",
       " publisher = {COVID-19 Data Hub},\n",
       " title = {{Dutch social media collection}},\n",
       " year = {2020},\n",
       " version = {DRAFT VERSION},\n",
       " doi = {10.5072/FK2/MTPTL7},\n",
       " url = {https://doi.org/10.5072/FK2/MTPTL7}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'nl'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification', 'multi-label-classification'], 'paperswithcode_id': None, 'pretty_name': 'Dutch Social Media Collection'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: dyk\n",
       " \tsha: fe5fadaa35bb174c317eedd0a5e0ea28ec3cd02c\n",
       " \tlastModified: 2022-07-01T11:51:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:bsd-3-clause', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Did You Know (pol. Czy wiesz?) dataset consists of human-annotated question-answer pairs. The task is to predict if the answer is correct. We chose the negatives which have the largest token overlap with a question.\n",
       " \tcitation: @inproceedings{marcinczuk2013open,\n",
       " title={Open dataset for development of Polish Question Answering systems},\n",
       " author={Marcinczuk, Michal and Ptak, Marcin and Radziszewski, Adam and Piasecki, Maciej},\n",
       " booktitle={Proceedings of the 6th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, Wydawnictwo Poznanskie, Fundacja Uniwersytetu im. Adama Mickiewicza},\n",
       " year={2013}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['bsd-3-clause'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'dyk'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: e2e_nlg\n",
       " \tsha: d8a13cdb408865841b1e62c8fc0666106dcccc8e\n",
       " \tlastModified: 2022-07-01T11:51:35.000Z\n",
       " \ttags: ['arxiv:1706.09254', 'arxiv:1901.11528', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-meaning-representation-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The E2E dataset is used for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area.\n",
       " The E2E dataset poses new challenges:\n",
       " (1) its human reference texts show more lexical richness and syntactic variation, including discourse phenomena;\n",
       " (2) generating from this set requires content selection. As such, learning from this dataset promises more natural, varied and less template-like system utterances.\n",
       " \n",
       " E2E is released in the following paper where you can find more details and baseline results:\n",
       " https://arxiv.org/abs/1706.09254\n",
       " \tcitation: @article{dusek.etal2020:csl,\n",
       "   title = {Evaluating the {{State}}-of-the-{{Art}} of {{End}}-to-{{End Natural Language Generation}}: {{The E2E NLG Challenge}}},\n",
       "   author = {Du{\\v{s}}ek, Ond\\v{r}ej and Novikova, Jekaterina and Rieser, Verena},\n",
       "   year = {2020},\n",
       "   month = jan,\n",
       "   volume = {59},\n",
       "   pages = {123--156},\n",
       "   doi = {10.1016/j.csl.2019.06.009},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint = {1901.11528},\n",
       "   eprinttype = {arxiv},\n",
       "   journal = {Computer Speech & Language}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-meaning-representation-to-text'], 'paperswithcode_id': 'e2e', 'pretty_name': 'End-to-End NLG Challenge'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1379\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: e2e\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: e2e_nlg_cleaned\n",
       " \tsha: 927a692e0a881a4b1dc8fd273f1d130348d45c95\n",
       " \tlastModified: 2022-07-01T11:51:36.000Z\n",
       " \ttags: ['arxiv:1706.09254', 'arxiv:1901.11528', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-meaning-representtion-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An update release of E2E NLG Challenge data with cleaned MRs and scripts, accompanying the following paper:\n",
       " \n",
       " Ondřej Dušek, David M. Howcroft, and Verena Rieser (2019): Semantic Noise Matters for Neural Natural Language Generation. In INLG, Tokyo, Japan.\n",
       " \tcitation: @inproceedings{dusek-etal-2019-semantic,\n",
       "     title = \"Semantic Noise Matters for Neural Natural Language Generation\",\n",
       "     author = \"Du{\\v{s}}ek, Ond{\\v{r}}ej  and\n",
       "       Howcroft, David M.  and\n",
       "       Rieser, Verena\",\n",
       "     booktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\n",
       "     month = oct # \"{--}\" # nov,\n",
       "     year = \"2019\",\n",
       "     address = \"Tokyo, Japan\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/W19-8652\",\n",
       "     doi = \"10.18653/v1/W19-8652\",\n",
       "     pages = \"421--426\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-meaning-representtion-to-text'], 'paperswithcode_id': None, 'pretty_name': 'the Cleaned Version of the E2E Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 840\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ecb\n",
       " \tsha: 4aba79a8055f052ecff70084c52bac92910cafd3\n",
       " \tlastModified: 2022-08-11T12:57:24.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:sk', 'language:sl', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Original source: Website and documentatuion from the European Central Bank, compiled and made available by Alberto Simoes (thank you very much!)\n",
       " 19 languages, 170 bitexts\n",
       " total number of files: 340\n",
       " total number of tokens: 757.37M\n",
       " total number of sentence fragments: 30.55M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'sk', 'sl'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'ecb', 'pretty_name': 'extension to the EventCorefBank'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 949\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: ecb\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ecthr_cases\n",
       " \tsha: c039f2710235b4170ceda0c5dc370d878ded7079\n",
       " \tlastModified: 2022-07-01T11:51:36.000Z\n",
       " \ttags: ['arxiv:2103.13084', 'annotations_creators:expert-generated', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-rationale-extraction', 'task_ids:text-classification-other-legal-judgment-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The ECtHR Cases dataset is designed for experimentation of neural judgment prediction and rationale extraction considering ECtHR cases.\n",
       " \tcitation: @InProceedings{chalkidis-et-al-2021-ecthr,\n",
       "     title = \"Paragraph-level Rationale Extraction through Regularization: A case study on European Court of Human Rights Cases\",\n",
       "     author = \"Chalkidis, Ilias and Fergadiotis, Manos and Tsarapatsanis, Dimitrios and Aletras, Nikolaos and Androutsopoulos, Ion and Malakasiotis, Prodromos\",\n",
       "     booktitle = \"Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics\",\n",
       "     year = \"2021\",\n",
       "     address = \"Mexico City, Mexico\",\n",
       "     publisher = \"Association for Computational Linguistics\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-rationale-extraction', 'text-classification-other-legal-judgment-prediction'], 'paperswithcode_id': 'ecthr', 'pretty_name': 'European Court of Human Rights Cases'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 845\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: ecthr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eduge\n",
       " \tsha: 0d7090b8afa1e9ade50912db1d1398af460097bd\n",
       " \tlastModified: 2022-07-01T11:51:36.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:mn', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Eduge news classification dataset is provided by Bolorsoft LLC. It is used for training the Eduge.mn production news classifier\n",
       " 75K news articles in 9 categories: урлаг соёл, эдийн засаг, эрүүл мэнд, хууль, улс төр, спорт, технологи, боловсрол and байгал орчин\n",
       " \tcitation: None\n",
       " \tcardData: {'pretty_name': 'Eduge', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['mn'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ehealth_kd\n",
       " \tsha: 911afc9df4c2a4df3702edaf4dc114126e1d138a\n",
       " \tlastModified: 2022-07-01T11:51:38.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:es', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:token-classification-other-relation-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset of the eHealth Knowledge Discovery Challenge at IberLEF 2020. It is designed for\n",
       " the identification of semantic entities and relations in Spanish health documents.\n",
       " \tcitation: @inproceedings{overview_ehealthkd2020,\n",
       "   author    = {Piad{-}Morffis, Alejandro and\n",
       "                Guti{\\'{e}}rrez, Yoan and\n",
       "                Cañizares-Diaz, Hian and\n",
       "                Estevez{-}Velarde, Suilan and\n",
       "                Almeida{-}Cruz, Yudivi{\\'{a}}n and\n",
       "                Muñoz, Rafael and\n",
       "                Montoyo, Andr{\\'{e}}s},\n",
       "   title     = {Overview of the eHealth Knowledge Discovery Challenge at IberLEF 2020},\n",
       "   booktitle = ,\n",
       "   year      = {2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['es'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'token-classification-other-relation-prediction'], 'paperswithcode_id': None, 'pretty_name': 'eHealth-KD'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eitb_parcc\n",
       " \tsha: 5db391822fc1eda45b3254541f2b1fd7f594ab81\n",
       " \tlastModified: 2022-07-01T11:51:39.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:es', 'language:eu', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: EiTB-ParCC: Parallel Corpus of Comparable News. A Basque-Spanish parallel corpus provided by Vicomtech (https://www.vicomtech.org), extracted from comparable news produced by the Basque public broadcasting group Euskal Irrati Telebista.\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['es', 'eu'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'eitb-parcc', 'pretty_name': 'EiTB-ParCC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: eitb-parcc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: electricity_load_diagrams\n",
       " \tsha: 4845354e2c6413d078d5f0bfcb4d550d7d8aef7e\n",
       " \tlastModified: 2022-07-01T11:51:39.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:unknown', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:time-series-forecasting', 'task_ids:univariate-time-series-forecasting']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This new dataset contains hourly kW electricity consumption time series of 370 Portuguese clients from 2011 to 2014.\n",
       " \tcitation: @inproceedings{10.1145/3209978.3210006,\n",
       "     author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},\n",
       "     title = {Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks},\n",
       "     year = {2018},\n",
       "     isbn = {9781450356572},\n",
       "     publisher = {Association for Computing Machinery},\n",
       "     address = {New York, NY, USA},\n",
       "     url = {https://doi.org/10.1145/3209978.3210006},\n",
       "     doi = {10.1145/3209978.3210006},\n",
       "     booktitle = {The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval},\n",
       "     pages = {95--104},\n",
       "     numpages = {10},\n",
       "     location = {Ann Arbor, MI, USA},\n",
       "     series = {SIGIR '18}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['unknown'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Electricity Load Diagrams', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['time-series-forecasting'], 'task_ids': ['univariate-time-series-forecasting']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 484\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eli5\n",
       " \tsha: 08283f5fab64049ee0294e3d8410179990f36579\n",
       " \tlastModified: 2022-08-11T16:23:35.000Z\n",
       " \ttags: ['arxiv:1907.09190', 'arxiv:1904.04047', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:open-domain-abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Explain Like I'm 5 long form QA dataset\n",
       " \tcitation: @inproceedings{DBLP:conf/acl/FanJPGWA19,\n",
       "   author    = {Angela Fan and\n",
       "                Yacine Jernite and\n",
       "                Ethan Perez and\n",
       "                David Grangier and\n",
       "                Jason Weston and\n",
       "                Michael Auli},\n",
       "   editor    = {Anna Korhonen and\n",
       "                David R. Traum and\n",
       "                Lluis Marquez},\n",
       "   title     = {{ELI5:} Long Form Question Answering},\n",
       "   booktitle = {Proceedings of the 57th Conference of the Association for Computational\n",
       "                Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,\n",
       "                Volume 1: Long Papers},\n",
       "   pages     = {3558--3567},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year      = {2019},\n",
       "   url       = {https://doi.org/10.18653/v1/p19-1346},\n",
       "   doi       = {10.18653/v1/p19-1346},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['abstractive-qa', 'open-domain-abstractive-qa'], 'paperswithcode_id': 'eli5', 'pretty_name': 'ELI5'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2532\n",
       " \tlikes: 10\n",
       " \tpaperswithcode_id: eli5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eli5_category\n",
       " \tsha: 11584d04bd699b1d1381c0bf1a781ae7fb683e06\n",
       " \tlastModified: 2022-07-01T11:51:40.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|eli5', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:open-domain-abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The ELI5-Category dataset is a smaller but newer and categorized version of the original ELI5 dataset. After 2017, a tagging system was introduced to this subreddit so that the questions can be categorized into different topics according to their tags. Since the training and validation set is built by questions in different topics, the dataset is expected to alleviate the train/validation overlapping issue in the original ELI5 dataset.\n",
       " \tcitation: @inproceedings{eli5-category,\n",
       "   author    = {Jingsong Gao and\n",
       "                Qingren Zhou and\n",
       "                Rui Qiu},\n",
       "   title     = {{ELI5-Category:} A categorized open-domain QA dataset},\n",
       "   year      = {2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'paperswithcode_id': None, 'pretty_name': 'ELI5-Category', 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|eli5'], 'task_categories': ['text2text-generation'], 'task_ids': ['abstractive-qa', 'open-domain-abstractive-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: emea\n",
       " \tsha: 23a475f74968137d9f188cce85e898ec8892940a\n",
       " \tlastModified: 2022-07-01T11:51:41.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation', 'configs:bg-el', 'configs:cs-et', 'configs:de-mt', 'configs:es-lt', 'configs:fr-sk']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a parallel corpus made out of PDF documents from the European Medicines Agency. All files are automatically converted from PDF to plain text using pdftotext with the command line arguments -layout -nopgbrk -eol unix. There are some known problems with tables and multi-column layouts - some of them are fixed in the current version.\n",
       " \n",
       " source: http://www.emea.europa.eu/\n",
       " \n",
       " 22 languages, 231 bitexts\n",
       " total number of files: 41,957\n",
       " total number of tokens: 311.65M\n",
       " total number of sentence fragments: 26.51M\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'EMEA', 'configs': ['bg-el', 'cs-et', 'de-mt', 'es-lt', 'fr-sk']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 952\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: emo\n",
       " \tsha: 14b2a9f228acc098930725b0dc36d1c670230aeb\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In this dataset, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others.\n",
       " \tcitation: @inproceedings{chatterjee-etal-2019-semeval,\n",
       "     title={SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text},\n",
       "     author={Ankush Chatterjee and Kedhar Nath Narahari and Meghana Joshi and Puneet Agrawal},\n",
       "     booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},\n",
       "     year={2019},\n",
       "     address={Minneapolis, Minnesota, USA},\n",
       "     publisher={Association for Computational Linguistics},\n",
       "     url={https://www.aclweb.org/anthology/S19-2005},\n",
       "     doi={10.18653/v1/S19-2005},\n",
       "     pages={39--48},\n",
       "     abstract={In this paper, we present the SemEval-2019 Task 3 - EmoContext: Contextual Emotion Detection in Text. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading ''Why don't you ever text me!'' we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps. A training data set of 30160 dialogues, and two evaluation data sets, Test1 and Test2, containing 2755 and 5509 dialogues respectively were released to the participants. A total of 311 teams made submissions to this task. The final leader-board was evaluated on Test2 data set, and the highest ranked submission achieved 79.59 micro-averaged F1 score. Our analysis of systems submitted to the task indicate that Bi-directional LSTM was the most common choice of neural architecture used, and most of the systems had the best performance for the Sad emotion class, and the worst for the Happy emotion class}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'emocontext', 'pretty_name': 'EmoContext'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 768\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: emocontext\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: emotion\n",
       " \tsha: 0acb3732a1fb5be71a4e09481c7ce6c3b628b6e0\n",
       " \tlastModified: 2022-07-01T11:51:43.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:text-classification-other-emotion-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
       " \tcitation: @inproceedings{saravia-etal-2018-carer,\n",
       "     title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
       "     author = \"Saravia, Elvis  and\n",
       "       Liu, Hsien-Chi Toby  and\n",
       "       Huang, Yen-Hao  and\n",
       "       Wu, Junlin  and\n",
       "       Chen, Yi-Shin\",\n",
       "     booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct # \"-\" # nov,\n",
       "     year = \"2018\",\n",
       "     address = \"Brussels, Belgium\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
       "     doi = \"10.18653/v1/D18-1404\",\n",
       "     pages = \"3687--3697\",\n",
       "     abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Emotion', 'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'text-classification-other-emotion-classification'], 'paperswithcode_id': 'emotion', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 15990\n",
       " \tlikes: 54\n",
       " \tpaperswithcode_id: emotion\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: emotone_ar\n",
       " \tsha: 19fbd0317934b9e15a085b9ef28c7af7a2718e91\n",
       " \tlastModified: 2022-07-01T11:51:43.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset of 10065 tweets in Arabic for Emotion detection in Arabic text\n",
       " \tcitation: @inbook{inbook,\n",
       " author = {Al-Khatib, Amr and El-Beltagy, Samhaa},\n",
       " year = {2018},\n",
       " month = {01},\n",
       " pages = {105-114},\n",
       " title = {Emotional Tone Detection in Arabic Tweets: 18th International Conference, CICLing 2017, Budapest, Hungary, April 17–23, 2017, Revised Selected Papers, Part II},\n",
       " isbn = {978-3-319-77115-1},\n",
       " doi = {10.1007/978-3-319-77116-8_8}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Emotional Tone in Arabic'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 353\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: empathetic_dialogues\n",
       " \tsha: caefc99c2051a11b71d117b575d148134e4aad0c\n",
       " \tlastModified: 2022-09-20T07:38:10.000Z\n",
       " \ttags: ['arxiv:1811.00207', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:crowdsourced', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:conversational', 'task_categories:question-answering', 'task_ids:dialogue-generation', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PyTorch original implementation of Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset\n",
       " \tcitation: @inproceedings{rashkin2019towards,\n",
       "   title = {Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset},\n",
       "   author = {Hannah Rashkin and Eric Michael Smith and Margaret Li and Y-Lan Boureau},\n",
       "   booktitle = {ACL},\n",
       "   year = {2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['crowdsourced'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'EmpatheticDialogues', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['conversational', 'question-answering'], 'task_ids': ['dialogue-generation', 'open-domain-qa'], 'paperswithcode_id': 'empatheticdialogues'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 756\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: empatheticdialogues\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: enriched_web_nlg\n",
       " \tsha: 89601c7cbe043501358e33382cd53b389a6aab90\n",
       " \tlastModified: 2022-07-01T11:51:43.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:crowdsourced', 'language:de', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-web-nlg', 'task_categories:tabular-to-text', 'task_ids:rdf-to-text', 'configs:de', 'configs:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WebNLG is a valuable resource and benchmark for the Natural Language Generation (NLG) community. However, as other NLG benchmarks, it only consists of a collection of parallel raw representations and their corresponding textual realizations. This work aimed to provide intermediate representations of the data for the development and evaluation of popular tasks in the NLG pipeline architecture (Reiter and Dale, 2000), such as Discourse Ordering, Lexicalization, Aggregation and Referring Expression Generation.\n",
       " \tcitation: @InProceedings{ferreiraetal2018,\n",
       "   author = \t\"Castro Ferreira, Thiago and Moussallem, Diego and Wubben, Sander and Krahmer, Emiel\",\n",
       "   title = \t\"Enriching the WebNLG corpus\",\n",
       "   booktitle = \t\"Proceedings of the 11th International Conference on Natural Language Generation\",\n",
       "   year = \t\"2018\",\n",
       "   series = {INLG'18},\n",
       "   publisher = \t\"Association for Computational Linguistics\",\n",
       "   address = \t\"Tilburg, The Netherlands\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['crowdsourced'], 'language': ['de', 'en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-web-nlg'], 'task_categories': ['tabular-to-text'], 'task_ids': ['rdf-to-text'], 'paperswithcode_id': None, 'pretty_name': 'Enriched WebNLG', 'configs': ['de', 'en']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 761\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eraser_multi_rc\n",
       " \tsha: 4acd3c6a44fb28701eafb40d6cd2db21cd2c47e8\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa', 'task_ids:multiple-choice-other-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Eraser Multi RC is a dataset for queries over multi-line passages, along with\n",
       " answers and a rationalte. Each example in this dataset has the following 5 parts\n",
       " 1. A Mutli-line Passage\n",
       " 2. A Query about the passage\n",
       " 3. An Answer to the query\n",
       " 4. A Classification as to whether the answer is right or wrong\n",
       " 5. An Explanation justifying the classification\n",
       " \tcitation: @unpublished{eraser2019,\n",
       "     title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n",
       "     author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n",
       " }\n",
       " @inproceedings{MultiRC2018,\n",
       "     author = {Daniel Khashabi and Snigdha Chaturvedi and Michael Roth and Shyam Upadhyay and Dan Roth},\n",
       "     title = {Looking Beyond the Surface:A Challenge Set for Reading Comprehension over Multiple Sentences},\n",
       "     booktitle = {NAACL},\n",
       "     year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'Eraser MultiRC (Multi-Sentence Reading Comprehension)', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa', 'multiple-choice-other-inference'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: esnli\n",
       " \tsha: 190841a03da3d391da4fbcf13b86d151da52f537\n",
       " \tlastModified: 2022-07-01T11:51:46.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\n",
       " include human-annotated natural language explanations of the entailment\n",
       " relations.\n",
       " \tcitation: @incollection{NIPS2018_8163,\n",
       " title = {e-SNLI: Natural Language Inference with Natural Language Explanations},\n",
       " author = {Camburu, Oana-Maria and Rockt\\\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},\n",
       " booktitle = {Advances in Neural Information Processing Systems 31},\n",
       " editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\n",
       " pages = {9539--9549},\n",
       " year = {2018},\n",
       " publisher = {Curran Associates, Inc.},\n",
       " url = {http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'e-snli', 'pretty_name': 'e-SNLI'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 14249\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: e-snli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eth_py150_open\n",
       " \tsha: fd325a4e74d444c5b58504822133e720ef423fc0\n",
       " \tlastModified: 2022-08-12T04:27:49.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:machine-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-contextual-embeddings']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A redistributable subset of the ETH Py150 corpus, introduced in the ICML 2020 paper 'Learning and Evaluating Contextual Embedding of Source Code'\n",
       " \tcitation: @inproceedings{kanade2020learning,\n",
       "   title={Learning and Evaluating Contextual Embedding of Source Code},\n",
       "   author={Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi, Kensen},\n",
       "   booktitle={International Conference on Machine Learning},\n",
       "   pages={5110--5121},\n",
       "   year={2020},\n",
       "   organization={PMLR}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-contextual-embeddings'], 'paperswithcode_id': 'eth-py150-open', 'pretty_name': 'ethpy150open'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: eth-py150-open\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ethos\n",
       " \tsha: 450166a367ec03fd301ba64839217b3263b60210\n",
       " \tlastModified: 2022-08-12T13:00:03.000Z\n",
       " \ttags: ['arxiv:2006.08328', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language_creators:other', 'language:en', 'license:agpl-3.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-Hate Speech Detection', 'configs:binary', 'configs:multilabel']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ETHOS: onlinE haTe speecH detectiOn dataSet. This repository contains a dataset for hate speech\n",
       " detection on social media platforms, called Ethos. There are two variations of the dataset:\n",
       " \n",
       " Ethos_Dataset_Binary: contains 998 comments in the dataset alongside with a label\n",
       " about hate speech presence or absence. 565 of them do not contain hate speech,\n",
       " while the rest of them, 433, contain.\n",
       " \n",
       " Ethos_Dataset_Multi_Label: which contains 8 labels for the 433 comments with hate speech content.\n",
       " These labels are violence (if it incites (1) or not (0) violence), directed_vs_general (if it is\n",
       " directed to a person (1) or a group (0)), and 6 labels about the category of hate speech like,\n",
       " gender, race, national_origin, disability, religion and sexual_orientation.\n",
       " \tcitation: @misc{mollas2020ethos,\n",
       "       title={ETHOS: an Online Hate Speech Detection Dataset},\n",
       "       author={Ioannis Mollas and Zoe Chrysopoulou and Stamatis Karlos and Grigorios Tsoumakas},\n",
       "       year={2020},\n",
       "       eprint={2006.08328},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found', 'other'], 'language': ['en'], 'license': ['agpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'sentiment-classification', 'text-classification-other-Hate Speech Detection'], 'paperswithcode_id': 'ethos', 'pretty_name': 'onlinE haTe speecH detectiOn dataSet', 'configs': ['binary', 'multilabel']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2369\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: ethos\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eu_regulatory_ir\n",
       " \tsha: c9ceff6b4c5b170264f8eb03a9206c4dc756736f\n",
       " \tlastModified: 2022-07-01T11:51:48.000Z\n",
       " \ttags: ['arxiv:2101.10726', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:document-retrieval', 'task_ids:text-retrieval-other-document-to-document-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: EURegIR: Regulatory Compliance IR (EU/UK)\n",
       " \tcitation: @inproceedings{chalkidis-etal-2021-regir,\n",
       "     title = \"Regulatory Compliance through Doc2Doc Information Retrieval: A case study in EU/UK legislation where text similarity has limitations\",\n",
       "     author = \"Chalkidis, Ilias  and Fergadiotis, Emmanouil and Manginas, Nikos and Katakalou, Eva,  and Malakasiotis, Prodromos\",\n",
       "     booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021)\",\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://arxiv.org/abs/2101.10726\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['document-retrieval', 'text-retrieval-other-document-to-document-retrieval'], 'paperswithcode_id': None, 'pretty_name': 'the RegIR datasets'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 481\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: eurlex\n",
       " \tsha: d86df6bcfb6141b805c4b507265e5c9d1ca15f2e\n",
       " \tlastModified: 2022-08-11T16:23:36.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-legal-topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: EURLEX57K contains 57k legislative documents in English from EUR-Lex portal, annotated with EUROVOC concepts.\n",
       " \tcitation: @inproceedings{chalkidis-etal-2019-large,\n",
       "     title = \"Large-Scale Multi-Label Text Classification on {EU} Legislation\",\n",
       "     author = \"Chalkidis, Ilias  and Fergadiotis, Emmanouil  and Malakasiotis, Prodromos  and Androutsopoulos, Ion\",\n",
       "     booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P19-1636\",\n",
       "     doi = \"10.18653/v1/P19-1636\",\n",
       "     pages = \"6314--6322\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-legal-topic-classification'], 'paperswithcode_id': 'eurlex57k', 'pretty_name': 'the EUR-Lex dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 562\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: eurlex57k\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: euronews\n",
       " \tsha: b559ed27d8b2ca60f78485654950d99ebdc65d91\n",
       " \tlastModified: 2022-07-01T11:51:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:de', 'language:fr', 'language:nl', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The corpora comprise of files per data provider that are encoded in the IOB format (Ramshaw & Marcus, 1995). The IOB format is a simple text chunking format that divides texts into single tokens per line, and, separated by a whitespace, tags to mark named entities. The most commonly used categories for tags are PER (person), LOC (location) and ORG (organization). To mark named entities that span multiple tokens, the tags have a prefix of either B- (beginning of named entity) or I- (inside of named entity). O (outside of named entity) tags are used to mark tokens that are not a named entity.\n",
       " \tcitation: @InProceedings{NEUDECKER16.110,\n",
       "   author = {Clemens Neudecker},\n",
       "   title = {An Open Corpus for Named Entity Recognition in Historic Newspapers},\n",
       "   booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)},\n",
       "   year = {2016},\n",
       "   month = {may},\n",
       "   date = {23-28},\n",
       "   location = {Portorož, Slovenia},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Sara Goggi and Marko Grobelnik and Bente Maegaard and Joseph Mariani and Helene Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   address = {Paris, France},\n",
       "   isbn = {978-2-9517408-9-1},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['de', 'fr', 'nl'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'europeana-newspapers', 'pretty_name': 'Europeana Newspapers'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 958\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: europeana-newspapers\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: europa_eac_tm\n",
       " \tsha: bb06aa4a5cc9a80d51207dcd9c71b3b63cc64b72\n",
       " \tlastModified: 2022-07-01T11:51:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hr', 'language:hu', 'language:is', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'language:tr', 'license:cc-by-4.0', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In October 2012, the European Union's (EU) Directorate General for Education and Culture ( DG EAC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-six languages. This resource bears the name EAC Translation Memory, short EAC-TM.\n",
       " \n",
       " EAC-TM covers up to 26 languages: 22 official languages of the EU (all except Irish) plus Icelandic, Croatian, Norwegian and Turkish. EAC-TM thus contains translations from English into the following 25 languages: Bulgarian, Czech, Danish, Dutch, Estonian, German, Greek, Finnish, French, Croatian, Hungarian, Icelandic, Italian, Latvian, Lithuanian, Maltese, Norwegian, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish, Swedish and Turkish.\n",
       " \n",
       " All documents and sentences were originally written in English (source language is English) and then translated into the other languages. The texts were translated by staff of the National Agencies of the Lifelong Learning and Youth in Action programmes. They are typically professionals in the field of education/youth and EU programmes. They are thus not professional translators, but they are normally native speakers of the target language.\n",
       " \tcitation: @Article{Steinberger2014,\n",
       "         author={Steinberger, Ralf\n",
       "                 and Ebrahim, Mohamed\n",
       "                 and Poulis, Alexandros\n",
       "                 and Carrasco-Benitez, Manuel\n",
       "                 and Schl{\\\"u}ter, Patrick\n",
       "                 and Przybyszewski, Marek\n",
       "                 and Gilbro, Signe},\n",
       "         title={An overview of the European Union's highly multilingual parallel corpora},\n",
       "         journal={Language Resources and Evaluation},\n",
       "         year={2014},\n",
       "         month={Dec},\n",
       "         day={01},\n",
       "         volume={48},\n",
       "         number={4},\n",
       "         pages={679-707},\n",
       "         issn={1574-0218},\n",
       "         doi={10.1007/s10579-014-9277-0},\n",
       "         url={https://doi.org/10.1007/s10579-014-9277-0}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hr', 'hu', 'is', 'it', 'lt', 'lv', 'mt', 'nl', 'no', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv', 'tr'], 'license': ['cc-by-4.0'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'Europa Education and Culture Translation Memory (EAC-TM)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 676\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: europa_ecdc_tm\n",
       " \tsha: 468b1ef0904d8abcd42e61e3c9a17e69c2cfede6\n",
       " \tlastModified: 2022-07-01T11:51:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:ga', 'language:hu', 'language:is', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'license:cc-by-sa-4.0', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages. This resource bears the name EAC Translation Memory, short EAC-TM.\n",
       " ECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following 24 languages: Bulgarian, Czech, Danish, Dutch, English, Estonian, Gaelige (Irish), German, Greek, Finnish, French, Hungarian, Icelandic, Italian, Latvian, Lithuanian, Maltese, Norwegian (NOrsk), Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish.\n",
       " All documents and sentences were thus originally written in English. They were then translated into the other languages by professional translators from the Translation Centre CdT in Luxembourg.\n",
       " \tcitation: @Article{Steinberger2014,\n",
       "         author={Steinberger, Ralf\n",
       "                 and Ebrahim, Mohamed\n",
       "                 and Poulis, Alexandros\n",
       "                 and Carrasco-Benitez, Manuel\n",
       "                 and Schl{\\\"u}ter, Patrick\n",
       "                 and Przybyszewski, Marek\n",
       "                 and Gilbro, Signe},\n",
       "         title={An overview of the European Union's highly multilingual parallel corpora},\n",
       "         journal={Language Resources and Evaluation},\n",
       "         year={2014},\n",
       "         month={Dec},\n",
       "         day={01},\n",
       "         volume={48},\n",
       "         number={4},\n",
       "         pages={679-707},\n",
       "         issn={1574-0218},\n",
       "         doi={10.1007/s10579-014-9277-0},\n",
       "         url={https://doi.org/10.1007/s10579-014-9277-0}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'ga', 'hu', 'is', 'it', 'lt', 'lv', 'mt', 'nl', 'no', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'EuropaEcdcTm'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 943\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: europarl_bilingual\n",
       " \tsha: b8840129f2e52f764fc641969639d8126d2459d4\n",
       " \tlastModified: 2022-07-01T11:51:51.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'license:unknown', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus extracted from the European Parliament web site by Philipp Koehn (University of Edinburgh). The main intended use is to aid statistical machine translation research.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'it', 'lt', 'lv', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'europarl-bilingual'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1288\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: event2Mind\n",
       " \tsha: 3ad7c4d1291f3b916edff96048df6cba8b18cfe0\n",
       " \tlastModified: 2022-09-20T07:38:10.000Z\n",
       " \ttags: ['arxiv:1805.06939', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-common-sense-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In Event2Mind, we explore the task of understanding stereotypical intents and reactions to events. Through crowdsourcing, we create a large corpus with 25,000 events and free-form descriptions of their intents and reactions, both of the event's subject and (potentially implied) other participants.\n",
       " \tcitation: @inproceedings{event2Mind,\n",
       "     title={Event2Mind: Commonsense Inference on Events, Intents, and Reactions},\n",
       "     author={Hannah Rashkin and Maarten Sap and Emily Allaway and Noah A. Smith† Yejin Choi},\n",
       "     year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Event2Mind', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-common-sense-inference'], 'paperswithcode_id': 'event2mind'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: event2mind\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: evidence_infer_treatment\n",
       " \tsha: 37020345314dde3cdda5bdca65493a43f4169fe6\n",
       " \tlastModified: 2022-07-01T11:51:53.000Z\n",
       " \ttags: ['arxiv:2005.04177', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:fact-checking-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Data and code from our \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\", NAACL 2019. This work concerns inferring the results reported in clinical trials from text.\n",
       " \n",
       " The dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple treatments. Each of these articles will have multiple questions, or 'prompts' associated with them. These prompts will ask about the relationship between an intervention and comparator with respect to an outcome, as reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared to placebo on the duration of headaches. For the sake of this task, we assume that a particular article will report that the intervention of interest either significantly increased, significantly decreased or had significant effect on the outcome, relative to the comparator.\n",
       " \n",
       " The dataset could be used for automatic data extraction of the results of a given RCT. This would enable readers to discover the effectiveness of different treatments without needing to read the paper.\n",
       " \tcitation: @inproceedings{lehman-etal-2019-inferring,\n",
       "     title = \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\",\n",
       "     author = \"Lehman, Eric  and\n",
       "       DeYoung, Jay  and\n",
       "       Barzilay, Regina  and\n",
       "       Wallace, Byron C.\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n",
       "     month = jun,\n",
       "     year = \"2019\",\n",
       "     address = \"Minneapolis, Minnesota\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/N19-1371\",\n",
       "     pages = \"3705--3717\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Evidence Infer Treatment', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['fact-checking-retrieval'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 800\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: exams\n",
       " \tsha: 977bf5b80027b842d55e9070174326821aa8a67a\n",
       " \tlastModified: 2022-08-16T06:29:40.000Z\n",
       " \ttags: ['arxiv:2011.03080', 'annotations_creators:found', 'language_creators:found', 'language:ar', 'language:bg', 'language:de', 'language:es', 'language:fr', 'language:hr', 'language:hu', 'language:it', 'language:lt', 'language:mk', 'language:pl', 'language:pt', 'language:sq', 'language:sr', 'language:tr', 'language:vi', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'configs:alignments', 'configs:crosslingual_bg', 'configs:crosslingual_hr', 'configs:crosslingual_hu', 'configs:crosslingual_it', 'configs:crosslingual_mk', 'configs:crosslingual_pl', 'configs:crosslingual_pt', 'configs:crosslingual_sq', 'configs:crosslingual_sr', 'configs:crosslingual_test', 'configs:crosslingual_tr', 'configs:crosslingual_vi', 'configs:crosslingual_with_para_bg', 'configs:crosslingual_with_para_hr', 'configs:crosslingual_with_para_hu', 'configs:crosslingual_with_para_it', 'configs:crosslingual_with_para_mk', 'configs:crosslingual_with_para_pl', 'configs:crosslingual_with_para_pt', 'configs:crosslingual_with_para_sq', 'configs:crosslingual_with_para_sr', 'configs:crosslingual_with_para_test', 'configs:crosslingual_with_para_tr', 'configs:crosslingual_with_para_vi', 'configs:multilingual', 'configs:multilingual_with_para']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: EXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations.\n",
       " It consists of more than 24,000 high-quality high school exam questions in 16 languages,\n",
       " covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.\n",
       " \tcitation: @article{hardalov2020exams,\n",
       "   title={EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering},\n",
       "   author={Hardalov, Momchil and Mihaylov, Todor and Dimitrina Zlatkova and Yoan Dinkov and Ivan Koychev and Preslav Nvakov},\n",
       "   journal={arXiv preprint arXiv:2011.03080},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'EXAMS', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'bg', 'de', 'es', 'fr', 'hr', 'hu', 'it', 'lt', 'mk', 'pl', 'pt', 'sq', 'sr', 'tr', 'vi'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual', 'multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'exams', 'configs': ['alignments', 'crosslingual_bg', 'crosslingual_hr', 'crosslingual_hu', 'crosslingual_it', 'crosslingual_mk', 'crosslingual_pl', 'crosslingual_pt', 'crosslingual_sq', 'crosslingual_sr', 'crosslingual_test', 'crosslingual_tr', 'crosslingual_vi', 'crosslingual_with_para_bg', 'crosslingual_with_para_hr', 'crosslingual_with_para_hu', 'crosslingual_with_para_it', 'crosslingual_with_para_mk', 'crosslingual_with_para_pl', 'crosslingual_with_para_pt', 'crosslingual_with_para_sq', 'crosslingual_with_para_sr', 'crosslingual_with_para_test', 'crosslingual_with_para_tr', 'crosslingual_with_para_vi', 'multilingual', 'multilingual_with_para']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4403\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: exams\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: factckbr\n",
       " \tsha: 502c05cc6ced679bea5bc65c14bee84c622ab702\n",
       " \tlastModified: 2022-07-01T11:51:54.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification.\n",
       " The data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.\n",
       " The FACTCK.BR dataset contains 1309 claims with its corresponding label.\n",
       " \tcitation: @inproceedings{10.1145/3323503.3361698,\n",
       "     author = {Moreno, Jo\\\\~{a}o and Bressan, Gra\\\\c{c}a},\n",
       "     title = {FACTCK.BR: A New Dataset to Study Fake News},\n",
       "     year = {2019},\n",
       "     isbn = {9781450367639},\n",
       "     publisher = {Association for Computing Machinery},\n",
       "     address = {New York, NY, USA},\n",
       "     url = {https://doi.org/10.1145/3323503.3361698},\n",
       "     doi = {10.1145/3323503.3361698},\n",
       "     abstract = {Machine learning algorithms can be used to combat fake news propagation. For the news classification, labeled datasets are required, however, among the existing datasets, few separate verified false from skewed ones with a good variety of sources. This work presents FACTCK.BR, a new dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification. The data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.},\n",
       "     booktitle = {Proceedings of the 25th Brazillian Symposium on Multimedia and the Web},\n",
       "     pages = {525–527},\n",
       "     numpages = {3},\n",
       "     keywords = {fake news, fact check, information extraction, dataset},\n",
       "     location = {Rio de Janeiro, Brazil},\n",
       "     series = {WebMedia '19}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'FACTCK BR'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: fake_news_english\n",
       " \tsha: 0b895802d3df18cd78de425c3158c79a8277b69f\n",
       " \tlastModified: 2022-07-01T11:51:54.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Fake news has become a major societal issue and a technical challenge for social media companies to identify. This content is difficult to identify because the term \"fake news\" covers intentionally false, deceptive stories as well as factual errors, satire, and sometimes, stories that a person just does not like. Addressing the problem requires clear definitions and examples. In this work, we present a dataset of fake news and satire stories that are hand coded, verified, and, in the case of fake news, include rebutting stories. We also include a thematic content analysis of the articles, identifying major themes that include hyperbolic support or condemnation of a gure, conspiracy theories, racist themes, and discrediting of reliable sources. In addition to releasing this dataset for research use, we analyze it and show results based on language that are promising for classification purposes. Overall, our contribution of a dataset and initial analysis are designed to support future work by fake news researchers.\n",
       " \tcitation: @inproceedings{inproceedings,\n",
       " author = {Golbeck, Jennifer and Everett, Jennine and Falak, Waleed and Gieringer, Carl and Graney, Jack and Hoffman, Kelly and Huth, Lindsay and Ma, Zhenya and Jha, Mayanka and Khan, Misbah and Kori, Varsha and Mauriello, Matthew and Lewis, Elo and Mirano, George and IV, William and Mussenden, Sean and Nelson, Tammie and Mcwillie, Sean and Pant, Akshat and Cheakalos, Paul},\n",
       " year = {2018},\n",
       " month = {05},\n",
       " pages = {17-21},\n",
       " title = {Fake News vs Satire: A Dataset and Analysis},\n",
       " doi = {10.1145/3201064.3201100}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification'], 'paperswithcode_id': None, 'pretty_name': 'Fake News English'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 346\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: fake_news_filipino\n",
       " \tsha: 3a04a65bc3687c54f625d7fe6b9bba600958eb56\n",
       " \tlastModified: 2022-07-01T11:51:54.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:tl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     Low-Resource Fake News Detection Corpora in Filipino. The first of its kind. Contains 3,206 expertly-labeled news samples, half of which are real and half of which are fake.\n",
       " \tcitation:     @inproceedings{cruz2020localization,\n",
       "       title={Localization of Fake News Detection via Multitask Transfer Learning},\n",
       "       author={Cruz, Jan Christian Blaise and Tan, Julianne Agatha and Cheng, Charibeth},\n",
       "       booktitle={Proceedings of The 12th Language Resources and Evaluation Conference},\n",
       "       pages={2596--2604},\n",
       "       year={2020}\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['tl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': 'fake-news-filipino-dataset', 'pretty_name': 'Fake News Filipino'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: fake-news-filipino-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: farsi_news\n",
       " \tsha: 6b57a9d26377b678cd144fefc214abb47d5546d7\n",
       " \tlastModified: 2022-08-11T12:57:24.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:fa', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Contains Farsi (Persian) datasets for Machine Learning tasks, particularly NLP.\n",
       " These datasets have been extracted from the RSS feed of two Farsi news agency websites:\n",
       " \n",
       " - Hamshahri\n",
       " - RadioFarda\n",
       " \tcitation: \\\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['fa'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'FarsiNews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: fashion_mnist\n",
       " \tsha: 14dc1f3d351532769a44daea4a723c3f1f52dbba\n",
       " \tlastModified: 2022-07-01T11:51:56.000Z\n",
       " \ttags: ['arxiv:1708.07747', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:image-classification', 'task_ids:multi-class-image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of\n",
       " 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image,\n",
       " associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in\n",
       " replacement for the original MNIST dataset for benchmarking machine learning algorithms.\n",
       " It shares the same image size and structure of training and testing splits.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1708-07747,\n",
       "   author    = {Han Xiao and\n",
       "                Kashif Rasul and\n",
       "                Roland Vollgraf},\n",
       "   title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                Algorithms},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1708.07747},\n",
       "   year      = {2017},\n",
       "   url       = {http://arxiv.org/abs/1708.07747},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1708.07747},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['image-classification'], 'task_ids': ['multi-class-image-classification'], 'paperswithcode_id': 'fashion-mnist', 'pretty_name': 'FashionMNIST'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6338\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: fashion-mnist\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: fever\n",
       " \tsha: 2408898d9e60171d1d433665e8fa30cdfe495524\n",
       " \tlastModified: 2022-07-06T11:41:59.000Z\n",
       " \ttags: ['language:en', 'annotations_creators:crowdsourced', 'language_creators:found', 'license:cc-by-sa-3.0', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|wikipedia', 'task_categories:text-classification', 'task_ids:text-classification-other-knowledge-verification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'fever', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'license': ['cc-by-sa-3.0', 'gpl-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'FEVER', 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-knowledge-verification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2316\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: fever\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: few_rel\n",
       " \tsha: c8735c8c38770d8f0d6d7d07c7cb1bc7e3ef681e\n",
       " \tlastModified: 2022-07-01T11:51:58.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-relation-extraction', 'configs:default', 'configs:pid2name']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: FewRel is a large-scale few-shot relation extraction dataset, which contains more than one hundred relations and tens of thousands of annotated instances cross different domains.\n",
       " \tcitation: @inproceedings{han-etal-2018-fewrel,\n",
       "     title = \"{F}ew{R}el: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation\",\n",
       "     author = \"Han, Xu and Zhu, Hao and Yu, Pengfei and Wang, Ziyun and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong\",\n",
       "     booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct # \"-\" # nov,\n",
       "     year = \"2018\",\n",
       "     address = \"Brussels, Belgium\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D18-1514\",\n",
       "     doi = \"10.18653/v1/D18-1514\",\n",
       "     pages = \"4803--4809\"\n",
       " }\n",
       " \n",
       " @inproceedings{gao-etal-2019-fewrel,\n",
       "     title = \"{F}ew{R}el 2.0: Towards More Challenging Few-Shot Relation Classification\",\n",
       "     author = \"Gao, Tianyu and Han, Xu and Zhu, Hao and Liu, Zhiyuan and Li, Peng and Sun, Maosong and Zhou, Jie\",\n",
       "     booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2019\",\n",
       "     address = \"Hong Kong, China\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D19-1649\",\n",
       "     doi = \"10.18653/v1/D19-1649\",\n",
       "     pages = \"6251--6256\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-relation-extraction'], 'paperswithcode_id': 'fewrel', 'pretty_name': 'Few-Shot Relation Classification Dataset', 'configs': ['default', 'pid2name']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 382\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: fewrel\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: financial_phrasebank\n",
       " \tsha: fca5cab46a86c97c68e9228f39a6ce95f78e2c0e\n",
       " \tlastModified: 2022-07-01T11:51:58.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The key arguments for the low utilization of statistical techniques in\n",
       " financial sentiment analysis have been the difficulty of implementation for\n",
       " practical applications and the lack of high quality training data for building\n",
       " such models. Especially in the case of finance and economic texts, annotated\n",
       " collections are a scarce resource and many are reserved for proprietary use\n",
       " only. To resolve the missing training data problem, we present a collection of\n",
       " ∼ 5000 sentences to establish human-annotated standards for benchmarking\n",
       " alternative modeling techniques.\n",
       " \n",
       " The objective of the phrase level annotation task was to classify each example\n",
       " sentence into a positive, negative or neutral category by considering only the\n",
       " information explicitly available in the given sentence. Since the study is\n",
       " focused only on financial and economic domains, the annotators were asked to\n",
       " consider the sentences from the view point of an investor only; i.e. whether\n",
       " the news may have positive, negative or neutral influence on the stock price.\n",
       " As a result, sentences which have a sentiment that is not relevant from an\n",
       " economic or financial perspective are considered neutral.\n",
       " \n",
       " This release of the financial phrase bank covers a collection of 4840\n",
       " sentences. The selected collection of phrases was annotated by 16 people with\n",
       " adequate background knowledge on financial markets. Three of the annotators\n",
       " were researchers and the remaining 13 annotators were master’s students at\n",
       " Aalto University School of Business with majors primarily in finance,\n",
       " accounting, and economics.\n",
       " \n",
       " Given the large number of overlapping annotations (5 to 8 annotations per\n",
       " sentence), there are several ways to define a majority vote based gold\n",
       " standard. To provide an objective comparison, we have formed 4 alternative\n",
       " reference datasets based on the strength of majority agreement: all annotators\n",
       " agree, >=75% of annotators agree, >=66% of annotators agree and >=50% of\n",
       " annotators agree.\n",
       " \tcitation: @article{Malo2014GoodDO,\n",
       "   title={Good debt or bad debt: Detecting semantic orientations in economic texts},\n",
       "   author={P. Malo and A. Sinha and P. Korhonen and J. Wallenius and P. Takala},\n",
       "   journal={Journal of the Association for Information Science and Technology},\n",
       "   year={2014},\n",
       "   volume={65}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'FinancialPhrasebank'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3348\n",
       " \tlikes: 22\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: finer\n",
       " \tsha: ff6744ae54b25af3d377f8a3d45f3c09932a5b27\n",
       " \tlastModified: 2022-07-01T11:51:59.000Z\n",
       " \ttags: ['arxiv:1908.04212', 'annotations_creators:expert-generated', 'language_creators:other', 'language:fi', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The directory data contains a corpus of Finnish technology related news articles with a manually prepared\n",
       " named entity annotation (digitoday.2014.csv). The text material was extracted from the archives of Digitoday,\n",
       " a Finnish online technology news source (www.digitoday.fi). The corpus consists of 953 articles\n",
       " (193,742 word tokens) with six named entity classes (organization, location, person, product, event, and date).\n",
       " The corpus is available for research purposes and can be readily used for development of NER systems for Finnish.\n",
       " \tcitation: @article{ruokolainen2019finnish,\n",
       "   title={A finnish news corpus for named entity recognition},\n",
       "   author={Ruokolainen, Teemu and Kauppinen, Pekka and Silfverberg, Miikka and Lind{\\'e}n, Krister},\n",
       "   journal={Language Resources and Evaluation},\n",
       "   pages={1--26},\n",
       "   year={2019},\n",
       "   publisher={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['fi'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'finer', 'pretty_name': 'Finnish News Corpus for Named Entity Recognition'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: finer\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: flores\n",
       " \tsha: b86548e24b0625b833ff7832af596c0d76f818f0\n",
       " \tlastModified: 2022-07-01T11:51:59.000Z\n",
       " \ttags: ['arxiv:1902.01382', 'annotations_creators:found', 'language_creators:found', 'language:en', 'language:ne', 'language:si', 'license:cc-by-4.0', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|wikipedia', 'source_datasets:extended|opus_gnome', 'source_datasets:extended|opus_ubuntu', 'source_datasets:extended|open_subtitles', 'source_datasets:extended|paracrawl', 'source_datasets:extended|bible_para', 'source_datasets:extended|kde4', 'source_datasets:extended|other-global-voices', 'source_datasets:extended|other-common-crawl', 'task_categories:translation', 'configs:neen', 'configs:sien']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English.\n",
       " \tcitation: @misc{guzmn2019new,\n",
       "     title={Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English},\n",
       "     author={Francisco Guzman and Peng-Jen Chen and Myle Ott and Juan Pino and Guillaume Lample and Philipp Koehn and Vishrav Chaudhary and Marc'Aurelio Ranzato},\n",
       "     year={2019},\n",
       "     eprint={1902.01382},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Flores', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'ne', 'si'], 'license': ['cc-by-4.0'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|wikipedia', 'extended|opus_gnome', 'extended|opus_ubuntu', 'extended|open_subtitles', 'extended|paracrawl', 'extended|bible_para', 'extended|kde4', 'extended|other-global-voices', 'extended|other-common-crawl'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'flores', 'configs': ['neen', 'sien']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 495\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: flores\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: flue\n",
       " \tsha: dd09f940ae055e6cdee54861510da84dc489f861\n",
       " \tlastModified: 2022-07-01T11:52:00.000Z\n",
       " \ttags: ['arxiv:1912.05372', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:fr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:semantic-similarity-classification', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-Word Sense Disambiguation for Verbs', 'configs:CLS', 'configs:PAWS-X', 'configs:WSD-V', 'configs:XNLI']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: FLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark. The goal is to enable further reproducible experiments in the future and to share models and progress on the French language.\n",
       " \tcitation: @misc{le2019flaubert,\n",
       "     title={FlauBERT: Unsupervised Language Model Pre-training for French},\n",
       "     author={Hang Le and Loïc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Benoît Crabbé and Laurent Besacier and Didier Schwab},\n",
       "     year={2019},\n",
       "     eprint={1912.05372},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'FLUE', 'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['fr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'semantic-similarity-classification', 'sentiment-classification', 'text-classification-other-Word Sense Disambiguation for Verbs'], 'paperswithcode_id': None, 'configs': ['CLS', 'PAWS-X', 'WSD-V', 'XNLI']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 191\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: food101\n",
       " \tsha: ebe9c9ed0c32ca034162fab0199e781f42cacc7b\n",
       " \tlastModified: 2022-07-01T11:52:00.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-foodspotting', 'task_categories:image-classification', 'task_ids:multi-class-image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation:  @inproceedings{bossard14,\n",
       "   title = {Food-101 -- Mining Discriminative Components with Random Forests},\n",
       "   author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},\n",
       "   booktitle = {European Conference on Computer Vision},\n",
       "   year = {2014}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Food-101', 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-foodspotting'], 'task_categories': ['image-classification'], 'task_ids': ['multi-class-image-classification'], 'paperswithcode_id': 'food-101'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1982\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: food-101\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: fquad\n",
       " \tsha: 2f0792c574076c617b7260b1a4a13739c9de6d7b\n",
       " \tlastModified: 2022-07-01T11:52:01.000Z\n",
       " \ttags: ['arxiv:2002.06071', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:fr', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text-retrieval', 'task_ids:extractive-qa', 'task_ids:closed-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: FQuAD: French Question Answering Dataset\n",
       " We introduce FQuAD, a native French Question Answering Dataset. FQuAD contains 25,000+ question and answer pairs.\n",
       " Finetuning CamemBERT on FQuAD yields a F1 score of 88% and an exact match of 77.9%.\n",
       " \tcitation: @ARTICLE{2020arXiv200206071\n",
       "        author = {Martin, d'Hoffschmidt and Maxime, Vidal and\n",
       "          Wacim, Belblidia and Tom, Brendlé},\n",
       "         title = \"{FQuAD: French Question Answering Dataset}\",\n",
       "       journal = {arXiv e-prints},\n",
       "      keywords = {Computer Science - Computation and Language},\n",
       "          year = \"2020\",\n",
       "         month = \"Feb\",\n",
       "           eid = {arXiv:2002.06071},\n",
       "         pages = {arXiv:2002.06071},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {2002.06071},\n",
       "  primaryClass = {cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['fr'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text-retrieval'], 'task_ids': ['extractive-qa', 'closed-domain-qa'], 'paperswithcode_id': 'fquad', 'pretty_name': 'FQuAD: French Question Answering Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: fquad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: freebase_qa\n",
       " \tsha: f55a6b9c9c38d1b216e6f77cbfc3cbaf55155445\n",
       " \tlastModified: 2022-07-01T11:52:02.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|trivia_qa', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: FreebaseQA is for open-domain factoid question answering (QA) tasks over structured knowledge bases, like Freebase The data set is generated by matching trivia-type question-answer pairs with subject-predicateobject triples in Freebase.\n",
       " \tcitation: @article{jiang2019freebaseqa,\n",
       "   title={FreebaseQA: A New Factoid QA Dataset Matching Trivia-Style Question-Answer Pairs with Freebase},\n",
       "   author={Jiang, Kelvin and Wu, Dekun and Jiang, Hui},\n",
       "   journal={north american chapter of the association for computational linguistics},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|trivia_qa'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'freebaseqa', 'pretty_name': 'FreebaseQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1053\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: freebaseqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gap\n",
       " \tsha: 22a6a48e62211b61d31bd5654c6a4e4ddd8a0590\n",
       " \tlastModified: 2022-09-20T07:38:10.000Z\n",
       " \ttags: ['arxiv:1810.05201', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:coreference-resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: GAP is a gender-balanced dataset containing 8,908 coreference-labeled pairs of\n",
       " (ambiguous pronoun, antecedent name), sampled from Wikipedia and released by\n",
       " Google AI Language for the evaluation of coreference resolution in practical\n",
       " applications.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1810-05201,\n",
       "   author    = {Kellie Webster and\n",
       "                Marta Recasens and\n",
       "                Vera Axelrod and\n",
       "                Jason Baldridge},\n",
       "   title     = {Mind the {GAP:} {A} Balanced Corpus of Gendered Ambiguous Pronouns},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1810.05201},\n",
       "   year      = {2018},\n",
       "   url       = {http://arxiv.org/abs/1810.05201},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1810.05201},\n",
       "   timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
       "   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-05201},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'GAP Benchmark Suite', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['coreference-resolution'], 'paperswithcode_id': 'gap'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 419\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: gap\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gem\n",
       " \tsha: 937184f5da9083408ec0fa097a18931cf7a07743\n",
       " \tlastModified: 2022-10-11T08:21:54.000Z\n",
       " \ttags: ['arxiv:2102.01672', 'annotations_creators:crowdsourced', 'annotations_creators:found', 'language_creators:crowdsourced', 'language_creators:found', 'language_creators:machine-generated', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:ru', 'language:tr', 'language:vi', 'license:other', 'multilinguality:monolingual', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:extended|other-vision-datasets', 'source_datasets:original', 'task_categories:fill-mask', 'task_categories:summarization', 'task_categories:table-to-text', 'task_categories:tabular-to-text', 'task_categories:text-generation', 'task_categories:text2text-generation', 'task_ids:dialogue-modeling', 'task_ids:other-concepts-to-text', 'task_ids:other-intent-to-text', 'task_ids:rdf-to-text', 'task_ids:news-articles-summarization', 'task_ids:text-simplification', 'task_ids:text2text-generation-other-meaning-representation-to-text', 'configs:common_gen', 'configs:cs_restaurants', 'configs:dart', 'configs:e2e_nlg', 'configs:mlsum_de', 'configs:mlsum_es', 'configs:schema_guided_dialog', 'configs:totto', 'configs:web_nlg_en', 'configs:web_nlg_ru', 'configs:wiki_auto_asset_turk', 'configs:wiki_lingua_es_en', 'configs:wiki_lingua_ru_en', 'configs:wiki_lingua_tr_en', 'configs:wiki_lingua_vi_en', 'configs:xsum']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: GEM is a benchmark environment for Natural Language Generation with a focus on its Evaluation,\n",
       " both through human annotations and automated Metrics.\n",
       " \n",
       " GEM aims to:\n",
       " - measure NLG progress across 13 datasets spanning many NLG tasks and languages.\n",
       " - provide an in-depth analysis of data and models presented via data statements and challenge sets.\n",
       " - develop standards for evaluation of generated text using both automated and human metrics.\n",
       " \n",
       " It is our goal to regularly update GEM and to encourage toward more inclusive practices in dataset development\n",
       " by extending existing data or developing datasets for additional languages.\n",
       " \tcitation: @article{gem_benchmark,\n",
       "   author    = {Sebastian Gehrmann and\n",
       "                Tosin P. Adewumi and\n",
       "                Karmanya Aggarwal and\n",
       "                Pawan Sasanka Ammanamanchi and\n",
       "                Aremu Anuoluwapo and\n",
       "                Antoine Bosselut and\n",
       "                Khyathi Raghavi Chandu and\n",
       "                Miruna{-}Adriana Clinciu and\n",
       "                Dipanjan Das and\n",
       "                Kaustubh D. Dhole and\n",
       "                Wanyu Du and\n",
       "                Esin Durmus and\n",
       "                Ondrej Dusek and\n",
       "                Chris Emezue and\n",
       "                Varun Gangal and\n",
       "                Cristina Garbacea and\n",
       "                Tatsunori Hashimoto and\n",
       "                Yufang Hou and\n",
       "                Yacine Jernite and\n",
       "                Harsh Jhamtani and\n",
       "                Yangfeng Ji and\n",
       "                Shailza Jolly and\n",
       "                Dhruv Kumar and\n",
       "                Faisal Ladhak and\n",
       "                Aman Madaan and\n",
       "                Mounica Maddela and\n",
       "                Khyati Mahajan and\n",
       "                Saad Mahamood and\n",
       "                Bodhisattwa Prasad Majumder and\n",
       "                Pedro Henrique Martins and\n",
       "                Angelina McMillan{-}Major and\n",
       "                Simon Mille and\n",
       "                Emiel van Miltenburg and\n",
       "                Moin Nadeem and\n",
       "                Shashi Narayan and\n",
       "                Vitaly Nikolaev and\n",
       "                Rubungo Andre Niyongabo and\n",
       "                Salomey Osei and\n",
       "                Ankur P. Parikh and\n",
       "                Laura Perez{-}Beltrachini and\n",
       "                Niranjan Ramesh Rao and\n",
       "                Vikas Raunak and\n",
       "                Juan Diego Rodriguez and\n",
       "                Sashank Santhanam and\n",
       "                Joao Sedoc and\n",
       "                Thibault Sellam and\n",
       "                Samira Shaikh and\n",
       "                Anastasia Shimorina and\n",
       "                Marco Antonio Sobrevilla Cabezudo and\n",
       "                Hendrik Strobelt and\n",
       "                Nishant Subramani and\n",
       "                Wei Xu and\n",
       "                Diyi Yang and\n",
       "                Akhila Yerukola and\n",
       "                Jiawei Zhou},\n",
       "   title     = {The {GEM} Benchmark: Natural Language Generation, its Evaluation and\n",
       "                Metrics},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2102.01672},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2102.01672},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2102.01672}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'found'], 'language_creators': ['crowdsourced', 'found', 'machine-generated'], 'language': ['cs', 'de', 'en', 'es', 'ru', 'tr', 'vi'], 'license': ['other'], 'multilinguality': ['monolingual', 'multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K'], 'source_datasets': ['extended|other-vision-datasets', 'original'], 'task_categories': ['fill-mask', 'summarization', 'table-to-text', 'tabular-to-text', 'text-generation', 'text2text-generation'], 'task_ids': ['dialogue-modeling', 'other-concepts-to-text', 'other-intent-to-text', 'rdf-to-text', 'news-articles-summarization', 'text-simplification', 'text2text-generation-other-meaning-representation-to-text'], 'paperswithcode_id': 'gem', 'pretty_name': 'GEM', 'configs': ['common_gen', 'cs_restaurants', 'dart', 'e2e_nlg', 'mlsum_de', 'mlsum_es', 'schema_guided_dialog', 'totto', 'web_nlg_en', 'web_nlg_ru', 'wiki_auto_asset_turk', 'wiki_lingua_es_en', 'wiki_lingua_ru_en', 'wiki_lingua_tr_en', 'wiki_lingua_vi_en', 'xsum']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5834\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: gem\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: generated_reviews_enth\n",
       " \tsha: 1793214baee339c4c9975c5419b17fc8e002c58f\n",
       " \tlastModified: 2022-08-11T16:23:38.000Z\n",
       " \ttags: ['arxiv:2007.03541', 'arxiv:1909.05858', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'language:th', 'license:cc-by-sa-4.0', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  `generated_reviews_enth`\n",
       "  Generated product reviews dataset for machine translation quality prediction, part of [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf)\n",
       "  `generated_reviews_enth` is created as part of [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf) for machine translation task.\n",
       "  This dataset (referred to as `generated_reviews_yn` in [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf)) are English product reviews\n",
       "  generated by [CTRL](https://arxiv.org/abs/1909.05858), translated by Google Translate API and annotated as accepted or rejected (`correct`)\n",
       "  based on fluency and adequacy of the translation by human annotators.\n",
       "  This allows it to be used for English-to-Thai translation quality esitmation (binary label), machine translation, and sentiment analysis.\n",
       " \tcitation: @article{lowphansirikul2020scb,\n",
       "   title={scb-mt-en-th-2020: A Large English-Thai Parallel Corpus},\n",
       "   author={Lowphansirikul, Lalita and Polpanumas, Charin and Rutherford, Attapol T and Nutanong, Sarana},\n",
       "   journal={arXiv preprint arXiv:2007.03541},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en', 'th'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation', 'text-classification'], 'task_ids': ['multi-class-classification', 'semantic-similarity-classification'], 'paperswithcode_id': None, 'pretty_name': 'generated_reviews_enth'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 612\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: generics_kb\n",
       " \tsha: a549874f37b73e961c0110c3392ed748513b68b3\n",
       " \tlastModified: 2022-07-01T11:52:04.000Z\n",
       " \ttags: ['arxiv:2005.00660', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-knowledge-base', 'configs:generics_kb', 'configs:generics_kb_best', 'configs:generics_kb_simplewiki', 'configs:generics_kb_waterloo']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The GenericsKB contains 3.4M+ generic sentences about the world, i.e., sentences expressing general truths such as \"Dogs bark,\" and \"Trees remove carbon dioxide from the atmosphere.\" Generics are potentially useful as a knowledge source for AI systems requiring general world knowledge. The GenericsKB is the first large-scale resource containing naturally occurring generic sentences (as opposed to extracted or crowdsourced triples), and is rich in high-quality, general, semantically complete statements. Generics were primarily extracted from three large text sources, namely the Waterloo Corpus, selected parts of Simple Wikipedia, and the ARC Corpus. A filtered, high-quality subset is also available in GenericsKB-Best, containing 1,020,868 sentences. We recommend you start with GenericsKB-Best.\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = {GenericsKB: A Knowledge Base of Generic Statements},\n",
       " authors={Sumithra Bhakthavatsalam, Chloe Anastasiades, Peter Clark},\n",
       " year={2020},\n",
       " publisher = {Allen Institute for AI},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-knowledge-base'], 'paperswithcode_id': 'genericskb', 'pretty_name': 'GenericsKB', 'configs': ['generics_kb', 'generics_kb_best', 'generics_kb_simplewiki', 'generics_kb_waterloo']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 800\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: genericskb\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: german_legal_entity_recognition\n",
       " \tsha: 2fd65eb8300a7be18e849043fe7b530b1f5626b8\n",
       " \tlastModified: 2022-08-11T12:57:24.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:de', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " \tcitation: @inproceedings{leitner2019fine,\n",
       "   author = {Elena Leitner and Georg Rehm and Julian Moreno-Schneider},\n",
       "   title = {{Fine-grained Named Entity Recognition in Legal Documents}},\n",
       "   booktitle = {Semantic Systems. The Power of AI and Knowledge\n",
       "                   Graphs. Proceedings of the 15th International Conference\n",
       "                   (SEMANTiCS 2019)},\n",
       "   year = 2019,\n",
       "   editor = {Maribel Acosta and Philippe Cudré-Mauroux and Maria\n",
       "                   Maleshkova and Tassilo Pellegrini and Harald Sack and York\n",
       "                   Sure-Vetter},\n",
       "   keywords = {aip},\n",
       "   publisher = {Springer},\n",
       "   series = {Lecture Notes in Computer Science},\n",
       "   number = {11702},\n",
       "   address = {Karlsruhe, Germany},\n",
       "   month = 9,\n",
       "   note = {10/11 September 2019},\n",
       "   pages = {272--287},\n",
       "   pdf = {https://link.springer.com/content/pdf/10.1007%2F978-3-030-33220-4_20.pdf}}\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['de'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'legal-documents-entity-recognition', 'pretty_name': 'Legal Documents Entity Recognition'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1530\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: legal-documents-entity-recognition\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: germaner\n",
       " \tsha: eeb8a94e24fdc8f89db77684273610ce0e9bec5f\n",
       " \tlastModified: 2022-07-01T11:52:05.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:de', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: GermaNER is a freely available statistical German Named Entity Tagger based on conditional random fields(CRF). The tagger is trained and evaluated on the NoSta-D Named Entity dataset, which was used in the GermEval 2014 for named entity recognition. The tagger comes close to the performance of the best (proprietary) system in the competition with 77% F-measure (this is the latest result; the one reported in the paper is 76%) test set performance on the four standard NER classes (PERson, LOCation, ORGanisation and OTHer).\n",
       " \n",
       " We describe a range of features and their influence on German NER classification and provide a comparative evaluation and some analysis of the results. The software components, the training data and all data used for feature generation are distributed under permissive licenses, thus this tagger can be used in academic and commercial settings without restrictions or fees. The tagger is available as a command-line tool and as an Apache UIMA component.\n",
       " \tcitation: @inproceedings{Benikova2015GermaNERFO,\n",
       "   title={GermaNER: Free Open German Named Entity Recognition Tool},\n",
       "   author={Darina Benikova and S. Yimam and Prabhakaran Santhanam and Chris Biemann},\n",
       "   booktitle={GSCL},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['de'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'GermaNER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 723\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: germeval_14\n",
       " \tsha: 001f29ecdaeefaa549cdb2193bb21290966daa43\n",
       " \tlastModified: 2022-05-04T18:34:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The GermEval 2014 NER Shared Task builds on a new dataset with German Named Entity annotation with the following properties:    - The data was sampled from German Wikipedia and News Corpora as a collection of citations.    - The dataset covers over 31,000 sentences corresponding to over 590,000 tokens.    - The NER annotation uses the NoSta-D guidelines, which extend the Tübingen Treebank guidelines,      using four main NER categories with sub-structure, and annotating embeddings among NEs      such as [ORG FC Kickers [LOC Darmstadt]].\n",
       " \tcitation: @inproceedings{benikova-etal-2014-nosta,\n",
       "     title = {NoSta-D Named Entity Annotation for German: Guidelines and Dataset},\n",
       "     author = {Benikova, Darina  and\n",
       "       Biemann, Chris  and\n",
       "       Reznicek, Marc},\n",
       "     booktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)},\n",
       "     month = {may},\n",
       "     year = {2014},\n",
       "     address = {Reykjavik, Iceland},\n",
       "     publisher = {European Language Resources Association (ELRA)},\n",
       "     url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/276_Paper.pdf},\n",
       "     pages = {2524--2531},\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': None, 'pretty_name': 'GermEval14'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2907\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: giga_fren\n",
       " \tsha: 7ddbf2922d579bb0a63db1ade4dfcf9414700327\n",
       " \tlastModified: 2022-08-11T12:57:24.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:fr', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Giga-word corpus for French-English from WMT2010 collected by Chris Callison-Burch\n",
       " 2 languages, total number of files: 452\n",
       " total number of tokens: 1.43G\n",
       " total number of sentence fragments: 47.55M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'fr'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'GigaFren'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gigaword\n",
       " \tsha: 05462d9c218d57941dc4dccce707ce21e48221f0\n",
       " \tlastModified: 2022-07-01T11:52:06.000Z\n",
       " \ttags: ['arxiv:1509.00685', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|gigaword_2003', 'task_categories:summarization', 'task_ids:summarization--other-headline-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Headline-generation on a corpus of article pairs from Gigaword consisting of\n",
       " around 4 million articles. Use the 'org_data' provided by\n",
       " https://github.com/microsoft/unilm/ which is identical to\n",
       " https://github.com/harvardnlp/sent-summary but with better format.\n",
       " \n",
       " There are two features:\n",
       "   - document: article.\n",
       "   - summary: headline.\n",
       " \tcitation: @article{graff2003english,\n",
       "   title={English gigaword},\n",
       "   author={Graff, David and Kong, Junbo and Chen, Ke and Maeda, Kazuaki},\n",
       "   journal={Linguistic Data Consortium, Philadelphia},\n",
       "   volume={4},\n",
       "   number={1},\n",
       "   pages={34},\n",
       "   year={2003}\n",
       " }\n",
       " \n",
       " @article{Rush_2015,\n",
       "    title={A Neural Attention Model for Abstractive Sentence Summarization},\n",
       "    url={http://dx.doi.org/10.18653/v1/D15-1044},\n",
       "    DOI={10.18653/v1/d15-1044},\n",
       "    journal={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},\n",
       "    publisher={Association for Computational Linguistics},\n",
       "    author={Rush, Alexander M. and Chopra, Sumit and Weston, Jason},\n",
       "    year={2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|gigaword_2003'], 'task_categories': ['summarization'], 'task_ids': ['summarization--other-headline-generation'], 'paperswithcode_id': None, 'pretty_name': 'Gigaword', 'train-eval-index': [{'config': 'default', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'document': 'text', 'summary': 'target'}, 'metrics': [{'type': 'rouge', 'name': 'Rouge'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 32561\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: glucose\n",
       " \tsha: 541686f203f5b25e2b6ece22af726f37ee10ca7b\n",
       " \tlastModified: 2022-07-01T11:52:07.000Z\n",
       " \ttags: ['arxiv:2009.07758', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-ROC-stories', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-generation-other-common-sense-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context.\n",
       " \tcitation: @inproceedings{mostafazadeh2020glucose,\n",
       "       title={GLUCOSE: GeneraLized and COntextualized Story Explanations},\n",
       "       author={Nasrin Mostafazadeh and Aditya Kalyanpur and Lori Moon and David Buchanan and Lauren Berkowitz and Or Biran and Jennifer Chu-Carroll},\n",
       "       year={2020},\n",
       "       booktitle={The Conference on Empirical Methods in Natural Language Processing},\n",
       "       publisher={Association for Computational Linguistics}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-ROC-stories'], 'task_categories': ['text-generation', 'fill-mask', 'text-generation', 'fill-mask', 'text-generation-other-common-sense-inference'], 'paperswithcode_id': 'glucose', 'pretty_name': 'GLUCOSE'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: glucose\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: glue\n",
       " \tsha: 7a85b2534f8aeeea6dd6603650451e78e89818d3\n",
       " \tlastModified: 2022-08-29T14:51:45.000Z\n",
       " \ttags: ['annotations_creators:other', 'language_creators:other', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:acceptability-classification', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-coreference-nli', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text-classification-other-qa-nli', 'task_ids:text-scoring', 'configs:ax', 'configs:cola', 'configs:mnli', 'configs:mnli_matched', 'configs:mnli_mismatched', 'configs:mrpc', 'configs:qnli', 'configs:qqp', 'configs:rte', 'configs:sst2', 'configs:stsb', 'configs:wnli']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: GLUE, the General Language Understanding Evaluation benchmark\n",
       " (https://gluebenchmark.com/) is a collection of resources for training,\n",
       " evaluating, and analyzing natural language understanding systems.\n",
       " \tcitation: @inproceedings{wang2019glue,\n",
       "   title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
       "   author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
       "   note={In the Proceedings of ICLR.},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['other'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['acceptability-classification', 'natural-language-inference', 'semantic-similarity-scoring', 'sentiment-classification', 'text-classification-other-coreference-nli', 'text-classification-other-paraphrase-identification', 'text-classification-other-qa-nli', 'text-scoring'], 'paperswithcode_id': 'glue', 'pretty_name': 'GLUE (General Language Understanding Evaluation benchmark)', 'train-eval-index': [{'config': 'cola', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence': 'text', 'label': 'target'}}, {'config': 'sst2', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence': 'text', 'label': 'target'}}, {'config': 'mrpc', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence1': 'text1', 'sentence2': 'text2', 'label': 'target'}}, {'config': 'qqp', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'question1': 'text1', 'question2': 'text2', 'label': 'target'}}, {'config': 'stsb', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence1': 'text1', 'sentence2': 'text2', 'label': 'target'}}, {'config': 'mnli', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation_matched'}, 'col_mapping': {'premise': 'text1', 'hypothesis': 'text2', 'label': 'target'}}, {'config': 'mnli_mismatched', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'premise': 'text1', 'hypothesis': 'text2', 'label': 'target'}}, {'config': 'mnli_matched', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'premise': 'text1', 'hypothesis': 'text2', 'label': 'target'}}, {'config': 'qnli', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'question': 'text1', 'sentence': 'text2', 'label': 'target'}}, {'config': 'rte', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence1': 'text1', 'sentence2': 'text2', 'label': 'target'}}, {'config': 'wnli', 'task': 'text-classification', 'task_id': 'natural_language_inference', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'sentence1': 'text1', 'sentence2': 'text2', 'label': 'target'}}], 'configs': ['ax', 'cola', 'mnli', 'mnli_matched', 'mnli_mismatched', 'mrpc', 'qnli', 'qqp', 'rte', 'sst2', 'stsb', 'wnli']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1172660\n",
       " \tlikes: 61\n",
       " \tpaperswithcode_id: glue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gnad10\n",
       " \tsha: 1e00d94bcb10c72a47dbdc235af3a960ab8cf236\n",
       " \tlastModified: 2022-08-24T04:09:32.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:de', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-from-One-Million-Posts-Corpus', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is intended to advance topic classification for German texts. A classifier that is efffective in\n",
       " English may not be effective in German dataset because it has a higher inflection and longer compound words.\n",
       " The 10kGNAD dataset contains 10273 German news articles from an Austrian online newspaper categorized into\n",
       " 9 categories. Article titles and text are concatenated together and authors are removed to avoid a keyword-like\n",
       " classification on authors that write frequently about one category. This dataset can be used as a benchmark\n",
       " for German topic classification.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['de'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-from-One-Million-Posts-Corpus'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': '10k German News Articles Datasets'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 523\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: go_emotions\n",
       " \tsha: 7ddd347fe2392f4220ad8141517d0eba746badd6\n",
       " \tlastModified: 2022-07-01T11:52:09.000Z\n",
       " \ttags: ['arxiv:2005.00547', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-emotion', 'configs:raw', 'configs:simplified']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\n",
       " The emotion categories are admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire,\n",
       " disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness,\n",
       " optimism, pride, realization, relief, remorse, sadness, surprise.\n",
       " \tcitation: @inproceedings{demszky2020goemotions,\n",
       "  author = {Demszky, Dorottya and Movshovitz-Attias, Dana and Ko, Jeongwoo and Cowen, Alan and Nemade, Gaurav and Ravi, Sujith},\n",
       "  booktitle = {58th Annual Meeting of the Association for Computational Linguistics (ACL)},\n",
       "  title = {{GoEmotions: A Dataset of Fine-Grained Emotions}},\n",
       "  year = {2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'multi-label-classification', 'text-classification-other-emotion'], 'paperswithcode_id': 'goemotions', 'pretty_name': 'GoEmotions', 'configs': ['raw', 'simplified']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4107\n",
       " \tlikes: 21\n",
       " \tpaperswithcode_id: goemotions\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gooaq\n",
       " \tsha: 16d12276dc14375744637ae570b379caf1d0aabe\n",
       " \tlastModified: 2022-07-01T11:52:10.000Z\n",
       " \ttags: ['arxiv:2104.08727', 'annotations_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: GooAQ is a large-scale dataset with a variety of answer types. This dataset contains over\n",
       " 5 million questions and 3 million answers collected from Google. GooAQ questions are collected\n",
       " semi-automatically from the Google search engine using its autocomplete feature. This results in\n",
       " naturalistic questions of practical interest that are nonetheless short and expressed using simple\n",
       " language. GooAQ answers are mined from Google's responses to our collected questions, specifically from\n",
       " the answer boxes in the search results. This yields a rich space of answer types, containing both\n",
       " textual answers (short and long) as well as more structured ones such as collections.\n",
       " \tcitation: @article{gooaq2021,\n",
       "   title={GooAQ: Open Question Answering with Diverse Answer Types},\n",
       "   author={Khashabi, Daniel and Ng, Amos and Khot, Tushar and Sabharwal, Ashish and Hajishirzi, Hannaneh and Callison-Burch, Chris},\n",
       "   journal={arXiv preprint},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'gooaq', 'pretty_name': 'GooAQ: Open Question Answering with Diverse Answer Types'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 349\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: gooaq\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: google_wellformed_query\n",
       " \tsha: 991a23e9eeaa059b6bcb68f75c532f45f638de93\n",
       " \tlastModified: 2022-07-01T11:52:10.000Z\n",
       " \ttags: ['arxiv:1808.09419', 'task_categories:text-classification', 'multilinguality:monolingual', 'task_ids:text-scoring', 'language:en', 'annotations_creators:crowdsourced', 'source_datasets:extended', 'size_categories:10K<n<100K', 'license:cc-by-sa-4.0', 'language_creators:found']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Google's query wellformedness dataset was created by crowdsourcing well-formedness annotations for 25,100 queries from the Paralex corpus. Every query was annotated by five raters each with 1/0 rating of whether or not the query is well-formed.\n",
       " \tcitation: @misc{faruqui2018identifying,\n",
       "       title={Identifying Well-formed Natural Language Questions},\n",
       "       author={Manaal Faruqui and Dipanjan Das},\n",
       "       year={2018},\n",
       "       eprint={1808.09419},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'task_categories': ['text-classification'], 'multilinguality': ['monolingual'], 'task_ids': ['text-scoring'], 'language': ['en'], 'annotations_creators': ['crowdsourced'], 'source_datasets': ['extended'], 'size_categories': ['10K<n<100K'], 'license': ['cc-by-sa-4.0'], 'paperswithcode_id': None, 'pretty_name': 'GoogleWellformedQuery', 'language_creators': ['found']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 838\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: grail_qa\n",
       " \tsha: 04917be97e12903732487a143ed3627379f2d88c\n",
       " \tlastModified: 2022-07-01T11:52:11.000Z\n",
       " \ttags: ['arxiv:2011.07743', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-knowledge-base-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Strongly Generalizable Question Answering (GrailQA) is a new large-scale, high-quality dataset for question answering on knowledge bases (KBQA) on Freebase with 64,331 questions annotated with both answers and corresponding logical forms in different syntax (i.e., SPARQL, S-expression, etc.). It can be used to test three levels of generalization in KBQA: i.i.d., compositional, and zero-shot.\n",
       " \tcitation: @misc{gu2020iid,\n",
       "     title={Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases},\n",
       "     author={Yu Gu and Sue Kase and Michelle Vanni and Brian Sadler and Percy Liang and Xifeng Yan and Yu Su},\n",
       "     year={2020},\n",
       "     eprint={2011.07743},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-knowledge-base-qa'], 'paperswithcode_id': None, 'pretty_name': 'Grail QA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: great_code\n",
       " \tsha: c750f3db8969572bd073feaf08359c0d9865b379\n",
       " \tlastModified: 2022-07-01T11:52:11.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:table-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset for the variable-misuse task, described in the ICLR 2020 paper 'Global Relational Models of Source Code' [https://openreview.net/forum?id=B1lnbRNtwr]\n",
       " \n",
       " This is the public version of the dataset used in that paper. The original, used to produce the graphs in the paper, could not be open-sourced due to licensing issues. See the public associated code repository [https://github.com/VHellendoorn/ICLR20-Great] for results produced from this dataset.\n",
       " \n",
       " This dataset was generated synthetically from the corpus of Python code in the ETH Py150 Open dataset [https://github.com/google-research-datasets/eth_py150_open].\n",
       " \tcitation: @inproceedings{DBLP:conf/iclr/HellendoornSSMB20,\n",
       "   author    = {Vincent J. Hellendoorn and\n",
       "                Charles Sutton and\n",
       "                Rishabh Singh and\n",
       "                Petros Maniatis and\n",
       "                David Bieber},\n",
       "   title     = {Global Relational Models of Source Code},\n",
       "   booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,\n",
       "                Addis Ababa, Ethiopia, April 26-30, 2020},\n",
       "   publisher = {OpenReview.net},\n",
       "   year      = {2020},\n",
       "   url       = {https://openreview.net/forum?id=B1lnbRNtwr},\n",
       "   timestamp = {Thu, 07 May 2020 17:11:47 +0200},\n",
       "   biburl    = {https://dblp.org/rec/conf/iclr/HellendoornSSMB20.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['table-to-text'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'GREAT'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 535\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: greek_legal_code\n",
       " \tsha: 82380de18be5975640085d3e4b95b5d03a195b59\n",
       " \tlastModified: 2022-07-01T11:52:13.000Z\n",
       " \ttags: ['arxiv:2109.15298', 'annotations_creators:found', 'language_creators:found', 'language:el', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Greek_Legal_Code contains 47k classified legal resources from Greek Legislation. Its origin is “Permanent Greek Legislation Code - Raptarchis”,\n",
       " a collection of Greek legislative documents classified into multi-level (from broader to more specialized) categories.\n",
       " \tcitation: @inproceedings{papaloukas-etal-2021-glc,\n",
       "     title = \"Multi-granular Legal Topic Classification on Greek Legislation\",\n",
       "     author = \"Papaloukas, Christos and Chalkidis, Ilias and Athinaios, Konstantinos and Pantazi, Despina-Athanasia and Koubarakis, Manolis\",\n",
       "     booktitle = \"Proceedings of the 3rd Natural Legal Language Processing (NLLP) Workshop\",\n",
       "     year = \"2021\",\n",
       "     address = \"Punta Cana, Dominican Republic\",\n",
       "     publisher = \"\",\n",
       "     url = \"\",\n",
       "     doi = \"\",\n",
       "     pages = \"\"\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Greek Legal Code', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['el'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'topic-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1469\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: guardian_authorship\n",
       " \tsha: 99a2f49b30e4e122181db45d6ae110f1c327b41a\n",
       " \tlastModified: 2022-08-29T16:13:39.000Z\n",
       " \ttags: ['annotations_creators:found', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset cross-topic authorship attribution. The dataset is provided by Stamatatos 2013.\n",
       " 1- The cross-topic scenarios are based on Table-4 in Stamatatos 2017 (Ex. cross_topic_1 => row 1:P S U&W ).\n",
       " 2- The cross-genre scenarios are based on Table-5 in the same paper. (Ex. cross_genre_1 => row 1:B P S&U&W).\n",
       " \n",
       " 3- The same-topic/genre scenario is created by grouping all the datasts as follows.\n",
       " For ex., to use same_topic and split the data 60-40 use:\n",
       " train_ds = load_dataset('guardian_authorship', name=\"cross_topic_<<#>>\",\n",
       "                         split='train[:60%]+validation[:60%]+test[:60%]')\n",
       " tests_ds = load_dataset('guardian_authorship', name=\"cross_topic_<<#>>\",\n",
       "                         split='train[-40%:]+validation[-40%:]+test[-40%:]')\n",
       " \n",
       " IMPORTANT: train+validation+test[:60%] will generate the wrong splits because the data is imbalanced\n",
       " \n",
       " * See https://huggingface.co/docs/datasets/splits.html for detailed/more examples\n",
       " \tcitation: @article{article,\n",
       "     author = {Stamatatos, Efstathios},\n",
       "     year = {2013},\n",
       "     month = {01},\n",
       "     pages = {421-439},\n",
       "     title = {On the robustness of authorship attribution based on character n-gram features},\n",
       "     volume = {21},\n",
       "     journal = {Journal of Law and Policy}\n",
       " }\n",
       " \n",
       " @inproceedings{stamatatos2017authorship,\n",
       "     title={Authorship attribution using text distortion},\n",
       "     author={Stamatatos, Efstathios},\n",
       "     booktitle={Proc. of the 15th Conf. of the European Chapter of the Association for Computational Linguistics},\n",
       "     volume={1}\n",
       "     pages={1138--1149},\n",
       "     year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'GuardianAuthorship', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'topic-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4245\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: gutenberg_time\n",
       " \tsha: 75c426ff31585101556bebd1d1e114bf081eb047\n",
       " \tlastModified: 2022-07-01T11:52:13.000Z\n",
       " \ttags: ['arxiv:2011.04124', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A clean data resource containing all explicit time references in a dataset of 52,183 novels whose full text is available via Project Gutenberg.\n",
       " \tcitation: @misc{kim2020time,\n",
       "       title={What time is it? Temporal Analysis of Novels},\n",
       "       author={Allen Kim and Charuta Pethe and Steven Skiena},\n",
       "       year={2020},\n",
       "       eprint={2011.04124},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'gutenberg-time-dataset', 'pretty_name': 'the Gutenberg Time dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1311\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: gutenberg-time-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hans\n",
       " \tsha: 315e3d8540f056f80a228520e0de400837b5dc8b\n",
       " \tlastModified: 2022-07-01T11:52:15.000Z\n",
       " \ttags: ['arxiv:1902.01007', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The HANS dataset is an NLI evaluation set that tests specific hypotheses about invalid heuristics that NLI models are likely to learn.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1902-01007,\n",
       "   author    = {R. Thomas McCoy and\n",
       "                Ellie Pavlick and\n",
       "                Tal Linzen},\n",
       "   title     = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\n",
       "                Language Inference},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1902.01007},\n",
       "   year      = {2019},\n",
       "   url       = {http://arxiv.org/abs/1902.01007},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1902.01007},\n",
       "   timestamp = {Tue, 21 May 2019 18:03:36 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-1902-01007.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'hans', 'pretty_name': 'Heuristic Analysis for NLI Systems'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2544\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: hans\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hansards\n",
       " \tsha: 96d31b951d70cfa36b3ae315583cd1a4dc4283b0\n",
       " \tlastModified: 2022-05-04T18:34:24.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This release contains 1.3 million pairs of aligned text chunks (sentences or smaller fragments)\n",
       " from the official records (Hansards) of the 36th Canadian Parliament.\n",
       " \n",
       " The complete Hansards of the debates in the House and Senate of the 36th Canadian Parliament,\n",
       " as far as available, were aligned. The corpus was then split into 5 sets of sentence pairs:\n",
       " training (80% of the sentence pairs), two sets of sentence pairs for testing (5% each), and\n",
       " two sets of sentence pairs for final evaluation (5% each). The current release consists of the\n",
       " training and testing sets. The evaluation sets are reserved for future MT evaluation purposes\n",
       " and currently not available.\n",
       " \n",
       " Caveats\n",
       " 1. This release contains only sentence pairs. Even though the order of the sentences is the same\n",
       " as in the original, there may be gaps resulting from many-to-one, many-to-many, or one-to-many\n",
       " alignments that were filtered out. Therefore, this release may not be suitable for\n",
       " discourse-related research.\n",
       " 2. Neither the sentence splitting nor the alignments are perfect. In particular, watch out for\n",
       " pairs that differ considerably in length. You may want to filter these out before you do\n",
       " any statistical training.\n",
       " \n",
       " The alignment of the Hansards was performed as part of the ReWrite project under funding\n",
       " from the DARPA TIDES program.\n",
       " \tcitation: \n",
       " \tcardData: {'paperswithcode_id': None, 'pretty_name': 'hansards'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 480\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hard\n",
       " \tsha: 05ea5951c855cc2a7f354986f1a99c5643685ea6\n",
       " \tlastModified: 2022-07-01T11:52:15.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains 93700 hotel reviews in Arabic language.The hotel reviews were collected from Booking.com website during June/July 2016.The reviews are expressed in Modern Standard Arabic as well as dialectal Arabic.The following table summarize some tatistics on the HARD Dataset.\n",
       " \tcitation: @incollection{elnagar2018hotel,\n",
       "   title={Hotel Arabic-reviews dataset construction for sentiment analysis applications},\n",
       "   author={Elnagar, Ashraf and Khalifa, Yasmin S and Einea, Anas},\n",
       "   booktitle={Intelligent Natural Language Processing: Trends and Applications},\n",
       "   pages={35--52},\n",
       "   year={2018},\n",
       "   publisher={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'hard', 'pretty_name': 'Hotel Arabic-Reviews Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: hard\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: harem\n",
       " \tsha: 2cdc6bcbc57e846d876a0f2fca97f9ea995fe0a4\n",
       " \tlastModified: 2022-07-01T11:52:16.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The HAREM is a Portuguese language corpus commonly used for Named Entity Recognition tasks. It includes about 93k words, from 129 different texts,\n",
       " from several genres, and language varieties. The split of this dataset version follows the division made by [1], where 7% HAREM\n",
       " documents are the validation set and the miniHAREM corpus (with about 65k words) is the test set. There are two versions of the dataset set,\n",
       " a version that has a total of 10 different named entity classes (Person, Organization, Location, Value, Date, Title, Thing, Event,\n",
       " Abstraction, and Other) and a \"selective\" version with only 5 classes (Person, Organization, Location, Value, and Date).\n",
       " \n",
       " It's important to note that the original version of the HAREM dataset has 2 levels of NER details, namely \"Category\" and \"Sub-type\".\n",
       " The dataset version processed here ONLY USE the \"Category\" level of the original dataset.\n",
       " \n",
       " [1] Souza, Fábio, Rodrigo Nogueira, and Roberto Lotufo. \"BERTimbau: Pretrained BERT Models for Brazilian Portuguese.\" Brazilian Conference on Intelligent Systems. Springer, Cham, 2020.\n",
       " \tcitation: @inproceedings{santos2006harem,\n",
       "   title={Harem: An advanced ner evaluation contest for portuguese},\n",
       "   author={Santos, Diana and Seco, Nuno and Cardoso, Nuno and Vilela, Rui},\n",
       "   booktitle={quot; In Nicoletta Calzolari; Khalid Choukri; Aldo Gangemi; Bente Maegaard; Joseph Mariani; Jan Odjik; Daniel Tapias (ed) Proceedings of the 5 th International Conference on Language Resources and Evaluation (LREC'2006)(Genoa Italy 22-28 May 2006)},\n",
       "   year={2006}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'HAREM'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 885\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: has_part\n",
       " \tsha: 02216fa3e7684391985fa2c679e9b77d5a22f4e8\n",
       " \tlastModified: 2022-07-01T11:52:16.000Z\n",
       " \ttags: ['arxiv:2006.07510', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-Generics-KB', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-Meronym-Prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is a new knowledge-base (KB) of hasPart relationships, extracted from a large corpus of generic statements. Complementary to other resources available, it is the first which is all three of: accurate (90% precision), salient (covers relationships a person may mention), and has high coverage of common terms (approximated as within a 10 year old’s vocabulary), as well as having several times more hasPart entries than in the popular ontologies ConceptNet and WordNet. In addition, it contains information about quantifiers, argument modifiers, and links the entities to appropriate concepts in Wikipedia and WordNet.\n",
       " \tcitation: @misc{bhakthavatsalam2020dogs,\n",
       "       title={Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations},\n",
       "       author={Sumithra Bhakthavatsalam and Kyle Richardson and Niket Tandon and Peter Clark},\n",
       "       year={2020},\n",
       "       eprint={2006.07510},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-Generics-KB'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-Meronym-Prediction'], 'paperswithcode_id': 'haspart-kb', 'pretty_name': 'hasPart KB'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: haspart-kb\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_offensive\n",
       " \tsha: 81aaa02a16dd6306375f6cd90a57fb64ca68ebe3\n",
       " \tlastModified: 2022-07-01T11:52:17.000Z\n",
       " \ttags: ['arxiv:1905.12516', 'annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @article{article,\n",
       " author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},\n",
       " year = {2017},\n",
       " month = {03},\n",
       " pages = {},\n",
       " title = {Automated Hate Speech Detection and the Problem of Offensive Language}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'text-classification-other-hate-speech-detection'], 'paperswithcode_id': 'hate-speech-and-offensive-language', 'pretty_name': 'HateOffensive'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 349\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: hate-speech-and-offensive-language\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_speech18\n",
       " \tsha: 4374894e22821f5f3ebeb8de6215339ba56883a0\n",
       " \tlastModified: 2022-07-01T11:52:17.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: These files contain text extracted from Stormfront, a white supremacist forum. A random set of\n",
       " forums posts have been sampled from several subforums and split into sentences. Those sentences\n",
       " have been manually labelled as containing hate speech or not, according to certain annotation guidelines.\n",
       " \tcitation: @inproceedings{gibert2018hate,\n",
       "     title = \"{Hate Speech Dataset from a White Supremacy Forum}\",\n",
       "     author = \"de Gibert, Ona  and\n",
       "       Perez, Naiara  and\n",
       "       Garcia-Pablos, Aitor  and\n",
       "       Cuadros, Montse\",\n",
       "     booktitle = \"Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2)\",\n",
       "     month = oct,\n",
       "     year = \"2018\",\n",
       "     address = \"Brussels, Belgium\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/W18-5102\",\n",
       "     doi = \"10.18653/v1/W18-5102\",\n",
       "     pages = \"11--20\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': 'hate-speech', 'pretty_name': 'Hate Speech', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6677\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: hate-speech\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_speech_filipino\n",
       " \tsha: cfe20069d8c409e4288a581e91f96890cf430d65\n",
       " \tlastModified: 2022-07-01T11:52:18.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:tl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-twitter-data-philippine-election', 'task_categories:text-classification', 'task_ids:sentiment-analysis']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     Contains 10k tweets (training set) that are labeled as hate speech or non-hate speech. Released with 4,232 validation and 4,232 testing samples. Collected during the 2016 Philippine Presidential Elections.\n",
       " \tcitation: @article{Cabasag-2019-hate-speech,\n",
       "   title={Hate speech in Philippine election-related tweets: Automatic detection and classification using natural language processing.},\n",
       "   author={Neil Vicente Cabasag, Vicente Raphael Chan, Sean Christian Lim, Mark Edward Gonzales, and Charibeth Cheng},\n",
       "   journal={Philippine Computing Journal},\n",
       "   volume={XIV},\n",
       "   number={1},\n",
       "   month={August},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['tl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-twitter-data-philippine-election'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-analysis'], 'paperswithcode_id': None, 'pretty_name': 'Hate Speech in Filipino'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 341\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_speech_offensive\n",
       " \tsha: 9c2c7270ac5f8b58c8d241b9fd7c10aa45f32762\n",
       " \tlastModified: 2022-07-01T11:52:18.000Z\n",
       " \ttags: ['arxiv:1703.04009', 'annotations_creators:expert-generated', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An annotated dataset for hate speech and offensive language detection on tweets.\n",
       " \tcitation: @inproceedings{hateoffensive,\n",
       " title = {Automated Hate Speech Detection and the Problem of Offensive Language},\n",
       " author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},\n",
       " booktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media},\n",
       " series = {ICWSM '17},\n",
       " year = {2017},\n",
       " location = {Montreal, Canada},\n",
       " pages = {512-515}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-detection'], 'paperswithcode_id': 'hate-speech-and-offensive-language', 'pretty_name': 'Hate Speech and Offensive Language', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train'}, 'col_mapping': {'tweet': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6857\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: hate-speech-and-offensive-language\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_speech_pl\n",
       " \tsha: 437c555ee9507cee511e71a35795a1ed3dbb8ac6\n",
       " \tlastModified: 2022-07-01T12:43:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pl', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HateSpeech corpus in the current version contains over 2000 posts crawled from public Polish web. They represent various types and degrees of offensive language, expressed toward minorities (eg. ethnical, racial). The data were annotated manually.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pl'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'multi-class-classification', 'multi-label-classification', 'sentiment-classification', 'sentiment-scoring', 'topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'HateSpeechPl'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hate_speech_portuguese\n",
       " \tsha: af8cbbbf54c37c30e68d93f0b0643c4676f8fb9f\n",
       " \tlastModified: 2022-07-01T11:52:20.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Portuguese dataset for hate speech detection composed of 5,668 tweets with binary annotations (i.e. 'hate' vs. 'no-hate').\n",
       " \tcitation: @inproceedings{fortuna-etal-2019-hierarchically,\n",
       " title = \"A Hierarchically-Labeled {P}ortuguese Hate Speech Dataset\",\n",
       " author = \"Fortuna, Paula  and\n",
       "     Rocha da Silva, Jo{\\\\~a}o  and\n",
       "     Soler-Company, Juan  and\n",
       "     Wanner, Leo  and\n",
       "     Nunes, S{\\'e}rgio\",\n",
       " booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\n",
       " month = aug,\n",
       " year = \"2019\",\n",
       " address = \"Florence, Italy\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " url = \"https://www.aclweb.org/anthology/W19-3510\",\n",
       " doi = \"10.18653/v1/W19-3510\",\n",
       " pages = \"94--104\",\n",
       " abstract = \"Over the past years, the amount of online offensive speech has been growing steadily. To successfully cope with it, machine learning are applied. However, ML-based techniques require sufficiently large annotated datasets. In the last years, different datasets were published, mainly for English. In this paper, we present a new dataset for Portuguese, which has not been in focus so far. The dataset is composed of 5,668 tweets. For its annotation, we defined two different schemes used by annotators with different levels of expertise. Firstly, non-experts annotated the tweets with binary labels ({`}hate{'} vs. {`}no-hate{'}). Secondly, expert annotators classified the tweets following a fine-grained hierarchical multiple label scheme with 81 hate speech categories in total. The inter-annotator agreement varied from category to category, which reflects the insight that some types of hate speech are more subtle than others and that their detection depends on personal perception. This hierarchical annotation scheme is the main contribution of the presented work, as it facilitates the identification of different types of hate speech and their intersections. To demonstrate the usefulness of our dataset, we carried a baseline classification experiment with pre-trained word embeddings and LSTM on the binary classified data, with a state-of-the-art outcome.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-detection'], 'paperswithcode_id': None, 'pretty_name': 'HateSpeechPortuguese'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hatexplain\n",
       " \tsha: 26ea2bad50b2e9407901670b85e0e101c69824d0\n",
       " \tlastModified: 2022-07-01T11:52:21.000Z\n",
       " \ttags: ['arxiv:2012.10289', 'arxiv:1703.04009', 'arxiv:1908.11049', 'arxiv:1812.01693', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Hatexplain is the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in the dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based.\n",
       " \tcitation: @misc{mathew2020hatexplain,\n",
       "       title={HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection},\n",
       "       author={Binny Mathew and Punyajoy Saha and Seid Muhie Yimam and Chris Biemann and Pawan Goyal and Animesh Mukherjee},\n",
       "       year={2020},\n",
       "       eprint={2012.10289},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-detection'], 'paperswithcode_id': 'hatexplain', 'pretty_name': 'hatexplain'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 720\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: hatexplain\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hausa_voa_ner\n",
       " \tsha: 040d9c310578b2c245362a451ea393f19dbaf508\n",
       " \tlastModified: 2022-07-01T11:52:21.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ha', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Hausa VOA NER dataset is a labeled dataset for named entity recognition in Hausa. The texts were obtained from\n",
       " Hausa Voice of America News articles https://www.voahausa.com/ . We concentrate on\n",
       " four types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n",
       " \n",
       " The Hausa VOA NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\n",
       " there is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\n",
       " is the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\n",
       " of type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\n",
       " have tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n",
       " \n",
       " For more details, see https://www.aclweb.org/anthology/2020.emnlp-main.204/\n",
       " \tcitation: @inproceedings{hedderich-etal-2020-transfer,\n",
       "     title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on {A}frican Languages\",\n",
       "     author = \"Hedderich, Michael A.  and\n",
       "       Adelani, David  and\n",
       "       Zhu, Dawei  and\n",
       "       Alabi, Jesujoba  and\n",
       "       Markus, Udia  and\n",
       "       Klakow, Dietrich\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n",
       "     doi = \"10.18653/v1/2020.emnlp-main.204\",\n",
       "     pages = \"2580--2591\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ha'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Hausa VOA NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hausa_voa_topics\n",
       " \tsha: ecb5aac27c7610fb2a5e6dbff0a22edd8b1dd1fe\n",
       " \tlastModified: 2022-07-01T11:52:22.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:ha', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of news article headlines in Hausa from VOA Hausa.\n",
       " Each headline is labeled with one of the following classes: Nigeria,\n",
       " Africa, World, Health or Politics.\n",
       " \n",
       " The dataset was presented in the paper:\n",
       " Hedderich, Adelani, Zhu, Alabi, Markus, Klakow: Transfer Learning and\n",
       " Distant Supervision for Multilingual Transformer Models: A Study on\n",
       " African Languages (EMNLP 2020).\n",
       " \tcitation: @inproceedings{hedderich-etal-2020-transfer,\n",
       "     title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages\",\n",
       "     author = \"Hedderich, Michael A.  and\n",
       "       Adelani, David  and\n",
       "       Zhu, Dawei  and\n",
       "       Alabi, Jesujoba  and\n",
       "       Markus, Udia  and\n",
       "       Klakow, Dietrich\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n",
       "     doi = \"10.18653/v1/2020.emnlp-main.204\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ha'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'Hausa Voa News Topic Classification Dataset (HausaVoaTopics)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hda_nli_hindi\n",
       " \tsha: 83269abc846f624e61128271fdd3fa3a8d0ede9e\n",
       " \tlastModified: 2022-07-01T11:52:22.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:hi', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|hindi_discourse', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is a recasted version of the Hindi Discourse Analysis Dataset used to train models for Natural Language Inference Tasks in Low-Resource Languages like Hindi.\n",
       " \tcitation:     @inproceedings{uppal-etal-2020-two,\n",
       "     title = \"Two-Step Classification using Recasted Data for Low Resource Settings\",\n",
       "     author = \"Uppal, Shagun  and\n",
       "       Gupta, Vivek  and\n",
       "       Swaminathan, Avinash  and\n",
       "       Zhang, Haimin  and\n",
       "       Mahata, Debanjan  and\n",
       "       Gosangi, Rakesh  and\n",
       "       Shah, Rajiv Ratn  and\n",
       "       Stent, Amanda\",\n",
       "     booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\",\n",
       "     month = dec,\n",
       "     year = \"2020\",\n",
       "     address = \"Suzhou, China\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.aacl-main.71\",\n",
       "     pages = \"706--719\",\n",
       "     abstract = \"An NLP model{'}s ability to reason should be independent of language. Previous works utilize Natural Language Inference (NLI) to understand the reasoning ability of models, mostly focusing on high resource languages like English. To address scarcity of data in low-resource languages such as Hindi, we use data recasting to create NLI datasets for four existing text classification datasets. Through experiments, we show that our recasted dataset is devoid of statistical irregularities and spurious patterns. We further study the consistency in predictions of the textual entailment models and propose a consistency regulariser to remove pairwise-inconsistencies in predictions. We propose a novel two-step classification method which uses textual-entailment predictions for classification task. We further improve the performance by using a joint-objective for classification and textual entailment. We therefore highlight the benefits of data recasting and improvements on classification performance using our approach with supporting experimental results.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['hi'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|hindi_discourse'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': None, 'pretty_name': 'Hindi Discourse Analysis Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: head_qa\n",
       " \tsha: 3f6b2048ca3c6e64603b6457142f28407e7ac8b5\n",
       " \tlastModified: 2022-07-05T15:50:31.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'language:es', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'configs:en', 'configs:es']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HEAD-QA is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the\n",
       " Spanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio\n",
       " de Sanidad, Consumo y Bienestar Social.\n",
       " \n",
       " The dataset contains questions about the following topics: medicine, nursing, psychology, chemistry, pharmacology and biology.\n",
       " \tcitation: @inproceedings{vilares-gomez-rodriguez-2019-head,\n",
       "     title = \"{HEAD}-{QA}: A Healthcare Dataset for Complex Reasoning\",\n",
       "     author = \"Vilares, David  and\n",
       "       G{\\'o}mez-Rodr{\\'i}guez, Carlos\",\n",
       "     booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P19-1092\",\n",
       "     doi = \"10.18653/v1/P19-1092\",\n",
       "     pages = \"960--966\",\n",
       "     abstract = \"We present HEAD-QA, a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. We then consider monolingual (Spanish) and cross-lingual (to English) experiments with information retrieval and neural techniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the results lag well behind human performance, demonstrating its usefulness as a benchmark for future work.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en', 'es'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'headqa', 'pretty_name': 'HEAD-QA', 'configs': ['en', 'es']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5658\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: headqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: health_fact\n",
       " \tsha: c9f941a6f5a1191fbe7036aab6dbe4ae597c1545\n",
       " \tlastModified: 2022-07-01T11:52:27.000Z\n",
       " \ttags: ['arxiv:2010.09926', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of\n",
       " public health claims. Each instance in the PUBHEALTH dataset has an associated\n",
       " veracity label (true, false, unproven, mixture). Furthermore each instance in the\n",
       " dataset has an explanation text field. The explanation is a justification for which\n",
       " the claim has been assigned a particular veracity label.\n",
       " \n",
       " The dataset was created to explore fact-checking of difficult to verify claims i.e.,\n",
       " those which require expertise from outside of the journalistics domain, in this case\n",
       " biomedical and public health expertise.\n",
       " \n",
       " It was also created in response to the lack of fact-checking datasets which provide\n",
       " gold standard natural language explanations for verdicts/labels.\n",
       " \n",
       " NOTE: There are missing labels in the dataset and we have replaced them with -1.\n",
       " \tcitation: @inproceedings{kotonya-toni-2020-explainable,\n",
       "     title = \"Explainable Automated Fact-Checking for Public Health Claims\",\n",
       "     author = \"Kotonya, Neema and Toni, Francesca\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods\n",
       "     in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.623\",\n",
       "     pages = \"7740--7754\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking', 'multi-class-classification'], 'paperswithcode_id': 'pubhealth', 'pretty_name': 'PUBHEALTH', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'claim': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1947\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: pubhealth\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hebrew_projectbenyehuda\n",
       " \tsha: 9973335f8d54a812f0b8774874cf274ed186b3ad\n",
       " \tlastModified: 2022-07-01T11:52:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:he', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This repository contains a dump of thousands of public domain works in Hebrew, from Project Ben-Yehuda, in plaintext UTF-8 files, with and without diacritics (nikkud). The metadata (pseudocatalogue.csv) file is a list of titles, authors, genres, and file paths, to help you process the dump.\n",
       " All these works are in the public domain, so you are free to make any use of them, and do not need to ask for permission.\n",
       " There are 10078 files, 3181136 lines\n",
       " \tcitation: @article{,\n",
       "   author = {},\n",
       "   title = {Public domain texts from Project Ben-Yehuda},\n",
       "   journal = {},\n",
       "   url = {https://github.com/projectbenyehuda/public_domain_dump},\n",
       "   year = {2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['he'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Hebrew Projectbenyehuda'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hebrew_sentiment\n",
       " \tsha: 2611dcd2c8e58433e63d0898987b64aa41a574da\n",
       " \tlastModified: 2022-07-01T11:52:28.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:he', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israel’s\n",
       " president, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder,\n",
       " 2013) to scrape all the comments to all of the president’s posts in the period of June – August 2014,\n",
       " the first three months of Rivlin’s presidency.2 While the president’s posts aimed at reconciling tensions\n",
       " and called for tolerance and empathy, the sentiment expressed in the comments to the president’s posts\n",
       " was polarized between citizens who warmly thanked the president, and citizens that fiercely critiqued his\n",
       " policy. Of the 12,804 comments, 370 are neutral; 8,512 are positive, 3,922 negative.\n",
       " \n",
       " Data Annotation: A trained researcher examined each comment and determined its sentiment value,\n",
       " where comments with an overall positive sentiment were assigned the value 1, comments with an overall\n",
       " negative sentiment were assigned the value -1, and comments that are off-topic to the post’s content\n",
       " were assigned the value 0. We validated the coding scheme by asking a second trained researcher to\n",
       " code the same data. There was substantial agreement between raters (N of agreements: 10623, N of\n",
       " disagreements: 2105, Coehn’s Kappa = 0.697, p = 0).\n",
       " \tcitation: @inproceedings{amram-etal-2018-representations,\n",
       "     title = \"Representations and Architectures in Neural Sentiment Analysis for Morphologically Rich Languages: A Case Study from {M}odern {H}ebrew\",\n",
       "     author = \"Amram, Adam  and\n",
       "       Ben David, Anat  and\n",
       "       Tsarfaty, Reut\",\n",
       "     booktitle = \"Proceedings of the 27th International Conference on Computational Linguistics\",\n",
       "     month = aug,\n",
       "     year = \"2018\",\n",
       "     address = \"Santa Fe, New Mexico, USA\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/C18-1190\",\n",
       "     pages = \"2242--2252\",\n",
       "     abstract = \"This paper empirically studies the effects of representation choices on neural sentiment analysis for Modern Hebrew, a morphologically rich language (MRL) for which no sentiment analyzer currently exists. We study two dimensions of representational choices: (i) the granularity of the input signal (token-based vs. morpheme-based), and (ii) the level of encoding of vocabulary items (string-based vs. character-based). We hypothesise that for MRLs, languages where multiple meaning-bearing elements may be carried by a single space-delimited token, these choices will have measurable effects on task perfromance, and that these effects may vary for different architectural designs {---} fully-connected, convolutional or recurrent. Specifically, we hypothesize that morpheme-based representations will have advantages in terms of their generalization capacity and task accuracy, due to their better OOV coverage. To empirically study these effects, we develop a new sentiment analysis benchmark for Hebrew, based on 12K social media comments, and provide two instances of these data: in token-based and morpheme-based settings. Our experiments show that representation choices empirical effects vary with architecture type. While fully-connected and convolutional networks slightly prefer token-based settings, RNNs benefit from a morpheme-based representation, in accord with the hypothesis that explicit morphological information may help generalize. Our endeavour also delivers the first state-of-the-art broad-coverage sentiment analyzer for Hebrew, with over 89% accuracy, alongside an established benchmark to further study the effects of linguistic representation choices on neural networks{'} task performance.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['he'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'modern-hebrew-sentiment-dataset', 'pretty_name': 'HebrewSentiment'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 597\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: modern-hebrew-sentiment-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hebrew_this_world\n",
       " \tsha: 65386ccdf036b6c640559aed03ac3987aed249dd\n",
       " \tlastModified: 2022-07-01T12:43:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:he', 'license:agpl-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HebrewThisWorld is a data set consists of 2028 issues of the newspaper 'This World' edited by Uri Avnery and were published between 1950 and 1989. Released under the AGPLv3 license.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['he'], 'license': ['agpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'HebrewSentiment'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hellaswag\n",
       " \tsha: bf771f8a6388f5b6046106cbb7781b15fae168c7\n",
       " \tlastModified: 2022-09-23T11:34:06.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HellaSwag: Can a Machine Really Finish Your Sentence? is a new dataset for commonsense NLI. A paper was published at ACL2019.\n",
       " \tcitation: @inproceedings{zellers2019hellaswag,\n",
       "     title={HellaSwag: Can a Machine Really Finish Your Sentence?},\n",
       "     author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},\n",
       "     booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n",
       "     year={2019}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'hellaswag', 'pretty_name': 'HellaSwag'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 67727\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: hellaswag\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hendrycks_test\n",
       " \tsha: b1bdbcba68d4f5c88d91a8f2685124f148fd1fd0\n",
       " \tlastModified: 2022-09-29T12:07:59.000Z\n",
       " \ttags: ['arxiv:2009.03300', 'arxiv:2005.00700', 'arxiv:2005.14165', 'arxiv:2008.02275', 'annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'language_bcp47:en-US', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.\n",
       " \tcitation: @article{hendryckstest2021,\n",
       "       title={Measuring Massive Multitask Language Understanding},\n",
       "       author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n",
       "       journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n",
       "       year={2021}\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'language_bcp47': ['en-US'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'pretty_name': 'HendrycksTest'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 16921\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hind_encorp\n",
       " \tsha: 580b6b4f01af4ca452185f04cd133f1d2b409dcc\n",
       " \tlastModified: 2022-07-01T11:52:31.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'language:hi', 'license:cc-by-nc-sa-3.0', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HindEnCorp parallel texts (sentence-aligned) come from the following sources:\n",
       " Tides, which contains 50K sentence pairs taken mainly from news articles. This dataset was originally col- lected for the DARPA-TIDES surprise-language con- test in 2002, later refined at IIIT Hyderabad and provided for the NLP Tools Contest at ICON 2008 (Venkatapathy, 2008).\n",
       " \n",
       " Commentaries by Daniel Pipes contain 322 articles in English written by a journalist Daniel Pipes and translated into Hindi.\n",
       " \n",
       " EMILLE. This corpus (Baker et al., 2002) consists of three components: monolingual, parallel and annotated corpora. There are fourteen monolingual sub- corpora, including both written and (for some lan- guages) spoken data for fourteen South Asian lan- guages. The EMILLE monolingual corpora contain in total 92,799,000 words (including 2,627,000 words of transcribed spoken data for Bengali, Gujarati, Hindi, Punjabi and Urdu). The parallel corpus consists of 200,000 words of text in English and its accompanying translations into Hindi and other languages.\n",
       " \n",
       " Smaller datasets as collected by Bojar et al. (2010) include the corpus used at ACL 2005 (a subcorpus of EMILLE), a corpus of named entities from Wikipedia (crawled in 2009), and Agriculture domain parallel corpus.\n",
       " ￼\n",
       " For the current release, we are extending the parallel corpus using these sources:\n",
       " Intercorp (Čermák and Rosen,2012) is a large multilingual parallel corpus of 32 languages including Hindi. The central language used for alignment is Czech. Intercorp’s core texts amount to 202 million words. These core texts are most suitable for us because their sentence alignment is manually checked and therefore very reliable. They cover predominately short sto- ries and novels. There are seven Hindi texts in Inter- corp. Unfortunately, only for three of them the English translation is available; the other four are aligned only with Czech texts. The Hindi subcorpus of Intercorp contains 118,000 words in Hindi.\n",
       " \n",
       " TED talks 3 held in various languages, primarily English, are equipped with transcripts and these are translated into 102 languages. There are 179 talks for which Hindi translation is available.\n",
       " \n",
       " The Indic multi-parallel corpus (Birch et al., 2011; Post et al., 2012) is a corpus of texts from Wikipedia translated from the respective Indian language into English by non-expert translators hired over Mechanical Turk. The quality is thus somewhat mixed in many respects starting from typesetting and punctuation over capi- talization, spelling, word choice to sentence structure. A little bit of control could be in principle obtained from the fact that every input sentence was translated 4 times. We used the 2012 release of the corpus.\n",
       " \n",
       " Launchpad.net is a software collaboration platform that hosts many open-source projects and facilitates also collaborative localization of the tools. We downloaded all revisions of all the hosted projects and extracted the localization (.po) files.\n",
       " \n",
       " Other smaller datasets. This time, we added Wikipedia entities as crawled in 2013 (including any morphological variants of the named entitity that appears on the Hindi variant of the Wikipedia page) and words, word examples and quotes from the Shabdkosh online dictionary.\n",
       " \tcitation: @InProceedings{hindencorp05:lrec:2014,\n",
       "   author = {Ond{\\v{r}}ej Bojar and Vojt{\\v{e}}ch Diatka\n",
       "             and Pavel Rychl{\\'{y}} and Pavel Stra{\\v{n}}{\\'{a}}k\n",
       "             and V{\\'{}}t Suchomel and Ale{\\v{s}} Tamchyna and Daniel Zeman},\n",
       "   title = \"{HindEnCorp - Hindi-English and Hindi-only Corpus for Machine\n",
       "             Translation}\",\n",
       "   booktitle = {Proceedings of the Ninth International Conference on Language\n",
       "                Resources and Evaluation (LREC'14)},\n",
       "   year = {2014},\n",
       "   month = {may},\n",
       "   date = {26-31},\n",
       "   address = {Reykjavik, Iceland},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and\n",
       "      Thierry Declerck and Hrafn Loftsson and Bente Maegaard and Joseph Mariani\n",
       "      and Asuncion Moreno and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-8-4},\n",
       "   language = {english}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['en', 'hi'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'hindencorp', 'pretty_name': 'HindEnCorp'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 355\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: hindencorp\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hindi_discourse\n",
       " \tsha: 026f918c4db13bf78523df24b44a5d72a8a6702e\n",
       " \tlastModified: 2022-08-29T16:13:39.000Z\n",
       " \ttags: ['annotations_creators:other', 'language_creators:found', 'language:hi', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-discourse-analysis']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Hindi Discourse Analysis dataset is a corpus for analyzing discourse modes present in its sentences.\n",
       " It contains sentences from stories written by 11 famous authors from the 20th Century.\n",
       " 4-5 stories by each author have been selected which were available in the public domain resulting\n",
       " in a collection of 53 stories. Most of these short stories were originally written in Hindi\n",
       " but some of them were written in other Indian languages and later translated to Hindi.\n",
       " \tcitation: @inproceedings{swapnil2020,\n",
       "     title={An Annotated Dataset of Discourse Modes in Hindi Stories},\n",
       "     author={Swapnil Dhanwal, Hritwik Dutta, Hitesh Nankani, Nilay Shrivastava, Yaman Kumar, Junyi Jessy Li, Debanjan Mahata, Rakesh Gosangi, Haimin Zhang, Rajiv Ratn Shah, Amanda Stent},\n",
       "     booktitle={Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n",
       "     volume={12},\n",
       "     pages={1191–1196},\n",
       "     year={2020}\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['found'], 'language': ['hi'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-discourse-analysis'], 'paperswithcode_id': None, 'pretty_name': 'Discourse Analysis dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hippocorpus\n",
       " \tsha: b8400f74027a9ca84c9e176e739c0857be8cbf33\n",
       " \tlastModified: 2022-07-01T12:43:29.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-narrative-flow']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: To examine the cognitive processes of remembering and imagining and their traces in language, we introduce Hippocorpus, a dataset of 6,854 English diary-like short stories about recalled and imagined events. Using a crowdsourcing framework, we first collect recalled stories and summaries from workers, then provide these summaries to other workers who write imagined stories. Finally, months later, we collect a retold version of the recalled stories from a subset of recalled authors. Our dataset comes paired with author demographics (age, gender, race), their openness to experience, as well as some variables regarding the author's relationship to the event (e.g., how personal the event is, how often they tell its story, etc.).\n",
       " \tcitation: @inproceedings{sap-etal-2020-recollection,\n",
       "     title = \"Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models\",\n",
       "     author = \"Sap, Maarten  and\n",
       "       Horvitz, Eric  and\n",
       "       Choi, Yejin  and\n",
       "       Smith, Noah A.  and\n",
       "       Pennebaker, James\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.178\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.178\",\n",
       "     pages = \"1970--1978\",\n",
       "     abstract = \"We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release Hippocorpus, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932). Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-narrative-flow'], 'paperswithcode_id': None, 'pretty_name': 'hippocorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hkcancor\n",
       " \tsha: 0a69a5595a32876ce7136c9a42145d6182c4826c\n",
       " \tlastModified: 2022-07-01T11:52:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:yue', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Hong Kong Cantonese Corpus (HKCanCor) comprise transcribed conversations\n",
       " recorded between March 1997 and August 1998. It contains recordings of\n",
       " spontaneous speech (51 texts) and radio programmes (42 texts),\n",
       " which involve 2 to 4 speakers, with 1 text of monologue.\n",
       " \n",
       " In total, the corpus contains around 230,000 Chinese words.\n",
       " The text is word-segmented, annotated with part-of-speech (POS) tags and\n",
       " romanised Cantonese pronunciation.\n",
       " \n",
       " Romanisation scheme - Linguistic Society of Hong Kong (LSHK)\n",
       " POS scheme - Peita-Fujitsu-Renmin Ribao (PRF) corpus (Duan et al., 2000),\n",
       "              with extended tags for Cantonese-specific phenomena added by\n",
       "              Luke and Wang (see original paper for details).\n",
       " \tcitation: @article{luke2015hong,\n",
       "   author={Luke, Kang-Kwong and Wong, May LY},\n",
       "   title={The Hong Kong Cantonese corpus: design and uses},\n",
       "   journal={Journal of Chinese Linguistics},\n",
       "   year={2015},\n",
       "   pages={309-330},\n",
       "   month={12}\n",
       " }\n",
       " @misc{lee2020,\n",
       "   author = {Lee, Jackson},\n",
       "   title = {PyCantonese: Cantonese Linguistics and NLP in Python},\n",
       "   year = {2020},\n",
       "   publisher = {GitHub},\n",
       "   journal = {GitHub repository},\n",
       "   howpublished = {https://github.com/jacksonllee/pycantonese},\n",
       "   commit = {1d58f44e1cb097faa69de6b617e1d28903b84b98}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['yue'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'hong-kong-cantonese-corpus', 'pretty_name': 'The Hong Kong Cantonese Corpus (HKCanCor)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: hong-kong-cantonese-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hlgd\n",
       " \tsha: 28c7b0bc2c4604aac48dcde82564c7cbcafec91f\n",
       " \tlastModified: 2022-07-01T11:52:32.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-headline-grouping', 'size_categories:10K<n<100K']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HLGD is a binary classification dataset consisting of 20,056 labeled news headlines pairs indicating\n",
       " whether the two headlines describe the same underlying world event or not.\n",
       " \tcitation: @inproceedings{Laban2021NewsHG,\n",
       "   title={News Headline Grouping as a Challenging NLU Task},\n",
       "   author={Philippe Laban and Lucas Bandarkar},\n",
       "   booktitle={NAACL 2021},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-headline-grouping'], 'size_categories': ['10K<n<100K'], 'pretty_name': 'Headline Grouping (HLGD)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 915\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hope_edi\n",
       " \tsha: f759d7b3e1256c842ada0fb23371775162204cf6\n",
       " \tlastModified: 2022-07-01T11:52:35.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:ml', 'language:ta', 'license:cc-by-4.0', 'multilinguality:monolingual', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hope-speech-classification', 'configs:english', 'configs:malayalam', 'configs:tamil']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not.\n",
       " \tcitation: @inproceedings{chakravarthi-2020-hopeedi,\n",
       " title = \"{H}ope{EDI}: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion\",\n",
       " author = \"Chakravarthi, Bharathi Raja\",\n",
       " booktitle = \"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media\",\n",
       " month = dec,\n",
       " year = \"2020\",\n",
       " address = \"Barcelona, Spain (Online)\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " url = \"https://www.aclweb.org/anthology/2020.peoples-1.5\",\n",
       " pages = \"41--53\",\n",
       " abstract = \"Over the past few years, systems have been developed to control online content and eliminate abusive, offensive or hate speech content. However, people in power sometimes misuse this form of censorship to obstruct the democratic right of freedom of speech. Therefore, it is imperative that research should take a positive reinforcement approach towards online content that is encouraging, positive and supportive contents. Until now, most studies have focused on solving this problem of negativity in the English language, though the problem is much more than just harmful content. Furthermore, it is multilingual as well. Thus, we have constructed a Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not. To our knowledge, this is the first research of its kind to annotate hope speech for equality, diversity and inclusion in a multilingual setting. We determined that the inter-annotator agreement of our dataset using Krippendorff{'}s alpha. Further, we created several baselines to benchmark the resulting dataset and the results have been expressed using precision, recall and F1-score. The dataset is publicly available for the research community. We hope that this resource will spur further research on encouraging inclusive and responsive speech that reinforces positiveness.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'ml', 'ta'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual', 'multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hope-speech-classification'], 'paperswithcode_id': 'hopeedi', 'pretty_name': 'HopeEDI: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion', 'configs': ['english', 'malayalam', 'tamil']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 642\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: hopeedi\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hotpot_qa\n",
       " \tsha: ef942f9c60c1194e827b674253e49f1de37ae7f4\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['arxiv:1809.09600', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-multi-hop']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HotpotQA is a new dataset with 113k Wikipedia-based question-answer pairs with four key features:\n",
       " (1) the questions require finding and reasoning over multiple supporting documents to answer;\n",
       " (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas;\n",
       " (3) we provide sentence-level supporting facts required for reasoning, allowingQA systems to reason with strong supervisionand explain the predictions;\n",
       " (4) we offer a new type of factoid comparison questions to testQA systems’ ability to extract relevant facts and perform necessary comparison.\n",
       " \tcitation: @inproceedings{yang2018hotpotqa,\n",
       "   title={{HotpotQA}: A Dataset for Diverse, Explainable Multi-hop Question Answering},\n",
       "   author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W. and Salakhutdinov, Ruslan and Manning, Christopher D.},\n",
       "   booktitle={Conference on Empirical Methods in Natural Language Processing ({EMNLP})},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'HotpotQA', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-multi-hop'], 'paperswithcode_id': 'hotpotqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2459\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: hotpotqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hover\n",
       " \tsha: 6be08fc1d798c0574a4e09169ae60ba5ee6a8373\n",
       " \tlastModified: 2022-08-11T12:57:25.000Z\n",
       " \ttags: ['arxiv:2011.03088', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-retrieval', 'task_ids:fact-checking-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: HoVer is an open-domain, many-hop fact extraction and claim verification dataset built upon the Wikipedia corpus. The original 2-hop claims are adapted from question-answer pairs from HotpotQA. It is collected by a team of NLP researchers at UNC Chapel Hill and Verisk Analytics.\n",
       " \tcitation: @inproceedings{jiang2020hover,\n",
       "   title={{HoVer}: A Dataset for Many-Hop Fact Extraction And Claim Verification},\n",
       "   author={Yichen Jiang and Shikha Bordia and Zheng Zhong and Charles Dognin and Maneesh Singh and Mohit Bansal.},\n",
       "   booktitle={Findings of the Conference on Empirical Methods in Natural Language Processing ({EMNLP})},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval'], 'task_ids': ['fact-checking-retrieval'], 'paperswithcode_id': 'hover', 'pretty_name': 'HoVer'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 371\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: hover\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hrenwac_para\n",
       " \tsha: 5b4a771c0e4db4f31a08cc606dabaa6f30aebc9d\n",
       " \tlastModified: 2022-07-01T11:52:35.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'language:hr', 'license:cc-by-sa-3.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The hrenWaC corpus version 2.0 consists of parallel Croatian-English texts crawled from the .hr top-level domain for Croatia.\n",
       " The corpus was built with Spidextor (https://github.com/abumatran/spidextor), a tool that glues together the output of SpiderLing used for crawling and Bitextor used for bitext extraction. The accuracy of the extracted bitext on the segment level is around 80% and on the word level around 84%.\n",
       " \tcitation: @misc{11356/1058,\n",
       "  title = {Croatian-English parallel corpus {hrenWaC} 2.0},\n",
       "  author = {Ljube{\\v s}i{\\'c}, Nikola and Espl{\\'a}-Gomis, Miquel and Ortiz Rojas, Sergio and Klubi{\\v c}ka, Filip and Toral, Antonio},\n",
       "  url = {http://hdl.handle.net/11356/1058},\n",
       "  note = {Slovenian language resource repository {CLARIN}.{SI}},\n",
       "  copyright = {{CLARIN}.{SI} User Licence for Internet Corpora},\n",
       "  year = {2016} }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en', 'hr'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'HrenwacPara'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hrwac\n",
       " \tsha: c44eed27a3ad3e507bacec4e53566a67073435f0\n",
       " \tlastModified: 2022-07-01T11:52:35.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:hr', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1B<n<10B', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Croatian web corpus hrWaC was built by crawling the .hr top-level domain in 2011 and again in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Croatian vs. Serbian).\n",
       " \n",
       " Version 2.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 2.1 contains newer and better linguistic annotations.\n",
       " \tcitation: @misc{11356/1064,\n",
       "  title = {Croatian web corpus {hrWaC} 2.1},\n",
       "  author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n",
       "  url = {http://hdl.handle.net/11356/1064},\n",
       "  note = {Slovenian language resource repository {CLARIN}.{SI}},\n",
       "  copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n",
       "  year = {2016} }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['hr'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1B<n<10B'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'HrWac'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: humicroedit\n",
       " \tsha: 9439e3457f84f64d8dc219433ab5f4a71a530f37\n",
       " \tlastModified: 2022-07-01T11:52:36.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-funnier-headline-identification', 'task_ids:text-classification-other-funniness-score-prediction', 'task_ids:text-scoring', 'configs:subtask-1', 'configs:subtask-2']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This new dataset is designed to assess the funniness of edited news headlines.\n",
       " \tcitation: @article{hossain2019president,\n",
       "   title={\" President Vows to Cut< Taxes> Hair\": Dataset and Analysis of Creative Text Editing for Humorous Headlines},\n",
       "   author={Hossain, Nabil and Krumm, John and Gamon, Michael},\n",
       "   journal={arXiv preprint arXiv:1906.00274},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-funnier-headline-identification', 'text-classification-other-funniness-score-prediction', 'text-scoring'], 'paperswithcode_id': 'humicroedit', 'pretty_name': 'Humicroedit', 'configs': ['subtask-1', 'subtask-2']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1374\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: humicroedit\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hybrid_qa\n",
       " \tsha: 4b41596e98ca5d70d3aa8c6dd1bfeb46ede67a60\n",
       " \tlastModified: 2022-07-01T11:52:39.000Z\n",
       " \ttags: ['arxiv:1909.05358', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-multihop-tabular-text-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Existing question answering datasets focus on dealing with homogeneous information, based either only on text or KB/Table information alone. However, as human knowledge is distributed over heterogeneous forms, using homogeneous information alone might lead to severe coverage problems. To fill in the gap, we present HybridQA, a new large-scale question-answering dataset that requires reasoning on heterogeneous information. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, i.e., lack of either form would render the question unanswerable.\n",
       " \tcitation: @article{chen2020hybridqa,\n",
       "   title={HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data},\n",
       "   author={Chen, Wenhu and Zha, Hanwen and Chen, Zhiyu and Xiong, Wenhan and Wang, Hong and Wang, William},\n",
       "   journal={Findings of EMNLP 2020},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-multihop-tabular-text-qa'], 'paperswithcode_id': 'hybridqa', 'pretty_name': 'HybridQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 605\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: hybridqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: hyperpartisan_news_detection\n",
       " \tsha: 278dcb80535950ab7432fe004cb5fd9a24add210\n",
       " \tlastModified: 2022-09-06T05:39:59.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-bias-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Hyperpartisan News Detection was a dataset created for PAN @ SemEval 2019 Task 4.\n",
       " Given a news article text, decide whether it follows a hyperpartisan argumentation, i.e., whether it exhibits blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person.\n",
       " \n",
       " There are 2 parts:\n",
       " - byarticle: Labeled through crowdsourcing on an article basis. The data contains only articles for which a consensus among the crowdsourcing workers existed.\n",
       " - bypublisher: Labeled by the overall bias of the publisher as provided by BuzzFeed journalists or MediaBiasFactCheck.com.\n",
       " \tcitation: @article{kiesel2019data,\n",
       "   title={Data for pan at semeval 2019 task 4: Hyperpartisan news detection},\n",
       "   author={Kiesel, Johannes and Mestre, Maria and Shukla, Rishabh and Vincent, Emmanuel and Corney, David and Adineh, Payam and Stein, Benno and Potthast, Martin},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'HyperpartisanNewsDetection', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-bias-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1399\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: iapp_wiki_qa_squad\n",
       " \tsha: e9ed79a27fb94b4cba82888805ca4c25cb9ad71d\n",
       " \tlastModified: 2022-07-01T11:52:39.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-iapp-wiki-qa-dataset', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: `iapp_wiki_qa_squad` is an extractive question answering dataset from Thai Wikipedia articles.\n",
       " It is adapted from [the original iapp-wiki-qa-dataset](https://github.com/iapp-technology/iapp-wiki-qa-dataset)\n",
       " to [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format, resulting in\n",
       " 5761/742/739 questions from 1529/191/192 articles.\n",
       " \tcitation: @dataset{kobkrit_viriyayudhakorn_2021_4539916,\n",
       "   author       = {Kobkrit Viriyayudhakorn and\n",
       "                   Charin Polpanumas},\n",
       "   title        = {iapp_wiki_qa_squad},\n",
       "   month        = feb,\n",
       "   year         = 2021,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = 1,\n",
       "   doi          = {10.5281/zenodo.4539916},\n",
       "   url          = {https://doi.org/10.5281/zenodo.4539916}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-iapp-wiki-qa-dataset'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'IappWikiQaSquad'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 415\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_clickbait\n",
       " \tsha: cd22657868c690aa6cc316a2b22ed72c2ef267a8\n",
       " \tlastModified: 2022-07-01T11:52:39.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:id', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\n",
       " publishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\n",
       " Tribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\n",
       " 15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\n",
       " Judgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\n",
       " sample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\n",
       " \tcitation: @inproceedings{id_clickbait,\n",
       "   author    = {Andika William, Yunita Sari},\n",
       "   title     = {CLICK-ID: A Novel Dataset for Indonesian Clickbait Headlines},\n",
       "   year      = {2020},\n",
       "   url       = {http://dx.doi.org/10.17632/k42j7x2kpn.1},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['id'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': None, 'pretty_name': 'Indonesian Clickbait Headlines'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 491\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_liputan6\n",
       " \tsha: 9d9c3f1bc2583ca221d74ec8b4dc213e0b82b9f6\n",
       " \tlastModified: 2022-07-01T11:52:39.000Z\n",
       " \ttags: ['arxiv:2011.00679', 'annotations_creators:no-annotation', 'language_creators:found', 'language:id', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-extractive-summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: In this paper, we introduce a large-scale Indonesian summarization dataset. We harvest articles from this http URL,\n",
       " an online news portal, and obtain 215,827 document-summary pairs. We leverage pre-trained language models to develop\n",
       " benchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual\n",
       " BERT-based models. We include a thorough error analysis by examining machine-generated summaries that have\n",
       " low ROUGE scores, and expose both issues with ROUGE it-self, as well as with extractive and abstractive\n",
       " summarization models.\n",
       " \tcitation: @inproceedings{id_liputan6,\n",
       "   author    = {Fajri Koto, Jey Han Lau, Timothy Baldwin},\n",
       "   title     = {Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\n",
       "   year      = {2020},\n",
       "   url       = {https://arxiv.org/abs/2011.00679},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['id'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-extractive-summarization', 'news-articles-summarization'], 'paperswithcode_id': None, 'pretty_name': 'Large-scale Indonesian Summarization'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 491\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_nergrit_corpus\n",
       " \tsha: 8702f40f24ab9641e8d87b0403cc0f6f9a095f2c\n",
       " \tlastModified: 2022-07-01T12:43:29.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:id', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Nergrit Corpus is a dataset collection for Indonesian Named Entity Recognition, Statement Extraction, and Sentiment\n",
       " Analysis. id_nergrit_corpus is the Named Entity Recognition of this dataset collection which contains 18 entities as\n",
       " follow:\n",
       "     'CRD': Cardinal\n",
       "     'DAT': Date\n",
       "     'EVT': Event\n",
       "     'FAC': Facility\n",
       "     'GPE': Geopolitical Entity\n",
       "     'LAW': Law Entity (such as Undang-Undang)\n",
       "     'LOC': Location\n",
       "     'MON': Money\n",
       "     'NOR': Political Organization\n",
       "     'ORD': Ordinal\n",
       "     'ORG': Organization\n",
       "     'PER': Person\n",
       "     'PRC': Percent\n",
       "     'PRD': Product\n",
       "     'QTY': Quantity\n",
       "     'REG': Religion\n",
       "     'TIM': Time\n",
       "     'WOA': Work of Art\n",
       "     'LAN': Language\n",
       " \tcitation: @inproceedings{id_nergrit_corpus,\n",
       "   author    = {Gria Inovasi Teknologi},\n",
       "   title     = {NERGRIT CORPUS},\n",
       "   year      = {2019},\n",
       "   url       = {https://github.com/grit-id/nergrit-corpus},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Nergrit Corpus', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['id'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'nergrit-corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 651\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: nergrit-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_newspapers_2018\n",
       " \tsha: c29721f915cdec49a2baa2effe0eb6ca84b422b6\n",
       " \tlastModified: 2022-07-01T11:52:42.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:id', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains around 500K articles (136M of words) from 7 Indonesian newspapers: Detik, Kompas, Tempo,\n",
       " CNN Indonesia, Sindo, Republika and Poskota. The articles are dated between 1st January 2018 and 20th August 2018\n",
       " (with few exceptions dated earlier). The size of uncompressed 500K json files (newspapers-json.tgz) is around 2.2GB,\n",
       " and the cleaned uncompressed in a big text file (newspapers.txt.gz) is about 1GB. The original source in Google Drive\n",
       " contains also a dataset in html format which include raw data (pictures, css, javascript, ...)\n",
       " from the online news website\n",
       " \tcitation: @inproceedings{id_newspapers_2018,\n",
       "   author    = {},\n",
       "   title     = {Indonesian Newspapers 2018},\n",
       "   year      = {2019},\n",
       "   url       = {https://github.com/feryandi/Dataset-Artikel},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['id'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Indonesian Newspapers 2018'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_panl_bppt\n",
       " \tsha: b6b2c6f4ab1fb98abfdd4ad5315e1b0a905dd759\n",
       " \tlastModified: 2022-08-24T04:09:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'language:id', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\n",
       " Application of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\n",
       " Capacity in Asia). The dataset contains around 24K sentences divided in 4 difference topics (Economic, international,\n",
       " Science and Technology and Sport).\n",
       " \tcitation: @inproceedings{id_panl_bppt,\n",
       "   author    = {PAN Localization - BPPT},\n",
       "   title     = {Parallel Text Corpora, English Indonesian},\n",
       "   year      = {2009},\n",
       "   url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en', 'id'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'IdPanlBppt'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: id_puisi\n",
       " \tsha: 7a83d963e03cc8a2d7bd3273feda7b14f5a11280\n",
       " \tlastModified: 2022-07-01T11:52:43.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:id', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:text2text-generation-other-poem-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Puisi (poem) is an Indonesian poetic form. The dataset contains 7223 Indonesian puisi with its title and author.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['id'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-generation', 'fill-mask'], 'task_ids': ['text2text-generation-other-poem-generation'], 'paperswithcode_id': None, 'pretty_name': 'Indonesian Puisi'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: igbo_english_machine_translation\n",
       " \tsha: a5408580a3ad8d08be768d0ff27b7a5d79c89831\n",
       " \tlastModified: 2022-08-11T12:57:24.000Z\n",
       " \ttags: ['arxiv:2004.00648', 'annotations_creators:found', 'language_creators:found', 'language:en', 'language:ig', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Parallel Igbo-English Dataset\n",
       " \tcitation: @misc{ezeani2020igboenglish,\n",
       "     title={Igbo-English Machine Translation: An Evaluation Benchmark},\n",
       "     author={Ignatius Ezeani and Paul Rayson and Ikechukwu Onyenwe and Chinedu Uchechukwu and Mark Hepple},\n",
       "     year={2020},\n",
       "     eprint={2004.00648},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL},\n",
       "     url={https://arxiv.org/abs/2004.00648}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'ig'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'igbonlp-datasets', 'pretty_name': 'IgboNLP Datasets'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: igbonlp-datasets\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: igbo_monolingual\n",
       " \tsha: 296bf1828d161ece706a33b9b7bbc2175b80e9db\n",
       " \tlastModified: 2022-07-01T11:52:43.000Z\n",
       " \ttags: ['arxiv:2004.00648', 'annotations_creators:found', 'language_creators:found', 'language:ig', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:bbc-igbo', 'configs:eze_goes_to_school', 'configs:igbo-radio', 'configs:jw-books', 'configs:jw-nt-igbo', 'configs:jw-ot-igbo', 'configs:jw-teta', 'configs:jw-ulo_nche', 'configs:jw-ulo_nche_naamu']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset is a collection of Monolingual Igbo sentences.\n",
       " \tcitation: @misc{ezeani2020igboenglish,\n",
       " title={Igbo-English Machine Translation: An Evaluation Benchmark},\n",
       " author={Ignatius Ezeani and Paul Rayson and Ikechukwu Onyenwe and Chinedu Uchechukwu and Mark Hepple},\n",
       " year={2020},\n",
       " eprint={2004.00648},\n",
       " archivePrefix={arXiv},\n",
       " primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ig'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Igbo Monolingual Dataset', 'configs': ['bbc-igbo', 'eze_goes_to_school', 'igbo-radio', 'jw-books', 'jw-nt-igbo', 'jw-ot-igbo', 'jw-teta', 'jw-ulo_nche', 'jw-ulo_nche_naamu']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1574\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: igbo_ner\n",
       " \tsha: df8eaf2381155d595e8468e6ae655019ec96317d\n",
       " \tlastModified: 2022-07-01T11:52:44.000Z\n",
       " \ttags: ['arxiv:2004.00648', 'annotations_creators:found', 'language_creators:found', 'language:ig', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Igbo Named Entity Recognition Dataset\n",
       " \tcitation: @misc{ezeani2020igboenglish,\n",
       "     title={Igbo-English Machine Translation: An Evaluation Benchmark},\n",
       "     author={Ignatius Ezeani and Paul Rayson and Ikechukwu Onyenwe and Chinedu Uchechukwu and Mark Hepple},\n",
       "     year={2020},\n",
       "     eprint={2004.00648},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ig'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Igbo NER dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 483\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ilist\n",
       " \tsha: 413a8d20ab70ff09b651cd7768891ab9466953f6\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['task_categories:text-classification', 'multilinguality:multilingual', 'task_ids:text-classification-other-language-identification', 'language:awa', 'language:bho', 'language:bra', 'language:hi', 'language:mag', 'language_creators:found', 'annotations_creators:no-annotation', 'source_datasets:original', 'size_categories:10K<n<100K', 'license:cc-by-4.0']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is introduced in a task which aimed at identifying 5 closely-related languages of Indo-Aryan language family –\n",
       " Hindi (also known as Khari Boli), Braj Bhasha, Awadhi, Bhojpuri, and Magahi.\n",
       " \tcitation: None\n",
       " \tcardData: {'task_categories': ['text-classification'], 'multilinguality': ['multilingual'], 'task_ids': ['text-classification-other-language-identification'], 'language': ['awa', 'bho', 'bra', 'hi', 'mag'], 'language_creators': ['found'], 'annotations_creators': ['no-annotation'], 'source_datasets': ['original'], 'size_categories': ['10K<n<100K'], 'license': ['cc-by-4.0'], 'paperswithcode_id': None, 'pretty_name': 'ilist'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: imdb\n",
       " \tsha: de29c6807273c76ed1aa49fb203fc830a603d46d\n",
       " \tlastModified: 2022-07-01T11:52:46.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large Movie Review Dataset.\n",
       " This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\\\n",
       " \tcitation: @InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "   author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "   title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "   booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "   month     = {June},\n",
       "   year      = {2011},\n",
       "   address   = {Portland, Oregon, USA},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {142--150},\n",
       "   url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'IMDB', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'imdb-movie-reviews', 'train-eval-index': [{'config': 'plain_text', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy'}, {'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 191852\n",
       " \tlikes: 21\n",
       " \tpaperswithcode_id: imdb-movie-reviews\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: imdb_urdu_reviews\n",
       " \tsha: fa943f8229c3e4bdfbb1dba1de59b141f5b61865\n",
       " \tlastModified: 2022-07-01T12:43:30.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:machine-generated', 'language:ur', 'license:odbl', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large Movie translated Urdu Reviews Dataset.\n",
       " This is a dataset for binary sentiment classification containing substantially more data than previous\n",
       " benchmark datasets. We provide a set of 40,000 highly polar movie reviews for training, and 10,000 for testing.\n",
       " To increase the availability of sentiment analysis dataset for a low recourse language like Urdu,\n",
       " we opted to use the already available IMDB Dataset. we have translated this dataset using google translator.\n",
       " This is a binary classification dataset having two classes as positive and negative.\n",
       " The reason behind using this dataset is high polarity for each class.\n",
       " It contains 50k samples equally divided in two classes.\n",
       " \tcitation: @InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "   author    = {Maas, Andrew L. and Daly,nRaymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y...},\n",
       "   title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "   month     = {June},\n",
       "   year      = {2011},\n",
       "   address   = {Portland, Oregon, USA},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {142--150},\n",
       "   url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['machine-generated'], 'language': ['ur'], 'license': ['odbl'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'ImDB Urdu Reviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: imppres\n",
       " \tsha: 72caf2a3d9e27936ca6b205cd76bffae8d164bfb\n",
       " \tlastModified: 2022-07-01T11:52:47.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Over >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. IMPPRES is an NLI dataset following the format of SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018) and XNLI (Conneau et al., 2018), which was created to evaluate how well trained NLI models recognize several classes of presuppositions and scalar implicatures.\n",
       " \tcitation: @inproceedings{jeretic-etal-2020-natural,\n",
       "     title = \"Are Natural Language Inference Models {IMPPRESsive}? {L}earning {IMPlicature} and {PRESupposition}\",\n",
       "     author = \"Jereti\\v{c}, Paloma  and\n",
       "       Warstadt, Alex  and\n",
       "       Bhooshan, Suvrat  and\n",
       "       Williams, Adina\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.768\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.768\",\n",
       "     pages = \"8690--8705\",\n",
       "     abstract = \"Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied. We create an IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of 32K semi-automatically generated sentence pairs illustrating well-studied pragmatic inference types. We use IMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we find that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by {``}some{''} as entailments. For some presupposition triggers like {``}only{''}, BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'imppres', 'pretty_name': 'IMPPRES'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2669\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: imppres\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: indic_glue\n",
       " \tsha: 479e75515f0cd3d7efc5dc870b631ff1a02c0551\n",
       " \tlastModified: 2022-09-15T21:57:58.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:as', 'language:bn', 'language:en', 'language:gu', 'language:hi', 'language:kn', 'language:ml', 'language:mr', 'language:or', 'language:pa', 'language:ta', 'language:te', 'language_creators:found', 'license:other', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other', 'task_categories:text-classification', 'task_categories:token-classification', 'task_categories:multiple-choice', 'task_ids:topic-classification', 'task_ids:natural-language-inference', 'task_ids:sentiment-analysis', 'task_ids:semantic-similarity-scoring', 'task_ids:text-classification-other-headline-classification', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text-classification-other-cross-lingual-similarity', 'task_ids:text-classification-other-discourse-mode-classification', 'task_ids:named-entity-recognition', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     IndicGLUE is a natural language understanding benchmark for Indian languages. It contains a wide\n",
       "     variety of tasks and covers 11 major Indian languages - as, bn, gu, hi, kn, ml, mr, or, pa, ta, te.\n",
       " \tcitation:     @inproceedings{kakwani2020indicnlpsuite,\n",
       "     title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n",
       "     author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n",
       "     year={2020},\n",
       "     booktitle={Findings of EMNLP},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['as', 'bn', 'en', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['multilingual'], 'pretty_name': 'IndicGLUE', 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other'], 'task_categories': ['text-classification', 'token-classification', 'multiple-choice'], 'task_ids': ['topic-classification', 'natural-language-inference', 'sentiment-analysis', 'semantic-similarity-scoring', 'text-classification-other-headline-classification', 'text-classification-other-paraphrase-identification', 'text-classification-other-cross-lingual-similarity', 'text-classification-other-discourse-mode-classification', 'named-entity-recognition', 'multiple-choice-qa'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9601\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: indonli\n",
       " \tsha: 6abb872e0a563f07b3f56fdfae48e8733bf97184\n",
       " \tlastModified: 2022-07-01T11:52:56.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:id', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:   IndoNLI is the first human-elicited Natural Language Inference (NLI) dataset for Indonesian.\n",
       "   IndoNLI is annotated by both crowd workers and experts. The expert-annotated data is used exclusively as a test set.\n",
       "   It is designed to provide a challenging test-bed for Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural changes, idioms, or temporal and spatial reasoning.\n",
       " \tcitation:   @inproceedings{mahendra-etal-2021-indonli,\n",
       "     title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\n",
       "     author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = nov,\n",
       "     year = \"2021\",\n",
       "     address = \"Online and Punta Cana, Dominican Republic\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.emnlp-main.821\",\n",
       "     pages = \"10511--10527\",\n",
       "   }\n",
       " \tcardData: {'pretty_name': 'IndoNLI', 'annotations_creators': ['expert-generated', 'crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['id'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'indonli'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 347\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: indonli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: indonlu\n",
       " \tsha: 5c2107b489101c1274336a6ce385a3e8430a2f8d\n",
       " \tlastModified: 2022-07-19T12:41:58.000Z\n",
       " \ttags: ['arxiv:1809.03391', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:id', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text-classification', 'task_categories:token-classification', 'task_ids:closed-domain-qa', 'task_ids:multi-class-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech', 'task_ids:semantic-similarity-classification', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-aspect-based-sentiment-analysis', 'task_ids:token-classification-other-keyphrase-extraction', 'task_ids:token-classification-other-span-extraction', 'configs:bapos', 'configs:casa', 'configs:emot', 'configs:facqa', 'configs:hoasa', 'configs:keps', 'configs:nergrit', 'configs:nerp', 'configs:posp', 'configs:smsa', 'configs:terma', 'configs:wrete']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The IndoNLU benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems for Bahasa Indonesia.\n",
       " \tcitation: @inproceedings{wilie2020indonlu,\n",
       " title = {{IndoNLU}: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n",
       " authors={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\n",
       " booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n",
       " year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['id'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text-classification', 'token-classification'], 'task_ids': ['closed-domain-qa', 'multi-class-classification', 'named-entity-recognition', 'part-of-speech', 'semantic-similarity-classification', 'sentiment-classification', 'text-classification-other-aspect-based-sentiment-analysis', 'token-classification-other-keyphrase-extraction', 'token-classification-other-span-extraction'], 'paperswithcode_id': 'indonlu-benchmark', 'pretty_name': 'IndoNLU', 'configs': ['bapos', 'casa', 'emot', 'facqa', 'hoasa', 'keps', 'nergrit', 'nerp', 'posp', 'smsa', 'terma', 'wrete']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2194\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: indonlu-benchmark\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: inquisitive_qg\n",
       " \tsha: 7841353751777c26a1435359c7d5ba02402fdea8\n",
       " \tlastModified: 2022-07-01T11:53:04.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-question-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset of about 20k questions that are elicited from readers as they naturally read through a document sentence by sentence. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text. Because these questions are generated while the readers are processing the information, the questions directly communicate gaps between the reader’s and writer’s knowledge about the events described in the text, and are not necessarily answered in the document itself. This type of question reflects a real-world scenario: if one has questions during reading, some of them are answered by the text later on, the rest are not, but any of them would help further the reader’s understanding at the particular point when they asked it. This resource could enable question generation models to simulate human-like curiosity and cognitive processing, which may open up a new realm of applications.\n",
       " \tcitation: @InProceedings{ko2020inquisitive,\n",
       "   author    = {Ko, Wei-Jen and Chen, Te-Yuan and Huang, Yiyan and Durrett, Greg and Li, Junyi Jessy},\n",
       "   title     = {Inquisitive Question Generation for High Level Text Comprehension},\n",
       "   booktitle = {Proceedings of EMNLP},\n",
       "   year      = {2020},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'InquisitiveQg', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-question-generation'], 'paperswithcode_id': 'inquisitive'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: inquisitive\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: interpress_news_category_tr\n",
       " \tsha: f7e9f9d16e4be254b9bd37b069c351e91cda69d8\n",
       " \tlastModified: 2022-07-01T11:53:25.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-news-category-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: It is a Turkish news data set consisting of 273601 news in 17 categories, compiled from print media and news websites between 2010 and 2017 by the Interpress (https://www.interpress.com/) media monitoring company.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-news-category-classification'], 'paperswithcode_id': None, 'pretty_name': 'Interpress Turkish News Category Dataset (270K)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: interpress_news_category_tr_lite\n",
       " \tsha: 26b28acac4d15829ec76d827274742623edd73e6\n",
       " \tlastModified: 2022-07-01T11:53:14.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|interpress_news_category_tr', 'task_categories:text-classification', 'task_ids:text-classification-other-news-category-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: It is a Turkish news data set consisting of 273601 news in 10 categories, compiled from print media and news websites between 2010 and 2017 by the Interpress (https://www.interpress.com/) media monitoring company. It has been rearranged as easily separable and with fewer classes.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|interpress_news_category_tr'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-news-category-classification'], 'paperswithcode_id': None, 'pretty_name': 'Interpress Turkish News Category Dataset (270K - Lite Version)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 372\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: irc_disentangle\n",
       " \tsha: d44d5d4847e8860bbddfe432699236a5e09bdcae\n",
       " \tlastModified: 2022-07-01T11:53:15.000Z\n",
       " \ttags: ['arxiv:1810.11118', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:token-classification-other-conversation-disentanglement']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Disentangling conversations mixed together in a single stream of messages is\n",
       " a difficult task, made harder by the lack of large manually annotated\n",
       " datasets. This new dataset of 77,563 messages manually annotated with\n",
       " reply-structure graphs that both disentangle conversations and define\n",
       " internal conversation structure. The dataset is 16 times larger than all\n",
       " previously released datasets combined, the first to include adjudication of\n",
       " annotation disagreements, and the first to include context.\n",
       " \tcitation: @inproceedings{kummerfeld-etal-2019-large,\n",
       "     title = \"A Large-Scale Corpus for Conversation Disentanglement\",\n",
       "     author = \"Kummerfeld, Jonathan K.  and\n",
       "       Gouravajhala, Sai R.  and\n",
       "       Peper, Joseph J.  and\n",
       "       Athreya, Vignesh  and\n",
       "       Gunasekara, Chulaka  and\n",
       "       Ganhotra, Jatin  and\n",
       "       Patel, Siva Sankalp  and\n",
       "       Polymenakos, Lazaros C  and\n",
       "       Lasecki, Walter\",\n",
       "     booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/P19-1374\",\n",
       "     doi = \"10.18653/v1/P19-1374\",\n",
       "     pages = \"3846--3856\",\n",
       "     arxiv = \"https://arxiv.org/abs/1810.11118\",\n",
       "     software = \"https://jkk.name/irc-disentanglement\",\n",
       "     data = \"https://jkk.name/irc-disentanglement\",\n",
       "     abstract = \"Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our data is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include context. We use our data to re-examine prior work, in particular, finding that 89% of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['token-classification-other-conversation-disentanglement'], 'paperswithcode_id': 'irc-disentanglement', 'pretty_name': 'IRC Disentanglement'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 484\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: irc-disentanglement\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: isixhosa_ner_corpus\n",
       " \tsha: 0df879eaee335ed203225624e5f9d0fc1afba4cd\n",
       " \tlastModified: 2022-07-01T12:43:31.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:xh', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{isixhosa_ner_corpus,\n",
       "   author    = {K. Podile and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT isiXhosa Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/312},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['xh'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'IsixhosaNerCorpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: isizulu_ner_corpus\n",
       " \tsha: 02a945432b7e458f766e8f4a157b8f3cf09be36e\n",
       " \tlastModified: 2022-07-01T12:43:31.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:zu', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{isizulu_ner_corpus,\n",
       "   author    = {A.N. Manzini and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT isiZulu Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/319},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['zu'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa', 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Isizulu Ner Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: iwslt2017\n",
       " \tsha: 0b942ec87fec3cb03ec9f4c7cf53fce5d10885bd\n",
       " \tlastModified: 2022-09-20T09:27:19.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:ar', 'language:de', 'language:en', 'language:fr', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:ro', 'language:zh', 'language_creators:expert-generated', 'license:cc-by-nc-nd-4.0', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The IWSLT 2017 Multilingual Task addresses text translation, including zero-shot translation, with a single MT system across all directions including English, German, Dutch, Italian and Romanian. As unofficial task, conventional bilingual text translation is offered between English and Arabic, French, Japanese, Chinese, German and Korean.\n",
       " \tcitation: @inproceedings{cettolo-etal-2017-overview,\n",
       "     title = \"Overview of the {IWSLT} 2017 Evaluation Campaign\",\n",
       "     author = {Cettolo, Mauro  and\n",
       "       Federico, Marcello  and\n",
       "       Bentivogli, Luisa  and\n",
       "       Niehues, Jan  and\n",
       "       St{\\\\\"u}ker, Sebastian  and\n",
       "       Sudoh, Katsuhito  and\n",
       "       Yoshino, Koichiro  and\n",
       "       Federmann, Christian},\n",
       "     booktitle = \"Proceedings of the 14th International Conference on Spoken Language Translation\",\n",
       "     month = dec # \" 14-15\",\n",
       "     year = \"2017\",\n",
       "     address = \"Tokyo, Japan\",\n",
       "     publisher = \"International Workshop on Spoken Language Translation\",\n",
       "     url = \"https://aclanthology.org/2017.iwslt-1.1\",\n",
       "     pages = \"2--14\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['ar', 'de', 'en', 'fr', 'it', 'ja', 'ko', 'nl', 'ro', 'zh'], 'language_creators': ['expert-generated'], 'license': ['cc-by-nc-nd-4.0'], 'multilinguality': ['translation'], 'pretty_name': 'IWSLT 2017', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'iwslt-2017'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4987\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: iwslt-2017\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: jeopardy\n",
       " \tsha: efd3c7b8bc62c311b11b51f3b8c94e7c89e18292\n",
       " \tlastModified: 2022-07-01T11:53:18.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset containing 216,930 Jeopardy questions, answers and other data.\n",
       " \n",
       " The json file is an unordered list of questions where each question has\n",
       " 'category' : the question category, e.g. \"HISTORY\"\n",
       " 'value' : integer $ value of the question as string, e.g. \"200\"\n",
       " Note: This is \"None\" for Final Jeopardy! and Tiebreaker questions\n",
       " 'question' : text of question\n",
       " Note: This sometimes contains hyperlinks and other things messy text such as when there's a picture or video question\n",
       " 'answer' : text of answer\n",
       " 'round' : one of \"Jeopardy!\",\"Double Jeopardy!\",\"Final Jeopardy!\" or \"Tiebreaker\"\n",
       " Note: Tiebreaker questions do happen but they're very rare (like once every 20 years)\n",
       " 'show_number' : int of show number, e.g '4680'\n",
       " 'air_date' : string of the show air date in format YYYY-MM-DD\n",
       " \tcitation: \n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': None, 'pretty_name': 'jeopardy'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 407\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: jfleg\n",
       " \tsha: 113edc8f3580767aed6ab8338fd4cd9709b87ce0\n",
       " \tlastModified: 2022-07-01T11:53:19.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'multilinguality:other-language-learner', 'size_categories:1K<n<10K', 'source_datasets:extended|other-GUG-grammaticality-judgements', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-grammatical-error-correction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: JFLEG (JHU FLuency-Extended GUG) is an English grammatical error correction (GEC) corpus.\n",
       " It is a gold standard benchmark for developing and evaluating GEC systems with respect to\n",
       " fluency (extent to which a text is native-sounding) as well as grammaticality.\n",
       " \n",
       " For each source document, there are four human-written corrections (ref0 to ref3).\n",
       " \tcitation: @InProceedings{napoles-sakaguchi-tetreault:2017:EACLshort,\n",
       "   author    = {Napoles, Courtney\n",
       "                and  Sakaguchi, Keisuke\n",
       "                and  Tetreault, Joel},\n",
       "   title     = {JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction},\n",
       "   booktitle = {Proceedings of the 15th Conference of the European Chapter of the\n",
       "                Association for Computational Linguistics: Volume 2, Short Papers},\n",
       "   month     = {April},\n",
       "   year      = {2017},\n",
       "   address   = {Valencia, Spain},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {229--234},\n",
       "   url       = {http://www.aclweb.org/anthology/E17-2037}\n",
       " }\n",
       " @InProceedings{heilman-EtAl:2014:P14-2,\n",
       "   author    = {Heilman, Michael\n",
       "                and  Cahill, Aoife\n",
       "                and  Madnani, Nitin\n",
       "                and  Lopez, Melissa\n",
       "                and  Mulholland, Matthew\n",
       "                and  Tetreault, Joel},\n",
       "   title     = {Predicting Grammaticality on an Ordinal Scale},\n",
       "   booktitle = {Proceedings of the 52nd Annual Meeting of the\n",
       "                Association for Computational Linguistics (Volume 2: Short Papers)},\n",
       "   month     = {June},\n",
       "   year      = {2014},\n",
       "   address   = {Baltimore, Maryland},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {174--180},\n",
       "   url       = {http://www.aclweb.org/anthology/P14-2029}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual', 'other-language-learner'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-GUG-grammaticality-judgements'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-grammatical-error-correction'], 'paperswithcode_id': 'jfleg', 'pretty_name': 'JHU FLuency-Extended GUG corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 866\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: jfleg\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: jigsaw_toxicity_pred\n",
       " \tsha: 293081ef65caebec62bed2cbf0a2470330ff37ad\n",
       " \tlastModified: 2022-08-24T04:09:32.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:other', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset consists of a large number of Wikipedia comments which have been labeled by human raters for toxic behavior.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['other'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification'], 'paperswithcode_id': None, 'pretty_name': 'JigsawToxicityPred', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'comment_text': 'text', 'toxic': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 609\n",
       " \tlikes: 6\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: jigsaw_unintended_bias\n",
       " \tsha: 15f3d2419fb33b85de2230f8063e299bbdb83206\n",
       " \tlastModified: 2022-07-01T11:53:19.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-toxicity-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of comments from the defunct Civil Comments platform that have been annotated for their toxicity.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Jigsaw Unintended Bias in Toxicity Classification', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-toxicity-prediction']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 545\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: jnlpba\n",
       " \tsha: 66959846764576c6a5be2f72f3e91effe073ece7\n",
       " \tlastModified: 2022-07-01T11:53:21.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-genia-v3.02', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The data came from the GENIA version 3.02 corpus (Kim et al., 2003). This was formed from a controlled search\n",
       " on MEDLINE using the MeSH terms \u0018human\u0019, \u0018blood cells\u0019 and \u0018transcription factors\u0019. From this search 2,000 abstracts\n",
       " were selected and hand annotated according to a small taxonomy of 48 classes based on a chemical classification.\n",
       " Among the classes, 36 terminal classes were used to annotate the GENIA corpus.\n",
       " \tcitation: @inproceedings{kim2004introduction,\n",
       "                title={Introduction to the bio-entity recognition task at JNLPBA},\n",
       "                author={Kim, Jin-Dong and Ohta, Tomoko and Tsuruoka, Yoshimasa and Tateisi, Yuka and Collier, Nigel},\n",
       "                booktitle={Proceedings of the international joint workshop on natural language processing in biomedicine and its applications},\n",
       "                pages={70--75},\n",
       "                year={2004},\n",
       "                organization={Citeseer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-genia-v3.02'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'BioNLP / JNLPBA Shared Task 2004'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5321\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: journalists_questions\n",
       " \tsha: e6d702bd4c3bb0e3f45c5614fa66e3a4490b53d9\n",
       " \tlastModified: 2022-07-01T11:53:21.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:other', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-question-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " The journalists_questions corpus (version 1.0) is a collection of 10K human-written Arabic\n",
       " tweets manually labeled for question identification over Arabic tweets posted by journalists.\n",
       " \tcitation: \\\n",
       " @inproceedings{hasanain2016questions,\n",
       "   title={What Questions Do Journalists Ask on Twitter?},\n",
       "   author={Hasanain, Maram and Bagdouri, Mossaab and Elsayed, Tamer and Oard, Douglas W},\n",
       "   booktitle={Tenth International AAAI Conference on Web and Social Media},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['other'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-question-identification'], 'paperswithcode_id': None, 'pretty_name': 'JournalistsQuestions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kan_hope\n",
       " \tsha: e26861e4de560acf47d8c5cddfd89c797bd864d7\n",
       " \tlastModified: 2022-07-27T14:38:42.000Z\n",
       " \ttags: ['arxiv:2108.04616', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:kn', 'language_bcp47:en-IN', 'language_bcp47:kn-IN', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-Hope Speech Detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Numerous methods have been developed to monitor the spread of negativity in modern years by\n",
       " eliminating vulgar, offensive, and fierce comments from social media platforms. However, there are relatively\n",
       " lesser amounts of study that converges on embracing positivity, reinforcing supportive and reassuring content in online forums.\n",
       " Consequently, we propose creating an English Kannada Hope speech dataset, KanHope and comparing several experiments to benchmark the dataset.\n",
       " The dataset consists of 6,176 user generated comments in code mixed Kannada scraped from YouTube and manually annotated as bearing hope\n",
       " speech or Not-hope speech.\n",
       " This dataset was prepared for hope-speech text classification benchmark on code-mixed Kannada, an under-resourced language.\n",
       " \tcitation: @misc{hande2021hope,\n",
       "       title={Hope Speech detection in under-resourced Kannada language},\n",
       "       author={Adeep Hande and Ruba Priyadharshini and Anbukkarasi Sampath and Kingston Pal Thamburaj and Prabakaran Chandran and Bharathi Raja Chakravarthi},\n",
       "       year={2021},\n",
       "       eprint={2108.04616},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'kn'], 'language_bcp47': ['en-IN', 'kn-IN'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'KanHope', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-Hope Speech Detection']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kannada_news\n",
       " \tsha: dfe5012f77ba76b2539429e9e140978fb4088e1f\n",
       " \tlastModified: 2022-07-01T11:53:22.000Z\n",
       " \ttags: ['annotations_creators:other', 'language_creators:other', 'language:kn', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Kannada news dataset contains only the headlines of news article in three categories:\n",
       " Entertainment, Tech, and Sports.\n",
       " \n",
       " The data set contains around 6300 news article headlines which collected from Kannada news websites.\n",
       " The data set has been cleaned and contains train and test set using which can be used to benchmark\n",
       " classification models in Kannada.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['other'], 'language': ['kn'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'KannadaNews Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kd_conv\n",
       " \tsha: aa43e522f50d9e0537d0e34f1acd2e50dae2271d\n",
       " \tlastModified: 2022-07-01T11:53:23.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:zh', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KdConv is a Chinese multi-domain Knowledge-driven Conversionsation dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics, while the corpus can also used for exploration of transfer learning and domain adaptation.\\\n",
       " \tcitation: @inproceedings{zhou-etal-2020-kdconv,\n",
       "     title = \"{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation\",\n",
       "     author = \"Zhou, Hao  and\n",
       "       Zheng, Chujie  and\n",
       "       Huang, Kaili  and\n",
       "       Huang, Minlie  and\n",
       "       Zhu, Xiaoyan\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.635\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.635\",\n",
       "     pages = \"7098--7108\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['zh'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'kdconv', 'pretty_name': 'Knowledge-driven Conversation'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1437\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: kdconv\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kde4\n",
       " \tsha: 6675d32bf1142ba07058c65b4d687a6375fbf633\n",
       " \tlastModified: 2022-07-27T14:38:43.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:af', 'language:ar', 'language:as', 'language:ast', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:crh', 'language:cs', 'language:csb', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hne', 'language:hr', 'language:hsb', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:lb', 'language:lt', 'language:lv', 'language:mai', 'language:mk', 'language:ml', 'language:mr', 'language:ms', 'language:mt', 'language:nb', 'language:nds', 'language:ne', 'language:nl', 'language:nn', 'language:nso', 'language:oc', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:se', 'language:si', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tr', 'language:uk', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:zh', 'language_bcp47:bn-IN', 'language_bcp47:en-GB', 'language_bcp47:pt-BR', 'language_bcp47:zh-CN', 'language_bcp47:zh-HK', 'language_bcp47:zh-TW', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of KDE4 localization files (v.2).\n",
       " \n",
       " 92 languages, 4,099 bitexts\n",
       " total number of files: 75,535\n",
       " total number of tokens: 60.75M\n",
       " total number of sentence fragments: 8.89M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'ar', 'as', 'ast', 'be', 'bg', 'bn', 'br', 'ca', 'crh', 'cs', 'csb', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gl', 'gu', 'ha', 'he', 'hi', 'hne', 'hr', 'hsb', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'lb', 'lt', 'lv', 'mai', 'mk', 'ml', 'mr', 'ms', 'mt', 'nb', 'nds', 'ne', 'nl', 'nn', 'nso', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rw', 'se', 'si', 'sk', 'sl', 'sr', 'sv', 'ta', 'te', 'tg', 'th', 'tr', 'uk', 'uz', 'vi', 'wa', 'xh', 'zh'], 'language_bcp47': ['bn-IN', 'en-GB', 'pt-BR', 'zh-CN', 'zh-HK', 'zh-TW'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'KDE4'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2075\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kelm\n",
       " \tsha: 7fc20a6e094a34ce1fe2550367fefa64e3efd7a5\n",
       " \tlastModified: 2022-07-01T12:43:32.000Z\n",
       " \ttags: ['arxiv:2010.12688', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-data-to-text-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Data-To-Text Generation involves converting knowledge graph (KG) triples of the form (subject, relation, object) into\n",
       " a natural language sentence(s). This dataset consists of English KG data converted into paired natural language text.\n",
       " The generated corpus consists of ∼18M sentences spanning ∼45M triples with ∼1500 distinct relations.\n",
       " \tcitation: @misc{agarwal2020large,\n",
       "       title={Large Scale Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training},\n",
       "       author={Oshin Agarwal and Heming Ge and Siamak Shakeri and Rami Al-Rfou},\n",
       "       year={2020},\n",
       "       eprint={2010.12688},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-data-to-text-generation'], 'paperswithcode_id': 'kelm', 'pretty_name': 'Corpus for Knowledge-Enhanced Language Model Pre-training (KELM)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 559\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: kelm\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kilt_tasks\n",
       " \tsha: a1aaa9bb284aa11fe66ce0727e93f72c362c9456\n",
       " \tlastModified: 2022-07-01T11:53:26.000Z\n",
       " \ttags: ['arxiv:2009.02252', 'annotations_creators:crowdsourced', 'annotations_creators:found', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'source_datasets:extended|natural_questions', 'source_datasets:extended|other-aidayago', 'source_datasets:extended|other-fever', 'source_datasets:extended|other-hotpotqa', 'source_datasets:extended|other-trex', 'source_datasets:extended|other-triviaqa', 'source_datasets:extended|other-wizardsofwikipedia', 'source_datasets:extended|other-wned-cweb', 'source_datasets:extended|other-wned-wiki', 'source_datasets:extended|other-zero-shot-re', 'source_datasets:original', 'task_categories:fill-mask', 'task_categories:question-answering', 'task_categories:text-classification', 'task_categories:text-generation', 'task_categories:text-retrieval', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:dialogue-modeling', 'task_ids:document-retrieval', 'task_ids:entity-linking-retrieval', 'task_ids:extractive-qa', 'task_ids:fact-checking', 'task_ids:fact-checking-retrieval', 'task_ids:open-domain-abstractive-qa', 'task_ids:open-domain-qa', 'task_ids:slot-filling', 'configs:aidayago2', 'configs:cweb', 'configs:eli5', 'configs:fever', 'configs:hotpotqa', 'configs:nq', 'configs:structured_zeroshot', 'configs:trex', 'configs:triviaqa_support_only', 'configs:wned', 'configs:wow']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KILT tasks training and evaluation data.\n",
       " - [FEVER](https://fever.ai) | Fact Checking | fever\n",
       " - [AIDA CoNLL-YAGO](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/ambiverse-nlu/aida/downloads) | Entity Linking | aidayago2\n",
       " - [WNED-WIKI](https://github.com/U-Alberta/wned) | Entity Linking | wned\n",
       " - [WNED-CWEB](https://github.com/U-Alberta/wned) | Entity Linking | cweb\n",
       " - [T-REx](https://hadyelsahar.github.io/t-rex) | Slot Filling | trex\n",
       " - [Zero-Shot RE](http://nlp.cs.washington.edu/zeroshot) | Slot Filling | structured_zeroshot\n",
       " - [Natural Questions](https://ai.google.com/research/NaturalQuestions) | Open Domain QA  | nq\n",
       " - [HotpotQA](https://hotpotqa.github.io) | Open Domain QA | hotpotqa\n",
       " - [TriviaQA](http://nlp.cs.washington.edu/triviaqa) | Open Domain QA | triviaqa\n",
       " - [ELI5](https://facebookresearch.github.io/ELI5/explore.html) | Open Domain QA | eli5\n",
       " - [Wizard of Wikipedia](https://parl.ai/projects/wizard_of_wikipedia) | Dialogue | wow\n",
       " \n",
       " To finish linking TriviaQA questions to the IDs provided, follow the instructions [here](http://github.com/huggingface/datasets/datasets/kilt_tasks/README.md).\n",
       " \tcitation: @inproceedings{fb_kilt,\n",
       "     author    = {Fabio Petroni and\n",
       "                  Aleksandra Piktus and\n",
       "                  Angela Fan and\n",
       "                  Patrick Lewis and\n",
       "                  Majid Yazdani and\n",
       "                  Nicola De Cao and\n",
       "                  James Thorne and\n",
       "                  Yacine Jernite and\n",
       "                  Vassilis Plachouras and\n",
       "                  Tim Rockt\\\"aschel and\n",
       "                  Sebastian Riedel},\n",
       "     title     = {{KILT:} a {B}enchmark for {K}nowledge {I}ntensive {L}anguage {T}asks},\n",
       "     journal   = {CoRR},\n",
       "     archivePrefix = {arXiv},\n",
       "     year      = {2020},\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'found', 'machine-generated'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', '1M<n<10M'], 'source_datasets': ['extended|natural_questions', 'extended|other-aidayago', 'extended|other-fever', 'extended|other-hotpotqa', 'extended|other-trex', 'extended|other-triviaqa', 'extended|other-wizardsofwikipedia', 'extended|other-wned-cweb', 'extended|other-wned-wiki', 'extended|other-zero-shot-re', 'original'], 'task_categories': ['fill-mask', 'question-answering', 'text-classification', 'text-generation', 'text-retrieval', 'text2text-generation'], 'task_ids': ['abstractive-qa', 'dialogue-modeling', 'document-retrieval', 'entity-linking-retrieval', 'extractive-qa', 'fact-checking', 'fact-checking-retrieval', 'open-domain-abstractive-qa', 'open-domain-qa', 'slot-filling'], 'paperswithcode_id': 'kilt', 'pretty_name': 'KILT', 'configs': ['aidayago2', 'cweb', 'eli5', 'fever', 'hotpotqa', 'nq', 'structured_zeroshot', 'trex', 'triviaqa_support_only', 'wned', 'wow']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 89072\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: kilt\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kilt_wikipedia\n",
       " \tsha: e3139fe78afec744c41f75f4b887b03aec2de2b7\n",
       " \tlastModified: 2022-05-04T18:34:27.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KILT-Wikipedia: Wikipedia pre-processed for KILT.\n",
       " \tcitation: @inproceedings{fb_kilt,\n",
       "     author    = {Fabio Petroni and\n",
       "                  Aleksandra Piktus and\n",
       "                  Angela Fan and\n",
       "                  Patrick Lewis and\n",
       "                  Majid Yazdani and\n",
       "                  Nicola De Cao and\n",
       "                  James Thorne and\n",
       "                  Yacine Jernite and\n",
       "                  Vassilis Plachouras and\n",
       "                  Tim Rockt\\\"aschel and\n",
       "                  Sebastian Riedel},\n",
       "     title     = {{KILT:} a {B}enchmark for {K}nowledge {I}ntensive {L}anguage {T}asks},\n",
       "     journal   = {CoRR},\n",
       "     archivePrefix = {arXiv},\n",
       "     year      = {2020},\n",
       " \tcardData: {'paperswithcode_id': None, 'pretty_name': 'KiltWikipedia'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 411\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kinnews_kirnews\n",
       " \tsha: dec78149ed2b30510ef7df30ffbf4e4f24070652\n",
       " \tlastModified: 2022-08-24T04:09:34.000Z\n",
       " \ttags: ['arxiv:2010.12174', 'annotations_creators:expert-generated', 'language_creators:found', 'language:rn', 'language:rw', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:topic-classification', 'configs:kinnews_cleaned', 'configs:kinnews_raw', 'configs:kirnews_cleaned', 'configs:kirnews_raw']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Kinyarwanda and Kirundi news classification datasets\n",
       " \tcitation: @article{niyongabo2020kinnews,\n",
       "   title={KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi},\n",
       "   author={Niyongabo, Rubungo Andre and Qu, Hong and Kreutzer, Julia and Huang, Li},\n",
       "   journal={arXiv preprint arXiv:2010.12174},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['rn', 'rw'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'topic-classification'], 'paperswithcode_id': 'kinnews-and-kirnews', 'pretty_name': 'KinnewsKirnews', 'configs': ['kinnews_cleaned', 'kinnews_raw', 'kirnews_cleaned', 'kirnews_raw']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 794\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: kinnews-and-kirnews\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: klue\n",
       " \tsha: af73865fb01a16f58a43062126fc064ff040f487\n",
       " \tlastModified: 2022-07-01T11:53:26.000Z\n",
       " \ttags: ['arxiv:2105.09680', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ko', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:fill-mask', 'task_categories:question-answering', 'task_categories:text-classification', 'task_categories:text-generation', 'task_categories:token-classification', 'task_ids:extractive-qa', 'task_ids:named-entity-recognition', 'task_ids:natural-language-inference', 'task_ids:other-dialogue-state-tracking', 'task_ids:parsing', 'task_ids:semantic-similarity-scoring', 'task_ids:text-scoring', 'task_ids:token-classification-other-relation-extraction', 'task_ids:topic-classification', 'configs:dp', 'configs:mrc', 'configs:ner', 'configs:nli', 'configs:re', 'configs:sts', 'configs:wos', 'configs:ynat']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KLUE (Korean Language Understanding Evaluation)\n",
       " Korean Language Understanding Evaluation (KLUE) benchmark is a series of datasets to evaluate natural language\n",
       " understanding capability of Korean language models. KLUE consists of 8 diverse and representative tasks, which are accessible\n",
       " to anyone without any restrictions. With ethical considerations in mind, we deliberately design annotation guidelines to obtain\n",
       " unambiguous annotations for all datasets. Futhermore, we build an evaluation system and carefully choose evaluations metrics\n",
       " for every task, thus establishing fair comparison across Korean language models.\n",
       " \tcitation: @misc{park2021klue,\n",
       "       title={KLUE: Korean Language Understanding Evaluation},\n",
       "       author={Sungjoon Park and Jihyung Moon and Sungdong Kim and Won Ik Cho and Jiyoon Han and Jangwon Park and Chisung Song and Junseong Kim and Yongsook Song and Taehwan Oh and Joohong Lee and Juhyun Oh and Sungwon Lyu and Younghoon Jeong and Inkwon Lee and Sangwoo Seo and Dongjun Lee and Hyunwoo Kim and Myeonghwa Lee and Seongbo Jang and Seungwon Do and Sunkyoung Kim and Kyungtae Lim and Jongwon Lee and Kyumin Park and Jamin Shin and Seonghyun Kim and Lucy Park and Alice Oh and Jungwoo Ha and Kyunghyun Cho},\n",
       "       year={2021},\n",
       "       eprint={2105.09680},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'KLUE', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ko'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['fill-mask', 'question-answering', 'text-classification', 'text-generation', 'token-classification'], 'task_ids': ['extractive-qa', 'named-entity-recognition', 'natural-language-inference', 'other-dialogue-state-tracking', 'parsing', 'semantic-similarity-scoring', 'text-scoring', 'token-classification-other-relation-extraction', 'topic-classification'], 'paperswithcode_id': 'klue', 'configs': ['dp', 'mrc', 'ner', 'nli', 're', 'sts', 'wos', 'ynat']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 16437\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: klue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_3i4k\n",
       " \tsha: 4d76b3d5611285f5415cdb3336b6f5d3ee2b0eb3\n",
       " \tlastModified: 2022-07-01T11:53:29.000Z\n",
       " \ttags: ['arxiv:1811.04231', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ko', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is designed to identify speaker intention based on real-life spoken utterance in Korean into one of\n",
       " 7 categories: fragment, description, question, command, rhetorical question, rhetorical command, utterances.\n",
       " \tcitation: @article{cho2018speech,\n",
       "     title={Speech Intention Understanding in a Head-final Language: A Disambiguation Utilizing Intonation-dependency},\n",
       "     author={Cho, Won Ik and Lee, Hyeon Seung and Yoon, Ji Won and Kim, Seok Min and Kim, Nam Soo},\n",
       "     journal={arXiv preprint arXiv:1811.04231},\n",
       "     year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ko'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': None, 'pretty_name': '3i4K'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_hate\n",
       " \tsha: 4b5c260128c52c69ff46bd7e64446115eed7baed\n",
       " \tlastModified: 2022-07-01T11:53:29.000Z\n",
       " \ttags: ['arxiv:2005.12503', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language:ko', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Human-annotated Korean corpus collected from a popular domestic entertainment news aggregation platform\n",
       " for toxic speech detection. Comments are annotated for gender bias, social bias and hate speech.\n",
       " \tcitation: @inproceedings{moon-etal-2020-beep,\n",
       "     title = \"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\",\n",
       "     author = \"Moon, Jihyung  and\n",
       "       Cho, Won Ik  and\n",
       "       Lee, Junbum\",\n",
       "     booktitle = \"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.socialnlp-1.4\",\n",
       "     pages = \"25--31\",\n",
       "     abstract = \"Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff{'}s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found'], 'language': ['ko'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification'], 'paperswithcode_id': 'korean-hatespeech-dataset', 'pretty_name': 'Korean HateSpeech Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 816\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: korean-hatespeech-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_ner\n",
       " \tsha: aa75b0368c2a76702c651ad2122ebc5326b89ead\n",
       " \tlastModified: 2022-07-01T11:53:29.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:ko', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Korean named entity recognition dataset\n",
       " \tcitation: @InProceedings{Kim:2016,\n",
       "   title     = \"Korean Named Entity Recognition Dataset\",\n",
       "   authors   = \"Jae-Hoon Kim\",\n",
       "   publisher = \"GitHub\",\n",
       "   year      = \"2016\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['ko'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'KorNER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_nli\n",
       " \tsha: 812b14c2369e0a9248aed2db6481dbc563cc7baf\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language_creators:expert-generated', 'language:ko', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|multi_nli', 'source_datasets:extended|snli', 'source_datasets:extended|xnli', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Korean Natural  Language Inference datasets\n",
       " \tcitation: @article{ham2020kornli,\n",
       "   title={KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding},\n",
       "   author={Ham, Jiyeon and Choe, Yo Joong and Park, Kyubyong and Choi, Ilji and Soh, Hyungjoon},\n",
       "   journal={arXiv preprint arXiv:2004.03289},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated', 'expert-generated'], 'language': ['ko'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|multi_nli', 'extended|snli', 'extended|xnli'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-input-text-classification'], 'paperswithcode_id': 'kornli', 'pretty_name': 'KorNLI'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 656\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: kornli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_nlu\n",
       " \tsha: 83f6a82c72d6c77687315e7179d9551d32de117e\n",
       " \tlastModified: 2022-08-11T16:23:39.000Z\n",
       " \ttags: ['arxiv:2004.03289', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:found', 'language_creators:machine-generated', 'language:ko', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|snli', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring', 'task_ids:text-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     The dataset contains data for bechmarking korean models on NLI and STS\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['expert-generated', 'found', 'machine-generated'], 'language': ['ko'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|snli'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'semantic-similarity-scoring', 'text-scoring'], 'paperswithcode_id': None, 'pretty_name': 'KorNlu'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 897\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_qpair\n",
       " \tsha: 0cb58cb34e210a3fdeaff58c621148bb80507433\n",
       " \tlastModified: 2022-07-01T11:53:30.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:ko', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a Korean paired question dataset containing labels indicating whether two questions in a given pair are semantically identical. This dataset was used to evaluate the performance of [KoGPT2](https://github.com/SKT-AI/KoGPT2#subtask-evaluations) on a phrase detection downstream task.\n",
       " \tcitation: @misc{Song:2018,\n",
       "   title     = \"Paired Question v.2\",\n",
       "   authors   = \"Youngsook Song\",\n",
       "   publisher = \"GitHub\",\n",
       "   year      = \"2018\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['ko'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification'], 'paperswithcode_id': None, 'pretty_name': 'KorQpair'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 353\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_sae\n",
       " \tsha: 6e634378c17d13d5f70ee01f87f0a63a9bfcda8e\n",
       " \tlastModified: 2022-07-01T11:53:30.000Z\n",
       " \ttags: ['arxiv:1912.00342', 'arxiv:1811.04231', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ko', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This new dataset is designed to extract intent from non-canonical directives which will help dialog managers\n",
       " extract intent from user dialog that may have no clear objective or are paraphrased forms of utterances.\n",
       " \tcitation: @article{cho2019machines,\n",
       "   title={Machines Getting with the Program: Understanding Intent Arguments of Non-Canonical Directives},\n",
       "   author={Cho, Won Ik and Moon, Young Ki and Moon, Sangwhan and Kim, Seok Min and Kim, Nam Soo},\n",
       "   journal={arXiv preprint arXiv:1912.00342},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ko'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': None, 'pretty_name': 'Structured Argument Extraction for Korean'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: kor_sarcasm\n",
       " \tsha: 075f3ab689ac02c74cef7dc54013ac9245764776\n",
       " \tlastModified: 2022-08-24T04:09:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:ko', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-sarcasm-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a dataset designed to detect sarcasm in Korean because it distorts the literal meaning of a sentence\n",
       " and is highly related to sentiment classification.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ko'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-sarcasm-detection'], 'paperswithcode_id': None, 'pretty_name': 'Korean Sarcasm Detection'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: labr\n",
       " \tsha: de35f2264edb8d37ab9ae7072606994893ab104a\n",
       " \tlastModified: 2022-07-01T11:53:32.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains over 63,000 book reviews in Arabic.It is the largest sentiment analysis dataset for Arabic to-date.The book reviews were harvested from the website Goodreads during the month or March 2013.Each book review comes with the goodreads review id, the user id, the book id, the rating (1 to 5) and the text of the review.\n",
       " \tcitation: @inproceedings{aly2013labr,\n",
       "   title={Labr: A large scale arabic book reviews dataset},\n",
       "   author={Aly, Mohamed and Atiya, Amir},\n",
       "   booktitle={Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},\n",
       "   pages={494--498},\n",
       "   year={2013}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'labr', 'pretty_name': 'LABR'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: labr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lama\n",
       " \tsha: 24a25ebd827534421fe3349cddfa7a627a8a7800\n",
       " \tlastModified: 2022-07-01T11:53:34.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:extended|conceptnet5', 'source_datasets:extended|squad', 'task_categories:text-retrieval', 'task_categories:text-classification', 'task_ids:fact-checking-retrieval', 'task_ids:text-classification-other-probing', 'task_ids:text-scoring', 'configs:conceptnet', 'configs:google_re', 'configs:squad', 'configs:trex']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LAMA is a dataset used to probe and analyze the factual and commonsense knowledge contained in pretrained language models. See https://github.com/facebookresearch/LAMA.\n",
       " \tcitation: @inproceedings{petroni2019language,\n",
       "   title={Language Models as Knowledge Bases?},\n",
       "   author={F. Petroni, T. Rockt{\\\"{a}}schel, A. H. Miller, P. Lewis, A. Bakhtin, Y. Wu and S. Riedel},\n",
       "   booktitle={In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2019},\n",
       "   year={2019}\n",
       " }\n",
       " @inproceedings{petroni2020how,\n",
       "   title={How Context Affects Language Models' Factual Predictions},\n",
       "   author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\\\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\n",
       "   booktitle={Automated Knowledge Base Construction},\n",
       "   year={2020},\n",
       "   url={https://openreview.net/forum?id=025X0zPfn}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'LAMA: LAnguage Model Analysis', 'annotations_creators': ['crowdsourced', 'expert-generated', 'machine-generated'], 'language_creators': ['crowdsourced', 'expert-generated', 'machine-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', '1M<n<10M', 'n<1K'], 'source_datasets': ['extended|conceptnet5', 'extended|squad'], 'task_categories': ['text-retrieval', 'text-classification'], 'task_ids': ['fact-checking-retrieval', 'text-classification-other-probing', 'text-scoring'], 'paperswithcode_id': 'lama', 'configs': ['conceptnet', 'google_re', 'squad', 'trex']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2559\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: lama\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lambada\n",
       " \tsha: 4e4608027d8edc5dbe9a82522669b9c2e369d7e6\n",
       " \tlastModified: 2022-07-01T11:53:38.000Z\n",
       " \ttags: ['task_categories:text2text-generation', 'task_ids:text2text-generation-other-long-range-dependency', 'multilinguality:monolingual', 'language:en', 'language_creators:found', 'annotations_creators:expert-generated', 'source_datasets:extended|bookcorpus', 'size_categories:10K<n<100K', 'license:cc-by-4.0']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The LAMBADA evaluates the capabilities of computational models\n",
       " for text understanding by means of a word prediction task.\n",
       " LAMBADA is a collection of narrative passages sharing the characteristic\n",
       " that human subjects are able to guess their last word if\n",
       " they are exposed to the whole passage, but not if they\n",
       " only see the last sentence preceding the target word.\n",
       " To succeed on LAMBADA, computational models cannot\n",
       " simply rely on local context, but must be able to\n",
       " keep track of information in the broader discourse.\n",
       " \n",
       " The LAMBADA dataset is extracted from BookCorpus and\n",
       " consists of 10'022 passages, divided into 4'869 development\n",
       " and 5'153 test passages. The training data for language\n",
       " models to be tested on LAMBADA include the full text\n",
       " of 2'662 novels (disjoint from those in dev+test),\n",
       " comprising 203 million words.\n",
       " \tcitation: @InProceedings{paperno-EtAl:2016:P16-1,\n",
       "   author    = {Paperno, Denis  and  Kruszewski, Germ\\'{a}n  and  Lazaridou,\n",
       " Angeliki  and  Pham, Ngoc Quan  and  Bernardi, Raffaella  and  Pezzelle,\n",
       " Sandro  and  Baroni, Marco  and  Boleda, Gemma  and  Fernandez, Raquel},\n",
       "   title     = {The {LAMBADA} dataset: Word prediction requiring a broad\n",
       " discourse context},\n",
       "   booktitle = {Proceedings of the 54th Annual Meeting of the Association for\n",
       " Computational Linguistics (Volume 1: Long Papers)},\n",
       "   month     = {August},\n",
       "   year      = {2016},\n",
       "   address   = {Berlin, Germany},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {1525--1534},\n",
       "   url       = {http://www.aclweb.org/anthology/P16-1144}\n",
       " }\n",
       " \tcardData: {'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-long-range-dependency'], 'multilinguality': ['monolingual'], 'language': ['en'], 'language_creators': ['found'], 'annotations_creators': ['expert-generated'], 'source_datasets': ['extended|bookcorpus'], 'size_categories': ['10K<n<100K'], 'license': ['cc-by-4.0'], 'paperswithcode_id': 'lambada', 'pretty_name': 'LAMBADA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4779\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: lambada\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: large_spanish_corpus\n",
       " \tsha: b0fc5e673c07010345d21f6d11ae6ea9cc8d8c17\n",
       " \tlastModified: 2022-07-01T11:53:36.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:es', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:100M<n<1B', 'size_categories:10K<n<100K', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-pretraining-language-models', 'configs:DGT', 'configs:DOGC', 'configs:ECB', 'configs:EMEA', 'configs:EUBookShop', 'configs:Europarl', 'configs:GlobalVoices', 'configs:JRC', 'configs:NewsCommentary11', 'configs:OpenSubtitles2018', 'configs:ParaCrawl', 'configs:TED', 'configs:UN', 'configs:all_wikis', 'configs:combined', 'configs:multiUN']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Large Spanish Corpus is a compilation of 15 unlabelled Spanish corpora spanning Wikipedia to European parliament notes. Each config contains the data corresponding to a different corpus. For example, \"all_wiki\" only includes examples from Spanish Wikipedia. By default, the config is set to \"combined\" which loads all the corpora; with this setting you can also specify the number of samples to return per corpus by configuring the \"split\" argument.\n",
       " \tcitation: @dataset{jose_canete_2019_3247731,\n",
       "   author       = {José Cañete},\n",
       "   title        = {Compilation of Large Spanish Unannotated Corpora},\n",
       "   month        = may,\n",
       "   year         = 2019,\n",
       "   publisher    = {Zenodo},\n",
       "   doi          = {10.5281/zenodo.3247731},\n",
       "   url          = {https://doi.org/10.5281/zenodo.3247731}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['es'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '100M<n<1B', '10K<n<100K', '10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-pretraining-language-models'], 'paperswithcode_id': None, 'pretty_name': 'The Large Spanish Corpus', 'configs': ['DGT', 'DOGC', 'ECB', 'EMEA', 'EUBookShop', 'Europarl', 'GlobalVoices', 'JRC', 'NewsCommentary11', 'OpenSubtitles2018', 'ParaCrawl', 'TED', 'UN', 'all_wikis', 'combined', 'multiUN']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2742\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: laroseda\n",
       " \tsha: 27cf5b5addbb43e3a58e72762ca6ce14bb4d2f48\n",
       " \tlastModified: 2022-07-01T11:53:37.000Z\n",
       " \ttags: ['arxiv:2101.04197', 'arxiv:1901.06543', 'annotations_creators:found', 'language_creators:found', 'language:ro', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:         LaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian, of which 7,500 are positive and 7,500 negative.\n",
       "         Star ratings of 1 and 2 and of 4 and 5 are provided for negative and positive reviews respectively.\n",
       "         The current dataset uses star rating as the label for multi-class classification.\n",
       " \tcitation: @article{\n",
       "     tache2101clustering,\n",
       "     title={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa -- A Large Romanian Sentiment Data Set},\n",
       "     author={Anca Maria Tache and Mihaela Gaman and Radu Tudor Ionescu},\n",
       "     journal={ArXiv},\n",
       "     year = {2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ro'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'LaRoSeDa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lc_quad\n",
       " \tsha: ad2a5cfa3f43d76fefdae813bfd9bfab34258061\n",
       " \tlastModified: 2022-08-26T04:42:17.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-knowledge-base-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LC-QuAD 2.0 is a Large Question Answering dataset with 30,000 pairs of question and its corresponding SPARQL query. The target knowledge base is Wikidata and DBpedia, specifically the 2018 version. Please see our paper for details about the dataset creation process and framework.\n",
       " \tcitation: @inproceedings{dubey2017lc2,\n",
       " title={LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and DBpedia},\n",
       " author={Dubey, Mohnish and Banerjee, Debayan and Abdelkawi, Abdelrahman and Lehmann, Jens},\n",
       " booktitle={Proceedings of the 18th International Semantic Web Conference (ISWC)},\n",
       " year={2019},\n",
       " organization={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'LC-QuAD 2.0: Large-scale Complex Question Answering Dataset', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-knowledge-base-qa'], 'paperswithcode_id': 'lc-quad-2-0'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 336\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: lc-quad-2-0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lener_br\n",
       " \tsha: 029d466dff0f0989596d2962c8ba897b245c88dc\n",
       " \tlastModified: 2022-07-01T11:53:45.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LeNER-Br is a Portuguese language dataset for named entity recognition\n",
       " applied to legal documents. LeNER-Br consists entirely of manually annotated\n",
       " legislation and legal cases texts and contains tags for persons, locations,\n",
       " time entities, organizations, legislation and legal cases.\n",
       " To compose the dataset, 66 legal documents from several Brazilian Courts were\n",
       " collected. Courts of superior and state levels were considered, such as Supremo\n",
       " Tribunal Federal, Superior Tribunal de Justiça, Tribunal de Justiça de Minas\n",
       " Gerais and Tribunal de Contas da União. In addition, four legislation documents\n",
       " were collected, such as \"Lei Maria da Penha\", giving a total of 70 documents\n",
       " \tcitation: @inproceedings{luz_etal_propor2018,\n",
       "     author = {Pedro H. {Luz de Araujo} and Te\\'{o}filo E. {de Campos} and\n",
       "     Renato R. R. {de Oliveira} and Matheus Stauffer and\n",
       "     Samuel Couto and Paulo Bermejo},\n",
       "     title = {{LeNER-Br}: a Dataset for Named Entity Recognition in {Brazilian} Legal Text},\n",
       "     booktitle = {International Conference on the Computational Processing of Portuguese ({PROPOR})},\n",
       "     publisher = {Springer},\n",
       "     series = {Lecture Notes on Computer Science ({LNCS})},\n",
       "     pages = {313--323},\n",
       "     year = {2018},\n",
       "     month = {September 24-26},\n",
       "     address = {Canela, RS, Brazil},\n",
       "     doi = {10.1007/978-3-319-99722-3_32},\n",
       "     url = {https://cic.unb.br/~teodecampos/LeNER-Br/},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'lener-br', 'pretty_name': 'leNER-br'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 682\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: lener-br\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lex_glue\n",
       " \tsha: bd4bac5e216edea0559ef24d09282908abdca0f9\n",
       " \tlastModified: 2022-09-30T16:22:15.000Z\n",
       " \ttags: ['arxiv:2110.00976', 'arxiv:2109.00904', 'arxiv:1805.01217', 'arxiv:2104.08671', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended', 'task_categories:question-answering', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:multiple-choice-qa', 'task_ids:topic-classification', 'configs:case_hold', 'configs:ecthr_a', 'configs:ecthr_b', 'configs:eurlex', 'configs:ledgar', 'configs:scotus', 'configs:unfair_tos']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Legal General Language Understanding Evaluation (LexGLUE) benchmark is\n",
       " a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks\n",
       " \tcitation: @article{chalkidis-etal-2021-lexglue,\n",
       "       title={{LexGLUE}: A Benchmark Dataset for Legal Language Understanding in English},\n",
       "       author={Chalkidis, Ilias and\n",
       "       Jana, Abhik and\n",
       "       Hartung, Dirk and\n",
       "       Bommarito, Michael and\n",
       "       Androutsopoulos, Ion and\n",
       "       Katz, Daniel Martin and\n",
       "       Aletras, Nikolaos},\n",
       "       year={2021},\n",
       "       eprint={2110.00976},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL},\n",
       "       note = {arXiv: 2110.00976},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'LexGLUE', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended'], 'task_categories': ['question-answering', 'text-classification'], 'task_ids': ['multi-class-classification', 'multi-label-classification', 'multiple-choice-qa', 'topic-classification'], 'configs': ['case_hold', 'ecthr_a', 'ecthr_b', 'eurlex', 'ledgar', 'scotus', 'unfair_tos']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 19395\n",
       " \tlikes: 12\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: liar\n",
       " \tsha: 8a7198712957ba7904d9e640c10499c2f1a47e56\n",
       " \tlastModified: 2022-07-01T11:53:46.000Z\n",
       " \ttags: ['arxiv:1705.00648', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-fake-news-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LIAR is a dataset for fake news detection with 12.8K human labeled short statements from politifact.com's API, and each statement is evaluated by a politifact.com editor for its truthfulness. The distribution of labels in the LIAR dataset is relatively well-balanced: except for 1,050 pants-fire cases, the instances for all other labels range from 2,063 to 2,638. In each case, the labeler provides a lengthy analysis report to ground each judgment.\n",
       " \tcitation: @inproceedings{wang-2017-liar,\n",
       " title = \"{``}Liar, Liar Pants on Fire{''}: A New Benchmark Dataset for Fake News Detection\",\n",
       " author = \"Wang, William Yang\",\n",
       " booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n",
       " month = jul,\n",
       " year = \"2017\",\n",
       " address = \"Vancouver, Canada\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " url = \"https://www.aclweb.org/anthology/P17-2067\",\n",
       " doi = \"10.18653/v1/P17-2067\",\n",
       " pages = \"422--426\",\n",
       " abstract = \"Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-fake-news-detection'], 'paperswithcode_id': 'liar', 'pretty_name': 'LIAR', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'statement': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1211\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: liar\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: librispeech_asr\n",
       " \tsha: 8cb4c64041dc7c76e05654f41e7223fd5e93acdc\n",
       " \tlastModified: 2022-08-30T10:03:55.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'task_ids:speaker-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\n",
       " prepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\n",
       " audiobooks from the LibriVox project, and has been carefully segmented and aligned.87\n",
       " \tcitation: @inproceedings{panayotov2015librispeech,\n",
       "   title={Librispeech: an ASR corpus based on public domain audio books},\n",
       "   author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n",
       "   booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n",
       "   pages={5206--5210},\n",
       "   year={2015},\n",
       "   organization={IEEE}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'LibriSpeech', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'librispeech-1', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition', 'audio-classification'], 'task_ids': ['speaker-identification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 12751\n",
       " \tlikes: 20\n",
       " \tpaperswithcode_id: librispeech-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: librispeech_lm\n",
       " \tsha: 594cc82f1fbe383476762575b06466a45bb150bb\n",
       " \tlastModified: 2022-08-25T13:44:00.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language:en', 'language_creators:found', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text-generation', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Language modeling resources to be used in conjunction with the LibriSpeech ASR corpus.\n",
       " \tcitation: @inproceedings{panayotov2015librispeech,\n",
       "   title={Librispeech: an ASR corpus based on public domain audio books},\n",
       "   author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n",
       "   booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n",
       "   pages={5206--5210},\n",
       "   year={2015},\n",
       "   organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'LibrispeechLm', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text-generation'], 'task_ids': ['language-modeling'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: limit\n",
       " \tsha: f7eb135831ccefa2c5080a3060d26638ce6cbcde\n",
       " \tlastModified: 2022-07-01T11:53:47.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|net-activities-captions', 'source_datasets:original', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. Literal-Motion-in-Text (LiMiT) dataset, is a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion.\n",
       " \tcitation: @inproceedings{manotas-etal-2020-limit,\n",
       "     title = \"{L}i{M}i{T}: The Literal Motion in Text Dataset\",\n",
       "     author = \"Manotas, Irene  and\n",
       "       Vo, Ngoc Phuoc An  and\n",
       "       Sheinin, Vadim\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.88\",\n",
       "     doi = \"10.18653/v1/2020.findings-emnlp.88\",\n",
       "     pages = \"991--1000\",\n",
       "     abstract = \"Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. We present the Literal-Motion-in-Text (LiMiT) dataset, a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion. We describe the annotation process for the dataset, analyze its scale and diversity, and report results of several baseline models. We also present future research directions and applications of the LiMiT dataset and share it publicly as a new resource for the research community.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|net-activities-captions', 'original'], 'task_categories': ['token-classification', 'text-classification'], 'task_ids': ['multi-class-classification', 'named-entity-recognition'], 'paperswithcode_id': 'limit', 'pretty_name': 'LiMiT'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 569\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: limit\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lince\n",
       " \tsha: 7f3b0618cf23412176ddb4216fc85a2501eb919f\n",
       " \tlastModified: 2022-05-04T18:34:31.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LinCE is a centralized Linguistic Code-switching Evaluation benchmark\n",
       " (https://ritual.uh.edu/lince/) that contains data for training and evaluating\n",
       " NLP systems on code-switching tasks.\n",
       " \tcitation: @inproceedings{aguilar-etal-2020-lince,\n",
       "     title = \"{L}in{CE}: A Centralized Benchmark for Linguistic Code-switching Evaluation\",\n",
       "     author = \"Aguilar, Gustavo  and\n",
       "       Kar, Sudipta  and\n",
       "       Solorio, Thamar\",\n",
       "     booktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.223\",\n",
       "     pages = \"1803--1813\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \n",
       " Note that each LinCE dataset has its own citation. Please see the source to see\n",
       " the correct citation for each contained dataset.\n",
       " \tcardData: {'paperswithcode_id': 'lince', 'pretty_name': 'Linguistic Code-switching Evaluation Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2303\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: lince\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: linnaeus\n",
       " \tsha: 07790d488a2bd379829e955cf086456399d593f8\n",
       " \tlastModified: 2022-07-01T11:53:49.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A novel corpus of full-text documents manually annotated for species mentions.\n",
       " \tcitation: @article{gerner2010linnaeus,\n",
       "          title={LINNAEUS: a species name identification system for biomedical literature},\n",
       "          author={Gerner, Martin and Nenadic, Goran and Bergman, Casey M},\n",
       "          journal={BMC bioinformatics},\n",
       "          volume={11},\n",
       "          number={1},\n",
       "          pages={85},\n",
       "          year={2010},\n",
       "          publisher={Springer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'linnaeus', 'pretty_name': 'LINNAEUS'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: linnaeus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: liveqa\n",
       " \tsha: f2c17f2f69b157aa926e5706351ec26ce154916f\n",
       " \tlastModified: 2022-07-01T11:53:49.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is LiveQA, a Chinese dataset constructed from play-by-play live broadcast.\n",
       " It contains 117k multiple-choice questions written by human commentators for over 1,670 NBA games,\n",
       " which are collected from the Chinese Hupu website.\n",
       " \tcitation: @inproceedings{qianying-etal-2020-liveqa,\n",
       "     title = \"{L}ive{QA}: A Question Answering Dataset over Sports Live\",\n",
       "     author = \"Qianying, Liu  and\n",
       "       Sicong, Jiang  and\n",
       "       Yizhong, Wang  and\n",
       "       Sujian, Li\",\n",
       "     booktitle = \"Proceedings of the 19th Chinese National Conference on Computational Linguistics\",\n",
       "     month = oct,\n",
       "     year = \"2020\",\n",
       "     address = \"Haikou, China\",\n",
       "     publisher = \"Chinese Information Processing Society of China\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.ccl-1.98\",\n",
       "     pages = \"1057--1067\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'liveqa', 'pretty_name': 'LiveQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: liveqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lj_speech\n",
       " \tsha: 8673990afa824117801261621bd1d4e645db21b2\n",
       " \tlastModified: 2022-07-01T12:43:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unlicense', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading\n",
       " passages from 7 non-fiction books in English. A transcription is provided for each clip. Clips vary in length\n",
       " from 1 to 10 seconds and have a total length of approximately 24 hours.\n",
       " \n",
       " Note that in order to limit the required storage for preparing this dataset, the audio\n",
       " is stored in the .wav format and is not converted to a float32 array. To convert the audio\n",
       " file to a float32 array, please make use of the `.map()` function as follows:\n",
       " \n",
       " \n",
       " ```python\n",
       " import soundfile as sf\n",
       " \n",
       " def map_to_array(batch):\n",
       "     speech_array, _ = sf.read(batch[\"file\"])\n",
       "     batch[\"speech\"] = speech_array\n",
       "     return batch\n",
       " \n",
       " dataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n",
       " ```\n",
       " \tcitation: @misc{ljspeech17,\n",
       "   author       = {Keith Ito and Linda Johnson},\n",
       "   title        = {The LJ Speech Dataset},\n",
       "   howpublished = {\\\\url{https://keithito.com/LJ-Speech-Dataset/}},\n",
       "   year         = 2017\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unlicense'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'ljspeech', 'pretty_name': 'LJ Speech', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'train-eval-index': [{'config': 'main', 'task': 'automatic-speech-recognition', 'task_id': 'speech_recognition', 'splits': {'train_split': 'train'}, 'col_mapping': {'file': 'path', 'text': 'text'}, 'metrics': [{'type': 'wer', 'name': 'WER'}, {'type': 'cer', 'name': 'CER'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 365\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: ljspeech\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lm1b\n",
       " \tsha: bd25e980eea107739626a899f1a65fd90f8463d2\n",
       " \tlastModified: 2022-01-25T15:50:38.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A benchmark corpus to be used for measuring progress in statistical language modeling. This has almost one billion words in the training data.\n",
       " \tcitation: @article{DBLP:journals/corr/ChelbaMSGBK13,\n",
       "   author    = {Ciprian Chelba and\n",
       "                Tomas Mikolov and\n",
       "                Mike Schuster and\n",
       "                Qi Ge and\n",
       "                Thorsten Brants and\n",
       "                Phillipp Koehn},\n",
       "   title     = {One Billion Word Benchmark for Measuring Progress in Statistical Language\n",
       "                Modeling},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1312.3005},\n",
       "   year      = {2013},\n",
       "   url       = {http://arxiv.org/abs/1312.3005},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1312.3005},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:46:16 +0200},\n",
       "   biburl    = {https://dblp.org/rec/bib/journals/corr/ChelbaMSGBK13},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Lm1b', 'paperswithcode_id': 'billion-word-benchmark'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 621\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: billion-word-benchmark\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: lst20\n",
       " \tsha: aae9cc754c69a2d6564c9362df04ab28c1b6277d\n",
       " \tlastModified: 2022-07-19T12:41:58.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech', 'task_ids:token-classification-other-clause-segmentation', 'task_ids:token-classification-other-sentence-segmentation', 'task_ids:token-classification-other-word-segmentation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: LST20 Corpus is a dataset for Thai language processing developed by National Electronics and Computer Technology Center (NECTEC), Thailand.\n",
       " It offers five layers of linguistic annotation: word boundaries, POS tagging, named entities, clause boundaries, and sentence boundaries.\n",
       " At a large scale, it consists of 3,164,002 words, 288,020 named entities, 248,181 clauses, and 74,180 sentences, while it is annotated with\n",
       " 16 distinct POS tags. All 3,745 documents are also annotated with one of 15 news genres. Regarding its sheer size, this dataset is\n",
       " considered large enough for developing joint neural models for NLP.\n",
       " Manually download at https://aiforthai.in.th/corpus.php\n",
       " \tcitation: @article{boonkwan2020annotation,\n",
       "   title={The Annotation Guideline of LST20 Corpus},\n",
       "   author={Boonkwan, Prachya and Luantangsrisuk, Vorapon and Phaholphinyo, Sitthaa and Kriengket, Kanyanat and Leenoi, Dhanon and Phrombut, Charun and Boriboon, Monthika and Kosawat, Krit and Supnithi, Thepchai},\n",
       "   journal={arXiv preprint arXiv:2008.05055},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'part-of-speech', 'token-classification-other-clause-segmentation', 'token-classification-other-sentence-segmentation', 'token-classification-other-word-segmentation'], 'paperswithcode_id': None, 'pretty_name': 'LST20'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 354\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: m_lama\n",
       " \tsha: f1d89f1e87db9d911df4d3c9d6d2705e722ef791\n",
       " \tlastModified: 2022-07-01T11:53:50.000Z\n",
       " \ttags: ['arxiv:2102.00894', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:ceb', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:it', 'language:ja', 'language:ka', 'language:ko', 'language:la', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:th', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-nc-sa-4.0', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:extended|lama', 'task_categories:question-answering', 'task_categories:text-classification', 'task_ids:open-domain-qa', 'task_ids:text-scoring', 'task_ids:text-classification-other-probing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: mLAMA: a multilingual version of the LAMA benchmark (T-REx and GoogleRE) covering 53 languages.\n",
       " \tcitation: @article{kassner2021multilingual,\n",
       "   author    = {Nora Kassner and\n",
       "                Philipp Dufter and\n",
       "                Hinrich Sch{\\\"{u}}tze},\n",
       "   title     = {Multilingual {LAMA:} Investigating Knowledge in Multilingual Pretrained\n",
       "                Language Models},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2102.00894},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2102.00894},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2102.00894},\n",
       "   timestamp = {Tue, 09 Feb 2021 13:35:56 +0100},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2102-00894.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org},\n",
       "   note      = {to appear in EACL2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated', 'machine-generated'], 'language_creators': ['crowdsourced', 'expert-generated', 'machine-generated'], 'language': ['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'ceb', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'ga', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'it', 'ja', 'ka', 'ko', 'la', 'lt', 'lv', 'ms', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'th', 'tr', 'uk', 'ur', 'vi', 'zh'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|lama'], 'task_categories': ['question-answering', 'text-classification'], 'task_ids': ['open-domain-qa', 'text-scoring', 'text-classification-other-probing'], 'paperswithcode_id': None, 'pretty_name': 'MLama'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mac_morpho\n",
       " \tsha: d54e2a56ebca6f59d2304a280e6f17985b343166\n",
       " \tlastModified: 2022-07-19T12:42:03.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Mac-Morpho is a corpus of Brazilian Portuguese texts annotated with part-of-speech tags.\n",
       " Its first version was released in 2003 [1], and since then, two revisions have been made in order\n",
       " to improve the quality of the resource [2, 3].\n",
       " The corpus is available for download split into train, development and test sections.\n",
       " These are 76%, 4% and 20% of the corpus total, respectively (the reason for the unusual numbers\n",
       " is that the corpus was first split into 80%/20% train/test, and then 5% of the train section was\n",
       " set aside for development). This split was used in [3], and new POS tagging research with Mac-Morpho\n",
       " is encouraged to follow it in order to make consistent comparisons possible.\n",
       " \n",
       " \n",
       " [1] Aluísio, S., Pelizzoni, J., Marchi, A.R., de Oliveira, L., Manenti, R., Marquiafável, V. 2003.\n",
       " An account of the challenge of tagging a reference corpus for brazilian portuguese.\n",
       " In: Proceedings of the 6th International Conference on Computational Processing of the Portuguese Language. PROPOR 2003\n",
       " \n",
       " [2] Fonseca, E.R., Rosa, J.L.G. 2013. Mac-morpho revisited: Towards robust part-of-speech.\n",
       " In: Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology – STIL\n",
       " \n",
       " [3] Fonseca, E.R., Aluísio, Sandra Maria, Rosa, J.L.G. 2015.\n",
       " Evaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese.\n",
       " Journal of the Brazilian Computer Society.\n",
       " \tcitation: @article{fonseca2015evaluating,\n",
       "   title={Evaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese},\n",
       "   author={Fonseca, Erick R and Rosa, Joao Luis G and Aluisio, Sandra Maria},\n",
       "   journal={Journal of the Brazilian Computer Society},\n",
       "   volume={21},\n",
       "   number={1},\n",
       "   pages={2},\n",
       "   year={2015},\n",
       "   publisher={Springer}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Mac-Morpho', 'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['part-of-speech'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: makhzan\n",
       " \tsha: 7693a141f50247b255c16b94f06f405fb509a10f\n",
       " \tlastModified: 2022-08-25T13:20:11.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ur', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An Urdu text corpus for machine learning, natural language processing and linguistic analysis.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ur'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'makhzan'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: masakhaner\n",
       " \tsha: 68b4ae88f650d7a1f3deb58356807950837a31fc\n",
       " \tlastModified: 2022-07-01T11:53:53.000Z\n",
       " \ttags: ['arxiv:2103.11811', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:am', 'language:ha', 'language:ig', 'language:lg', 'language:luo', 'language:pcm', 'language:rw', 'language:sw', 'language:wo', 'language:yo', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'configs:am', 'configs:ha', 'configs:ig', 'configs:lg', 'configs:luo', 'configs:pcm', 'configs:rw', 'configs:sw', 'configs:wo', 'configs:yo']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MasakhaNER is the first large publicly available high-quality dataset for named entity recognition (NER) in ten African languages.\n",
       " \n",
       " Named entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n",
       " \n",
       " Example:\n",
       " [PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\n",
       " MasakhaNER is a named entity dataset consisting of PER, ORG, LOC, and DATE entities annotated by Masakhane for ten African languages:\n",
       " - Amharic\n",
       " - Hausa\n",
       " - Igbo\n",
       " - Kinyarwanda\n",
       " - Luganda\n",
       " - Luo\n",
       " - Nigerian-Pidgin\n",
       " - Swahili\n",
       " - Wolof\n",
       " - Yoruba\n",
       " \n",
       " The train/validation/test sets are available for all the ten languages.\n",
       " \n",
       " For more details see https://arxiv.org/abs/2103.11811\n",
       " \tcitation: @article{Adelani2021MasakhaNERNE,\n",
       "   title={MasakhaNER: Named Entity Recognition for African Languages},\n",
       "   author={D. Adelani and Jade Abbott and Graham Neubig and Daniel D'Souza and Julia Kreutzer and Constantine Lignos\n",
       "   and Chester Palen-Michel and Happy Buzaaba and Shruti Rijhwani and Sebastian Ruder and Stephen Mayhew and\n",
       "   Israel Abebe Azime and S. Muhammad and Chris C. Emezue and Joyce Nakatumba-Nabende and Perez Ogayo and\n",
       "   Anuoluwapo Aremu and Catherine Gitau and Derguene Mbaye and J. Alabi and Seid Muhie Yimam and Tajuddeen R. Gwadabe and\n",
       "   Ignatius Ezeani and Rubungo Andre Niyongabo and Jonathan Mukiibi and V. Otiende and Iroro Orife and Davis David and\n",
       "   Samba Ngom and Tosin P. Adewumi and Paul Rayson and Mofetoluwa Adeyemi and Gerald Muriuki and Emmanuel Anebi and\n",
       "   C. Chukwuneke and N. Odu and Eric Peter Wairagala and S. Oyerinde and Clemencia Siro and Tobius Saul Bateesa and\n",
       "   Temilola Oloyede and Yvonne Wambui and Victor Akinode and Deborah Nabagereka and Maurice Katusiime and\n",
       "   Ayodele Awokoya and Mouhamadane Mboup and D. Gebreyohannes and Henok Tilaye and Kelechi Nwaike and Degaga Wolde and\n",
       "    Abdoulaye Faye and Blessing Sibanda and Orevaoghene Ahia and Bonaventure F. P. Dossou and Kelechi Ogueji and\n",
       "    Thierno Ibrahima Diop and A. Diallo and Adewale Akinfaderin and T. Marengereke and Salomey Osei},\n",
       "   journal={ArXiv},\n",
       "   year={2021},\n",
       "   volume={abs/2103.11811}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['am', 'ha', 'ig', 'lg', 'luo', 'pcm', 'rw', 'sw', 'wo', 'yo'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'MasakhaNER', 'configs': ['am', 'ha', 'ig', 'lg', 'luo', 'pcm', 'rw', 'sw', 'wo', 'yo']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1783\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: math_dataset\n",
       " \tsha: f9d913e2efbdb2fdf28cd482f0db78f7a0f23143\n",
       " \tlastModified: 2022-07-01T11:53:53.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Mathematics database.\n",
       " \n",
       " This dataset code generates mathematical question and answer pairs,\n",
       " from a range of question types at roughly school-level difficulty.\n",
       " This is designed to test the mathematical learning and algebraic\n",
       " reasoning skills of learning models.\n",
       " \n",
       " Original paper: Analysing Mathematical Reasoning Abilities of Neural Models\n",
       " (Saxton, Grefenstette, Hill, Kohli).\n",
       " \n",
       " Example usage:\n",
       " train_examples, val_examples = datasets.load_dataset(\n",
       "     'math_dataset/arithmetic__mul',\n",
       "     split=['train', 'test'],\n",
       "     as_supervised=True)\n",
       " \tcitation: @article{2019arXiv,\n",
       "   author = {Saxton, Grefenstette, Hill, Kohli},\n",
       "   title = {Analysing Mathematical Reasoning Abilities of Neural Models},\n",
       "   year = {2019},\n",
       "   journal = {arXiv:1904.01557}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Mathematics Dataset', 'language': ['en'], 'paperswithcode_id': 'mathematics'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 14499\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: mathematics\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: math_qa\n",
       " \tsha: 3a67e50740e0cfbd0ee13bc3b7167ab51f0394fc\n",
       " \tlastModified: 2022-08-24T11:33:45.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|aqua_rat', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.\n",
       " \tcitation: \n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['crowdsourced', 'expert-generated'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'MathQA', 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|aqua_rat'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'mathqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 13590\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: mathqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: matinf\n",
       " \tsha: 28ed2d13e6fd83bc3f9a7d2fc16d63d9d647775a\n",
       " \tlastModified: 2022-05-04T18:34:32.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MATINF is the first jointly labeled large-scale dataset for classification, question answering and summarization.\n",
       "  MATINF contains 1.07 million question-answer pairs with human-labeled categories and user-generated question\n",
       "  descriptions. Based on such rich information, MATINF is applicable for three major NLP tasks, including classification,\n",
       "  question answering, and summarization. We benchmark existing methods and a novel multi-task baseline over MATINF to\n",
       "  inspire further research. Our comprehensive comparison and experiments over MATINF and other datasets demonstrate the\n",
       "  merits held by MATINF.\n",
       " \tcitation: @inproceedings{xu-etal-2020-matinf,\n",
       "     title = \"{MATINF}: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization\",\n",
       "     author = \"Xu, Canwen  and\n",
       "       Pei, Jiaxin  and\n",
       "       Wu, Hongtao  and\n",
       "       Liu, Yiyu  and\n",
       "       Li, Chenliang\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.330\",\n",
       "     pages = \"3586--3596\",\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': 'matinf', 'pretty_name': 'Maternal and Infant Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 801\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: matinf\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mbpp\n",
       " \tsha: 9f0faf100c6702959aa97e999b56bcc6fd676e80\n",
       " \tlastModified: 2022-09-13T12:27:48.000Z\n",
       " \ttags: ['arxiv:2108.07732', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-code-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\n",
       " programming problems, designed to be solvable by entry level programmers, covering programming\n",
       " fundamentals, standard library functionality, and so on. Each problem consists of a task\n",
       " description, code solution and 3 automated test cases. The sanitized subset of the data has been\n",
       " hand-verified by the authors.\n",
       " \tcitation: @article{austin2021program,\n",
       "   title={Program Synthesis with Large Language Models},\n",
       "   author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},\n",
       "   journal={arXiv preprint arXiv:2108.07732},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Mostly Basic Python Problems', 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-code-generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 737\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mc4\n",
       " \tsha: 4cafefa2c30246e50b2b101bf90cafa387887422\n",
       " \tlastModified: 2022-10-05T14:04:19.000Z\n",
       " \ttags: ['arxiv:1910.10683', 'annotations_creators:no-annotation', 'language_creators:found', 'language:af', 'language:am', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:ca', 'language:ceb', 'language:co', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:haw', 'language:he', 'language:hi', 'language:hmn', 'language:ht', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:iw', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lb', 'language:lo', 'language:lt', 'language:lv', 'language:mg', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:ne', 'language:nl', 'language:no', 'language:ny', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:sm', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:st', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tr', 'language:uk', 'language:und', 'language:ur', 'language:uz', 'language:vi', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language_bcp47:bg-Latn', 'language_bcp47:el-Latn', 'language_bcp47:hi-Latn', 'language_bcp47:ja-Latn', 'language_bcp47:ru-Latn', 'language_bcp47:zh-Latn', 'license:odc-by', 'multilinguality:multilingual', 'size_categories:n<1K', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'size_categories:10M<n<100M', 'size_categories:100M<n<1B', 'size_categories:1B<n<10B', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A colossal, cleaned version of Common Crawl's web crawl corpus.\n",
       " \n",
       " Based on Common Crawl dataset: \"https://commoncrawl.org\".\n",
       " \n",
       " This is the processed version of Google's mC4 dataset by AllenAI.\n",
       " \tcitation: @article{2019t5,\n",
       "     author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n",
       "     title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n",
       "     journal = {arXiv e-prints},\n",
       "     year = {2019},\n",
       "     archivePrefix = {arXiv},\n",
       "     eprint = {1910.10683},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'mC4', 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['af', 'am', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'ceb', 'co', 'cs', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fil', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'haw', 'he', 'hi', 'hmn', 'ht', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'iw', 'ja', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'ne', 'nl', 'no', 'ny', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sd', 'si', 'sk', 'sl', 'sm', 'sn', 'so', 'sq', 'sr', 'st', 'su', 'sv', 'sw', 'ta', 'te', 'tg', 'th', 'tr', 'uk', 'und', 'ur', 'uz', 'vi', 'xh', 'yi', 'yo', 'zh', 'zu'], 'language_bcp47': ['bg-Latn', 'el-Latn', 'hi-Latn', 'ja-Latn', 'ru-Latn', 'zh-Latn'], 'license': ['odc-by'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K', '1K<n<10K', '10K<n<100K', '100K<n<1M', '1M<n<10M', '10M<n<100M', '100M<n<1B', '1B<n<10B'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'mc4'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 19743\n",
       " \tlikes: 25\n",
       " \tpaperswithcode_id: mc4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mc_taco\n",
       " \tsha: fa52ba33d6e0ccb450fe146363dd824146a1e082\n",
       " \tlastModified: 2022-08-11T12:57:27.000Z\n",
       " \ttags: ['arxiv:1909.03065', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MC-TACO (Multiple Choice TemporAl COmmonsense) is a dataset of 13k question-answer\n",
       " pairs that require temporal commonsense comprehension. A system receives a sentence\n",
       " providing context information, a question designed to require temporal commonsense\n",
       " knowledge, and multiple candidate answers. More than one candidate answer can be plausible.\n",
       " \n",
       " The task is framed as binary classification: givent he context, the question,\n",
       " and the candidate answer, the task is to determine whether the candidate\n",
       " answer is plausible (\"yes\") or not (\"no\").\n",
       " \tcitation: @inproceedings{ZKNR19,\n",
       "     author = {Ben Zhou, Daniel Khashabi, Qiang Ning and Dan Roth},\n",
       "     title = {“Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding },\n",
       "     booktitle = {EMNLP},\n",
       "     year = {2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'mc-taco', 'pretty_name': 'MC-TACO'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1485\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: mc-taco\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: md_gender_bias\n",
       " \tsha: 9791da45bb0316ee30fe36a8cecc0ce2513d63bd\n",
       " \tlastModified: 2022-07-01T11:53:57.000Z\n",
       " \ttags: ['arxiv:1811.00552', 'annotations_creators:crowdsourced', 'annotations_creators:found', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:extended|other-convai2', 'source_datasets:extended|other-light', 'source_datasets:extended|other-opensubtitles', 'source_datasets:extended|other-yelp', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-gender-bias', 'configs:convai2_inferred', 'configs:funpedia', 'configs:gendered_words', 'configs:image_chat', 'configs:light_inferred', 'configs:name_genders', 'configs:new_data', 'configs:opensubtitles_inferred', 'configs:wizard', 'configs:yelp_inferred']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Machine learning models are trained to find patterns in data.\n",
       " NLP models can inadvertently learn socially undesirable patterns when training on gender biased text.\n",
       " In this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions:\n",
       " bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker.\n",
       " Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information.\n",
       " In addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites.\n",
       " Distinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers.\n",
       " We show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models,\n",
       " detecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.\n",
       " \tcitation: @inproceedings{md_gender_bias,\n",
       "   author    = {Emily Dinan and\n",
       "                Angela Fan and\n",
       "                Ledell Wu and\n",
       "                Jason Weston and\n",
       "                Douwe Kiela and\n",
       "                Adina Williams},\n",
       "   editor    = {Bonnie Webber and\n",
       "                Trevor Cohn and\n",
       "                Yulan He and\n",
       "                Yang Liu},\n",
       "   title     = {Multi-Dimensional Gender Bias Classification},\n",
       "   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural\n",
       "                Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},\n",
       "   pages     = {314--331},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year      = {2020},\n",
       "   url       = {https://www.aclweb.org/anthology/2020.emnlp-main.23/}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Multi-Dimensional Gender Bias Classification', 'annotations_creators': ['crowdsourced', 'found', 'machine-generated'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', '1M<n<10M', 'n<1K'], 'source_datasets': ['extended|other-convai2', 'extended|other-light', 'extended|other-opensubtitles', 'extended|other-yelp', 'original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-gender-bias'], 'paperswithcode_id': 'md-gender', 'configs': ['convai2_inferred', 'funpedia', 'gendered_words', 'image_chat', 'light_inferred', 'name_genders', 'new_data', 'opensubtitles_inferred', 'wizard', 'yelp_inferred']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1922\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: md-gender\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mdd\n",
       " \tsha: 72910980a2aaa63695dce03d402b15091e0f1461\n",
       " \tlastModified: 2022-07-01T11:53:57.000Z\n",
       " \ttags: ['arxiv:1511.06931', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling', 'configs:task1_qa', 'configs:task2_recs', 'configs:task3_qarecs', 'configs:task4_reddit']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Movie Dialog dataset (MDD) is designed to measure how well\n",
       " models can perform at goal and non-goal orientated dialog\n",
       " centered around the topic of movies (question answering,\n",
       " recommendation and discussion).\n",
       " \tcitation: @misc{dodge2016evaluating,\n",
       "       title={Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems},\n",
       "       author={Jesse Dodge and Andreea Gane and Xiang Zhang and Antoine Bordes and Sumit Chopra and Alexander Miller and Arthur Szlam and Jason Weston},\n",
       "       year={2016},\n",
       "       eprint={1511.06931},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'mdd', 'pretty_name': 'Movie Dialog dataset (MDD)', 'configs': ['task1_qa', 'task2_recs', 'task3_qarecs', 'task4_reddit']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1288\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: mdd\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: med_hop\n",
       " \tsha: f945bc516522973dc624997a4298596dff528698\n",
       " \tlastModified: 2022-08-11T12:57:27.000Z\n",
       " \ttags: ['arxiv:1710.06481', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-multi-hop']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MedHop is based on research paper abstracts from PubMed, and the queries are about interactions between pairs of drugs. The correct answer has to be inferred by combining information from a chain of reactions of drugs and proteins.\n",
       " \tcitation: @misc{welbl2018constructing,\n",
       "       title={Constructing Datasets for Multi-hop Reading Comprehension Across Documents},\n",
       "       author={Johannes Welbl and Pontus Stenetorp and Sebastian Riedel},\n",
       "       year={2018},\n",
       "       eprint={1710.06481},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-multi-hop'], 'paperswithcode_id': 'medhop', 'pretty_name': 'MedHop'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 482\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: medhop\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: medal\n",
       " \tsha: 5211f3569e4d15815cd8e1af5d60b6962f3a6e2c\n",
       " \tlastModified: 2022-07-01T11:53:57.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-disambiguation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large medical text dataset (14Go) curated to 4Go for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. For example, DHF can be disambiguated to dihydrofolate, diastolic heart failure, dengue hemorragic fever or dihydroxyfumarate\n",
       " \tcitation: @inproceedings{wen-etal-2020-medal,\n",
       "     title = \"{M}e{DAL}: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining\",\n",
       "     author = \"Wen, Zhi  and\n",
       "       Lu, Xing Han  and\n",
       "       Reddy, Siva\",\n",
       "     booktitle = \"Proceedings of the 3rd Clinical Natural Language Processing Workshop\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.clinicalnlp-1.15\",\n",
       "     pages = \"130--135\",\n",
       "     abstract = \"One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-disambiguation'], 'paperswithcode_id': 'medal', 'pretty_name': 'MeDAL'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 567\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: medal\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: medical_dialog\n",
       " \tsha: 134f75ec45df6de9c9f97f277cfedfe52cb587d0\n",
       " \tlastModified: 2022-07-01T11:53:58.000Z\n",
       " \ttags: ['arxiv:2004.03329', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa', 'configs:en', 'configs:zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The MedDialog dataset (English) contains conversations (in English) between doctors and patients.It has 0.26 million dialogues. The data is continuously growing and more dialogues will be added. The raw dialogues are from healthcaremagic.com and icliniq.com.\n",
       " All copyrights of the data belong to healthcaremagic.com and icliniq.com.\n",
       " \tcitation: @article{chen2020meddiag,\n",
       "   title={MedDialog: a large-scale medical dialogue dataset},\n",
       "   author={Chen, Shu and Ju, Zeqian and Dong, Xiangyu and Fang, Hongchao and Wang, Sicheng and Yang, Yue and Zeng, Jiaqi and Zhang, Ruisi and Zhang, Ruoyu and Zhou, Meng and Zhu, Penghui and Xie, Pengtao},\n",
       "   journal={arXiv preprint arXiv:2004.03329},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['expert-generated', 'found'], 'language': ['en', 'zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'MedDialog', 'configs': ['en', 'zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 726\n",
       " \tlikes: 6\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: medical_questions_pairs\n",
       " \tsha: 27a4d07b7fde8cdd17cabd61255ebb52ceb7ac5f\n",
       " \tlastModified: 2022-07-01T11:54:00.000Z\n",
       " \ttags: ['arxiv:2008.13546', 'annotations_creators:expert-generated', 'language_creators:other', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset consists of 3048 similar and dissimilar medical question pairs hand-generated and labeled by Curai's doctors.\n",
       " \tcitation: @misc{mccreery2020effective,\n",
       "       title={Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n",
       "       author={Clara H. McCreery and Namit Katariya and Anitha Kannan and Manish Chablani and Xavier Amatriain},\n",
       "       year={2020},\n",
       "       eprint={2008.13546},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.IR}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification'], 'paperswithcode_id': None, 'pretty_name': 'MedicalQuestionsPairs'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1599\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: menyo20k_mt\n",
       " \tsha: 2448e381c72b28b868567d2407839411df22f1b6\n",
       " \tlastModified: 2022-07-01T11:54:00.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:found', 'language_creators:found', 'language:en', 'language:yo', 'license:cc-by-4.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MENYO-20k is a multi-domain parallel dataset with texts obtained from news articles, ted talks, movie transcripts, radio transcripts, science and technology texts, and other short articles curated from the web and professional translators. The dataset has 20,100 parallel sentences split into 10,070 training sentences, 3,397 development sentences, and 6,633 test sentences (3,419 multi-domain, 1,714 news domain, and 1,500 ted talks speech transcript domain). The development and test sets are available upon request.\n",
       " \tcitation: @dataset{david_ifeoluwa_adelani_2020_4297448,\n",
       "   author       = {David Ifeoluwa Adelani and\n",
       "                   Jesujoba O. Alabi and\n",
       "                   Damilola Adebonojo and\n",
       "                   Adesina Ayeni and\n",
       "                   Mofe Adeyemi and\n",
       "                   Ayodele Awokoya},\n",
       "   title        = {MENYO-20k: A Multi-domain English - Yorùbá Corpus\n",
       "                   for Machine Translation},\n",
       "   month        = nov,\n",
       "   year         = 2020,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {1.0},\n",
       "   doi          = {10.5281/zenodo.4297448},\n",
       "   url          = {https://doi.org/10.5281/zenodo.4297448}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'found'], 'language_creators': ['found'], 'language': ['en', 'yo'], 'license': ['cc-by-4.0'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'MENYO-20k'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: meta_woz\n",
       " \tsha: 41c9281454a6d81ede664d42a88c84812a38d84d\n",
       " \tlastModified: 2022-07-01T12:43:34.000Z\n",
       " \ttags: ['arxiv:2003.01680', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MetaLWOz: A Dataset of Multi-Domain Dialogues for the Fast Adaptation of Conversation Models. We introduce the Meta-Learning Wizard of Oz (MetaLWOz) dialogue dataset for developing fast adaptation methods for conversation models. This data can be used to train task-oriented dialogue models, specifically to develop methods to quickly simulate user responses with a small amount of data. Such fast-adaptation models fall into the research areas of transfer learning and meta learning. The dataset consists of 37,884 crowdsourced dialogues recorded between two human users in a Wizard of Oz setup, in which one was instructed to behave like a bot, and the other a true human user. The users are assigned a task belonging to a particular domain, for example booking a reservation at a particular restaurant, and work together to complete the task. Our dataset spans 47 domains having 227 tasks total. Dialogues are a minimum of 10 turns long.\n",
       " \tcitation: @InProceedings{shalyminov2020fast,\n",
       " author = {Shalyminov, Igor and Sordoni, Alessandro and Atkinson, Adam and Schulz, Hannes},\n",
       " title = {Fast Domain Adaptation For Goal-Oriented Dialogue Using A Hybrid Generative-Retrieval Transformer},\n",
       " booktitle = {2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n",
       " year = {2020},\n",
       " month = {April},\n",
       " url = {https://www.microsoft.com/en-us/research/publication/fast-domain-adaptation-for-goal-oriented-dialogue-using-a\n",
       " -hybrid-generative-retrieval-transformer/},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['other'], 'license_details': 'Microsoft Research Data License Agreement', 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'metalwoz', 'pretty_name': 'Meta-Learning Wizard-of-Oz'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 924\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: metalwoz\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: metooma\n",
       " \tsha: febc6264a27677554094da1c0928dbd1af292b3d\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:text-retrieval', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset consists of tweets belonging to #MeToo movement on Twitter, labelled into different categories.\n",
       " Due to Twitter's development policies, we only provide the tweet ID's and corresponding labels,\n",
       " other data can be fetched via Twitter API.\n",
       " The data has been labelled by experts, with the majority taken into the account for deciding the final label.\n",
       " We provide these labels for each of the tweets. The labels provided for each data point\n",
       " includes -- Relevance, Directed Hate, Generalized Hate,\n",
       " Sarcasm, Allegation, Justification, Refutation, Support, Oppose\n",
       " \tcitation: @inproceedings{gautam2020metooma,\n",
       "     title={# MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo Movement},\n",
       "     author={Gautam, Akash and Mathur, Puneet and Gosangi, Rakesh and Mahata, Debanjan and Sawhney, Ramit and Shah, Rajiv Ratn},\n",
       "     booktitle={Proceedings of the International AAAI Conference on Web and Social Media},\n",
       "     volume={14},\n",
       "     pages={209--216},\n",
       "     year={2020} }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification', 'text-retrieval'], 'task_ids': ['multi-class-classification', 'multi-label-classification'], 'paperswithcode_id': 'metooma', 'pretty_name': '#MeTooMA dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: metooma\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: metrec\n",
       " \tsha: a1de632ec996d7e42cada4f9f69bbd6dcb916b1a\n",
       " \tlastModified: 2022-07-01T11:54:04.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-poetry-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Arabic Poetry Metric Classification.\n",
       " The dataset contains the verses and their corresponding meter classes.Meter classes are represented as numbers from 0 to 13. The dataset can be highly useful for further research in order to improve the field of Arabic poems’ meter classification.The train dataset contains 47,124 records and the test dataset contains 8316 records.\n",
       " \tcitation: @article{metrec2020,\n",
       "   title={MetRec: A dataset for meter classification of arabic poetry},\n",
       "   author={Al-shaibani, Maged S and Alyafeai, Zaid and Ahmad, Irfan},\n",
       "   journal={Data in Brief},\n",
       "   year={2020},\n",
       "   publisher={Elsevier}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-poetry-classification'], 'paperswithcode_id': 'metrec', 'pretty_name': 'MetRec'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: metrec\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: miam\n",
       " \tsha: 23d9f85652cb881e1c1473220de67aa68fadb022\n",
       " \tlastModified: 2022-08-14T10:26:33.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:text-classification-other-dialogue-act-classification', 'configs:dihana', 'configs:ilisten', 'configs:loria', 'configs:maptask', 'configs:vm2']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multilingual dIalogAct benchMark is a collection of resources for training, evaluating, and\n",
       " analyzing natural language understanding systems specifically designed for spoken language. Datasets\n",
       " are in English, French, German, Italian and Spanish. They cover a variety of domains including\n",
       " spontaneous speech, scripted scenarios, and joint task completion. Some datasets additionally include\n",
       " emotion and/or sentimant labels.\n",
       " \tcitation: @unpublished{\n",
       " anonymous2021cross-lingual,\n",
       " title={Cross-Lingual Pretraining Methods for Spoken Dialog},\n",
       " author={Anonymous},\n",
       " journal={OpenReview Preprint},\n",
       " year={2021},\n",
       " url{https://openreview.net/forum?id=c1oDhu_hagR},\n",
       " note={anonymous preprint under review}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['de', 'en', 'es', 'fr', 'it'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['dialogue-modeling', 'language-modeling', 'masked-language-modeling', 'text-classification-other-dialogue-act-classification'], 'paperswithcode_id': None, 'pretty_name': 'MIAM', 'configs': ['dihana', 'ilisten', 'loria', 'maptask', 'vm2']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1061\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mkb\n",
       " \tsha: 20c32b338e13691dba811f978c8deb9ef4cd273e\n",
       " \tlastModified: 2022-07-27T14:38:47.000Z\n",
       " \ttags: ['arxiv:2007.07691', 'task_categories:text-generation', 'task_categories:fill-mask', 'multilinguality:translation', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'language:bn', 'language:en', 'language:gu', 'language:hi', 'language:ml', 'language:mr', 'language:or', 'language:pa', 'language:ta', 'language:te', 'language:ur', 'annotations_creators:no-annotation', 'source_datasets:original', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'license:cc-by-4.0', 'configs:bn-en', 'configs:bn-gu', 'configs:bn-hi', 'configs:bn-ml', 'configs:bn-mr', 'configs:bn-or', 'configs:bn-ta', 'configs:bn-te', 'configs:bn-ur', 'configs:en-gu', 'configs:en-hi', 'configs:en-ml', 'configs:en-mr', 'configs:en-or', 'configs:en-ta', 'configs:en-te', 'configs:en-ur', 'configs:gu-hi', 'configs:gu-ml', 'configs:gu-mr', 'configs:gu-or', 'configs:gu-ta', 'configs:gu-te', 'configs:gu-ur', 'configs:hi-ml', 'configs:hi-mr', 'configs:hi-or', 'configs:hi-ta', 'configs:hi-te', 'configs:hi-ur', 'configs:ml-mr', 'configs:ml-or', 'configs:ml-ta', 'configs:ml-te', 'configs:ml-ur', 'configs:mr-or', 'configs:mr-ta', 'configs:mr-te', 'configs:mr-ur', 'configs:or-ta', 'configs:or-te', 'configs:or-ur', 'configs:ta-te', 'configs:ta-ur', 'configs:te-ur']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Prime Minister's speeches - Mann Ki Baat, on All India Radio, translated into many languages.\n",
       " \tcitation: @misc{siripragada2020multilingual,\n",
       "       title={A Multilingual Parallel Corpora Collection Effort for Indian Languages},\n",
       "       author={Shashank Siripragada and Jerin Philip and Vinay P. Namboodiri and C V Jawahar},\n",
       "       year={2020},\n",
       "       eprint={2007.07691},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'task_categories': ['text-generation', 'fill-mask'], 'multilinguality': ['translation'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'language': ['bn', 'en', 'gu', 'hi', 'ml', 'mr', 'or', 'pa', 'ta', 'te', 'ur'], 'annotations_creators': ['no-annotation'], 'source_datasets': ['original'], 'size_categories': ['1K<n<10K', 'n<1K'], 'license': ['cc-by-4.0'], 'paperswithcode_id': None, 'pretty_name': 'CVIT MKB', 'configs': ['bn-en', 'bn-gu', 'bn-hi', 'bn-ml', 'bn-mr', 'bn-or', 'bn-ta', 'bn-te', 'bn-ur', 'en-gu', 'en-hi', 'en-ml', 'en-mr', 'en-or', 'en-ta', 'en-te', 'en-ur', 'gu-hi', 'gu-ml', 'gu-mr', 'gu-or', 'gu-ta', 'gu-te', 'gu-ur', 'hi-ml', 'hi-mr', 'hi-or', 'hi-ta', 'hi-te', 'hi-ur', 'ml-mr', 'ml-or', 'ml-ta', 'ml-te', 'ml-ur', 'mr-or', 'mr-ta', 'mr-te', 'mr-ur', 'or-ta', 'or-te', 'or-ur', 'ta-te', 'ta-ur', 'te-ur']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7187\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mkqa\n",
       " \tsha: db2f2b1048c909ad29f5f1c35aa6abf7f8e2731f\n",
       " \tlastModified: 2022-08-11T09:38:24.000Z\n",
       " \ttags: ['arxiv:2007.15207', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:ar', 'language:da', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:km', 'language:ko', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-3.0', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:extended|natural_questions', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.\n",
       " \tcitation: @misc{mkqa,\n",
       "     title = {MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering},\n",
       "     author = {Shayne Longpre and Yi Lu and Joachim Daiber},\n",
       "     year = {2020},\n",
       "     URL = {https://arxiv.org/pdf/2007.15207.pdf}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ar', 'da', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hu', 'it', 'ja', 'km', 'ko', 'ms', 'nl', 'no', 'pl', 'pt', 'ru', 'sv', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-3.0'], 'multilinguality': ['multilingual', 'translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|natural_questions', 'original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'mkqa', 'pretty_name': 'Multilingual Knowledge Questions and Answers'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: mkqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mlqa\n",
       " \tsha: 9e433ff4cacc12c8a424c2e9e5719d5adf65d831\n",
       " \tlastModified: 2022-08-09T13:27:25.000Z\n",
       " \ttags: ['language:en', 'language:de', 'language:es', 'language:ar', 'language:zh', 'language:vi', 'language:hi', 'license:cc-by-sa-3.0', 'source_datasets:original', 'size_categories:10K<n<100K', 'language_creators:crowdsourced', 'annotations_creators:crowdsourced', 'multilinguality:multilingual', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     MLQA (MultiLingual Question Answering) is a benchmark dataset for evaluating cross-lingual question answering performance.\n",
       "     MLQA consists of over 5K extractive QA instances (12K in English) in SQuAD format in seven languages - English, Arabic,\n",
       "     German, Spanish, Hindi, Vietnamese and Simplified Chinese. MLQA is highly parallel, with QA instances parallel between\n",
       "     4 different languages on average.\n",
       " \tcitation: @article{lewis2019mlqa,\n",
       "   title={MLQA: Evaluating Cross-lingual Extractive Question Answering},\n",
       "   author={Lewis, Patrick and Oguz, Barlas and Rinott, Ruty and Riedel, Sebastian and Schwenk, Holger},\n",
       "   journal={arXiv preprint arXiv:1910.07475},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'MLQA (MultiLingual Question Answering)', 'language': ['en', 'de', 'es', 'ar', 'zh', 'vi', 'hi'], 'license': ['cc-by-sa-3.0'], 'source_datasets': ['original'], 'size_categories': ['10K<n<100K'], 'language_creators': ['crowdsourced'], 'annotations_creators': ['crowdsourced'], 'multilinguality': ['multilingual'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'mlqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 12129\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: mlqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mlsum\n",
       " \tsha: cbeab7f5084245cbb149ea98f8c5d8e23679fd07\n",
       " \tlastModified: 2022-07-21T12:40:33.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:de', 'language:es', 'language:fr', 'language:ru', 'language:tr', 'license:other', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:extended|cnn_dailymail', 'source_datasets:original', 'task_categories:summarization', 'task_categories:translation', 'task_categories:text-classification', 'task_ids:news-articles-summarization', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:topic-classification', 'configs:de', 'configs:es', 'configs:fr', 'configs:ru', 'configs:tu']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We present MLSUM, the first large-scale MultiLingual SUMmarization dataset.\n",
       " Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish.\n",
       " Together with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community.\n",
       " We report cross-lingual comparative analyses based on state-of-the-art systems.\n",
       " These highlight existing biases which motivate the use of a multi-lingual dataset.\n",
       " \tcitation: @article{scialom2020mlsum,\n",
       "   title={MLSUM: The Multilingual Summarization Corpus},\n",
       "   author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},\n",
       "   journal={arXiv preprint arXiv:2004.14900},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['de', 'es', 'fr', 'ru', 'tr'], 'license': ['other'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['extended|cnn_dailymail', 'original'], 'task_categories': ['summarization', 'translation', 'text-classification'], 'task_ids': ['news-articles-summarization', 'multi-class-classification', 'multi-label-classification', 'topic-classification'], 'paperswithcode_id': 'mlsum', 'pretty_name': 'MLSUM', 'configs': ['de', 'es', 'fr', 'ru', 'tu']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2151\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: mlsum\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mnist\n",
       " \tsha: de9625c6cd440a29515e0acc58c106b5ab61c214\n",
       " \tlastModified: 2022-07-01T11:54:07.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-nist', 'task_categories:image-classification', 'task_ids:multi-class-image-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\n",
       " images per class. There are 60,000 training images and 10,000 test images.\n",
       " \tcitation: @article{lecun2010mnist,\n",
       "   title={MNIST handwritten digit database},\n",
       "   author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "   journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "   volume={2},\n",
       "   year={2010}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-nist'], 'task_categories': ['image-classification'], 'task_ids': ['multi-class-image-classification'], 'paperswithcode_id': 'mnist', 'pretty_name': 'MNIST'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5341\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: mnist\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mocha\n",
       " \tsha: 4a2df1d771519917a369bf287bb3652a75c2b7ec\n",
       " \tlastModified: 2022-07-01T11:54:09.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-generative-reading-comprehension-metric']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Posing reading comprehension as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. To address this, we introduce a benchmark for training and evaluating generative reading comprehension metrics: MOdeling Correctness with Human Annotations. MOCHA contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train an evaluation metric: LERC, a Learned Evaluation metric for Reading Comprehension, to mimic human judgement scores.\n",
       " \tcitation: @inproceedings{Chen2020MOCHAAD,\n",
       "     author={Anthony Chen and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
       "     title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
       "     booktitle={EMNLP},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'MOCHA', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-generative-reading-comprehension-metric'], 'paperswithcode_id': 'mocha'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 570\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: mocha\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: moroco\n",
       " \tsha: c58f8137f0274f72434891515de13fcec7a83885\n",
       " \tlastModified: 2022-07-27T14:38:47.000Z\n",
       " \ttags: ['arxiv:1901.06543', 'annotations_creators:found', 'language_creators:found', 'language:ro', 'language_bcp47:ro-MD', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The MOROCO (Moldavian and Romanian Dialectal Corpus) dataset contains 33564 samples of text collected from the news domain.\n",
       " The samples belong to one of the following six topics:\n",
       "     - culture\n",
       "     - finance\n",
       "     - politics\n",
       "     - science\n",
       "     - sports\n",
       "     - tech\n",
       " \tcitation: @inproceedings{ Butnaru-ACL-2019,\n",
       "     author = {Andrei M. Butnaru and Radu Tudor Ionescu},\n",
       "     title = \"{MOROCO: The Moldavian and Romanian Dialectal Corpus}\",\n",
       "     booktitle = {Proceedings of ACL},\n",
       "     year = {2019},\n",
       "     pages={688--698},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ro'], 'language_bcp47': ['ro-MD'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': 'moroco', 'pretty_name': 'MOROCO: The Moldavian and Romanian Dialectal Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: moroco\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: movie_rationales\n",
       " \tsha: 795fcfadf9d3df8c38e40be8d79a37326b5cc86d\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The movie rationale dataset contains human annotated rationales for movie\n",
       " reviews.\n",
       " \tcitation: @unpublished{eraser2019,\n",
       "     title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n",
       "     author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n",
       " }\n",
       " @InProceedings{zaidan-eisner-piatko-2008:nips,\n",
       "   author    =  {Omar F. Zaidan  and  Jason Eisner  and  Christine Piatko},\n",
       "   title     =  {Machine Learning with Annotator Rationales to Reduce Annotation Cost},\n",
       "   booktitle =  {Proceedings of the NIPS*2008 Workshop on Cost Sensitive Learning},\n",
       "   month     =  {December},\n",
       "   year      =  {2008}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'MovieRationales', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 614\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mrqa\n",
       " \tsha: c43560ba09a45327e990a21453a949dafdd2ad8e\n",
       " \tlastModified: 2022-08-11T12:57:27.000Z\n",
       " \ttags: ['arxiv:1910.09753', 'arxiv:1606.05250', 'arxiv:1611.09830', 'arxiv:1705.03551', 'arxiv:1704.05179', 'arxiv:1809.09600', 'arxiv:1903.00161', 'arxiv:1804.07927', 'arxiv:1704.04683', 'arxiv:1706.04115', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|drop', 'source_datasets:extended|hotpot_qa', 'source_datasets:extended|natural_questions', 'source_datasets:extended|race', 'source_datasets:extended|search_qa', 'source_datasets:extended|squad', 'source_datasets:extended|trivia_qa', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The MRQA 2019 Shared Task focuses on generalization in question answering.\n",
       " An effective question answering system should do more than merely\n",
       " interpolate from the training set to answer test examples drawn\n",
       " from the same distribution: it should also be able to extrapolate\n",
       " to out-of-distribution examples — a significantly harder challenge.\n",
       " \n",
       " The dataset is a collection of 18 existing QA dataset (carefully selected\n",
       " subset of them) and converted to the same format (SQuAD format). Among\n",
       " these 18 datasets, six datasets were made available for training,\n",
       " six datasets were made available for development, and the final six\n",
       " for testing. The dataset is released as part of the MRQA 2019 Shared Task.\n",
       " \tcitation: @inproceedings{fisch2019mrqa,\n",
       "     title={{MRQA} 2019 Shared Task: Evaluating Generalization in Reading Comprehension},\n",
       "     author={Adam Fisch and Alon Talmor and Robin Jia and Minjoon Seo and Eunsol Choi and Danqi Chen},\n",
       "     booktitle={Proceedings of 2nd Machine Reading for Reading Comprehension (MRQA) Workshop at EMNLP},\n",
       "     year={2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|drop', 'extended|hotpot_qa', 'extended|natural_questions', 'extended|race', 'extended|search_qa', 'extended|squad', 'extended|trivia_qa'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'mrqa-2019', 'pretty_name': 'MRQA 2019'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3744\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: mrqa-2019\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ms_marco\n",
       " \tsha: f5c2daf536ceb2bd61c59b159182c09c5366cab5\n",
       " \tlastModified: 2022-07-01T11:54:11.000Z\n",
       " \ttags: ['arxiv:1611.09268', 'language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Starting with a paper released at NIPS 2016, MS MARCO is a collection of datasets focused on deep learning in search.\n",
       " \n",
       " The first dataset was a question answering dataset featuring 100,000 real Bing questions and a human generated answer.\n",
       " Since then we released a 1,000,000 question dataset, a natural langauge generation dataset, a passage ranking dataset,\n",
       " keyphrase extraction dataset, crawling dataset, and a conversational search.\n",
       " \n",
       " There have been 277 submissions. 20 KeyPhrase Extraction submissions, 87 passage ranking submissions, 0 document ranking\n",
       " submissions, 73 QnA V2 submissions, 82 NLGEN submisions, and 15 QnA V1 submissions\n",
       " \n",
       " This data comes in three tasks/forms: Original QnA dataset(v1.1), Question Answering(v2.1), Natural Language Generation(v2.1).\n",
       " \n",
       " The original question answering datset featured 100,000 examples and was released in 2016. Leaderboard is now closed but data is availible below.\n",
       " \n",
       " The current competitive tasks are Question Answering and Natural Language Generation. Question Answering features over 1,000,000 queries and\n",
       " is much like the original QnA dataset but bigger and with higher quality. The Natural Language Generation dataset features 180,000 examples and\n",
       " builds upon the QnA dataset to deliver answers that could be spoken by a smart speaker.\n",
       " \tcitation: @article{DBLP:journals/corr/NguyenRSGTMD16,\n",
       "   author    = {Tri Nguyen and\n",
       "                Mir Rosenberg and\n",
       "                Xia Song and\n",
       "                Jianfeng Gao and\n",
       "                Saurabh Tiwary and\n",
       "                Rangan Majumder and\n",
       "                Li Deng},\n",
       "   title     = {{MS} {MARCO:} {A} Human Generated MAchine Reading COmprehension Dataset},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1611.09268},\n",
       "   year      = {2016},\n",
       "   url       = {http://arxiv.org/abs/1611.09268},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1611.09268},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:49:03 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/NguyenRSGTMD16.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'ms-marco', 'pretty_name': 'Microsoft Machine Reading Comprehension Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1263\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: ms-marco\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ms_terms\n",
       " \tsha: 1ef2b6777ef7b5921fe9e84f03a1b6874339e281\n",
       " \tlastModified: 2022-07-27T14:38:47.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:af', 'language:am', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:bs', 'language:ca', 'language:chr', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:guc', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:knn', 'language:ko', 'language:ku', 'language:ky', 'language:lb', 'language:lo', 'language:lt', 'language:lv', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:ory', 'language:pa', 'language:pl', 'language:prs', 'language:pst', 'language:pt', 'language:qu', 'language:quc', 'language:ro', 'language:ru', 'language:rw', 'language:sd', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:st', 'language:sv', 'language:swh', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:ti', 'language:tk', 'language:tn', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wo', 'language:xh', 'language:yo', 'language:zh', 'language:zu', 'language_bcp47:bn-IN', 'language_bcp47:bs-Latn', 'language_bcp47:es-MX', 'language_bcp47:fr-CA', 'language_bcp47:ms-BN', 'language_bcp47:pt-BR', 'language_bcp47:sr-BH', 'language_bcp47:sr-Latn', 'language_bcp47:zh-Hant-HK', 'language_bcp47:zh-Hant-TW', 'license:ms-pl', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\n",
       " It can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\n",
       " for language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'bs', 'ca', 'chr', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fil', 'fr', 'ga', 'gd', 'gl', 'gu', 'guc', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'iu', 'ja', 'ka', 'kk', 'km', 'kn', 'knn', 'ko', 'ku', 'ky', 'lb', 'lo', 'lt', 'lv', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'nb', 'ne', 'nl', 'nn', 'ory', 'pa', 'pl', 'prs', 'pst', 'pt', 'qu', 'quc', 'ro', 'ru', 'rw', 'sd', 'si', 'sk', 'sl', 'sq', 'sr', 'st', 'sv', 'swh', 'ta', 'te', 'tg', 'th', 'ti', 'tk', 'tn', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'wo', 'xh', 'yo', 'zh', 'zu'], 'language_bcp47': ['bn-IN', 'bs-Latn', 'es-MX', 'fr-CA', 'ms-BN', 'pt-BR', 'sr-BH', 'sr-Latn', 'zh-Hant-HK', 'zh-Hant-TW'], 'license': ['ms-pl'], 'multilinguality': ['multilingual', 'translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'MsTerms'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: msr_genomics_kbcomp\n",
       " \tsha: 911c8b3d5c5cfe034fa4f9542619d72a75410523\n",
       " \tlastModified: 2022-07-01T12:43:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-NCI-PID-PubMed Genomics Knowledge Base Completion Dataset']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The database is derived from the NCI PID Pathway Interaction Database, and the textual mentions are extracted from cooccurring pairs of genes in PubMed abstracts, processed and annotated by Literome (Poon et al. 2014). This dataset was used in the paper “Compositional Learning of Embeddings for Relation Paths in Knowledge Bases and Text” (Toutanova, Lin, Yih, Poon, and Quirk, 2016).\n",
       " \tcitation: @inproceedings{toutanova-etal-2016-compositional,\n",
       "     title = \"Compositional Learning of Embeddings for Relation Paths in Knowledge Base and Text\",\n",
       "     author = \"Toutanova, Kristina  and\n",
       "       Lin, Victoria  and\n",
       "       Yih, Wen-tau  and\n",
       "       Poon, Hoifung  and\n",
       "       Quirk, Chris\",\n",
       "     booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
       "     month = aug,\n",
       "     year = \"2016\",\n",
       "     address = \"Berlin, Germany\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P16-1136\",\n",
       "     doi = \"10.18653/v1/P16-1136\",\n",
       "     pages = \"1434--1444\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-NCI-PID-PubMed Genomics Knowledge Base Completion Dataset'], 'paperswithcode_id': None, 'pretty_name': 'MsrGenomicsKbcomp'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: msr_sqa\n",
       " \tsha: fade99188942eaf8e6ead3693020fca91e5d6797\n",
       " \tlastModified: 2022-10-03T09:08:37.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:ms-pl', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Recent work in semantic parsing for question answering has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but inter-related questions. We created SQA by asking crowdsourced workers to decompose 2,022 questions from WikiTableQuestions (WTQ), which contains highly-compositional questions about tables from Wikipedia. We had three workers decompose each WTQ question, resulting in a dataset of 6,066 sequences that contain 17,553 questions in total. Each question is also associated with answers in the form of cell locations in the tables.\n",
       " \tcitation: @inproceedings{iyyer2017search,\n",
       "   title={Search-based neural structured learning for sequential question answering},\n",
       "   author={Iyyer, Mohit and Yih, Wen-tau and Chang, Ming-Wei},\n",
       "   booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n",
       "   pages={1821--1831},\n",
       "   year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['ms-pl'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': None, 'pretty_name': 'Microsoft Research Sequential Question Answering'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: msr_text_compression\n",
       " \tsha: 7a198b46129a55dc876ca1e34eb8ce168b8b1cfb\n",
       " \tlastModified: 2022-07-01T12:43:34.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-Open-American-National-Corpus-(OANC1)', 'task_categories:summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains sentences and short paragraphs with corresponding shorter (compressed) versions. There are up to five compressions for each input text, together with quality judgements of their meaning preservation and grammaticality. The dataset is derived using source texts from the Open American National Corpus (ww.anc.org) and crowd-sourcing.\n",
       " \tcitation: @inproceedings{Toutanova2016ADA,\n",
       "   title={A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs},\n",
       "   author={Kristina Toutanova and Chris Brockett and Ke M. Tran and Saleema Amershi},\n",
       "   booktitle={EMNLP},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'license_details': 'Microsoft Research Data License Agreement', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-Open-American-National-Corpus-(OANC1)'], 'task_categories': ['summarization'], 'task_ids': [], 'pretty_name': 'MsrTextCompression'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: msr_zhen_translation_parity\n",
       " \tsha: a38f1a891c05bc7a870b7c27aacca1ec73b7407b\n",
       " \tlastModified: 2022-07-01T11:54:13.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'license:ms-pl', 'multilinguality:monolingual', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|other-newstest2017', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Translator Human Parity Data\n",
       " \n",
       " Human evaluation results and translation output for the Translator Human Parity Data release,\n",
       " as described in https://blogs.microsoft.com/ai/machine-translation-news-test-set-human-parity/.\n",
       " The Translator Human Parity Data release contains all human evaluation results and translations\n",
       " related to our paper \"Achieving Human Parity on Automatic Chinese to English News Translation\",\n",
       " published on March 14, 2018.\n",
       " \tcitation: @misc{hassan2018achieving,\n",
       "       title={Achieving Human Parity on Automatic Chinese to English News Translation},\n",
       "       author={ Hany Hassan and Anthony Aue and Chang Chen and Vishal Chowdhary and Jonathan Clark\n",
       "                and Christian Federmann and Xuedong Huang and Marcin Junczys-Dowmunt and William Lewis\n",
       "                and Mu Li and Shujie Liu and Tie-Yan Liu and Renqian Luo and Arul Menezes and Tao Qin\n",
       "                and Frank Seide and Xu Tan and Fei Tian and Lijun Wu and Shuangzhi Wu and Yingce Xia\n",
       "                and Dongdong Zhang and Zhirui Zhang and Ming Zhou},\n",
       "       year={2018},\n",
       "       eprint={1803.05567},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated', 'machine-generated'], 'language': ['en'], 'license': ['ms-pl'], 'multilinguality': ['monolingual', 'translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-newstest2017'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'MsrZhenTranslationParity'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: msra_ner\n",
       " \tsha: dc637b6d03ff78493dd0d3b18aa5a5490fedab7f\n",
       " \tlastModified: 2022-07-01T11:54:15.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Third International Chinese Language\n",
       " Processing Bakeoff was held in Spring\n",
       " 2006 to assess the state of the art in two\n",
       " important tasks: word segmentation and\n",
       " named entity recognition. Twenty-nine\n",
       " groups submitted result sets in the two\n",
       " tasks across two tracks and a total of five\n",
       " corpora. We found strong results in both\n",
       " tasks as well as continuing challenges.\n",
       " \n",
       " MSRA NER is one of the provided dataset.\n",
       " There are three types of NE, PER (person),\n",
       " ORG (organization) and LOC (location).\n",
       " The dataset is in the BIO scheme.\n",
       " \n",
       " For more details see https://faculty.washington.edu/levow/papers/sighan06.pdf\n",
       " \tcitation: @inproceedings{levow2006third,\n",
       "   author    = {Gina{-}Anne Levow},\n",
       "   title     = {The Third International Chinese Language Processing Bakeoff: Word\n",
       "                Segmentation and Named Entity Recognition},\n",
       "   booktitle = {SIGHAN@COLING/ACL},\n",
       "   pages     = {108--117},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year      = {2006}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'MSRA NER', 'train-eval-index': [{'config': 'msra_ner', 'task': 'token-classification', 'task_id': 'entity_extraction', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'tokens': 'tokens', 'ner_tags': 'tags'}, 'metrics': [{'type': 'seqeval', 'name': 'seqeval'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 956\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mt_eng_vietnamese\n",
       " \tsha: d920febde0102173ce3cc4d33ec86e2ba495a74f\n",
       " \tlastModified: 2022-07-01T11:54:15.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'multilinguality:multilingual', 'language:en', 'language:vi', 'license:unknown', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Preprocessed Dataset from IWSLT'15 English-Vietnamese machine translation: English-Vietnamese.\n",
       " \tcitation: @inproceedings{Luong-Manning:iwslt15,\n",
       "         Address = {Da Nang, Vietnam}\n",
       "         Author = {Luong, Minh-Thang  and Manning, Christopher D.},\n",
       "         Booktitle = {International Workshop on Spoken Language Translation},\n",
       "         Title = {Stanford Neural Machine Translation Systems for Spoken Language Domain},\n",
       "         Year = {2015}}\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'multilinguality': ['multilingual'], 'language': ['en', 'vi'], 'license': ['unknown'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'MtEngVietnamese'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 538\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: muchocine\n",
       " \tsha: ec8845d5300b57c82179196e01cdee9d9d32682d\n",
       " \tlastModified: 2022-07-01T11:54:15.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:es', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Muchocine reviews dataset contains 3,872 longform movie reviews in Spanish language,\n",
       " each with a shorter summary review, and a rating on a 1-5 scale.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['es'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Muchocine'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_booked\n",
       " \tsha: 75655a284da2158b78b5f2074b4158d04f180322\n",
       " \tlastModified: 2022-07-01T11:54:15.000Z\n",
       " \ttags: ['arxiv:1803.08614', 'annotations_creators:expert-generated', 'language_creators:found', 'language:ca', 'language:eu', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'configs:ca', 'configs:eu']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MultiBooked is a corpus of Basque and Catalan Hotel Reviews Annotated for Aspect-level Sentiment Classification.\n",
       " \n",
       " The corpora are compiled from hotel reviews taken mainly from booking.com. The corpora are in Kaf/Naf format, which is\n",
       " an xml-style stand-off format that allows for multiple layers of annotation. Each review was sentence- and\n",
       " word-tokenized and lemmatized using Freeling for Catalan and ixa-pipes for Basque. Finally, for each language two\n",
       " annotators annotated opinion holders, opinion targets, and opinion expressions for each review, following the\n",
       " guidelines set out in the OpeNER project.\n",
       " \tcitation: @inproceedings{Barnes2018multibooked,\n",
       "     author={Barnes, Jeremy and Lambert, Patrik and Badia, Toni},\n",
       "     title={MultiBooked: A corpus of Basque and Catalan Hotel Reviews Annotated for Aspect-level Sentiment Classification},\n",
       "     booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC'18)},\n",
       "     year = {2018},\n",
       "     month = {May},\n",
       "     date = {7-12},\n",
       "     address = {Miyazaki, Japan},\n",
       "     publisher = {European Language Resources Association (ELRA)},\n",
       "     language = {english}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ca', 'eu'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'multibooked', 'pretty_name': 'MultiBooked', 'configs': ['ca', 'eu']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 479\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: multibooked\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_eurlex\n",
       " \tsha: b13bb71cb0bf1ba158ade7482e736e970c4fd4a4\n",
       " \tlastModified: 2022-10-11T14:36:35.000Z\n",
       " \ttags: ['arxiv:2109.00904', 'annotations_creators:found', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MultiEURLEX comprises 65k EU laws in 23 official EU languages (some low-ish resource).\n",
       " Each EU law has been annotated with EUROVOC concepts (labels) by the Publication Office of EU.\n",
       " As with the English EURLEX, the goal is to predict the relevant EUROVOC concepts (labels);\n",
       " this is multi-label classification task (given the text, predict multiple labels).\n",
       " \tcitation: @InProceedings{chalkidis-etal-2021-multieurlex,\n",
       "   author = {Chalkidis, Ilias\n",
       "                 and Fergadiotis, Manos\n",
       "                 and Androutsopoulos, Ion},\n",
       "   title = {MultiEURLEX -- A multi-lingual and multi-label legal document\n",
       "                classification dataset for zero-shot cross-lingual transfer},\n",
       "   booktitle = {Proceedings of the 2021 Conference on Empirical Methods\n",
       "                in Natural Language Processing},\n",
       "   year = {2021},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   location = {Punta Cana, Dominican Republic},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'MultiEURLEX', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'topic-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4721\n",
       " \tlikes: 8\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_news\n",
       " \tsha: b3b0548287252200f4518ac2702487a474184d77\n",
       " \tlastModified: 2022-07-01T12:43:35.000Z\n",
       " \ttags: ['arxiv:1906.01749', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multi-News, consists of news articles and human-written summaries\n",
       " of these articles from the site newser.com.\n",
       " Each summary is professionally written by editors and\n",
       " includes links to the original articles cited.\n",
       " \n",
       " There are two features:\n",
       "   - document: text of news articles seperated by special token \"|||||\".\n",
       "   - summary: news summary.\n",
       " \tcitation: @misc{alex2019multinews,\n",
       "     title={Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},\n",
       "     author={Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},\n",
       "     year={2019},\n",
       "     eprint={1906.01749},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'Multi-News', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'paperswithcode_id': 'multi-news', 'train-eval-index': [{'config': 'default', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'document': 'text', 'summary': 'target'}, 'metrics': [{'type': 'rouge', 'name': 'Rouge'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 24809\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: multi-news\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_nli\n",
       " \tsha: 0b9a59175fb3d9f84d71743272cedcf58f837188\n",
       " \tlastModified: 2022-07-01T12:43:36.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-3.0', 'license:cc-by-sa-3.0', 'license:mit', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Multi-Genre Natural Language Inference (MultiNLI) corpus is a\n",
       " crowd-sourced collection of 433k sentence pairs annotated with textual\n",
       " entailment information. The corpus is modeled on the SNLI corpus, but differs in\n",
       " that covers a range of genres of spoken and written text, and supports a\n",
       " distinctive cross-genre generalization evaluation. The corpus served as the\n",
       " basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.\n",
       " \tcitation: @InProceedings{N18-1101,\n",
       "   author = {Williams, Adina\n",
       "             and Nangia, Nikita\n",
       "             and Bowman, Samuel},\n",
       "   title = {A Broad-Coverage Challenge Corpus for\n",
       "            Sentence Understanding through Inference},\n",
       "   booktitle = {Proceedings of the 2018 Conference of\n",
       "                the North American Chapter of the\n",
       "                Association for Computational Linguistics:\n",
       "                Human Language Technologies, Volume 1 (Long\n",
       "                Papers)},\n",
       "   year = {2018},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages = {1112--1122},\n",
       "   location = {New Orleans, Louisiana},\n",
       "   url = {http://aclweb.org/anthology/N18-1101}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['cc-by-3.0', 'cc-by-sa-3.0', 'mit', 'other'], 'license_details': 'Open Portion of the American National Corpus', 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-input-text-classification'], 'paperswithcode_id': 'multinli', 'pretty_name': 'Multi-Genre Natural Language Inference'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7843\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: multinli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_nli_mismatch\n",
       " \tsha: 4fc9024214304da6516823cefaac8f8c7b98e8a5\n",
       " \tlastModified: 2022-07-01T12:43:37.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-3.0', 'license:cc-by-sa-3.0', 'license:mit', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Multi-Genre Natural Language Inference (MultiNLI) corpus is a\n",
       " crowd-sourced collection of 433k sentence pairs annotated with textual\n",
       " entailment information. The corpus is modeled on the SNLI corpus, but differs in\n",
       " that covers a range of genres of spoken and written text, and supports a\n",
       " distinctive cross-genre generalization evaluation. The corpus served as the\n",
       " basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.\n",
       " \tcitation: @InProceedings{N18-1101,\n",
       "   author = {Williams, Adina\n",
       "             and Nangia, Nikita\n",
       "             and Bowman, Samuel},\n",
       "   title = {A Broad-Coverage Challenge Corpus for\n",
       "            Sentence Understanding through Inference},\n",
       "   booktitle = {Proceedings of the 2018 Conference of\n",
       "                the North American Chapter of the\n",
       "                Association for Computational Linguistics:\n",
       "                Human Language Technologies, Volume 1 (Long\n",
       "                Papers)},\n",
       "   year = {2018},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages = {1112--1122},\n",
       "   location = {New Orleans, Louisiana},\n",
       "   url = {http://aclweb.org/anthology/N18-1101}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['cc-by-3.0', 'cc-by-sa-3.0', 'mit', 'other'], 'license_details': 'Open Portion of the American National Corpus', 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-input-text-classification'], 'paperswithcode_id': 'multinli', 'pretty_name': 'Multi-Genre Natural Language Inference'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: multinli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_para_crawl\n",
       " \tsha: 9237fd0cd2d65ef4a956a9fa6d4b8dc6b7fbb442\n",
       " \tlastModified: 2022-08-11T12:57:27.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:ha', 'language:hr', 'language:hu', 'language:ig', 'language:is', 'language:it', 'language:km', 'language:lt', 'language:lv', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sv', 'language:sw', 'language:tl', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n",
       " 40 languages, 669 bitexts\n",
       " total number of files: 40\n",
       " total number of tokens: 10.14G\n",
       " total number of sentence fragments: 505.48M\n",
       " \n",
       " Please, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'ca', 'cs', 'da', 'de', 'el', 'es', 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'ha', 'hr', 'hu', 'ig', 'is', 'it', 'km', 'lt', 'lv', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'pl', 'ps', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'so', 'sv', 'sw', 'tl'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'MultiParaCrawl'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 973\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_re_qa\n",
       " \tsha: 0c6b13f26287bca98267308ae75aae450f779f16\n",
       " \tlastModified: 2022-07-01T11:54:19.000Z\n",
       " \ttags: ['arxiv:2005.02507', 'annotations_creators:expert-generated', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'source_datasets:extended|other-BioASQ', 'source_datasets:extended|other-DuoRC', 'source_datasets:extended|other-HotpotQA', 'source_datasets:extended|other-Natural-Questions', 'source_datasets:extended|other-Relation-Extraction', 'source_datasets:extended|other-SQuAD', 'source_datasets:extended|other-SearchQA', 'source_datasets:extended|other-TextbookQA', 'source_datasets:extended|other-TriviaQA', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa', 'configs:BioASQ', 'configs:DuoRC', 'configs:HotpotQA', 'configs:NaturalQuestions', 'configs:RelationExtraction', 'configs:SQuAD', 'configs:SearchQA', 'configs:TextbookQA', 'configs:TriviaQA']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MultiReQA contains the sentence boundary annotation from eight publicly available QA datasets including SearchQA, TriviaQA, HotpotQA, NaturalQuestions, SQuAD, BioASQ, RelationExtraction, and TextbookQA. Five of these datasets, including SearchQA, TriviaQA, HotpotQA, NaturalQuestions, SQuAD, contain both training and test data, and three, including BioASQ, RelationExtraction, TextbookQA, contain only the test data\n",
       " \tcitation: @misc{m2020multireqa,\n",
       "     title={MultiReQA: A Cross-Domain Evaluation for Retrieval Question Answering Models},\n",
       "     author={Mandy Guo and Yinfei Yang and Daniel Cer and Qinlan Shen and Noah Constant},\n",
       "     year={2020},\n",
       "     eprint={2005.02507},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'found'], 'language_creators': ['expert-generated', 'found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', '1M<n<10M'], 'source_datasets': ['extended|other-BioASQ', 'extended|other-DuoRC', 'extended|other-HotpotQA', 'extended|other-Natural-Questions', 'extended|other-Relation-Extraction', 'extended|other-SQuAD', 'extended|other-SearchQA', 'extended|other-TextbookQA', 'extended|other-TriviaQA'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': 'multireqa', 'pretty_name': 'MultiReQA', 'configs': ['BioASQ', 'DuoRC', 'HotpotQA', 'NaturalQuestions', 'RelationExtraction', 'SQuAD', 'SearchQA', 'TextbookQA', 'TriviaQA']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1572\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: multireqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_woz_v22\n",
       " \tsha: 295337c8bacf639b58924ca3de2d50fa236c2af1\n",
       " \tlastModified: 2022-10-10T08:46:44.000Z\n",
       " \ttags: ['arxiv:1810.00278', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:multi-class-classification', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.\n",
       " MultiWOZ 2.1 (Eric et al., 2019) identified and fixed many erroneous annotations and user utterances in the original version, resulting in an\n",
       " improved version of the dataset. MultiWOZ 2.2 is a yet another improved version of this dataset, which identifies and fizes dialogue state annotation errors\n",
       " across 17.3% of the utterances on top of MultiWOZ 2.1 and redefines the ontology by disallowing vocabularies of slots with a large number of possible values\n",
       " (e.g., restaurant name, time of booking) and introducing standardized slot span annotations for these slots.\n",
       " \tcitation: @article{corr/abs-2007-12720,\n",
       "   author    = {Xiaoxue Zang and\n",
       "                Abhinav Rastogi and\n",
       "                Srinivas Sunkara and\n",
       "                Raghav Gupta and\n",
       "                Jianguo Zhang and\n",
       "                Jindong Chen},\n",
       "   title     = {MultiWOZ 2.2 : {A} Dialogue Dataset with Additional Annotation Corrections\n",
       "                and State Tracking Baselines},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2007.12720},\n",
       "   year      = {2020},\n",
       "   url       = {https://arxiv.org/abs/2007.12720},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2007.12720}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'token-classification', 'text-classification'], 'task_ids': ['dialogue-modeling', 'multi-class-classification', 'parsing'], 'paperswithcode_id': 'multiwoz', 'pretty_name': 'Multi-domain Wizard-of-Oz'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2467\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: multiwoz\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multi_x_science_sum\n",
       " \tsha: c4177ad8a70841fd3616fd3417869bb2c0249895\n",
       " \tlastModified: 2022-07-01T11:54:20.000Z\n",
       " \ttags: ['arxiv:2010.14235', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-paper-abstract-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. Multi-XScience introduces a challenging multi-document summarization task: writing the related-work section of a paper based on its abstract and the articles it references.\n",
       " \tcitation: @article{lu2020multi,\n",
       "   title={Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles},\n",
       "   author={Lu, Yao and Dong, Yue and Charlin, Laurent},\n",
       "   journal={arXiv preprint arXiv:2010.14235},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-paper-abstract-generation'], 'paperswithcode_id': 'multi-xscience', 'pretty_name': 'Multi-XScience'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2975\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: multi-xscience\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multidoc2dial\n",
       " \tsha: 508faaecd3ad5291d1392f884094655d2f56f209\n",
       " \tlastModified: 2022-07-01T11:54:22.000Z\n",
       " \ttags: ['arxiv:2109.12595', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:extended|doc2dial', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'configs:dialogue_domain', 'configs:document_domain', 'configs:multidoc2dial']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: MultiDoc2Dial is a new task and dataset on modeling goal-oriented dialogues grounded in multiple documents. Most previous works treat document-grounded dialogue modeling as a machine reading comprehension task based on a single given document or passage. We aim to address more realistic scenarios where a goal-oriented information-seeking conversation involves multiple topics, and hence is grounded on different documents.\n",
       " \tcitation: @inproceedings{feng2021multidoc2dial,\n",
       "     title={MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents},\n",
       "     author={Feng, Song and Patel, Siva Sankalp and Wan, Hui and Joshi, Sachindra},\n",
       "     booktitle={EMNLP},\n",
       "     year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'MultiDoc2Dial', 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['extended|doc2dial'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'multidoc2dial', 'configs': ['dialogue_domain', 'document_domain', 'multidoc2dial']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 641\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: multidoc2dial\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: multilingual_librispeech\n",
       " \tsha: 0e12e166ac1121729fd45e25858da4fd2190b272\n",
       " \tlastModified: 2022-09-23T12:03:14.000Z\n",
       " \ttags: ['arxiv:2012.03411', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:de', 'language:es', 'language:fr', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'task_ids:speaker-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.\n",
       " \tcitation: @article{Pratap2020MLSAL,\n",
       "   title={MLS: A Large-Scale Multilingual Dataset for Speech Research},\n",
       "   author={Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},\n",
       "   journal={ArXiv},\n",
       "   year={2020},\n",
       "   volume={abs/2012.03411}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'MultiLingual LibriSpeech', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['de', 'es', 'fr', 'it', 'nl', 'pl', 'pt'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'paperswithcode_id': 'librispeech-1', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition', 'audio-classification'], 'task_ids': ['speaker-identification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1296\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: librispeech-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mutual_friends\n",
       " \tsha: d6d8545bd1097038c1b899f755da493203ff73e5\n",
       " \tlastModified: 2022-07-01T11:54:22.000Z\n",
       " \ttags: ['arxiv:1704.07130', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Our goal is to build systems that collaborate with people by exchanging\n",
       " information through natural language and reasoning over structured knowledge\n",
       " base. In the MutualFriend task, two agents, A and B, each have a private\n",
       " knowledge base, which contains a list of friends with multiple attributes\n",
       " (e.g., name, school, major, etc.). The agents must chat with each other\n",
       " to find their unique mutual friend.\n",
       " \tcitation: @inproceedings{he-etal-2017-learning,\n",
       "     title = \"Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\",\n",
       "     author = \"He, He  and\n",
       "       Balakrishnan, Anusha  and\n",
       "       Eric, Mihail  and\n",
       "       Liang, Percy\",\n",
       "     booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
       "     month = jul,\n",
       "     year = \"2017\",\n",
       "     address = \"Vancouver, Canada\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P17-1162\",\n",
       "     doi = \"10.18653/v1/P17-1162\",\n",
       "     pages = \"1766--1776\",\n",
       "     abstract = \"We study a \\textit{symmetric collaborative dialogue} setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'mutualfriends', 'pretty_name': 'MutualFriends'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 351\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: mutualfriends\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: mwsc\n",
       " \tsha: cdb2890fdd99d65e04690cb0aa93b6703bbd4d9c\n",
       " \tlastModified: 2022-08-25T13:44:00.000Z\n",
       " \ttags: ['arxiv:1806.08730', 'annotations_creators:expert-generated', 'language:en', 'language_creators:expert-generated', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:extended|winograd_wsc', 'task_categories:multiple-choice', 'task_ids:multiple-choice-coreference-resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Examples taken from the Winograd Schema Challenge modified to ensure that answers are a single word from the context.\n",
       " This modified Winograd Schema Challenge (MWSC) ensures that scores are neither inflated nor deflated by oddities in phrasing.\n",
       " \tcitation: @article{McCann2018decaNLP,\n",
       "   title={The Natural Language Decathlon: Multitask Learning as Question Answering},\n",
       "   author={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\n",
       "   journal={arXiv preprint arXiv:1806.08730},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['expert-generated'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Modified Winograd Schema Challenge (MWSC)', 'size_categories': ['n<1K'], 'source_datasets': ['extended|winograd_wsc'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-coreference-resolution'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 524\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: myanmar_news\n",
       " \tsha: 2373e8accc2ccd68f437a8fe96d1f02e074bed72\n",
       " \tlastModified: 2022-07-01T11:54:23.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:my', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Myanmar news dataset contains article snippets in four categories:\n",
       " Business, Entertainment, Politics, and Sport.\n",
       " \n",
       " These were collected in October 2017 by Aye Hninn Khine\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['my'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'MyanmarNews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: narrativeqa\n",
       " \tsha: a2a39502d1e31def7b22fb70b946747a2679042e\n",
       " \tlastModified: 2022-07-01T11:54:24.000Z\n",
       " \ttags: ['arxiv:1712.07040', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The NarrativeQA dataset for question answering on long documents (movie scripts, books). It includes the list of documents with Wikipedia summaries, links to full stories, and questions and answers.\n",
       " \tcitation: @article{narrativeqa,\n",
       " author = {Tom\\\\'a\\\\v s Ko\\\\v cisk\\\\'y and Jonathan Schwarz and Phil Blunsom and\n",
       "           Chris Dyer and Karl Moritz Hermann and G\\\\'abor Melis and\n",
       "           Edward Grefenstette},\n",
       " title = {The {NarrativeQA} Reading Comprehension Challenge},\n",
       " journal = {Transactions of the Association for Computational Linguistics},\n",
       " url = {https://TBD},\n",
       " volume = {TBD},\n",
       " year = {2018},\n",
       " pages = {TBD},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['abstractive-qa'], 'paperswithcode_id': 'narrativeqa', 'pretty_name': 'NarrativeQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 620\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: narrativeqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: narrativeqa_manual\n",
       " \tsha: a52ed311a71f56b30536357ee4627ab08ec51d44\n",
       " \tlastModified: 2022-07-01T11:54:26.000Z\n",
       " \ttags: ['arxiv:1712.07040', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Narrative QA Manual dataset is a reading comprehension dataset, in which the reader must answer questions about stories by reading entire books or movie scripts. The QA tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience.\\THIS DATASET REQUIRES A MANUALLY DOWNLOADED FILE! Because of a script in the original repository which downloads the stories from original URLs everytime, The links are sometimes broken or invalid.  Therefore, you need to manually download the stories for this dataset using the script provided by the authors (https://github.com/deepmind/narrativeqa/blob/master/download_stories.sh). Running the shell script creates a folder named \"tmp\" in the root directory and downloads the stories there. This folder containing the storiescan be used to load the dataset via `datasets.load_dataset(\"narrativeqa_manual\", data_dir=\"<path/to/folder>\")`.\n",
       " \tcitation: @article{kovcisky2018narrativeqa,\n",
       "   title={The narrativeqa reading comprehension challenge},\n",
       "   author={Ko{\\v{c}}isk{\\'y}, Tom{\\'a}{\\v{s}} and Schwarz, Jonathan and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz and Melis, G{\\'a}bor and Grefenstette, Edward},\n",
       "   journal={Transactions of the Association for Computational Linguistics},\n",
       "   volume={6},\n",
       "   pages={317--328},\n",
       "   year={2018},\n",
       "   publisher={MIT Press}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['abstractive-qa'], 'paperswithcode_id': 'narrativeqa', 'pretty_name': 'NarrativeQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 367\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: narrativeqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: natural_questions\n",
       " \tsha: 86f88c01ce8f972707861471e6e50d4de047dcf4\n",
       " \tlastModified: 2022-08-02T16:03:49.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The NQ corpus contains questions from real users, and it requires QA systems to\n",
       " read and comprehend an entire Wikipedia article that may or may not contain the\n",
       " answer to the question. The inclusion of real user questions, and the\n",
       " requirement that solutions should read an entire page to find the answer, cause\n",
       " NQ to be a more realistic and challenging task than prior QA datasets.\n",
       " \tcitation: @article{47761,\n",
       " title\t= {Natural Questions: a Benchmark for Question Answering Research},\n",
       " author\t= {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},\n",
       " year\t= {2019},\n",
       " journal\t= {Transactions of the Association of Computational Linguistics}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Natural Questions', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'natural-questions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 897\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: natural-questions\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ncbi_disease\n",
       " \tsha: 32aa07cb4790f22e36d2ed39fab81346fcac55e9\n",
       " \tlastModified: 2022-07-01T11:54:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This paper presents the disease name and concept annotations of the NCBI disease corpus, a collection of 793 PubMed\n",
       " abstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural\n",
       " language processing community. Each PubMed abstract was manually annotated by two annotators with disease mentions\n",
       " and their corresponding concepts in Medical Subject Headings (MeSH®) or Online Mendelian Inheritance in Man (OMIM®).\n",
       " Manual curation was performed using PubTator, which allowed the use of pre-annotations as a pre-step to manual annotations.\n",
       " Fourteen annotators were randomly paired and differing annotations were discussed for reaching a consensus in two\n",
       " annotation phases. In this setting, a high inter-annotator agreement was observed. Finally, all results were checked\n",
       " against annotations of the rest of the corpus to assure corpus-wide consistency.\n",
       " \n",
       " For more details, see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3951655/\n",
       " \n",
       " The original dataset can be downloaded from: https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/NCBI_corpus.zip\n",
       " This dataset has been converted to CoNLL format for NER using the following tool: https://github.com/spyysalo/standoff2conll\n",
       " Note: there is a duplicate document (PMID 8528200) in the original data, and the duplicate is recreated in the converted data.\n",
       " \tcitation: @article{dougan2014ncbi,\n",
       "          title={NCBI disease corpus: a resource for disease name recognition and concept normalization},\n",
       "          author={Dogan, Rezarta Islamaj and Leaman, Robert and Lu, Zhiyong},\n",
       "          journal={Journal of biomedical informatics},\n",
       "          volume={47},\n",
       "          pages={1--10},\n",
       "          year={2014},\n",
       "          publisher={Elsevier}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'ncbi-disease-1', 'pretty_name': 'NCBI Disease', 'train-eval-index': [{'config': 'ncbi_disease', 'task': 'token-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'tokens': 'text', 'ner_tags': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1770\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: ncbi-disease-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nchlt\n",
       " \tsha: e311a08365ad0c8c878fba1b1a29fd7287c689c2\n",
       " \tlastModified: 2022-07-01T11:54:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:af', 'language:nr', 'language:nso', 'language:ss', 'language:tn', 'language:ts', 'language:ve', 'language:xh', 'language:zu', 'license:cc-by-2.5', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The development of linguistic resources for use in natural language processingis of utmost importance for the continued growth of research anddevelopment in the field, especially for resource-scarce languages. In this paper we describe the process and challenges of simultaneouslydevelopingmultiple linguistic resources for ten of the official languages of South Africa. The project focussed on establishing a set of foundational resources that can foster further development of both resources and technologies for the NLP industry in South Africa. The development efforts during the project included creating monolingual unannotated corpora, of which a subset of the corpora for each language was annotated on token, orthographic, morphological and morphosyntactic layers. The annotated subsetsincludes both development and test setsand were used in the creation of five core-technologies, viz. atokeniser, sentenciser,lemmatiser, part of speech tagger and morphological decomposer for each language. We report on the quality of these tools for each language and provide some more context of the importance of the resources within the South African context.\n",
       " \tcitation: @inproceedings{eiselen2014developing,\n",
       "   title={Developing Text Resources for Ten South African Languages.},\n",
       "   author={Eiselen, Roald and Puttkammer, Martin J},\n",
       "   booktitle={LREC},\n",
       "   pages={3698--3703},\n",
       "   year={2014}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['af', 'nr', 'nso', 'ss', 'tn', 'ts', 've', 'xh', 'zu'], 'license': ['cc-by-2.5'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'NCHLT'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1733\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ncslgr\n",
       " \tsha: 5182f40b9cbcae9c4c3aa79bc4662177d1ee2762\n",
       " \tlastModified: 2022-07-01T11:54:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ase', 'language:en', 'license:mit', 'multilinguality:translation', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A small corpus of American Sign Language (ASL) video data from native signers, annotated with non-manual features.\n",
       " \tcitation: @misc{dataset:databases2007volumes,\n",
       "     title={Volumes 2--7},\n",
       "     author={Databases, NCSLGR},\n",
       "     year={2007},\n",
       "     publisher={American Sign Language Linguistic Research Project (Distributed on CD-ROM~…}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ase', 'en'], 'license': ['mit'], 'multilinguality': ['translation'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'NCSLGR'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 512\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nell\n",
       " \tsha: 7ee4b3b3af32229cc31b07c7bc4c33608d9423ef\n",
       " \tlastModified: 2022-08-11T16:23:39.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100M<n<1B', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other-text-to-tabular', 'task_categories:text-retrieval', 'task_categories:other-text-to-structured', 'task_ids:entity-linking-retrieval', 'task_ids:fact-checking-retrieval', 'task_ids:other-relation-extraction', 'configs:nell_belief', 'configs:nell_belief_sentences', 'configs:nell_candidate', 'configs:nell_candidate_sentences']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset provides version 1115 of the belief\n",
       " extracted by CMU's Never Ending Language Learner (NELL) and version\n",
       " 1110 of the candidate belief extracted by NELL. See\n",
       " http://rtw.ml.cmu.edu/rtw/overview.  NELL is an open information\n",
       " extraction system that attempts to read the Clueweb09 of 500 million\n",
       " web pages (http://boston.lti.cs.cmu.edu/Data/clueweb09/) and general\n",
       " web searches.\n",
       " \n",
       " The dataset has 4 configurations: nell_belief, nell_candidate,\n",
       " nell_belief_sentences, and nell_candidate_sentences. nell_belief is\n",
       " certainties of belief are lower. The two sentences config extracts the\n",
       " CPL sentence patterns filled with the applicable 'best' literal string\n",
       " for the entities filled into the sentence patterns. And also provides\n",
       " sentences found using web searches containing the entities and\n",
       " relationships.\n",
       " \n",
       " There are roughly 21M entries for nell_belief_sentences, and 100M\n",
       " sentences for nell_candidate_sentences.\n",
       " \tcitation: @inproceedings{mitchell2015,\n",
       "   added-at = {2015-01-27T15:35:24.000+0100},\n",
       "   author = {Mitchell, T. and Cohen, W. and Hruscha, E. and Talukdar, P. and Betteridge, J. and Carlson, A. and Dalvi, B. and Gardner, M. and Kisiel, B. and Krishnamurthy, J. and Lao, N. and Mazaitis, K. and Mohammad, T. and Nakashole, N. and Platanios, E. and Ritter, A. and Samadi, M. and Settles, B. and Wang, R. and Wijaya, D. and Gupta, A. and Chen, X. and Saparov, A. and Greaves, M. and Welling, J.},\n",
       "   biburl = {https://www.bibsonomy.org/bibtex/263070703e6bb812852cca56574aed093/hotho},\n",
       "   booktitle = {AAAI},\n",
       "   description = {Papers by William W. Cohen},\n",
       "   interhash = {52d0d71f6f5b332dabc1412f18e3a93d},\n",
       "   intrahash = {63070703e6bb812852cca56574aed093},\n",
       "   keywords = {learning nell ontology semantic toread},\n",
       "   note = {: Never-Ending Learning in AAAI-2015},\n",
       "   timestamp = {2015-01-27T15:35:24.000+0100},\n",
       "   title = {Never-Ending Learning},\n",
       "   url = {http://www.cs.cmu.edu/~wcohen/pubs.html},\n",
       "   year = 2015\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100M<n<1B', '10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other-text-to-tabular', 'text-retrieval', 'other-text-to-structured'], 'task_ids': ['entity-linking-retrieval', 'fact-checking-retrieval', 'other-relation-extraction'], 'paperswithcode_id': 'nell', 'pretty_name': 'Never Ending Language Learning (NELL)', 'configs': ['nell_belief', 'nell_belief_sentences', 'nell_candidate', 'nell_candidate_sentences']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 795\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: nell\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: neural_code_search\n",
       " \tsha: 00661af1421ca7577f36d6f0c6b4dcf0641aba14\n",
       " \tlastModified: 2022-07-01T11:54:29.000Z\n",
       " \ttags: ['arxiv:1908.09804', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'configs:evaluation_dataset', 'configs:search_corpus']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Neural-Code-Search-Evaluation-Dataset presents an evaluation dataset consisting of natural language query and code snippet pairs and a search corpus consisting of code snippets collected from the most popular Android repositories on GitHub.\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title         = {Neural Code Search Evaluation Dataset},\n",
       " authors       = {Hongyu Li, Seohyun Kim and Satish Chandra},\n",
       " journal       = {arXiv e-prints},\n",
       " year          = 2018,\n",
       " eid           = {arXiv:1908.09804 [cs.SE]},\n",
       " pages         = {arXiv:1908.09804 [cs.SE]},\n",
       " archivePrefix = {arXiv},\n",
       " eprint        = {1908.09804},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Neural Code Search', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'neural-code-search-evaluation-dataset', 'configs': ['evaluation_dataset', 'search_corpus']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 764\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: neural-code-search-evaluation-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: news_commentary\n",
       " \tsha: 6a2985ee6eb2c73c6c6692a86f0b83c41f8affea\n",
       " \tlastModified: 2022-08-11T12:57:28.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:nl', 'language:pt', 'language:ru', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of News Commentaries provided by WMT for training SMT. The source is taken from CASMACAT: http://www.casmacat.eu/corpus/news-commentary.html\n",
       " \n",
       " 12 languages, 63 bitexts\n",
       " total number of files: 61,928\n",
       " total number of tokens: 49.66M\n",
       " total number of sentence fragments: 1.93M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'cs', 'de', 'en', 'es', 'fr', 'it', 'ja', 'nl', 'pt', 'ru', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'NewsCommentary'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 150654\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newsgroup\n",
       " \tsha: 6b1e684b216e73a156a6c641789738f05735bd55\n",
       " \tlastModified: 2022-09-20T07:38:10.000Z\n",
       " \ttags: ['annotations_creators:found', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across\n",
       " 20 different newsgroups. The 20 newsgroups collection has become a popular data set for experiments in text applications of\n",
       " machine learning techniques, such as text classification and text clustering.\n",
       " \tcitation: @inproceedings{Lang95,\n",
       "     author = {Ken Lang},\n",
       "     title = {Newsweeder: Learning to filter netnews}\n",
       "     year = {1995}\n",
       "     booktitle = {Proceedings of the Twelfth International Conference on Machine Learning}\n",
       "     pages = {331-339}\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': '20 Newsgroups', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': '20-newsgroups'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 14963\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: 20-newsgroups\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newsph\n",
       " \tsha: e8d5595ff342a9a241d45ce3a95301c4be0a8cc6\n",
       " \tlastModified: 2022-07-01T11:54:30.000Z\n",
       " \ttags: ['arxiv:2010.11574', 'annotations_creators:no-annotation', 'language_creators:found', 'language:fil', 'language:tl', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large-scale dataset of Filipino news articles. Sourced for the NewsPH-NLI Project (Cruz et al., 2020).\n",
       " \tcitation: @article{cruz2020investigating,\n",
       "   title={Investigating the True Performance of Transformers in Low-Resource Languages: A Case Study in Automatic Corpus Creation},\n",
       "   author={Jan Christian Blaise Cruz and Jose Kristian Resabal and James Lin and Dan John Velasco and Charibeth Cheng},\n",
       "   journal={arXiv preprint arXiv:2010.11574},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['fil', 'tl'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'newsph-nli', 'pretty_name': 'NewsPH-NLI'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: newsph-nli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newsph_nli\n",
       " \tsha: ed49445bd773bddadaacef1e585f91d1e95d0f24\n",
       " \tlastModified: 2022-07-01T11:54:30.000Z\n",
       " \ttags: ['arxiv:2010.11574', 'annotations_creators:machine-generated', 'language_creators:found', 'language:tl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: First benchmark dataset for sentence entailment in the low-resource Filipino language.\n",
       " Constructed through exploting the structure of news articles. Contains 600,000 premise-hypothesis pairs,\n",
       " in 70-15-15 split for training, validation, and testing.\n",
       " \tcitation: @article{cruz2020investigating,\n",
       "     title={Investigating the True Performance of Transformers in Low-Resource Languages: A Case Study in Automatic Corpus Creation},\n",
       "     author={Jan Christian Blaise Cruz and Jose Kristian Resabal and James Lin and Dan John Velasco and Charibeth Cheng},\n",
       "     journal={arXiv preprint arXiv:2010.11574},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['tl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'newsph-nli', 'pretty_name': 'NewsPH NLI'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: newsph-nli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newspop\n",
       " \tsha: f8bc0e496cac8ee8988748e5fbc7f5b2280599c2\n",
       " \tlastModified: 2022-07-01T11:54:31.000Z\n",
       " \ttags: ['arxiv:1801.07055', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:text-classification-other-social-media-shares-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.\n",
       " The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine.\n",
       " This data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation.\n",
       " \tcitation: @article{Moniz2018MultiSourceSF,\n",
       "   title={Multi-Source Social Feedback of Online News Feeds},\n",
       "   author={N. Moniz and L. Torgo},\n",
       "   journal={ArXiv},\n",
       "   year={2018},\n",
       "   volume={abs/1801.07055}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'text-classification-other-social-media-shares-prediction'], 'paperswithcode_id': None, 'pretty_name': 'News Popularity in Multiple Social Media Platforms'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 627\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newsqa\n",
       " \tsha: d7a817dd30bf48daeb726dfe7e01e1b416784783\n",
       " \tlastModified: 2022-07-01T11:54:33.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'configs:combined-csv', 'configs:combined-json', 'configs:split']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NewsQA is a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text from the corresponding articles.\n",
       " \tcitation: @inproceedings{trischler2017newsqa,\n",
       "   title={NewsQA: A Machine Comprehension Dataset},\n",
       "   author={Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},\n",
       "   booktitle={Proceedings of the 2nd Workshop on Representation Learning for NLP},\n",
       "   pages={191--200},\n",
       "   year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'newsqa', 'pretty_name': 'NewsQA', 'configs': ['combined-csv', 'combined-json', 'split']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 646\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: newsqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: newsroom\n",
       " \tsha: 33e834332ded196f687396cebe6b4247df72fbd2\n",
       " \tlastModified: 2022-07-01T12:43:37.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NEWSROOM is a large dataset for training and evaluating summarization systems.\n",
       " It contains 1.3 million articles and summaries written by authors and\n",
       " editors in the newsrooms of 38 major publications.\n",
       " \n",
       " Dataset features includes:\n",
       "   - text: Input news text.\n",
       "   - summary: Summary for the news.\n",
       " And additional features:\n",
       "   - title: news title.\n",
       "   - url: url of the news.\n",
       "   - date: date of the article.\n",
       "   - density: extractive density.\n",
       "   - coverage: extractive coverage.\n",
       "   - compression: compression ratio.\n",
       "   - density_bin: low, medium, high.\n",
       "   - coverage_bin: extractive, abstractive.\n",
       "   - compression_bin: low, medium, high.\n",
       " \n",
       " This dataset can be downloaded upon requests. Unzip all the contents\n",
       " \"train.jsonl, dev.josnl, test.jsonl\" to the tfds folder.\n",
       " \tcitation: @inproceedings{N18-1065,\n",
       "   author    = {Grusky, Max and Naaman, Mor and Artzi, Yoav},\n",
       "   title     = {NEWSROOM: A Dataset of 1.3 Million Summaries\n",
       "                with Diverse Extractive Strategies},\n",
       "   booktitle = {Proceedings of the 2018 Conference of the\n",
       "                North American Chapter of the Association for\n",
       "                Computational Linguistics: Human Language Technologies},\n",
       "   year      = {2018},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'CORNELL NEWSROOM', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'paperswithcode_id': 'newsroom'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 361\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: newsroom\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nkjp-ner\n",
       " \tsha: 775672ede609ec0ec0e0ca3cb867be1f3bc70e5f\n",
       " \tlastModified: 2022-07-01T11:54:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The NKJP-NER is based on a human-annotated part of National Corpus of Polish (NKJP). We extracted sentences with named entities of exactly one type. The task is to predict the type of the named entity.\n",
       " \tcitation: @book{przepiorkowski2012narodowy,\n",
       " title={Narodowy korpus jezyka polskiego},\n",
       " author={Przepi{\\'o}rkowski, Adam},\n",
       " year={2012},\n",
       " publisher={Naukowe PWN}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'NJKP NER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nli_tr\n",
       " \tsha: 8067985590a60b9c45f627ab4a884baf63542dd2\n",
       " \tlastModified: 2022-09-12T08:43:39.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:machine-generated', 'language:tr', 'license:cc-by-3.0', 'license:cc-by-4.0', 'license:cc-by-sa-3.0', 'license:mit', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|snli', 'source_datasets:extended|multi_nli', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring', 'task_ids:text-scoring', 'configs:multinli_tr', 'configs:snli_tr']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " The Natural Language Inference in Turkish (NLI-TR) is a set of two large scale datasets that were obtained by translating the foundational NLI corpora (SNLI and MNLI) using Amazon Translate.\n",
       " \tcitation: \\\n",
       " @inproceedings{budur-etal-2020-data,\n",
       "     title = \"Data and Representation for Turkish Natural Language Inference\",\n",
       "     author = \"Budur, Emrah and\n",
       "       \\\"{O}zçelik, Rıza and\n",
       "       G\\\"{u}ng\\\"{o}r, Tunga\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     abstract = \"Large annotated datasets in NLP are overwhelmingly in English. This is an obstacle to progress in other languages. Unfortunately, obtaining new annotated resources for each task in each language would be prohibitively expensive. At the same time, commercial machine translation systems are now robust. Can we leverage these systems to translate English-language datasets automatically? In this paper, we offer a positive response for natural language inference (NLI) in Turkish. We translated two large English NLI datasets into Turkish and had a team of experts validate their translation quality and fidelity to the original labels. Using these datasets, we address core issues of representation for Turkish NLI. We find that in-language embeddings are essential and that morphological parsing can be avoided where the training set is large. Finally, we show that models trained on our machine-translated datasets are successful on human-translated evaluation sets. We share all code, models, and data publicly.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['machine-generated'], 'language': ['tr'], 'license': ['cc-by-3.0', 'cc-by-4.0', 'cc-by-sa-3.0', 'mit', 'other'], 'license_details': 'Open Portion of the American National Corpus', 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|snli', 'extended|multi_nli'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'semantic-similarity-scoring', 'text-scoring'], 'paperswithcode_id': 'nli-tr', 'pretty_name': 'Natural Language Inference in Turkish', 'configs': ['multinli_tr', 'snli_tr']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 481\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: nli-tr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nlu_evaluation_data\n",
       " \tsha: acb6b540db502e5e47f1ebb8c7b5e95e38bfd27a\n",
       " \tlastModified: 2022-07-01T11:54:34.000Z\n",
       " \ttags: ['arxiv:1903.05566', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Raw part of NLU Evaluation Data. It contains 25 715 non-empty examples (original dataset has 25716 examples) from 68 unique intents belonging to 18 scenarios.\n",
       " \tcitation: @InProceedings{XLiu.etal:IWSDS2019,\n",
       "   author    = {Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser},\n",
       "   title     = {Benchmarking Natural Language Understanding Services for building Conversational Agents},\n",
       "   booktitle = {Proceedings of the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)},\n",
       "   month     = {April},\n",
       "   year      = {2019},\n",
       "   address   = {Ortigia, Siracusa (SR), Italy},\n",
       "   publisher = {Springer},\n",
       "   pages     = {xxx--xxx},\n",
       "   url       = {http://www.xx.xx/xx/}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'multi-class-classification'], 'paperswithcode_id': None, 'pretty_name': 'NLU Evaluation Data'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 768\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: norec\n",
       " \tsha: d9ef1176cbb0f438a6ba16933f6b9f62ed69ba36\n",
       " \tlastModified: 2022-08-11T12:57:29.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:nb', 'language:nn', 'language:no', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NoReC was created as part of the SANT project (Sentiment Analysis for Norwegian Text), a collaboration between the Language Technology Group (LTG) at the Department of Informatics at the University of Oslo, the Norwegian Broadcasting Corporation (NRK), Schibsted Media Group and Aller Media. This first release of the corpus comprises 35,194 reviews extracted from eight different news sources: Dagbladet, VG, Aftenposten, Bergens Tidende, Fædrelandsvennen, Stavanger Aftenblad, DinSide.no and P3.no. In terms of publishing date the reviews mainly cover the time span 2003–2017, although it also includes a handful of reviews dating back as far as 1998.\n",
       " \tcitation: @InProceedings{VelOvrBer18,\n",
       "   author = {Erik Velldal and Lilja Ovrelid and\n",
       "             Eivind Alexander Bergem and Cathrine Stadsnes and\n",
       "             Samia Touileb and Fredrik Jorgensen},\n",
       "   title = {{NoReC}: The {N}orwegian {R}eview {C}orpus},\n",
       "   booktitle = {Proceedings of the 11th edition of the\n",
       "                Language Resources and Evaluation Conference},\n",
       "   year = {2018},\n",
       "   address = {Miyazaki, Japan},\n",
       "   pages = {4186--4191}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'NoReC', 'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['nb', 'nn', 'no'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'norec'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 186\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: norec\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: norne\n",
       " \tsha: 869ab741174b5f3e70c5b519f2c1457bd3d9603e\n",
       " \tlastModified: 2022-07-27T14:38:51.000Z\n",
       " \ttags: ['arxiv:1911.12146', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:no', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NorNE is a manually annotated\n",
       " corpus of named entities which extends the annotation of the existing\n",
       " Norwegian Dependency Treebank. Comprising both of the official standards of\n",
       " written Norwegian (Bokmål and Nynorsk), the corpus contains around 600,000\n",
       " tokens and annotates a rich set of entity types including persons,\n",
       " organizations, locations, geo-political entities, products, and events,\n",
       " in addition to a class corresponding to nominals derived from names.\n",
       " \tcitation: @inproceedings{johansen2019ner,\n",
       "   title={NorNE: Annotating Named Entities for Norwegian},\n",
       "   author={Fredrik Jørgensen, Tobias Aasmoe, Anne-Stine Ruud Husevåg,\n",
       "           Lilja Øvrelid, and Erik Velldal},\n",
       "   booktitle={LREC 2020},\n",
       "   year={2020},\n",
       "   url={https://arxiv.org/abs/1911.12146}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['no'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'NorNE: Norwegian Named Entities'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 600\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: norwegian_ner\n",
       " \tsha: 7968948d65d1372c5e1d64056cf035c99163222a\n",
       " \tlastModified: 2022-07-01T12:43:38.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:no', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entities Recognition dataset for Norwegian. It is\n",
       " a version of the Universal Dependency (UD) Treebank for both Bokmål and Nynorsk (UDN) where\n",
       " all proper nouns have been tagged with their type according to the NER tagging scheme. UDN is a converted\n",
       " version of the Norwegian Dependency Treebank into the UD scheme.\n",
       " \tcitation: @inproceedings{johansen2019ner,\n",
       "   title={Named-Entity Recognition for Norwegian},\n",
       "   author={Johansen, Bjarte},\n",
       "   booktitle={Proceedings of the 22nd Nordic Conference on Computational Linguistics, NoDaLiDa},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['no'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Norwegian NER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 184\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nq_open\n",
       " \tsha: f7a4df6bc8be66573790a499e74ccd7c52351824\n",
       " \tlastModified: 2022-07-01T11:54:37.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|natural_questions', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The NQ-Open task, introduced by Lee et.al. 2019,\n",
       " is an open domain question answering benchmark that is derived from Natural Questions.\n",
       " The goal is to predict an English answer string for an input English question.\n",
       " All questions can be answered using the contents of English Wikipedia.\n",
       " \tcitation: @article{doi:10.1162/tacl_a_00276,\n",
       "     author = {Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and Toutanova, Kristina and Jones, Llion and Kelcey, Matthew and Chang, Ming-Wei and Dai, Andrew                         M. and Uszkoreit, Jakob and Le, Quoc and Petrov, Slav},\n",
       "     title = {Natural Questions: A Benchmark for Question Answering Research},\n",
       "     journal = {Transactions of the Association for Computational Linguistics},\n",
       "     volume = {7},\n",
       "     number = {},\n",
       "     pages = {453-466},\n",
       "     year = {2019},\n",
       "     doi = {10.1162/tacl_a_00276},\n",
       "     URL = {\n",
       "             https://doi.org/10.1162/tacl_a_00276\n",
       "         },\n",
       "     eprint = {\n",
       "             https://doi.org/10.1162/tacl_a_00276\n",
       "         },\n",
       "     abstract = { We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature. }\n",
       " }\n",
       " \n",
       " @inproceedings{lee-etal-2019-latent,\n",
       "     title = \"Latent Retrieval for Weakly Supervised Open Domain Question Answering\",\n",
       "     author = \"Lee, Kenton  and\n",
       "       Chang, Ming-Wei  and\n",
       "       Toutanova, Kristina\",\n",
       "     booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P19-1612\",\n",
       "     doi = \"10.18653/v1/P19-1612\",\n",
       "     pages = \"6086--6096\",\n",
       "     abstract = \"Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'NQ-Open', 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|natural_questions'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2981\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: nsmc\n",
       " \tsha: 27897ffa46fb9e88d81b956039ea790ac4d9a2a9\n",
       " \tlastModified: 2022-07-01T12:43:39.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ko', 'license:cc-by-2.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a movie review dataset in the Korean language. Reviews were scraped from Naver movies. The dataset construction is based on the method noted in Large movie review dataset from Maas et al., 2011.\n",
       " \tcitation: @InProceedings{Park:2016,\n",
       "   title        = \"Naver Sentiment Movie Corpus\",\n",
       "   author       = \"Lucy Park\",\n",
       "   year         = \"2016\",\n",
       "   howpublished = {\\\\url{https://github.com/e9t/nsmc}}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ko'], 'license': ['cc-by-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'nsmc', 'pretty_name': 'Naver Sentiment Movie Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2852\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: nsmc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: numer_sense\n",
       " \tsha: 57d6b32ac10075a5a23983893a2b7a512b04d2f2\n",
       " \tlastModified: 2022-07-01T11:54:38.000Z\n",
       " \ttags: ['arxiv:2005.00683', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:slot-filling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NumerSense is a new numerical commonsense reasoning probing task, with a diagnostic dataset consisting of 3,145 masked-word-prediction probes.\n",
       " \n",
       " We propose to study whether numerical commonsense knowledge can be induced from pre-trained language models like BERT, and to what extent this access to knowledge robust against adversarial examples is. We hope this will be beneficial for tasks such as knowledge base completion and open-domain question answering.\n",
       " \tcitation: @inproceedings{lin2020numersense,\n",
       "     title={Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models},\n",
       "     author={Bill Yuchen Lin and Seyeon Lee and Rahul Khanna and Xiang Ren},\n",
       "     booktitle={Proceedings of EMNLP},\n",
       "     year={2020},\n",
       "     note={to appear}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['slot-filling'], 'paperswithcode_id': 'numersense', 'pretty_name': 'NumerSense'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 758\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: numersense\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: numeric_fused_head\n",
       " \tsha: 829a090b6d543a056659536c0f42d1297832fee2\n",
       " \tlastModified: 2022-07-01T11:54:38.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:token-classification-other-fused-head-identification', 'configs:identification', 'configs:resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Fused Head constructions are noun phrases in which the head noun is missing and is said to be \"fused\" with its dependent modifier. This missing information is implicit and is important for sentence understanding.The missing heads are easily filled in by humans,  but pose a challenge for computational models.\n",
       " \n",
       " For example, in the sentence: \"I bought 5 apples but got only 4.\", 4 is a Fused-Head, and the missing head is apples, which appear earlier in the sentence.\n",
       " \n",
       " This is a crowd-sourced dataset of 10k numerical fused head examples (1M tokens).\n",
       " \tcitation: @article{elazar_head,\n",
       "     author = {Elazar, Yanai and Goldberg, Yoav},\n",
       "     title = {Where’s My Head? Definition, Data Set, and Models for Numeric Fused-Head Identification and Resolution},\n",
       "     journal = {Transactions of the Association for Computational Linguistics},\n",
       "     volume = {7},\n",
       "     number = {},\n",
       "     pages = {519-535},\n",
       "     year = {2019},\n",
       "     doi = {10.1162/tacl\\\\_a\\\\_00280},\n",
       "     URL = {https://doi.org/10.1162/tacl_a_00280},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated', 'machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['token-classification-other-fused-head-identification'], 'paperswithcode_id': 'numeric-fused-head', 'pretty_name': 'Numeric Fused Heads', 'configs': ['identification', 'resolution']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 484\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: numeric-fused-head\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: oclar\n",
       " \tsha: 2b48f2ace146d3d8efc20d9bb6c57fb6dc4cda5f\n",
       " \tlastModified: 2022-07-01T11:54:40.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The researchers of OCLAR Marwan et al. (2019), they gathered Arabic costumer reviews from Google reviewsa and Zomato\n",
       " website (https://www.zomato.com/lebanon) on wide scope of domain, including restaurants, hotels, hospitals, local shops,\n",
       " etc.The corpus finally contains 3916 reviews in 5-rating scale. For this research purpose, the positive class considers\n",
       " rating stars from 5 to 3 of 3465 reviews, and the negative class is represented from values of 1 and 2 of about\n",
       " 451 texts.\n",
       " \tcitation: @misc{Dua:2019 ,\n",
       " author = \"Dua, Dheeru and Graff, Casey\",\n",
       " year = \"2017\",\n",
       " title = \"{UCI} Machine Learning Repository\",\n",
       " url = \"http://archive.ics.uci.edu/ml\",\n",
       " institution = \"University of California, Irvine, School of Information and Computer Sciences\" }\n",
       " \n",
       " @InProceedings{AlOmari2019oclar,\n",
       " title = {Sentiment Classifier: Logistic Regression for Arabic Services Reviews in Lebanon},\n",
       " authors={Al Omari, M., Al-Hajj, M., Hammami, N., & Sabra, A.},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'sentiment-classification', 'sentiment-scoring'], 'paperswithcode_id': None, 'pretty_name': 'OCLAR'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: offcombr\n",
       " \tsha: 2c3597c447a00d1c9c6994a9cbdcb7c58ebea51a\n",
       " \tlastModified: 2022-07-01T11:54:40.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pt', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OffComBR: an annotated dataset containing for hate speech detection in Portuguese composed of news comments on the Brazilian Web.\n",
       " \tcitation: @article{Pelle2017,\n",
       " title={Offensive Comments in the Brazilian Web: a dataset and baseline results},\n",
       " author={Rogers P. de Pelle and Viviane P. Moreira},\n",
       " booktitle={6th Brazilian Workshop on Social Network Analysis and Mining (BraSNAM)},\n",
       " year={2017},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pt'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-detection'], 'paperswithcode_id': 'offcombr', 'pretty_name': 'Offensive Comments in the Brazilian Web'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 479\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: offcombr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: offenseval2020_tr\n",
       " \tsha: f43703615dade6eb6846eb460eb64e9b27d33d98\n",
       " \tlastModified: 2022-07-01T11:54:41.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:cc-by-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-offensive-language-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OffensEval-TR 2020 is a Turkish offensive language corpus. The corpus consist of randomly sampled tweets and annotated in a similar way to OffensEval and GermEval.\n",
       " \tcitation: @InProceedings{coltekin2020lrec,\n",
       "  author  = {Cagri Coltekin},\n",
       "  year  = {2020},\n",
       "  title  = {A Corpus of Turkish Offensive Language on Social Media},\n",
       "  booktitle  = {Proceedings of The 12th Language Resources and Evaluation Conference},\n",
       "  pages  = {6174--6184},\n",
       "  address  = {Marseille, France},\n",
       "  url  = {https://www.aclweb.org/anthology/2020.lrec-1.758},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['cc-by-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-offensive-language-classification'], 'paperswithcode_id': None, 'pretty_name': 'OffensEval-TR 2020'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 938\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: offenseval_dravidian\n",
       " \tsha: cbbb773fb5a47d3c8c123d02c2bb4074b04c4a2f\n",
       " \tlastModified: 2022-07-01T11:54:41.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:kn', 'language:ml', 'language:ta', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-offensive-language', 'configs:kannada', 'configs:malayalam', 'configs:tamil']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Offensive language identification in dravidian lanaguages dataset. The goal of this task is to identify offensive language content of the code-mixed dataset of comments/posts in Dravidian Languages ( (Tamil-English, Malayalam-English, and Kannada-English)) collected from social media.\n",
       " \tcitation: @inproceedings{dravidianoffensive-eacl,\n",
       " title={Findings of the Shared Task on {O}ffensive {L}anguage {I}dentification in {T}amil, {M}alayalam, and {K}annada},\n",
       " author={Chakravarthi, Bharathi Raja and\n",
       " Priyadharshini, Ruba and\n",
       " Jose, Navya and\n",
       " M, Anand Kumar and\n",
       " Mandl, Thomas and\n",
       " Kumaresan, Prasanna Kumar and\n",
       " Ponnsamy, Rahul and\n",
       " V,Hariharan and\n",
       " Sherly, Elizabeth and\n",
       " McCrae, John Philip },\n",
       " booktitle = \"Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages\",\n",
       " month = April,\n",
       " year = \"2021\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'kn', 'ml', 'ta'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-offensive-language'], 'paperswithcode_id': None, 'pretty_name': 'Offenseval Dravidian', 'configs': ['kannada', 'malayalam', 'tamil']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 637\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ofis_publik\n",
       " \tsha: eb085626823adb5bb0522f8e69a5a91deb72f986\n",
       " \tlastModified: 2022-08-11T12:57:29.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:br', 'language:fr', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Texts from the Ofis Publik ar Brezhoneg (Breton Language Board) provided by Francis Tyers\n",
       " 2 languages, total number of files: 278\n",
       " total number of tokens: 2.12M\n",
       " total number of sentence fragments: 0.13M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       "  @inproceedings{tyers-2009-rule,\n",
       "     title = \"Rule-Based Augmentation of Training Data in {B}reton-{F}rench Statistical Machine Translation\",\n",
       "     author = \"Tyers, Francis M.\",\n",
       "     booktitle = \"Proceedings of the 13th Annual conference of the European Association for Machine Translation\",\n",
       "     month = may # \" 14{--}15\",\n",
       "     year = \"2009\",\n",
       "     address = \"Barcelona, Spain\",\n",
       "     publisher = \"European Association for Machine Translation\",\n",
       "     url = \"https://www.aclweb.org/anthology/2009.eamt-1.29\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['br', 'fr'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OfisPublik'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ohsumed\n",
       " \tsha: 3a6d0c0d99463e9b3093a242cd8129cd5b0984f8\n",
       " \tlastModified: 2022-08-12T04:27:49.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The OHSUMED test collection is a set of 348,566 references from\n",
       " MEDLINE, the on-line medical information database, consisting of\n",
       " titles and/or abstracts from 270 medical journals over a five-year\n",
       " period (1987-1991). The available fields are title, abstract, MeSH\n",
       " indexing terms, author, source, and publication type.\n",
       " \tcitation: @InProceedings{10.1007/978-1-4471-2099-5_20,\n",
       " author=\"Hersh, William\n",
       " and Buckley, Chris\n",
       " and Leone, T. J.\n",
       " and Hickam, David\",\n",
       " editor=\"Croft, Bruce W.\n",
       " and van Rijsbergen, C. J.\",\n",
       " title=\"OHSUMED: An Interactive Retrieval Evaluation and New Large Test Collection for Research\",\n",
       " booktitle=\"SIGIR '94\",\n",
       " year=\"1994\",\n",
       " publisher=\"Springer London\",\n",
       " address=\"London\",\n",
       " pages=\"192--201\",\n",
       " abstract=\"A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create a new large medical test collection, which was used in experiments with the SMART retrieval system to obtain baseline performance data as well as compare SMART with the other searchers.\",\n",
       " isbn=\"978-1-4471-2099-5\"\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Ohsumed', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 378\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ollie\n",
       " \tsha: b487247df7e5dde938ab2f7467bcaf7e97c0d453\n",
       " \tlastModified: 2022-08-11T16:23:39.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:other-text-to-structured', 'task_ids:other-relation-extraction', 'configs:ollie_lemmagrep', 'configs:ollie_patterned']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Ollie dataset includes two configs for the data\n",
       " used to train the Ollie informatation extraction algorithm, for 18M\n",
       " sentences and 3M sentences respectively.\n",
       " \n",
       " This data is for academic use only. From the authors:\n",
       " \n",
       " Ollie is a program that automatically identifies and extracts binary\n",
       " relationships from English sentences. Ollie is designed for Web-scale\n",
       " information extraction, where target relations are not specified in\n",
       " advance.\n",
       " \n",
       " Ollie is our second-generation information extraction system . Whereas\n",
       " ReVerb operates on flat sequences of tokens, Ollie works with the\n",
       " tree-like (graph with only small cycles) representation using\n",
       " Stanford's compression of the dependencies. This allows Ollie to\n",
       " capture expression that ReVerb misses, such as long-range relations.\n",
       " \n",
       " Ollie also captures context that modifies a binary relation. Presently\n",
       " Ollie handles attribution (He said/she believes) and enabling\n",
       " conditions (if X then).\n",
       " \n",
       " More information is available at the Ollie homepage:\n",
       " https://knowitall.github.io/ollie/\n",
       " \tcitation: @inproceedings{ollie-emnlp12,\n",
       "   author = {Mausam and Michael Schmitz and Robert Bart and Stephen Soderland and Oren Etzioni},\n",
       "   title = {Open Language Learning for Information Extraction},\n",
       "   booktitle = {Proceedings of Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CONLL)},\n",
       "   year = {2012}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['other-text-to-structured'], 'task_ids': ['other-relation-extraction'], 'paperswithcode_id': None, 'pretty_name': 'Ollie', 'configs': ['ollie_lemmagrep', 'ollie_patterned']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 480\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: omp\n",
       " \tsha: 30fbf187ee0b1916ef2a6beb11f7fae4907a6dc3\n",
       " \tlastModified: 2022-07-01T11:54:43.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:de', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The “One Million Posts” corpus is an annotated data set consisting of\n",
       " user comments posted to an Austrian newspaper website (in German language).\n",
       " \n",
       " DER STANDARD is an Austrian daily broadsheet newspaper. On the newspaper’s website,\n",
       " there is a discussion section below each news article where readers engage in\n",
       " online discussions. The data set contains a selection of user posts from the\n",
       " 12 month time span from 2015-06-01 to 2016-05-31. There are 11,773 labeled and\n",
       " 1,000,000 unlabeled posts in the data set. The labeled posts were annotated by\n",
       " professional forum moderators employed by the newspaper.\n",
       " \n",
       " The data set contains the following data for each post:\n",
       " \n",
       " * Post ID\n",
       " * Article ID\n",
       " * Headline (max. 250 characters)\n",
       " * Main Body (max. 750 characters)\n",
       " * User ID (the user names used by the website have been re-mapped to new numeric IDs)\n",
       " * Time stamp\n",
       " * Parent post (replies give rise to tree-like discussion thread structures)\n",
       " * Status (online or deleted by a moderator)\n",
       " * Number of positive votes by other community members\n",
       " * Number of negative votes by other community members\n",
       " \n",
       " For each article, the data set contains the following data:\n",
       " \n",
       " * Article ID\n",
       " * Publishing date\n",
       " * Topic Path (e.g.: Newsroom / Sports / Motorsports / Formula 1)\n",
       " * Title\n",
       " * Body\n",
       " \n",
       " Detailed descriptions of the post selection and annotation procedures are given in the paper.\n",
       " \n",
       " ## Annotated Categories\n",
       " \n",
       " Potentially undesirable content:\n",
       " \n",
       " * Sentiment (negative/neutral/positive)\n",
       "     An important goal is to detect changes in the prevalent sentiment in a discussion, e.g.,\n",
       "     the location within the fora and the point in time where a turn from positive/neutral\n",
       "     sentiment to negative sentiment takes place.\n",
       " * Off-Topic (yes/no)\n",
       "     Posts which digress too far from the topic of the corresponding article.\n",
       " * Inappropriate (yes/no)\n",
       "     Swearwords, suggestive and obscene language, insults, threats etc.\n",
       " * Discriminating (yes/no)\n",
       "     Racist, sexist, misogynistic, homophobic, antisemitic and other misanthropic content.\n",
       " \n",
       " Neutral content that requires a reaction:\n",
       " \n",
       " * Feedback (yes/no)\n",
       "     Sometimes users ask questions or give feedback to the author of the article or the\n",
       "     newspaper in general, which may require a reply/reaction.\n",
       " \n",
       " Potentially desirable content:\n",
       " \n",
       " * Personal Stories (yes/no)\n",
       "     In certain fora, users are encouraged to share their personal stories, experiences,\n",
       "     anecdotes etc. regarding the respective topic.\n",
       " * Arguments Used (yes/no)\n",
       "     It is desirable for users to back their statements with rational argumentation,\n",
       "     reasoning and sources.\n",
       " \tcitation: @InProceedings{Schabus2017,\n",
       "   Author    = {Dietmar Schabus and Marcin Skowron and Martin Trapp},\n",
       "   Title     = {One Million Posts: A Data Set of German Online Discussions},\n",
       "   Booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)},\n",
       "   Pages     = {1241--1244},\n",
       "   Year      = {2017},\n",
       "   Address   = {Tokyo, Japan},\n",
       "   Doi       = {10.1145/3077136.3080711},\n",
       "   Month     = aug\n",
       " }\n",
       " \tcardData: {'pretty_name': 'One Million Posts', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['de'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'one-million-posts-corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 642\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: one-million-posts-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: onestop_english\n",
       " \tsha: 823f72da396757272c968ed7c1642c9db4731829\n",
       " \tlastModified: 2022-07-01T11:54:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is a compilation of the OneStopEnglish corpus of texts written at three reading levels into one file.\n",
       " Text documents are classified into three reading levels - ele, int, adv (Elementary, Intermediate and Advance).\n",
       " This dataset demonstrates its usefulness for through two applica-tions - automatic  readability  assessment  and automatic text simplification.\n",
       " The corpus consists of 189 texts, each in three versions/reading levels (567 in total).\n",
       " \tcitation: @inproceedings{vajjala-lucic-2018-onestopenglish,\n",
       "     title = {OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification},\n",
       "     author = {Sowmya Vajjala and Ivana Lučić},\n",
       "     booktitle = {Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications},\n",
       "     year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-classification'], 'task_ids': ['multi-class-classification', 'text-simplification'], 'paperswithcode_id': 'onestopenglish', 'pretty_name': 'OneStopEnglish corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1769\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: onestopenglish\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: onestop_qa\n",
       " \tsha: 50ca0611962152c3efb77baa9fc14ec2c424f146\n",
       " \tlastModified: 2022-07-27T14:38:51.000Z\n",
       " \ttags: ['arxiv:2004.14797', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'language_bcp47:en-US', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'source_datasets:extended|onestop_english', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OneStopQA is a multiple choice reading comprehension dataset annotated according to the STARC (Structured Annotations for Reading Comprehension) scheme. The reading materials are Guardian articles taken from the [OneStopEnglish corpus](https://github.com/nishkalavallabhi/OneStopEnglishCorpus). Each article comes in three difficulty levels, Elementary, Intermediate and Advanced. Each paragraph is annotated with three multiple choice reading comprehension questions. The reading comprehension questions can be answered based on any of the three paragraph levels.\n",
       " \tcitation: @inproceedings{starc2020,\n",
       "       author    = {Berzak, Yevgeni and Malmaud, Jonathan and Levy, Roger},\n",
       "       title     = {STARC: Structured Annotations for Reading Comprehension},\n",
       "       booktitle = {ACL},\n",
       "       year      = {2020},\n",
       "       publisher = {Association for Computational Linguistics}\n",
       "       }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'language_bcp47': ['en-US'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'onestopqa', 'pretty_name': 'OneStopQA', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original', 'extended|onestop_english'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: onestopqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: open_subtitles\n",
       " \tsha: 2fdfb5483f1e4a2815241d324f013fade28bf0b6\n",
       " \tlastModified: 2022-08-11T14:03:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:af', 'language:ar', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:gl', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:ko', 'language:lt', 'language:lv', 'language:mk', 'language:ml', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:vi', 'language:zh', 'language_bcp47:pt-BR', 'language_bcp47:ze-EN', 'language_bcp47:ze-ZH', 'language_bcp47:zh-CN', 'language_bcp47:zh-TW', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation', 'configs:bn-is', 'configs:bs-eo', 'configs:da-ru', 'configs:en-hi', 'configs:fr-hy']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.\n",
       " \n",
       " IMPORTANT: If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/ to your website and to your reports and publications produced with the data!\n",
       " \n",
       " This is a slightly cleaner version of the subtitle collection using improved sentence alignment and better language checking.\n",
       " \n",
       " 62 languages, 1,782 bitexts\n",
       " total number of files: 3,735,070\n",
       " total number of tokens: 22.10G\n",
       " total number of sentence fragments: 3.35G\n",
       " \tcitation: P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'ar', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lt', 'lv', 'mk', 'ml', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh'], 'language_bcp47': ['pt-BR', 'ze-EN', 'ze-ZH', 'zh-CN', 'zh-TW'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1M<n<10M', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'opensubtitles', 'pretty_name': 'OpenSubtitles', 'configs': ['bn-is', 'bs-eo', 'da-ru', 'en-hi', 'fr-hy']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1285\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: opensubtitles\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: openai_humaneval\n",
       " \tsha: f9dbefd506a6b47baae4f75709dae9fc753d3b6f\n",
       " \tlastModified: 2022-07-01T11:54:45.000Z\n",
       " \ttags: ['arxiv:2107.03374', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-code-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The HumanEval dataset released by OpenAI contains 164 handcrafted programming challenges together with unittests to very the viability of a proposed solution.\n",
       " \tcitation: @misc{chen2021evaluating,\n",
       "       title={Evaluating Large Language Models Trained on Code},\n",
       "       author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},\n",
       "       year={2021},\n",
       "       eprint={2107.03374},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.LG}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'OpenAI HumanEval', 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-code-generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2340\n",
       " \tlikes: 8\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: openbookqa\n",
       " \tsha: 2fc280dec5e4cb0fa5a6c80bca60773e787a3124\n",
       " \tlastModified: 2022-07-01T11:54:47.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OpenBookQA aims to promote research in advanced question-answering, probing a deeper understanding of both the topic\n",
       " (with salient facts summarized as an open book, also provided with the dataset) and the language it is expressed in. In\n",
       " particular, it contains questions that require multi-step reasoning, use of additional common and commonsense knowledge,\n",
       " and rich text comprehension.\n",
       " OpenBookQA is a new kind of question-answering dataset modeled after open book exams for assessing human understanding\n",
       " of a subject.\n",
       " \tcitation: @inproceedings{OpenBookQA2018,\n",
       "  title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering},\n",
       "  author={Todor Mihaylov and Peter Clark and Tushar Khot and Ashish Sabharwal},\n",
       "  booktitle={EMNLP},\n",
       "  year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'OpenBookQA', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'openbookqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 39004\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: openbookqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: openslr\n",
       " \tsha: 455c67a5057b84605f708b4d6d130de27ab4191e\n",
       " \tlastModified: 2022-07-27T14:38:51.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:af', 'language:bn', 'language:ca', 'language:en', 'language:es', 'language:eu', 'language:gl', 'language:gu', 'language:jv', 'language:km', 'language:kn', 'language:ml', 'language:mr', 'language:my', 'language:ne', 'language:si', 'language:st', 'language:su', 'language:ta', 'language:te', 'language:tn', 'language:ve', 'language:xh', 'language:yo', 'language_bcp47:en-GB', 'language_bcp47:en-IE', 'language_bcp47:en-NG', 'language_bcp47:es-CL', 'language_bcp47:es-CO', 'language_bcp47:es-PE', 'language_bcp47:es-PR', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:automatic-speech-recognition', 'configs:SLR32', 'configs:SLR35', 'configs:SLR36', 'configs:SLR41', 'configs:SLR42', 'configs:SLR43', 'configs:SLR44', 'configs:SLR52', 'configs:SLR53', 'configs:SLR54', 'configs:SLR63', 'configs:SLR64', 'configs:SLR65', 'configs:SLR66', 'configs:SLR69', 'configs:SLR70', 'configs:SLR71', 'configs:SLR72', 'configs:SLR73', 'configs:SLR74', 'configs:SLR75', 'configs:SLR76', 'configs:SLR77', 'configs:SLR78', 'configs:SLR79', 'configs:SLR80', 'configs:SLR83', 'configs:SLR86']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OpenSLR is a site devoted to hosting speech and language resources, such as training corpora for speech recognition,\n",
       " and software related to speech recognition. We intend to be a convenient place for anyone to put resources that\n",
       " they have created, so that they can be downloaded publicly.\n",
       " \tcitation: SLR32:\n",
       " @inproceedings{van-niekerk-etal-2017,\n",
       "     title = {{Rapid development of TTS corpora for four South African languages}},\n",
       "     author = {Daniel van Niekerk and Charl van Heerden and Marelie Davel and Neil Kleynhans and Oddur Kjartansson\n",
       "     and Martin Jansche and Linne Ha},\n",
       "     booktitle = {Proc. Interspeech 2017},\n",
       "     pages = {2178--2182},\n",
       "     address = {Stockholm, Sweden},\n",
       "     month = aug,\n",
       "     year  = {2017},\n",
       "     URL   = {http://dx.doi.org/10.21437/Interspeech.2017-1139}\n",
       " }\n",
       " \n",
       " SLR35, SLR36, SLR52, SLR53, SLR54:\n",
       " @inproceedings{kjartansson-etal-sltu2018,\n",
       "     title = {{Crowd-Sourced Speech Corpora for Javanese, Sundanese,  Sinhala, Nepali, and Bangladeshi Bengali}},\n",
       "     author = {Oddur Kjartansson and Supheakmungkol Sarin and Knot Pipatsrisawat and Martin Jansche and Linne Ha},\n",
       "     booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\n",
       "     year  = {2018},\n",
       "     address = {Gurugram, India},\n",
       "     month = aug,\n",
       "     pages = {52--55},\n",
       "     URL   = {https://dx.doi.org/10.21437/SLTU.2018-11},\n",
       " }\n",
       " \n",
       " SLR41, SLR42, SLR43, SLR44:\n",
       " @inproceedings{kjartansson-etal-tts-sltu2018,\n",
       "     title = {{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Framework for Bangla, Javanese,\n",
       "     Khmer, Nepali, Sinhala, and Sundanese}},\n",
       "     author = {Keshan Sodimana and Knot Pipatsrisawat and Linne Ha and Martin Jansche and Oddur Kjartansson and Pasindu\n",
       "     De Silva and Supheakmungkol Sarin},\n",
       "     booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\n",
       "     year  = {2018},\n",
       "     address = {Gurugram, India},\n",
       "     month = aug,\n",
       "     pages = {66--70},\n",
       "     URL   = {https://dx.doi.org/10.21437/SLTU.2018-14}\n",
       " }\n",
       " \n",
       " SLR63, SLR64, SLR65, SLR66, SLR78, SLR79:\n",
       " @inproceedings{he-etal-2020-open,\n",
       "   title = {{Open-source Multi-speaker Speech Corpora for Building Gujarati, Kannada, Malayalam, Marathi, Tamil and\n",
       "   Telugu Speech Synthesis Systems}},\n",
       "   author = {He, Fei and Chu, Shan-Hui Cathy and Kjartansson, Oddur and Rivera, Clara and Katanova, Anna and Gutkin,\n",
       "   Alexander and Demirsahin, Isin and Johny, Cibu and Jansche, Martin and Sarin, Supheakmungkol and Pipatsrisawat, Knot},\n",
       "   booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n",
       "   month = may,\n",
       "   year = {2020},\n",
       "   address = {Marseille, France},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   pages = {6494--6503},\n",
       "   url = {https://www.aclweb.org/anthology/2020.lrec-1.800},\n",
       "   ISBN = \"{979-10-95546-34-4},\n",
       " }\n",
       " \n",
       " SLR69, SLR76, SLR77:\n",
       " @inproceedings{kjartansson-etal-2020-open,\n",
       "     title = {{Open-Source High Quality Speech Datasets for Basque, Catalan and Galician}},\n",
       "     author = {Kjartansson, Oddur and Gutkin, Alexander and Butryna, Alena and Demirsahin, Isin and Rivera, Clara},\n",
       "     booktitle = {Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages\n",
       "     (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)},\n",
       "     year = {2020},\n",
       "     pages = {21--27},\n",
       "     month = may,\n",
       "     address = {Marseille, France},\n",
       "     publisher = {European Language Resources association (ELRA)},\n",
       "     url = {https://www.aclweb.org/anthology/2020.sltu-1.3},\n",
       "     ISBN = {979-10-95546-35-1},\n",
       " }\n",
       " \n",
       " SLR71, SLR71, SLR72, SLR73, SLR74, SLR75:\n",
       " @inproceedings{guevara-rukoz-etal-2020-crowdsourcing,\n",
       "     title = {{Crowdsourcing Latin American Spanish for Low-Resource Text-to-Speech}},\n",
       "     author = {Guevara-Rukoz, Adriana and Demirsahin, Isin and He, Fei and Chu, Shan-Hui Cathy and Sarin,\n",
       "     Supheakmungkol and Pipatsrisawat, Knot and Gutkin, Alexander and Butryna, Alena and Kjartansson, Oddur},\n",
       "     booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n",
       "     year = {2020},\n",
       "     month = may,\n",
       "     address = {Marseille, France},\n",
       "     publisher = {European Language Resources Association (ELRA)},\n",
       "     url = {https://www.aclweb.org/anthology/2020.lrec-1.801},\n",
       "     pages = {6504--6513},\n",
       "     ISBN = {979-10-95546-34-4},\n",
       " }\n",
       " \n",
       " SLR80\n",
       " @inproceedings{oo-etal-2020-burmese,\n",
       "     title = {{Burmese Speech Corpus, Finite-State Text Normalization and Pronunciation Grammars with an Application\n",
       "     to Text-to-Speech}},\n",
       "     author = {Oo, Yin May and Wattanavekin, Theeraphol and Li, Chenfang and De Silva, Pasindu and Sarin,\n",
       "     Supheakmungkol and Pipatsrisawat, Knot and Jansche, Martin and Kjartansson, Oddur and Gutkin, Alexander},\n",
       "     booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n",
       "     month = may,\n",
       "     year = {2020},\n",
       "     pages = \"6328--6339\",\n",
       "     address = {Marseille, France},\n",
       "     publisher = {European Language Resources Association (ELRA)},\n",
       "     url = {https://www.aclweb.org/anthology/2020.lrec-1.777},\n",
       "     ISBN = {979-10-95546-34-4},\n",
       " }\n",
       " \n",
       " SLR86\n",
       " @inproceedings{gutkin-et-al-yoruba2020,\n",
       "     title = {{Developing an Open-Source Corpus of Yoruba Speech}},\n",
       "     author = {Alexander Gutkin and Işın Demirşahin and Oddur Kjartansson and Clara Rivera and Kọ́lá Túbọ̀sún},\n",
       "     booktitle = {Proceedings of Interspeech 2020},\n",
       "     pages = {404--408},\n",
       "     month = {October},\n",
       "     year = {2020},\n",
       "     address = {Shanghai, China},\n",
       "     publisher = {International Speech and Communication Association (ISCA)},\n",
       "     doi = {10.21437/Interspeech.2020-1096},\n",
       "     url = {https://dx.doi.org/10.21437/Interspeech.2020-1096},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'OpenSLR', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'bn', 'ca', 'en', 'es', 'eu', 'gl', 'gu', 'jv', 'km', 'kn', 'ml', 'mr', 'my', 'ne', 'si', 'st', 'su', 'ta', 'te', 'tn', 've', 'xh', 'yo'], 'language_bcp47': ['en-GB', 'en-IE', 'en-NG', 'es-CL', 'es-CO', 'es-PE', 'es-PR'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'paperswithcode_id': None, 'configs': ['SLR32', 'SLR35', 'SLR36', 'SLR41', 'SLR42', 'SLR43', 'SLR44', 'SLR52', 'SLR53', 'SLR54', 'SLR63', 'SLR64', 'SLR65', 'SLR66', 'SLR69', 'SLR70', 'SLR71', 'SLR72', 'SLR73', 'SLR74', 'SLR75', 'SLR76', 'SLR77', 'SLR78', 'SLR79', 'SLR80', 'SLR83', 'SLR86']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4407\n",
       " \tlikes: 6\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: openwebtext\n",
       " \tsha: 7a51242bad7ba426b069d81dc767dcb25735b267\n",
       " \tlastModified: 2022-07-01T11:54:48.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An open-source replication of the WebText dataset from OpenAI.\n",
       " \tcitation: @misc{Gokaslan2019OpenWeb,\n",
       "   title={OpenWebText Corpus},\n",
       "   author={Aaron Gokaslan*, Vanya Cohen*, Ellie Pavlick, Stefanie Tellex},\n",
       "   howpublished{\\\\url{http://Skylion007.github.io/OpenWebTextCorpus}},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'OpenWebText', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'openwebtext'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3345\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: openwebtext\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opinosis\n",
       " \tsha: 75fe07dccc420c1bec82676dee472c5c4cc081a1\n",
       " \tlastModified: 2022-09-06T05:39:59.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-abstractive-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Opinosis Opinion Dataset consists of sentences extracted from reviews for 51 topics.\n",
       " Topics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.\n",
       " \tcitation: @inproceedings{ganesan2010opinosis,\n",
       "   title={Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions},\n",
       "   author={Ganesan, Kavita and Zhai, ChengXiang and Han, Jiawei},\n",
       "   booktitle={Proceedings of the 23rd International Conference on Computational Linguistics},\n",
       "   pages={340--348},\n",
       "   year={2010},\n",
       "   organization={Association for Computational Linguistics}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Opinosis', 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-abstractive-summarization'], 'paperswithcode_id': 'opinosis'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 430\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: opinosis\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus100\n",
       " \tsha: 0dcb209f91cebae93421775febd0e81eb8e73016\n",
       " \tlastModified: 2022-08-25T13:44:00.000Z\n",
       " \ttags: ['arxiv:2004.11867', 'task_categories:text-generation', 'task_categories:fill-mask', 'multilinguality:translation', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'language:af', 'language:am', 'language:an', 'language:ar', 'language:as', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:dz', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:id', 'language:ig', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:li', 'language:lt', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:or', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rw', 'language:se', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'annotations_creators:no-annotation', 'language_creators:found', 'source_datasets:extended', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'license:unknown', 'configs:af-en', 'configs:am-en', 'configs:an-en', 'configs:ar-de', 'configs:ar-en', 'configs:ar-fr', 'configs:ar-nl', 'configs:ar-ru', 'configs:ar-zh', 'configs:as-en', 'configs:az-en', 'configs:be-en', 'configs:bg-en', 'configs:bn-en', 'configs:br-en', 'configs:bs-en', 'configs:ca-en', 'configs:cs-en', 'configs:cy-en', 'configs:da-en', 'configs:de-en', 'configs:de-fr', 'configs:de-nl', 'configs:de-ru', 'configs:de-zh', 'configs:dz-en', 'configs:el-en', 'configs:en-eo', 'configs:en-es', 'configs:en-et', 'configs:en-eu', 'configs:en-fa', 'configs:en-fi', 'configs:en-fr', 'configs:en-fy', 'configs:en-ga', 'configs:en-gd', 'configs:en-gl', 'configs:en-gu', 'configs:en-ha', 'configs:en-he', 'configs:en-hi', 'configs:en-hr', 'configs:en-hu', 'configs:en-hy', 'configs:en-id', 'configs:en-ig', 'configs:en-is', 'configs:en-it', 'configs:en-ja', 'configs:en-ka', 'configs:en-kk', 'configs:en-km', 'configs:en-kn', 'configs:en-ko', 'configs:en-ku', 'configs:en-ky', 'configs:en-li', 'configs:en-lt', 'configs:en-lv', 'configs:en-mg', 'configs:en-mk', 'configs:en-ml', 'configs:en-mn', 'configs:en-mr', 'configs:en-ms', 'configs:en-mt', 'configs:en-my', 'configs:en-nb', 'configs:en-ne', 'configs:en-nl', 'configs:en-nn', 'configs:en-no', 'configs:en-oc', 'configs:en-or', 'configs:en-pa', 'configs:en-pl', 'configs:en-ps', 'configs:en-pt', 'configs:en-ro', 'configs:en-ru', 'configs:en-rw', 'configs:en-se', 'configs:en-sh', 'configs:en-si', 'configs:en-sk', 'configs:en-sl', 'configs:en-sq', 'configs:en-sr', 'configs:en-sv', 'configs:en-ta', 'configs:en-te', 'configs:en-tg', 'configs:en-th', 'configs:en-tk', 'configs:en-tr', 'configs:en-tt', 'configs:en-ug', 'configs:en-uk', 'configs:en-ur', 'configs:en-uz', 'configs:en-vi', 'configs:en-wa', 'configs:en-xh', 'configs:en-yi', 'configs:en-yo', 'configs:en-zh', 'configs:en-zu', 'configs:fr-nl', 'configs:fr-ru', 'configs:fr-zh', 'configs:nl-ru', 'configs:nl-zh', 'configs:ru-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OPUS-100 is English-centric, meaning that all training pairs include English on either the source or target side.\n",
       " The corpus covers 100 languages (including English).OPUS-100 contains approximately 55M sentence pairs.\n",
       " Of the 99 language pairs, 44 have 1M sentence pairs of training data, 73 have at least 100k, and 95 have at least 10k.\n",
       " \tcitation: @misc{zhang2020improving,\n",
       "       title={Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation},\n",
       "       author={Biao Zhang and Philip Williams and Ivan Titov and Rico Sennrich},\n",
       "       year={2020},\n",
       "       eprint={2004.11867},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Opus100', 'task_categories': ['text-generation', 'fill-mask'], 'multilinguality': ['translation'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'language': ['af', 'am', 'an', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'li', 'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rw', 'se', 'sh', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'ta', 'te', 'tg', 'th', 'tk', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'wa', 'xh', 'yi', 'yo', 'zh', 'zu'], 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'source_datasets': ['extended'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', '1M<n<10M', 'n<1K'], 'license': ['unknown'], 'paperswithcode_id': 'opus-100', 'configs': ['af-en', 'am-en', 'an-en', 'ar-de', 'ar-en', 'ar-fr', 'ar-nl', 'ar-ru', 'ar-zh', 'as-en', 'az-en', 'be-en', 'bg-en', 'bn-en', 'br-en', 'bs-en', 'ca-en', 'cs-en', 'cy-en', 'da-en', 'de-en', 'de-fr', 'de-nl', 'de-ru', 'de-zh', 'dz-en', 'el-en', 'en-eo', 'en-es', 'en-et', 'en-eu', 'en-fa', 'en-fi', 'en-fr', 'en-fy', 'en-ga', 'en-gd', 'en-gl', 'en-gu', 'en-ha', 'en-he', 'en-hi', 'en-hr', 'en-hu', 'en-hy', 'en-id', 'en-ig', 'en-is', 'en-it', 'en-ja', 'en-ka', 'en-kk', 'en-km', 'en-kn', 'en-ko', 'en-ku', 'en-ky', 'en-li', 'en-lt', 'en-lv', 'en-mg', 'en-mk', 'en-ml', 'en-mn', 'en-mr', 'en-ms', 'en-mt', 'en-my', 'en-nb', 'en-ne', 'en-nl', 'en-nn', 'en-no', 'en-oc', 'en-or', 'en-pa', 'en-pl', 'en-ps', 'en-pt', 'en-ro', 'en-ru', 'en-rw', 'en-se', 'en-sh', 'en-si', 'en-sk', 'en-sl', 'en-sq', 'en-sr', 'en-sv', 'en-ta', 'en-te', 'en-tg', 'en-th', 'en-tk', 'en-tr', 'en-tt', 'en-ug', 'en-uk', 'en-ur', 'en-uz', 'en-vi', 'en-wa', 'en-xh', 'en-yi', 'en-yo', 'en-zh', 'en-zu', 'fr-nl', 'fr-ru', 'fr-zh', 'nl-ru', 'nl-zh', 'ru-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 28594\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: opus-100\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_books\n",
       " \tsha: f545de061b848566ef3c89244ce80cba1045ceb8\n",
       " \tlastModified: 2022-08-11T12:57:30.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ca', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:fi', 'language:fr', 'language:hu', 'language:it', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ru', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of copyright free books aligned by Andras Farkas, which are available from http://www.farkastranslations.com/bilingual_books.php\n",
       " Note that the texts are rather dated due to copyright issues and that some of them are manually reviewed (check the meta-data at the top of the corpus files in XML). The source is multilingually aligned, which is available from http://www.farkastranslations.com/bilingual_books.php. In OPUS, the alignment is formally bilingual but the multilingual alignment can be recovered from the XCES sentence alignment files. Note also that the alignment units from the original source may include multi-sentence paragraphs, which are split and sentence-aligned in OPUS.\n",
       " All texts are freely available for personal, educational and research use. Commercial use (e.g. reselling as parallel books) and mass redistribution without explicit permission are not granted. Please acknowledge the source when using the data!\n",
       " \n",
       " 16 languages, 64 bitexts\n",
       " total number of files: 158\n",
       " total number of tokens: 19.50M\n",
       " total number of sentence fragments: 0.91M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ca', 'de', 'el', 'en', 'eo', 'es', 'fi', 'fr', 'hu', 'it', 'nl', 'no', 'pl', 'pt', 'ru', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusBooks'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 11252\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_dgt\n",
       " \tsha: d72c5b73a114716087b136e5b48a5b8f28665a9a\n",
       " \tlastModified: 2022-08-09T17:38:48.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:ga', 'language:hr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sh', 'language:sk', 'language:sl', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation', 'configs:bg-ga', 'configs:bg-hr', 'configs:bg-sh', 'configs:es-ga', 'configs:fi-ga', 'configs:ga-nl', 'configs:ga-sh', 'configs:hr-sk', 'configs:hr-sv', 'configs:mt-sh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of translation memories provided by the JRC. Source: https://ec.europa.eu/jrc/en/language-technologies/dgt-translation-memory\n",
       " 25 languages, 299 bitexts\n",
       " total number of files: 817,410\n",
       " total number of tokens: 2.13G\n",
       " total number of sentence fragments: 113.52M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'ga', 'hr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sh', 'sk', 'sl', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusDgt', 'configs': ['bg-ga', 'bg-hr', 'bg-sh', 'es-ga', 'fi-ga', 'ga-nl', 'ga-sh', 'hr-sk', 'hr-sv', 'mt-sh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1732\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_dogc\n",
       " \tsha: a41330ee0b74395eaa9df5fccf68847845b02800\n",
       " \tlastModified: 2022-07-01T11:54:51.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:ca', 'language:es', 'license:cc0-1.0', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of documents from the Official Journal of the Government of Catalonia, in Catalan and Spanish languages, provided by Antoni Oliver Gonzalez from the Universitat Oberta de Catalunya.\n",
       " \tcitation: @inproceedings{tiedemann-2012-parallel,\n",
       "     title = \"Parallel Data, Tools and Interfaces in {OPUS}\",\n",
       "     author = {Tiedemann, J{\\\"o}rg},\n",
       "     booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)\",\n",
       "     month = may,\n",
       "     year = \"2012\",\n",
       "     address = \"Istanbul, Turkey\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf\",\n",
       "     pages = \"2214--2218\",\n",
       "     abstract = \"This paper presents the current status of OPUS, a growing language resource of parallel corpora and related tools. The focus in OPUS is to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies. In this paper, we report about new data sets and their features, additional annotation tools and models provided from the website and essential interfaces and on-line services included in the project.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['ca', 'es'], 'license': ['cc0-1.0'], 'multilinguality': ['translation'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OPUS DOGC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_elhuyar\n",
       " \tsha: bf136844724b94f523a4be7544b3bed964014af1\n",
       " \tlastModified: 2022-07-01T11:54:52.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:es', 'language:eu', 'license:unknown', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset provided by the foundation Elhuyar, which is having data in languages Spanish to Basque.\n",
       " \tcitation: @InProceedings{opus:Elhuyar,\n",
       " title = {Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)},\n",
       " authors={J. Tiedemann},\n",
       " year={2012}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['es', 'eu'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusElhuyar'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_euconst\n",
       " \tsha: 7f495955ec1d452a8e120415aacc887922fc5098\n",
       " \tlastModified: 2022-07-01T11:54:52.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:ga', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:sk', 'language:sl', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus collected from the European Constitution for 21 language.\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'ga', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'sk', 'sl', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusEuconst'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 32851\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_finlex\n",
       " \tsha: b332557f7e006936c0b00f1eb5dd834bb2cdced8\n",
       " \tlastModified: 2022-07-01T11:54:52.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:fi', 'language:sv', 'license:unknown', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Finlex Data Base is a comprehensive collection of legislative and other judicial information of Finland, which is available in Finnish, Swedish and partially in English. This corpus is taken from the Semantic Finlex serice that provides the Finnish and Swedish data as linked open data and also raw XML files.\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['fi', 'sv'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusFinlex'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_fiskmo\n",
       " \tsha: 0d78e411416f2d597a713797c6ec8eba5ca87fe7\n",
       " \tlastModified: 2022-07-01T11:54:53.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:fi', 'language:sv', 'license:unknown', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: fiskmo, a massive parallel corpus for Finnish and Swedish.\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['fi', 'sv'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusFiskmo'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_gnome\n",
       " \tsha: b3f47721678904e297232f7416d645b1a58f5e58\n",
       " \tlastModified: 2022-08-09T11:52:31.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:af', 'language:am', 'language:an', 'language:ang', 'language:ar', 'language:as', 'language:ast', 'language:az', 'language:bal', 'language:be', 'language:bem', 'language:bg', 'language:bn', 'language:bo', 'language:br', 'language:brx', 'language:bs', 'language:ca', 'language:crh', 'language:cs', 'language:csb', 'language:cy', 'language:da', 'language:de', 'language:dv', 'language:dz', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fur', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:gu', 'language:gv', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ig', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jbo', 'language:ka', 'language:kg', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:kr', 'language:ks', 'language:ku', 'language:ky', 'language:la', 'language:lg', 'language:li', 'language:lo', 'language:lt', 'language:lv', 'language:mai', 'language:mg', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:mus', 'language:my', 'language:nb', 'language:nds', 'language:ne', 'language:nhn', 'language:nl', 'language:nn', 'language:no', 'language:nqo', 'language:nr', 'language:nso', 'language:oc', 'language:or', 'language:os', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:quz', 'language:ro', 'language:ru', 'language:rw', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:st', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:ts', 'language:tt', 'language:tyj', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:wa', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language_bcp47:ar-TN', 'language_bcp47:az-IR', 'language_bcp47:bg-BG', 'language_bcp47:bn-IN', 'language_bcp47:da-DK', 'language_bcp47:de-CH', 'language_bcp47:en-AU', 'language_bcp47:en-CA', 'language_bcp47:en-GB', 'language_bcp47:en-NZ', 'language_bcp47:en-US', 'language_bcp47:en-ZA', 'language_bcp47:es-AR', 'language_bcp47:es-CL', 'language_bcp47:es-CO', 'language_bcp47:es-CR', 'language_bcp47:es-DO', 'language_bcp47:es-EC', 'language_bcp47:es-ES', 'language_bcp47:es-GT', 'language_bcp47:es-HN', 'language_bcp47:es-MX', 'language_bcp47:es-NI', 'language_bcp47:es-PA', 'language_bcp47:es-PE', 'language_bcp47:es-PR', 'language_bcp47:es-SV', 'language_bcp47:es-UY', 'language_bcp47:es-VE', 'language_bcp47:fa-IR', 'language_bcp47:hi-IN', 'language_bcp47:it-IT', 'language_bcp47:ms-MY', 'language_bcp47:nb-NO', 'language_bcp47:nn-NO', 'language_bcp47:no-NB', 'language_bcp47:pt-BR', 'language_bcp47:pt-PT', 'language_bcp47:sr-ME', 'language_bcp47:tg-TJ', 'language_bcp47:tl-PH', 'language_bcp47:tr-TR', 'language_bcp47:ur-PK', 'language_bcp47:vi-VN', 'language_bcp47:zh-CN', 'language_bcp47:zh-HK', 'language_bcp47:zh-TW', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation', 'configs:ar-bal', 'configs:bg-csb', 'configs:ca-en_GB', 'configs:cs-eo', 'configs:cs-tk', 'configs:da-vi', 'configs:de-ha', 'configs:de-tt', 'configs:el-sk', 'configs:en_GB-my']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of GNOME localization files. Source: https://l10n.gnome.org\n",
       " \n",
       " 187 languages, 12,822 bitexts\n",
       " total number of files: 113,344\n",
       " total number of tokens: 267.27M\n",
       " total number of sentence fragments: 58.12M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'am', 'an', 'ang', 'ar', 'as', 'ast', 'az', 'bal', 'be', 'bem', 'bg', 'bn', 'bo', 'br', 'brx', 'bs', 'ca', 'crh', 'cs', 'csb', 'cy', 'da', 'de', 'dv', 'dz', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fur', 'fy', 'ga', 'gd', 'gl', 'gn', 'gu', 'gv', 'ha', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ig', 'io', 'is', 'it', 'ja', 'jbo', 'ka', 'kg', 'kk', 'km', 'kn', 'ko', 'kr', 'ks', 'ku', 'ky', 'la', 'lg', 'li', 'lo', 'lt', 'lv', 'mai', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'mus', 'my', 'nb', 'nds', 'ne', 'nhn', 'nl', 'nn', 'no', 'nqo', 'nr', 'nso', 'oc', 'or', 'os', 'pa', 'pl', 'ps', 'pt', 'quz', 'ro', 'ru', 'rw', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'st', 'sv', 'sw', 'szl', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'ts', 'tt', 'tyj', 'ug', 'uk', 'ur', 'uz', 'vi', 'wa', 'xh', 'yi', 'yo', 'zh', 'zu'], 'language_bcp47': ['ar-TN', 'az-IR', 'bg-BG', 'bn-IN', 'da-DK', 'de-CH', 'en-AU', 'en-CA', 'en-GB', 'en-NZ', 'en-US', 'en-ZA', 'es-AR', 'es-CL', 'es-CO', 'es-CR', 'es-DO', 'es-EC', 'es-ES', 'es-GT', 'es-HN', 'es-MX', 'es-NI', 'es-PA', 'es-PE', 'es-PR', 'es-SV', 'es-UY', 'es-VE', 'fa-IR', 'hi-IN', 'it-IT', 'ms-MY', 'nb-NO', 'nn-NO', 'no-NB', 'pt-BR', 'pt-PT', 'sr-ME', 'tg-TJ', 'tl-PH', 'tr-TR', 'ur-PK', 'vi-VN', 'zh-CN', 'zh-HK', 'zh-TW'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusGnome', 'configs': ['ar-bal', 'bg-csb', 'ca-en_GB', 'cs-eo', 'cs-tk', 'da-vi', 'de-ha', 'de-tt', 'el-sk', 'en_GB-my']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1728\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_infopankki\n",
       " \tsha: 042fc8a3ca633665c95415daa404c48f49fc74e6\n",
       " \tlastModified: 2022-07-01T11:54:55.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:ru', 'language:so', 'language:sv', 'language:tr', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:ar-en', 'configs:ar-es', 'configs:ar-et', 'configs:ar-fa', 'configs:ar-fi', 'configs:ar-fr', 'configs:ar-ru', 'configs:ar-so', 'configs:ar-sv', 'configs:ar-tr', 'configs:ar-zh', 'configs:en-es', 'configs:en-et', 'configs:en-fa', 'configs:en-fi', 'configs:en-fr', 'configs:en-ru', 'configs:en-so', 'configs:en-sv', 'configs:en-tr', 'configs:en-zh', 'configs:es-et', 'configs:es-fa', 'configs:es-fi', 'configs:es-fr', 'configs:es-ru', 'configs:es-so', 'configs:es-sv', 'configs:es-tr', 'configs:es-zh', 'configs:et-fa', 'configs:et-fi', 'configs:et-fr', 'configs:et-ru', 'configs:et-so', 'configs:et-sv', 'configs:et-tr', 'configs:et-zh', 'configs:fa-fi', 'configs:fa-fr', 'configs:fa-ru', 'configs:fa-so', 'configs:fa-sv', 'configs:fa-tr', 'configs:fa-zh', 'configs:fi-fr', 'configs:fi-ru', 'configs:fi-so', 'configs:fi-sv', 'configs:fi-tr', 'configs:fi-zh', 'configs:fr-ru', 'configs:fr-so', 'configs:fr-sv', 'configs:fr-tr', 'configs:fr-zh', 'configs:ru-so', 'configs:ru-sv', 'configs:ru-tr', 'configs:ru-zh', 'configs:so-sv', 'configs:so-tr', 'configs:so-zh', 'configs:sv-tr', 'configs:sv-zh', 'configs:tr-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of 12 languages, 66 bitexts.\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'ru', 'so', 'sv', 'tr', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusInfopankki', 'configs': ['ar-en', 'ar-es', 'ar-et', 'ar-fa', 'ar-fi', 'ar-fr', 'ar-ru', 'ar-so', 'ar-sv', 'ar-tr', 'ar-zh', 'en-es', 'en-et', 'en-fa', 'en-fi', 'en-fr', 'en-ru', 'en-so', 'en-sv', 'en-tr', 'en-zh', 'es-et', 'es-fa', 'es-fi', 'es-fr', 'es-ru', 'es-so', 'es-sv', 'es-tr', 'es-zh', 'et-fa', 'et-fi', 'et-fr', 'et-ru', 'et-so', 'et-sv', 'et-tr', 'et-zh', 'fa-fi', 'fa-fr', 'fa-ru', 'fa-so', 'fa-sv', 'fa-tr', 'fa-zh', 'fi-fr', 'fi-ru', 'fi-so', 'fi-sv', 'fi-tr', 'fi-zh', 'fr-ru', 'fr-so', 'fr-sv', 'fr-tr', 'fr-zh', 'ru-so', 'ru-sv', 'ru-tr', 'ru-zh', 'so-sv', 'so-tr', 'so-zh', 'sv-tr', 'sv-zh', 'tr-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 10442\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_memat\n",
       " \tsha: b1b2aa59d08f2682c5f351e9b40e560e809076cd\n",
       " \tlastModified: 2022-07-01T11:54:55.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:xh', 'license:unknown', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Xhosa-English parallel corpora, funded by EPSRC, the Medical Machine Translation project worked on machine translation between ixiXhosa and English, with a focus on the medical domain.\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'xh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusMemat'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_montenegrinsubs\n",
       " \tsha: bbad069217abc1f93344f1f1afd18c754d4575f4\n",
       " \tlastModified: 2022-07-27T14:38:56.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:cnr', 'language:en', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Opus MontenegrinSubs dataset for machine translation task, for language pair en-me: english and montenegrin\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['cnr', 'en'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusMontenegrinsubs'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_openoffice\n",
       " \tsha: 13ed7330a9d6b6e90d79160ff32c4fea9d6108cd\n",
       " \tlastModified: 2022-07-27T14:38:56.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:ru', 'language:sv', 'language:zh', 'language_bcp47:en-GB', 'language_bcp47:zh-CN', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:de-en_GB', 'configs:de-es', 'configs:de-fr', 'configs:de-ja', 'configs:de-ru', 'configs:de-sv', 'configs:de-zh_CN', 'configs:en_GB-es', 'configs:en_GB-fr', 'configs:en_GB-ja', 'configs:en_GB-ru', 'configs:en_GB-sv', 'configs:en_GB-zh_CN', 'configs:es-fr', 'configs:es-ja', 'configs:es-ru', 'configs:es-sv', 'configs:es-zh_CN', 'configs:fr-ja', 'configs:fr-ru', 'configs:fr-sv', 'configs:fr-zh_CN', 'configs:ja-ru', 'configs:ja-sv', 'configs:ja-zh_CN', 'configs:ru-sv', 'configs:ru-zh_CN', 'configs:sv-zh_CN']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of documents from http://www.openoffice.org/.\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['de', 'en', 'es', 'fr', 'ja', 'ru', 'sv', 'zh'], 'language_bcp47': ['en-GB', 'zh-CN'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusOpenoffice', 'configs': ['de-en_GB', 'de-es', 'de-fr', 'de-ja', 'de-ru', 'de-sv', 'de-zh_CN', 'en_GB-es', 'en_GB-fr', 'en_GB-ja', 'en_GB-ru', 'en_GB-sv', 'en_GB-zh_CN', 'es-fr', 'es-ja', 'es-ru', 'es-sv', 'es-zh_CN', 'fr-ja', 'fr-ru', 'fr-sv', 'fr-zh_CN', 'ja-ru', 'ja-sv', 'ja-zh_CN', 'ru-sv', 'ru-zh_CN', 'sv-zh_CN']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4550\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_paracrawl\n",
       " \tsha: 282d5f72dd861f5783e9f835eb4531864c8e56bb\n",
       " \tlastModified: 2022-08-12T14:18:26.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:ga', 'language:gl', 'language:hr', 'language:hu', 'language:is', 'language:it', 'language:km', 'language:ko', 'language:lt', 'language:lv', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sv', 'language:sw', 'language:tl', 'language:uk', 'language:zh', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation', 'configs:de-pl', 'configs:el-en', 'configs:en-ha', 'configs:en-ig', 'configs:en-km', 'configs:en-so', 'configs:en-sw', 'configs:en-tl', 'configs:es-gl', 'configs:fr-nl']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Parallel corpora from Web Crawls collected in the ParaCrawl project.\n",
       " \n",
       " 42 languages, 43 bitexts\n",
       " total number of files: 59,996\n",
       " total number of tokens: 56.11G\n",
       " total number of sentence fragments: 3.13G\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fi', 'fr', 'ga', 'gl', 'hr', 'hu', 'is', 'it', 'km', 'ko', 'lt', 'lv', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'pl', 'pt', 'ro', 'ru', 'si', 'sk', 'sl', 'so', 'sv', 'sw', 'tl', 'uk', 'zh'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusParaCrawl', 'configs': ['de-pl', 'el-en', 'en-ha', 'en-ig', 'en-km', 'en-so', 'en-sw', 'en-tl', 'es-gl', 'fr-nl']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1803\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_rf\n",
       " \tsha: 65ed7854ac11972e79881d431d32df6c4e004962\n",
       " \tlastModified: 2022-07-01T11:54:58.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:expert-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation', 'configs:de-en', 'configs:de-es', 'configs:de-fr', 'configs:de-sv', 'configs:en-es', 'configs:en-fr', 'configs:en-sv', 'configs:es-fr', 'configs:es-sv', 'configs:fr-sv']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: RF is a tiny parallel corpus of the Declarations of the Swedish Government and its translations.\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['expert-generated'], 'language': ['de', 'en', 'es', 'fr', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusRf', 'configs': ['de-en', 'de-es', 'de-fr', 'de-sv', 'en-es', 'en-fr', 'en-sv', 'es-fr', 'es-sv', 'fr-sv']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1728\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_tedtalks\n",
       " \tsha: 46581856f7a129f72958f96e30a60640c3e1cf3d\n",
       " \tlastModified: 2022-08-11T12:57:30.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:hr', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a Croatian-English parallel corpus of transcribed and translated TED talks, originally extracted from https://wit3.fbk.eu. The corpus is compiled by Željko Agić and is taken from http://lt.ffzg.hr/zagic provided under the CC-BY-NC-SA license.\n",
       " 2 languages, total number of files: 2\n",
       " total number of tokens: 2.81M\n",
       " total number of sentence fragments: 0.17M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'hr'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusTedtalks'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_ubuntu\n",
       " \tsha: 7decb58f274dd0017957b76830f00352681ea8df\n",
       " \tlastModified: 2022-07-27T14:38:56.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language:ace', 'language:af', 'language:ak', 'language:am', 'language:an', 'language:ang', 'language:ar', 'language:ary', 'language:as', 'language:ast', 'language:az', 'language:ba', 'language:bal', 'language:be', 'language:bem', 'language:ber', 'language:bg', 'language:bho', 'language:bn', 'language:bo', 'language:br', 'language:brx', 'language:bs', 'language:bua', 'language:byn', 'language:ca', 'language:ce', 'language:ceb', 'language:chr', 'language:ckb', 'language:co', 'language:crh', 'language:cs', 'language:csb', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:dsb', 'language:dv', 'language:dz', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:ff', 'language:fi', 'language:fil', 'language:fo', 'language:fr', 'language:frm', 'language:frp', 'language:fur', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:grc', 'language:gu', 'language:guc', 'language:gv', 'language:ha', 'language:haw', 'language:he', 'language:hi', 'language:hil', 'language:hne', 'language:hr', 'language:hsb', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ig', 'language:io', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:jbo', 'language:jv', 'language:ka', 'language:kab', 'language:kg', 'language:kk', 'language:kl', 'language:km', 'language:kn', 'language:ko', 'language:kok', 'language:ks', 'language:ksh', 'language:ku', 'language:kw', 'language:ky', 'language:la', 'language:lb', 'language:lg', 'language:li', 'language:lij', 'language:lld', 'language:ln', 'language:lo', 'language:lt', 'language:ltg', 'language:lv', 'language:mai', 'language:mg', 'language:mh', 'language:mhr', 'language:mi', 'language:miq', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:mus', 'language:my', 'language:nan', 'language:nap', 'language:nb', 'language:nds', 'language:ne', 'language:nhn', 'language:nl', 'language:nn', 'language:no', 'language:nso', 'language:ny', 'language:oc', 'language:om', 'language:or', 'language:os', 'language:pa', 'language:pam', 'language:pap', 'language:pl', 'language:pms', 'language:pmy', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:ro', 'language:rom', 'language:ru', 'language:rw', 'language:sa', 'language:sc', 'language:sco', 'language:sd', 'language:se', 'language:shn', 'language:shs', 'language:si', 'language:sk', 'language:sl', 'language:sm', 'language:sml', 'language:sn', 'language:so', 'language:son', 'language:sq', 'language:sr', 'language:st', 'language:sv', 'language:sw', 'language:syr', 'language:szl', 'language:ta', 'language:te', 'language:tet', 'language:tg', 'language:th', 'language:ti', 'language:tk', 'language:tl', 'language:tlh', 'language:tr', 'language:trv', 'language:ts', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:ve', 'language:vec', 'language:vi', 'language:wa', 'language:wae', 'language:wo', 'language:xal', 'language:xh', 'language:yi', 'language:yo', 'language:zh', 'language:zu', 'language:zza', 'language_bcp47:ar-SY', 'language_bcp47:bn-IN', 'language_bcp47:de-AT', 'language_bcp47:de-DE', 'language_bcp47:en-AU', 'language_bcp47:en-CA', 'language_bcp47:en-GB', 'language_bcp47:en-NZ', 'language_bcp47:en-US', 'language_bcp47:es-AR', 'language_bcp47:es-CL', 'language_bcp47:es-CO', 'language_bcp47:es-CR', 'language_bcp47:es-DO', 'language_bcp47:es-EC', 'language_bcp47:es-ES', 'language_bcp47:es-GT', 'language_bcp47:es-HN', 'language_bcp47:es-MX', 'language_bcp47:es-NI', 'language_bcp47:es-PA', 'language_bcp47:es-PE', 'language_bcp47:es-PR', 'language_bcp47:es-SV', 'language_bcp47:es-UY', 'language_bcp47:es-VE', 'language_bcp47:fa-AF', 'language_bcp47:fr-CA', 'language_bcp47:fr-FR', 'language_bcp47:nl-NL', 'language_bcp47:pt-BR', 'language_bcp47:pt-PT', 'language_bcp47:ta-LK', 'language_bcp47:zh-CN', 'language_bcp47:zh-HK', 'language_bcp47:zh-TW', 'license:bsd-3-clause', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation', 'configs:as-bs', 'configs:az-cs', 'configs:bg-de', 'configs:bn-ga', 'configs:br-es_PR', 'configs:br-hi', 'configs:br-la', 'configs:br-uz', 'configs:br-yi', 'configs:bs-szl']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of Ubuntu localization files. Source: https://translations.launchpad.net\n",
       " 244 languages, 23,988 bitexts\n",
       " total number of files: 30,959\n",
       " total number of tokens: 29.84M\n",
       " total number of sentence fragments: 7.73M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found'], 'language': ['ace', 'af', 'ak', 'am', 'an', 'ang', 'ar', 'ary', 'as', 'ast', 'az', 'ba', 'bal', 'be', 'bem', 'ber', 'bg', 'bho', 'bn', 'bo', 'br', 'brx', 'bs', 'bua', 'byn', 'ca', 'ce', 'ceb', 'chr', 'ckb', 'co', 'crh', 'cs', 'csb', 'cv', 'cy', 'da', 'de', 'dsb', 'dv', 'dz', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'ff', 'fi', 'fil', 'fo', 'fr', 'frm', 'frp', 'fur', 'fy', 'ga', 'gd', 'gl', 'gn', 'grc', 'gu', 'guc', 'gv', 'ha', 'haw', 'he', 'hi', 'hil', 'hne', 'hr', 'hsb', 'ht', 'hu', 'hy', 'ia', 'id', 'ig', 'io', 'is', 'it', 'iu', 'ja', 'jbo', 'jv', 'ka', 'kab', 'kg', 'kk', 'kl', 'km', 'kn', 'ko', 'kok', 'ks', 'ksh', 'ku', 'kw', 'ky', 'la', 'lb', 'lg', 'li', 'lij', 'lld', 'ln', 'lo', 'lt', 'ltg', 'lv', 'mai', 'mg', 'mh', 'mhr', 'mi', 'miq', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'mus', 'my', 'nan', 'nap', 'nb', 'nds', 'ne', 'nhn', 'nl', 'nn', 'no', 'nso', 'ny', 'oc', 'om', 'or', 'os', 'pa', 'pam', 'pap', 'pl', 'pms', 'pmy', 'ps', 'pt', 'qu', 'rm', 'ro', 'rom', 'ru', 'rw', 'sa', 'sc', 'sco', 'sd', 'se', 'shn', 'shs', 'si', 'sk', 'sl', 'sm', 'sml', 'sn', 'so', 'son', 'sq', 'sr', 'st', 'sv', 'sw', 'syr', 'szl', 'ta', 'te', 'tet', 'tg', 'th', 'ti', 'tk', 'tl', 'tlh', 'tr', 'trv', 'ts', 'tt', 'ug', 'uk', 'ur', 'uz', 've', 'vec', 'vi', 'wa', 'wae', 'wo', 'xal', 'xh', 'yi', 'yo', 'zh', 'zu', 'zza'], 'language_bcp47': ['ar-SY', 'bn-IN', 'de-AT', 'de-DE', 'en-AU', 'en-CA', 'en-GB', 'en-NZ', 'en-US', 'es-AR', 'es-CL', 'es-CO', 'es-CR', 'es-DO', 'es-EC', 'es-ES', 'es-GT', 'es-HN', 'es-MX', 'es-NI', 'es-PA', 'es-PE', 'es-PR', 'es-SV', 'es-UY', 'es-VE', 'fa-AF', 'fr-CA', 'fr-FR', 'nl-NL', 'pt-BR', 'pt-PT', 'ta-LK', 'zh-CN', 'zh-HK', 'zh-TW'], 'license': ['bsd-3-clause'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'Opus Ubuntu', 'configs': ['as-bs', 'az-cs', 'bg-de', 'bn-ga', 'br-es_PR', 'br-hi', 'br-la', 'br-uz', 'br-yi', 'bs-szl']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9893\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_wikipedia\n",
       " \tsha: 08524956ea6a9f58338cdb3d0fa46d84f9f559b0\n",
       " \tlastModified: 2022-08-09T17:38:48.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:bg', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:he', 'language:hu', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sl', 'language:tr', 'language:vi', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:ar-en', 'configs:ar-pl', 'configs:en-ru', 'configs:en-sl', 'configs:en-vi']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a corpus of parallel sentences extracted from Wikipedia by Krzysztof Wołk and Krzysztof Marasek. Please cite the following publication if you use the data: Krzysztof Wołk and Krzysztof Marasek: Building Subject-aligned Comparable Corpora and Mining it for Truly Parallel Sentence Pairs., Procedia Technology, 18, Elsevier, p.126-132, 2014\n",
       " 20 languages, 36 bitexts\n",
       " total number of files: 114\n",
       " total number of tokens: 610.13M\n",
       " total number of sentence fragments: 25.90M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa', 'fr', 'he', 'hu', 'it', 'nl', 'pl', 'pt', 'ro', 'ru', 'sl', 'tr', 'vi'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusWikipedia', 'configs': ['ar-en', 'ar-pl', 'en-ru', 'en-sl', 'en-vi']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 954\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: opus_xhosanavy\n",
       " \tsha: 38eab5089c4fea2ec9bcc02a69da03b9cf730062\n",
       " \tlastModified: 2022-07-01T11:55:00.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:xh', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is designed for machine translation from English to Xhosa.\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'xh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'OpusXhosanavy'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: orange_sum\n",
       " \tsha: 9bab50e352c0dd2776afd18eddfbf421a374e1fd\n",
       " \tlastModified: 2022-07-01T11:55:00.000Z\n",
       " \ttags: ['arxiv:2010.12321', 'annotations_creators:found', 'language_creators:found', 'language:fr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-headline-generation', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The OrangeSum dataset was inspired by the XSum dataset. It was created by scraping the \"Orange Actu\" website: https://actu.orange.fr/. Orange S.A. is a large French multinational telecommunications corporation, with 266M customers worldwide. Scraped pages cover almost a decade from Feb 2011 to Sep 2020. They belong to five main categories: France, world, politics, automotive, and society. The society category is itself divided into 8 subcategories: health, environment, people, culture, media, high-tech, unsual (\"insolite\" in French), and miscellaneous.\n",
       " \n",
       " Each article featured a single-sentence title as well as a very brief abstract, both professionally written by the author of the article. These two fields were extracted from each page, thus creating two summarization tasks: OrangeSum Title and OrangeSum Abstract.\n",
       " \tcitation: @article{eddine2020barthez,\n",
       "   title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model},\n",
       "   author={Eddine, Moussa Kamal and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n",
       "   journal={arXiv preprint arXiv:2010.12321},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'OrangeSum', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['fr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-headline-generation', 'news-articles-summarization'], 'paperswithcode_id': 'orangesum'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 494\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: orangesum\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: oscar\n",
       " \tsha: 916f956518279c5e60c63902ebdf3ddf9fa9d629\n",
       " \tlastModified: 2022-07-01T11:55:03.000Z\n",
       " \ttags: ['arxiv:2010.14571', 'annotations_creators:no-annotation', 'language_creators:found', 'language:af', 'language:als', 'language:am', 'language:an', 'language:ar', 'language:arz', 'language:as', 'language:ast', 'language:av', 'language:az', 'language:azb', 'language:ba', 'language:bar', 'language:bcl', 'language:be', 'language:bg', 'language:bh', 'language:bn', 'language:bo', 'language:bpy', 'language:br', 'language:bs', 'language:bxr', 'language:ca', 'language:cbk', 'language:ce', 'language:ceb', 'language:ckb', 'language:cs', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:diq', 'language:dsb', 'language:dv', 'language:el', 'language:eml', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:frr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:gom', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:hsb', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:ilo', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jbo', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:krc', 'language:ku', 'language:kv', 'language:kw', 'language:ky', 'language:la', 'language:lb', 'language:lez', 'language:li', 'language:lmo', 'language:lo', 'language:lrc', 'language:lt', 'language:lv', 'language:mai', 'language:mg', 'language:mhr', 'language:min', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:mrj', 'language:ms', 'language:mt', 'language:mwl', 'language:my', 'language:myv', 'language:mzn', 'language:nah', 'language:nap', 'language:nds', 'language:ne', 'language:new', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:or', 'language:os', 'language:pa', 'language:pam', 'language:pl', 'language:pms', 'language:pnb', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:ro', 'language:ru', 'language:sa', 'language:sah', 'language:scn', 'language:sd', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:tt', 'language:tyv', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vec', 'language:vi', 'language:vo', 'language:wa', 'language:war', 'language:wuu', 'language:xal', 'language:xmf', 'language:yi', 'language:yo', 'language:yue', 'language:zh', 'license:cc0-1.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:100M<n<1B', 'size_categories:10K<n<100K', 'size_categories:10M<n<100M', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'configs:unshuffled_deduplicated_af', 'configs:unshuffled_deduplicated_als', 'configs:unshuffled_deduplicated_am', 'configs:unshuffled_deduplicated_an', 'configs:unshuffled_deduplicated_ar', 'configs:unshuffled_deduplicated_arz', 'configs:unshuffled_deduplicated_as', 'configs:unshuffled_deduplicated_ast', 'configs:unshuffled_deduplicated_av', 'configs:unshuffled_deduplicated_az', 'configs:unshuffled_deduplicated_azb', 'configs:unshuffled_deduplicated_ba', 'configs:unshuffled_deduplicated_bar', 'configs:unshuffled_deduplicated_bcl', 'configs:unshuffled_deduplicated_be', 'configs:unshuffled_deduplicated_bg', 'configs:unshuffled_deduplicated_bh', 'configs:unshuffled_deduplicated_bn', 'configs:unshuffled_deduplicated_bo', 'configs:unshuffled_deduplicated_bpy', 'configs:unshuffled_deduplicated_br', 'configs:unshuffled_deduplicated_bs', 'configs:unshuffled_deduplicated_bxr', 'configs:unshuffled_deduplicated_ca', 'configs:unshuffled_deduplicated_cbk', 'configs:unshuffled_deduplicated_ce', 'configs:unshuffled_deduplicated_ceb', 'configs:unshuffled_deduplicated_ckb', 'configs:unshuffled_deduplicated_cs', 'configs:unshuffled_deduplicated_cv', 'configs:unshuffled_deduplicated_cy', 'configs:unshuffled_deduplicated_da', 'configs:unshuffled_deduplicated_de', 'configs:unshuffled_deduplicated_diq', 'configs:unshuffled_deduplicated_dsb', 'configs:unshuffled_deduplicated_dv', 'configs:unshuffled_deduplicated_el', 'configs:unshuffled_deduplicated_eml', 'configs:unshuffled_deduplicated_en', 'configs:unshuffled_deduplicated_eo', 'configs:unshuffled_deduplicated_es', 'configs:unshuffled_deduplicated_et', 'configs:unshuffled_deduplicated_eu', 'configs:unshuffled_deduplicated_fa', 'configs:unshuffled_deduplicated_fi', 'configs:unshuffled_deduplicated_fr', 'configs:unshuffled_deduplicated_frr', 'configs:unshuffled_deduplicated_fy', 'configs:unshuffled_deduplicated_ga', 'configs:unshuffled_deduplicated_gd', 'configs:unshuffled_deduplicated_gl', 'configs:unshuffled_deduplicated_gn', 'configs:unshuffled_deduplicated_gom', 'configs:unshuffled_deduplicated_gu', 'configs:unshuffled_deduplicated_he', 'configs:unshuffled_deduplicated_hi', 'configs:unshuffled_deduplicated_hr', 'configs:unshuffled_deduplicated_hsb', 'configs:unshuffled_deduplicated_ht', 'configs:unshuffled_deduplicated_hu', 'configs:unshuffled_deduplicated_hy', 'configs:unshuffled_deduplicated_ia', 'configs:unshuffled_deduplicated_id', 'configs:unshuffled_deduplicated_ie', 'configs:unshuffled_deduplicated_ilo', 'configs:unshuffled_deduplicated_io', 'configs:unshuffled_deduplicated_is', 'configs:unshuffled_deduplicated_it', 'configs:unshuffled_deduplicated_ja', 'configs:unshuffled_deduplicated_jbo', 'configs:unshuffled_deduplicated_jv', 'configs:unshuffled_deduplicated_ka', 'configs:unshuffled_deduplicated_kk', 'configs:unshuffled_deduplicated_km', 'configs:unshuffled_deduplicated_kn', 'configs:unshuffled_deduplicated_ko', 'configs:unshuffled_deduplicated_krc', 'configs:unshuffled_deduplicated_ku', 'configs:unshuffled_deduplicated_kv', 'configs:unshuffled_deduplicated_kw', 'configs:unshuffled_deduplicated_ky', 'configs:unshuffled_deduplicated_la', 'configs:unshuffled_deduplicated_lb', 'configs:unshuffled_deduplicated_lez', 'configs:unshuffled_deduplicated_li', 'configs:unshuffled_deduplicated_lmo', 'configs:unshuffled_deduplicated_lo', 'configs:unshuffled_deduplicated_lrc', 'configs:unshuffled_deduplicated_lt', 'configs:unshuffled_deduplicated_lv', 'configs:unshuffled_deduplicated_mai', 'configs:unshuffled_deduplicated_mg', 'configs:unshuffled_deduplicated_mhr', 'configs:unshuffled_deduplicated_min', 'configs:unshuffled_deduplicated_mk', 'configs:unshuffled_deduplicated_ml', 'configs:unshuffled_deduplicated_mn', 'configs:unshuffled_deduplicated_mr', 'configs:unshuffled_deduplicated_mrj', 'configs:unshuffled_deduplicated_ms', 'configs:unshuffled_deduplicated_mt', 'configs:unshuffled_deduplicated_mwl', 'configs:unshuffled_deduplicated_my', 'configs:unshuffled_deduplicated_myv', 'configs:unshuffled_deduplicated_mzn', 'configs:unshuffled_deduplicated_nah', 'configs:unshuffled_deduplicated_nap', 'configs:unshuffled_deduplicated_nds', 'configs:unshuffled_deduplicated_ne', 'configs:unshuffled_deduplicated_new', 'configs:unshuffled_deduplicated_nl', 'configs:unshuffled_deduplicated_nn', 'configs:unshuffled_deduplicated_no', 'configs:unshuffled_deduplicated_oc', 'configs:unshuffled_deduplicated_or', 'configs:unshuffled_deduplicated_os', 'configs:unshuffled_deduplicated_pa', 'configs:unshuffled_deduplicated_pam', 'configs:unshuffled_deduplicated_pl', 'configs:unshuffled_deduplicated_pms', 'configs:unshuffled_deduplicated_pnb', 'configs:unshuffled_deduplicated_ps', 'configs:unshuffled_deduplicated_pt', 'configs:unshuffled_deduplicated_qu', 'configs:unshuffled_deduplicated_rm', 'configs:unshuffled_deduplicated_ro', 'configs:unshuffled_deduplicated_ru', 'configs:unshuffled_deduplicated_sa', 'configs:unshuffled_deduplicated_sah', 'configs:unshuffled_deduplicated_scn', 'configs:unshuffled_deduplicated_sd', 'configs:unshuffled_deduplicated_sh', 'configs:unshuffled_deduplicated_si', 'configs:unshuffled_deduplicated_sk', 'configs:unshuffled_deduplicated_sl', 'configs:unshuffled_deduplicated_so', 'configs:unshuffled_deduplicated_sq', 'configs:unshuffled_deduplicated_sr', 'configs:unshuffled_deduplicated_su', 'configs:unshuffled_deduplicated_sv', 'configs:unshuffled_deduplicated_sw', 'configs:unshuffled_deduplicated_ta', 'configs:unshuffled_deduplicated_te', 'configs:unshuffled_deduplicated_tg', 'configs:unshuffled_deduplicated_th', 'configs:unshuffled_deduplicated_tk', 'configs:unshuffled_deduplicated_tl', 'configs:unshuffled_deduplicated_tr', 'configs:unshuffled_deduplicated_tt', 'configs:unshuffled_deduplicated_tyv', 'configs:unshuffled_deduplicated_ug', 'configs:unshuffled_deduplicated_uk', 'configs:unshuffled_deduplicated_ur', 'configs:unshuffled_deduplicated_uz', 'configs:unshuffled_deduplicated_vec', 'configs:unshuffled_deduplicated_vi', 'configs:unshuffled_deduplicated_vo', 'configs:unshuffled_deduplicated_wa', 'configs:unshuffled_deduplicated_war', 'configs:unshuffled_deduplicated_wuu', 'configs:unshuffled_deduplicated_xal', 'configs:unshuffled_deduplicated_xmf', 'configs:unshuffled_deduplicated_yi', 'configs:unshuffled_deduplicated_yo', 'configs:unshuffled_deduplicated_yue', 'configs:unshuffled_deduplicated_zh', 'configs:unshuffled_original_af', 'configs:unshuffled_original_als', 'configs:unshuffled_original_am', 'configs:unshuffled_original_an', 'configs:unshuffled_original_ar', 'configs:unshuffled_original_arz', 'configs:unshuffled_original_as', 'configs:unshuffled_original_ast', 'configs:unshuffled_original_av', 'configs:unshuffled_original_az', 'configs:unshuffled_original_azb', 'configs:unshuffled_original_ba', 'configs:unshuffled_original_bar', 'configs:unshuffled_original_bcl', 'configs:unshuffled_original_be', 'configs:unshuffled_original_bg', 'configs:unshuffled_original_bh', 'configs:unshuffled_original_bn', 'configs:unshuffled_original_bo', 'configs:unshuffled_original_bpy', 'configs:unshuffled_original_br', 'configs:unshuffled_original_bs', 'configs:unshuffled_original_bxr', 'configs:unshuffled_original_ca', 'configs:unshuffled_original_cbk', 'configs:unshuffled_original_ce', 'configs:unshuffled_original_ceb', 'configs:unshuffled_original_ckb', 'configs:unshuffled_original_cs', 'configs:unshuffled_original_cv', 'configs:unshuffled_original_cy', 'configs:unshuffled_original_da', 'configs:unshuffled_original_de', 'configs:unshuffled_original_diq', 'configs:unshuffled_original_dsb', 'configs:unshuffled_original_dv', 'configs:unshuffled_original_el', 'configs:unshuffled_original_eml', 'configs:unshuffled_original_en', 'configs:unshuffled_original_eo', 'configs:unshuffled_original_es', 'configs:unshuffled_original_et', 'configs:unshuffled_original_eu', 'configs:unshuffled_original_fa', 'configs:unshuffled_original_fi', 'configs:unshuffled_original_fr', 'configs:unshuffled_original_frr', 'configs:unshuffled_original_fy', 'configs:unshuffled_original_ga', 'configs:unshuffled_original_gd', 'configs:unshuffled_original_gl', 'configs:unshuffled_original_gn', 'configs:unshuffled_original_gom', 'configs:unshuffled_original_gu', 'configs:unshuffled_original_he', 'configs:unshuffled_original_hi', 'configs:unshuffled_original_hr', 'configs:unshuffled_original_hsb', 'configs:unshuffled_original_ht', 'configs:unshuffled_original_hu', 'configs:unshuffled_original_hy', 'configs:unshuffled_original_ia', 'configs:unshuffled_original_id', 'configs:unshuffled_original_ie', 'configs:unshuffled_original_ilo', 'configs:unshuffled_original_io', 'configs:unshuffled_original_is', 'configs:unshuffled_original_it', 'configs:unshuffled_original_ja', 'configs:unshuffled_original_jbo', 'configs:unshuffled_original_jv', 'configs:unshuffled_original_ka', 'configs:unshuffled_original_kk', 'configs:unshuffled_original_km', 'configs:unshuffled_original_kn', 'configs:unshuffled_original_ko', 'configs:unshuffled_original_krc', 'configs:unshuffled_original_ku', 'configs:unshuffled_original_kv', 'configs:unshuffled_original_kw', 'configs:unshuffled_original_ky', 'configs:unshuffled_original_la', 'configs:unshuffled_original_lb', 'configs:unshuffled_original_lez', 'configs:unshuffled_original_li', 'configs:unshuffled_original_lmo', 'configs:unshuffled_original_lo', 'configs:unshuffled_original_lrc', 'configs:unshuffled_original_lt', 'configs:unshuffled_original_lv', 'configs:unshuffled_original_mai', 'configs:unshuffled_original_mg', 'configs:unshuffled_original_mhr', 'configs:unshuffled_original_min', 'configs:unshuffled_original_mk', 'configs:unshuffled_original_ml', 'configs:unshuffled_original_mn', 'configs:unshuffled_original_mr', 'configs:unshuffled_original_mrj', 'configs:unshuffled_original_ms', 'configs:unshuffled_original_mt', 'configs:unshuffled_original_mwl', 'configs:unshuffled_original_my', 'configs:unshuffled_original_myv', 'configs:unshuffled_original_mzn', 'configs:unshuffled_original_nah', 'configs:unshuffled_original_nap', 'configs:unshuffled_original_nds', 'configs:unshuffled_original_ne', 'configs:unshuffled_original_new', 'configs:unshuffled_original_nl', 'configs:unshuffled_original_nn', 'configs:unshuffled_original_no', 'configs:unshuffled_original_oc', 'configs:unshuffled_original_or', 'configs:unshuffled_original_os', 'configs:unshuffled_original_pa', 'configs:unshuffled_original_pam', 'configs:unshuffled_original_pl', 'configs:unshuffled_original_pms', 'configs:unshuffled_original_pnb', 'configs:unshuffled_original_ps', 'configs:unshuffled_original_pt', 'configs:unshuffled_original_qu', 'configs:unshuffled_original_rm', 'configs:unshuffled_original_ro', 'configs:unshuffled_original_ru', 'configs:unshuffled_original_sa', 'configs:unshuffled_original_sah', 'configs:unshuffled_original_scn', 'configs:unshuffled_original_sd', 'configs:unshuffled_original_sh', 'configs:unshuffled_original_si', 'configs:unshuffled_original_sk', 'configs:unshuffled_original_sl', 'configs:unshuffled_original_so', 'configs:unshuffled_original_sq', 'configs:unshuffled_original_sr', 'configs:unshuffled_original_su', 'configs:unshuffled_original_sv', 'configs:unshuffled_original_sw', 'configs:unshuffled_original_ta', 'configs:unshuffled_original_te', 'configs:unshuffled_original_tg', 'configs:unshuffled_original_th', 'configs:unshuffled_original_tk', 'configs:unshuffled_original_tl', 'configs:unshuffled_original_tr', 'configs:unshuffled_original_tt', 'configs:unshuffled_original_tyv', 'configs:unshuffled_original_ug', 'configs:unshuffled_original_uk', 'configs:unshuffled_original_ur', 'configs:unshuffled_original_uz', 'configs:unshuffled_original_vec', 'configs:unshuffled_original_vi', 'configs:unshuffled_original_vo', 'configs:unshuffled_original_wa', 'configs:unshuffled_original_war', 'configs:unshuffled_original_wuu', 'configs:unshuffled_original_xal', 'configs:unshuffled_original_xmf', 'configs:unshuffled_original_yi', 'configs:unshuffled_original_yo', 'configs:unshuffled_original_yue', 'configs:unshuffled_original_zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\\n",
       " \tcitation: @inproceedings{ortiz-suarez-etal-2020-monolingual,\n",
       "     title = \"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages\",\n",
       "     author = \"Ortiz Su{\\'a}rez, Pedro Javier  and\n",
       "       Romary, Laurent  and\n",
       "       Sagot, Benoit\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.156\",\n",
       "     pages = \"1703--1714\",\n",
       "     abstract = \"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures.\",\n",
       " }\n",
       " \n",
       " @inproceedings{OrtizSuarezSagotRomary2019,\n",
       "   author    = {Pedro Javier {Ortiz Su{\\'a}rez} and Benoit Sagot and Laurent Romary},\n",
       "   title     = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},\n",
       "   series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},\n",
       "   editor    = {Piotr Bański and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\\\"u}ngen and Caroline Iliadi},\n",
       "   publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n",
       "   address   = {Mannheim},\n",
       "   doi       = {10.14618/ids-pub-9021},\n",
       "   url       = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},\n",
       "   pages     = {9 -- 16},\n",
       "   year      = {2019},\n",
       "   abstract  = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},\n",
       "   language  = {en}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'OSCAR', 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['af', 'als', 'am', 'an', 'ar', 'arz', 'as', 'ast', 'av', 'az', 'azb', 'ba', 'bar', 'bcl', 'be', 'bg', 'bh', 'bn', 'bo', 'bpy', 'br', 'bs', 'bxr', 'ca', 'cbk', 'ce', 'ceb', 'ckb', 'cs', 'cv', 'cy', 'da', 'de', 'diq', 'dsb', 'dv', 'el', 'eml', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'frr', 'fy', 'ga', 'gd', 'gl', 'gn', 'gom', 'gu', 'he', 'hi', 'hr', 'hsb', 'ht', 'hu', 'hy', 'ia', 'id', 'ie', 'ilo', 'io', 'is', 'it', 'ja', 'jbo', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'krc', 'ku', 'kv', 'kw', 'ky', 'la', 'lb', 'lez', 'li', 'lmo', 'lo', 'lrc', 'lt', 'lv', 'mai', 'mg', 'mhr', 'min', 'mk', 'ml', 'mn', 'mr', 'mrj', 'ms', 'mt', 'mwl', 'my', 'myv', 'mzn', 'nah', 'nap', 'nds', 'ne', 'new', 'nl', 'nn', 'no', 'oc', 'or', 'os', 'pa', 'pam', 'pl', 'pms', 'pnb', 'ps', 'pt', 'qu', 'rm', 'ro', 'ru', 'sa', 'sah', 'scn', 'sd', 'sh', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'tyv', 'ug', 'uk', 'ur', 'uz', 'vec', 'vi', 'vo', 'wa', 'war', 'wuu', 'xal', 'xmf', 'yi', 'yo', 'yue', 'zh'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '100M<n<1B', '10K<n<100K', '10M<n<100M', '1K<n<10K', '1M<n<10M', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'oscar', 'configs': ['unshuffled_deduplicated_af', 'unshuffled_deduplicated_als', 'unshuffled_deduplicated_am', 'unshuffled_deduplicated_an', 'unshuffled_deduplicated_ar', 'unshuffled_deduplicated_arz', 'unshuffled_deduplicated_as', 'unshuffled_deduplicated_ast', 'unshuffled_deduplicated_av', 'unshuffled_deduplicated_az', 'unshuffled_deduplicated_azb', 'unshuffled_deduplicated_ba', 'unshuffled_deduplicated_bar', 'unshuffled_deduplicated_bcl', 'unshuffled_deduplicated_be', 'unshuffled_deduplicated_bg', 'unshuffled_deduplicated_bh', 'unshuffled_deduplicated_bn', 'unshuffled_deduplicated_bo', 'unshuffled_deduplicated_bpy', 'unshuffled_deduplicated_br', 'unshuffled_deduplicated_bs', 'unshuffled_deduplicated_bxr', 'unshuffled_deduplicated_ca', 'unshuffled_deduplicated_cbk', 'unshuffled_deduplicated_ce', 'unshuffled_deduplicated_ceb', 'unshuffled_deduplicated_ckb', 'unshuffled_deduplicated_cs', 'unshuffled_deduplicated_cv', 'unshuffled_deduplicated_cy', 'unshuffled_deduplicated_da', 'unshuffled_deduplicated_de', 'unshuffled_deduplicated_diq', 'unshuffled_deduplicated_dsb', 'unshuffled_deduplicated_dv', 'unshuffled_deduplicated_el', 'unshuffled_deduplicated_eml', 'unshuffled_deduplicated_en', 'unshuffled_deduplicated_eo', 'unshuffled_deduplicated_es', 'unshuffled_deduplicated_et', 'unshuffled_deduplicated_eu', 'unshuffled_deduplicated_fa', 'unshuffled_deduplicated_fi', 'unshuffled_deduplicated_fr', 'unshuffled_deduplicated_frr', 'unshuffled_deduplicated_fy', 'unshuffled_deduplicated_ga', 'unshuffled_deduplicated_gd', 'unshuffled_deduplicated_gl', 'unshuffled_deduplicated_gn', 'unshuffled_deduplicated_gom', 'unshuffled_deduplicated_gu', 'unshuffled_deduplicated_he', 'unshuffled_deduplicated_hi', 'unshuffled_deduplicated_hr', 'unshuffled_deduplicated_hsb', 'unshuffled_deduplicated_ht', 'unshuffled_deduplicated_hu', 'unshuffled_deduplicated_hy', 'unshuffled_deduplicated_ia', 'unshuffled_deduplicated_id', 'unshuffled_deduplicated_ie', 'unshuffled_deduplicated_ilo', 'unshuffled_deduplicated_io', 'unshuffled_deduplicated_is', 'unshuffled_deduplicated_it', 'unshuffled_deduplicated_ja', 'unshuffled_deduplicated_jbo', 'unshuffled_deduplicated_jv', 'unshuffled_deduplicated_ka', 'unshuffled_deduplicated_kk', 'unshuffled_deduplicated_km', 'unshuffled_deduplicated_kn', 'unshuffled_deduplicated_ko', 'unshuffled_deduplicated_krc', 'unshuffled_deduplicated_ku', 'unshuffled_deduplicated_kv', 'unshuffled_deduplicated_kw', 'unshuffled_deduplicated_ky', 'unshuffled_deduplicated_la', 'unshuffled_deduplicated_lb', 'unshuffled_deduplicated_lez', 'unshuffled_deduplicated_li', 'unshuffled_deduplicated_lmo', 'unshuffled_deduplicated_lo', 'unshuffled_deduplicated_lrc', 'unshuffled_deduplicated_lt', 'unshuffled_deduplicated_lv', 'unshuffled_deduplicated_mai', 'unshuffled_deduplicated_mg', 'unshuffled_deduplicated_mhr', 'unshuffled_deduplicated_min', 'unshuffled_deduplicated_mk', 'unshuffled_deduplicated_ml', 'unshuffled_deduplicated_mn', 'unshuffled_deduplicated_mr', 'unshuffled_deduplicated_mrj', 'unshuffled_deduplicated_ms', 'unshuffled_deduplicated_mt', 'unshuffled_deduplicated_mwl', 'unshuffled_deduplicated_my', 'unshuffled_deduplicated_myv', 'unshuffled_deduplicated_mzn', 'unshuffled_deduplicated_nah', 'unshuffled_deduplicated_nap', 'unshuffled_deduplicated_nds', 'unshuffled_deduplicated_ne', 'unshuffled_deduplicated_new', 'unshuffled_deduplicated_nl', 'unshuffled_deduplicated_nn', 'unshuffled_deduplicated_no', 'unshuffled_deduplicated_oc', 'unshuffled_deduplicated_or', 'unshuffled_deduplicated_os', 'unshuffled_deduplicated_pa', 'unshuffled_deduplicated_pam', 'unshuffled_deduplicated_pl', 'unshuffled_deduplicated_pms', 'unshuffled_deduplicated_pnb', 'unshuffled_deduplicated_ps', 'unshuffled_deduplicated_pt', 'unshuffled_deduplicated_qu', 'unshuffled_deduplicated_rm', 'unshuffled_deduplicated_ro', 'unshuffled_deduplicated_ru', 'unshuffled_deduplicated_sa', 'unshuffled_deduplicated_sah', 'unshuffled_deduplicated_scn', 'unshuffled_deduplicated_sd', 'unshuffled_deduplicated_sh', 'unshuffled_deduplicated_si', 'unshuffled_deduplicated_sk', 'unshuffled_deduplicated_sl', 'unshuffled_deduplicated_so', 'unshuffled_deduplicated_sq', 'unshuffled_deduplicated_sr', 'unshuffled_deduplicated_su', 'unshuffled_deduplicated_sv', 'unshuffled_deduplicated_sw', 'unshuffled_deduplicated_ta', 'unshuffled_deduplicated_te', 'unshuffled_deduplicated_tg', 'unshuffled_deduplicated_th', 'unshuffled_deduplicated_tk', 'unshuffled_deduplicated_tl', 'unshuffled_deduplicated_tr', 'unshuffled_deduplicated_tt', 'unshuffled_deduplicated_tyv', 'unshuffled_deduplicated_ug', 'unshuffled_deduplicated_uk', 'unshuffled_deduplicated_ur', 'unshuffled_deduplicated_uz', 'unshuffled_deduplicated_vec', 'unshuffled_deduplicated_vi', 'unshuffled_deduplicated_vo', 'unshuffled_deduplicated_wa', 'unshuffled_deduplicated_war', 'unshuffled_deduplicated_wuu', 'unshuffled_deduplicated_xal', 'unshuffled_deduplicated_xmf', 'unshuffled_deduplicated_yi', 'unshuffled_deduplicated_yo', 'unshuffled_deduplicated_yue', 'unshuffled_deduplicated_zh', 'unshuffled_original_af', 'unshuffled_original_als', 'unshuffled_original_am', 'unshuffled_original_an', 'unshuffled_original_ar', 'unshuffled_original_arz', 'unshuffled_original_as', 'unshuffled_original_ast', 'unshuffled_original_av', 'unshuffled_original_az', 'unshuffled_original_azb', 'unshuffled_original_ba', 'unshuffled_original_bar', 'unshuffled_original_bcl', 'unshuffled_original_be', 'unshuffled_original_bg', 'unshuffled_original_bh', 'unshuffled_original_bn', 'unshuffled_original_bo', 'unshuffled_original_bpy', 'unshuffled_original_br', 'unshuffled_original_bs', 'unshuffled_original_bxr', 'unshuffled_original_ca', 'unshuffled_original_cbk', 'unshuffled_original_ce', 'unshuffled_original_ceb', 'unshuffled_original_ckb', 'unshuffled_original_cs', 'unshuffled_original_cv', 'unshuffled_original_cy', 'unshuffled_original_da', 'unshuffled_original_de', 'unshuffled_original_diq', 'unshuffled_original_dsb', 'unshuffled_original_dv', 'unshuffled_original_el', 'unshuffled_original_eml', 'unshuffled_original_en', 'unshuffled_original_eo', 'unshuffled_original_es', 'unshuffled_original_et', 'unshuffled_original_eu', 'unshuffled_original_fa', 'unshuffled_original_fi', 'unshuffled_original_fr', 'unshuffled_original_frr', 'unshuffled_original_fy', 'unshuffled_original_ga', 'unshuffled_original_gd', 'unshuffled_original_gl', 'unshuffled_original_gn', 'unshuffled_original_gom', 'unshuffled_original_gu', 'unshuffled_original_he', 'unshuffled_original_hi', 'unshuffled_original_hr', 'unshuffled_original_hsb', 'unshuffled_original_ht', 'unshuffled_original_hu', 'unshuffled_original_hy', 'unshuffled_original_ia', 'unshuffled_original_id', 'unshuffled_original_ie', 'unshuffled_original_ilo', 'unshuffled_original_io', 'unshuffled_original_is', 'unshuffled_original_it', 'unshuffled_original_ja', 'unshuffled_original_jbo', 'unshuffled_original_jv', 'unshuffled_original_ka', 'unshuffled_original_kk', 'unshuffled_original_km', 'unshuffled_original_kn', 'unshuffled_original_ko', 'unshuffled_original_krc', 'unshuffled_original_ku', 'unshuffled_original_kv', 'unshuffled_original_kw', 'unshuffled_original_ky', 'unshuffled_original_la', 'unshuffled_original_lb', 'unshuffled_original_lez', 'unshuffled_original_li', 'unshuffled_original_lmo', 'unshuffled_original_lo', 'unshuffled_original_lrc', 'unshuffled_original_lt', 'unshuffled_original_lv', 'unshuffled_original_mai', 'unshuffled_original_mg', 'unshuffled_original_mhr', 'unshuffled_original_min', 'unshuffled_original_mk', 'unshuffled_original_ml', 'unshuffled_original_mn', 'unshuffled_original_mr', 'unshuffled_original_mrj', 'unshuffled_original_ms', 'unshuffled_original_mt', 'unshuffled_original_mwl', 'unshuffled_original_my', 'unshuffled_original_myv', 'unshuffled_original_mzn', 'unshuffled_original_nah', 'unshuffled_original_nap', 'unshuffled_original_nds', 'unshuffled_original_ne', 'unshuffled_original_new', 'unshuffled_original_nl', 'unshuffled_original_nn', 'unshuffled_original_no', 'unshuffled_original_oc', 'unshuffled_original_or', 'unshuffled_original_os', 'unshuffled_original_pa', 'unshuffled_original_pam', 'unshuffled_original_pl', 'unshuffled_original_pms', 'unshuffled_original_pnb', 'unshuffled_original_ps', 'unshuffled_original_pt', 'unshuffled_original_qu', 'unshuffled_original_rm', 'unshuffled_original_ro', 'unshuffled_original_ru', 'unshuffled_original_sa', 'unshuffled_original_sah', 'unshuffled_original_scn', 'unshuffled_original_sd', 'unshuffled_original_sh', 'unshuffled_original_si', 'unshuffled_original_sk', 'unshuffled_original_sl', 'unshuffled_original_so', 'unshuffled_original_sq', 'unshuffled_original_sr', 'unshuffled_original_su', 'unshuffled_original_sv', 'unshuffled_original_sw', 'unshuffled_original_ta', 'unshuffled_original_te', 'unshuffled_original_tg', 'unshuffled_original_th', 'unshuffled_original_tk', 'unshuffled_original_tl', 'unshuffled_original_tr', 'unshuffled_original_tt', 'unshuffled_original_tyv', 'unshuffled_original_ug', 'unshuffled_original_uk', 'unshuffled_original_ur', 'unshuffled_original_uz', 'unshuffled_original_vec', 'unshuffled_original_vi', 'unshuffled_original_vo', 'unshuffled_original_wa', 'unshuffled_original_war', 'unshuffled_original_wuu', 'unshuffled_original_xal', 'unshuffled_original_xmf', 'unshuffled_original_yi', 'unshuffled_original_yo', 'unshuffled_original_yue', 'unshuffled_original_zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 55900\n",
       " \tlikes: 38\n",
       " \tpaperswithcode_id: oscar\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: para_crawl\n",
       " \tsha: 3799127cd025cdd51b3206b0d4026c11c57c3496\n",
       " \tlastModified: 2022-07-01T11:55:02.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:ga', 'language:hr', 'language:hu', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:sk', 'language:sl', 'language:sv', 'license:cc0-1.0', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @misc {paracrawl,\n",
       "     title  = {ParaCrawl},\n",
       "     year   = {2018},\n",
       "     url    = {http://paracrawl.eu/download.html.}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'ga', 'hr', 'hu', 'it', 'lt', 'lv', 'mt', 'nl', 'pl', 'pt', 'ro', 'sk', 'sl', 'sv'], 'license': ['cc0-1.0'], 'multilinguality': ['translation'], 'pretty_name': 'ParaCrawl', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'paracrawl'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3772\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: paracrawl\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: para_pat\n",
       " \tsha: 0668517f186a60fd2e91252f5d094b90bf47f04c\n",
       " \tlastModified: 2022-07-27T14:38:56.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:expert-generated', 'language:cs', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fr', 'language:hu', 'language:ja', 'language:ko', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:uk', 'language:zh', 'license:cc-by-4.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\n",
       " \n",
       " This dataset contains the developed parallel corpus from the open access Google\n",
       " Patents dataset in 74 language pairs, comprising more than 68 million sentences\n",
       " and 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm\n",
       " for the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.\n",
       " \tcitation: @inproceedings{soares-etal-2020-parapat,\n",
       "     title = \"{P}ara{P}at: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\",\n",
       "     author = \"Soares, Felipe  and\n",
       "       Stevenson, Mark  and\n",
       "       Bartolome, Diego  and\n",
       "       Zaretskaya, Anna\",\n",
       "     booktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.465\",\n",
       "     pages = \"3769--3774\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['expert-generated'], 'language': ['cs', 'de', 'el', 'en', 'es', 'fr', 'hu', 'ja', 'ko', 'pt', 'ro', 'ru', 'sk', 'uk', 'zh'], 'license': ['cc-by-4.0'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'parapat', 'pretty_name': 'Parallel Corpus of Patents Abstracts'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3297\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: parapat\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: parsinlu_reading_comprehension\n",
       " \tsha: c64a8a6f33a9103bd6f0eebdbaf36166ca1811c3\n",
       " \tlastModified: 2022-07-01T11:55:03.000Z\n",
       " \ttags: ['arxiv:2012.06154', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:fa', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|wikipedia|google', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A Persian reading comprehenion task (generating an answer, given a question and a context paragraph).\n",
       " The questions are mined using Google auto-complete, their answers and the corresponding evidence documents are manually annotated by native speakers.\n",
       " \tcitation: @article{huggingface:dataset,\n",
       "     title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n",
       "     authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n",
       "     year={2020}\n",
       "     journal = {arXiv e-prints},\n",
       "     eprint = {2012.06154},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['fa'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|wikipedia|google'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': None, 'pretty_name': 'PersiNLU (Reading Comprehension)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pass\n",
       " \tsha: 26d85f315805d09990a3316bdbf2d7c761d43da7\n",
       " \tlastModified: 2022-08-22T09:10:26.000Z\n",
       " \ttags: ['arxiv:2109.13228', 'annotations_creators:no-annotation', 'language_creators:machine-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:extended|yffc100M', 'task_categories:other', 'task_ids:other-image-self-supervised pretraining']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PASS (Pictures without humAns for Self-Supervision) is a large-scale dataset of 1,440,191 images that does not include any humans\n",
       " and which can be used for high-quality pretraining while significantly reducing privacy concerns.\n",
       " The PASS images are sourced from the YFCC-100M dataset.\n",
       " \tcitation: @Article{asano21pass,\n",
       " author = \"Yuki M. Asano and Christian Rupprecht and Andrew Zisserman and Andrea Vedaldi\",\n",
       " title = \"PASS: An ImageNet replacement for self-supervised pretraining without humans\",\n",
       " journal = \"NeurIPS Track on Datasets and Benchmarks\",\n",
       " year = \"2021\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['machine-generated', 'expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['extended|yffc100M'], 'task_categories': ['other'], 'task_ids': ['other-image-self-supervised pretraining'], 'paperswithcode_id': 'pass', 'pretty_name': 'Pictures without humAns for Self-Supervision'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 346\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: pass\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: paws-x\n",
       " \tsha: 3f1043f8c4eabaf2e0c229f9f47da8a425c98309\n",
       " \tlastModified: 2022-07-01T11:55:05.000Z\n",
       " \ttags: ['arxiv:1908.11828', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ja', 'language:ko', 'language:zh', 'license:other', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-paws', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'task_ids:semantic-similarity-scoring', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text-scoring', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PAWS-X, a multilingual version of PAWS (Paraphrase Adversaries from Word Scrambling) for six languages.\n",
       " \n",
       " This dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine\n",
       " translated training pairs in six typologically distinct languages: French, Spanish, German,\n",
       " Chinese, Japanese, and Korean. English language is available by default. All translated\n",
       " pairs are sourced from examples in PAWS-Wiki.\n",
       " \n",
       " For further details, see the accompanying paper: PAWS-X: A Cross-lingual Adversarial Dataset\n",
       " for Paraphrase Identification (https://arxiv.org/abs/1908.11828)\n",
       " \n",
       " NOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1.\n",
       " \tcitation: @InProceedings{pawsx2019emnlp,\n",
       "   title = {{PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification}},\n",
       "   author = {Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},\n",
       "   booktitle = {Proc. of EMNLP},\n",
       "   year = {2019}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification', 'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['expert-generated', 'machine-generated'], 'language': ['de', 'en', 'es', 'fr', 'ja', 'ko', 'zh'], 'license': ['other'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-paws'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification', 'semantic-similarity-scoring', 'text-classification-other-paraphrase-identification', 'text-scoring', 'multi-input-text-classification'], 'paperswithcode_id': 'paws-x'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8021\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: paws-x\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: paws\n",
       " \tsha: a90f7fe5630568baf7a053fccc45547ad9dc9717\n",
       " \tlastModified: 2022-07-01T11:55:03.000Z\n",
       " \ttags: ['arxiv:1904.01130', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'task_ids:semantic-similarity-scoring', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text-scoring', 'task_ids:multi-input-text-classification', 'configs:labeled_final', 'configs:labeled_swap', 'configs:unlabeled_final']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PAWS: Paraphrase Adversaries from Word Scrambling\n",
       " \n",
       " This dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature\n",
       " the importance of modeling structure, context, and word order information for the problem\n",
       " of paraphrase identification. The dataset has two subsets, one based on Wikipedia and the\n",
       " other one based on the Quora Question Pairs (QQP) dataset.\n",
       " \n",
       " For further details, see the accompanying paper: PAWS: Paraphrase Adversaries from Word Scrambling\n",
       " (https://arxiv.org/abs/1904.01130)\n",
       " \n",
       " PAWS-QQP is not available due to license of QQP. It must be reconstructed by downloading the original\n",
       " data and then running our scripts to produce the data and attach the labels.\n",
       " \n",
       " NOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1.\n",
       " \tcitation: @InProceedings{paws2019naacl,\n",
       "   title = {{PAWS: Paraphrase Adversaries from Word Scrambling}},\n",
       "   author = {Zhang, Yuan and Baldridge, Jason and He, Luheng},\n",
       "   booktitle = {Proc. of NAACL},\n",
       "   year = {2019}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'PAWS: Paraphrase Adversaries from Word Scrambling', 'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification', 'semantic-similarity-scoring', 'text-classification-other-paraphrase-identification', 'text-scoring', 'multi-input-text-classification'], 'paperswithcode_id': 'paws', 'configs': ['labeled_final', 'labeled_swap', 'unlabeled_final']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 83286\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: paws\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pec\n",
       " \tsha: dd35cd8beb594af92163b62f35c9f6b4c5f48c34\n",
       " \tlastModified: 2022-07-01T11:55:06.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-retrieval', 'task_ids:dialogue-modeling', 'task_ids:utterance-retrieval', 'configs:all', 'configs:happy', 'configs:offmychest']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " A dataset of around 350K persona-based empathetic conversations. Each speaker is associated with a persona, which comprises multiple persona sentences. The response of each conversation is empathetic.\n",
       " \tcitation: \\\n",
       " @inproceedings{zhong2020towards,\n",
       "     title = \"Towards Persona-Based Empathetic Conversational Models\",\n",
       "     author = \"Zhong, Peixiang  and\n",
       "       Zhang, Chen  and\n",
       "       Wang, Hao  and\n",
       "       Liu, Yong  and\n",
       "       Miao, Chunyan\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.531\",\n",
       "     pages = \"6556--6566\"}\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-retrieval'], 'task_ids': ['dialogue-modeling', 'utterance-retrieval'], 'paperswithcode_id': 'pec', 'pretty_name': 'Persona-Based Empathetic Conversational', 'configs': ['all', 'happy', 'offmychest']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 654\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: pec\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: peer_read\n",
       " \tsha: ca2b32972092c08b70d277e3dbbf769d745504c9\n",
       " \tlastModified: 2022-07-01T11:55:06.000Z\n",
       " \ttags: ['arxiv:1804.09635', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-acceptability-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PearRead is a dataset of scientific peer reviews available to help researchers study this important artifact. The dataset consists of over 14K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR, as well as over 10K textual peer reviews written by experts for a subset of the papers.\n",
       " \tcitation: @inproceedings{kang18naacl,\n",
       "   title = {A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications},\n",
       "   author = {Dongyeop Kang and Waleed Ammar and Bhavana Dalvi and Madeleine van Zuylen and Sebastian Kohlmeier and Eduard Hovy and Roy Schwartz},\n",
       "   booktitle = {Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL)},\n",
       "   address = {New Orleans, USA},\n",
       "   month = {June},\n",
       "   url = {https://arxiv.org/abs/1804.09635},\n",
       "   year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-acceptability-classification'], 'paperswithcode_id': 'peerread', 'pretty_name': 'PeerRead'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 503\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: peerread\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: peoples_daily_ner\n",
       " \tsha: 22f2b5c4f8dd575395624e2679381b95a320aa8f\n",
       " \tlastModified: 2022-07-01T11:55:07.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: People's Daily NER Dataset is a commonly used dataset for Chinese NER, with\n",
       " text from People's Daily (人民日报), the largest official newspaper.\n",
       " \n",
       " The dataset is in BIO scheme. Entity types are: PER (person), ORG (organization)\n",
       " and LOC (location).\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': \"People's Daily NER\"}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 473\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: per_sent\n",
       " \tsha: da87a42660f0cac63630fc9e3c7e3fb1f62ca000\n",
       " \tlastModified: 2022-07-01T11:55:07.000Z\n",
       " \ttags: ['arxiv:2011.06128', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-MPQA-KBP Challenge-MediaRank', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Person SenTiment (PerSenT) is a crowd-sourced dataset that captures the sentiment of an author towards the main entity in a news article. This dataset contains annotation for 5.3k documents and 38k paragraphs covering 3.2k unique entities.\n",
       " \n",
       " The dataset consists of sentiment annotations on news articles about people. For each article, annotators judge what the author’s sentiment is towards the main (target) entity of the article. The annotations also include similar judgments on paragraphs within the article.\n",
       " \n",
       " To split the dataset, entities into 4 mutually exclusive sets. Due to the nature of news collections, some entities tend to dominate the collection. In the collection, there were four entities which were the main entity in nearly 800 articles. To avoid these entities from dominating the train or test splits, we moved them to a separate test collection. We split the remaining into a training, dev, and test sets at random. Thus our collection includes one standard test set consisting of articles drawn at random (Test Standard -- `test_random`), while the other is a test set which contains multiple articles about a small number of popular entities (Test Frequent -- `test_fixed`).\n",
       " \tcitation: @inproceedings{bastan2020authors,\n",
       "       title={Author's Sentiment Prediction},\n",
       "       author={Mohaddeseh Bastan and Mahnaz Koupaee and Youngseo Son and Richard Sicoli and Niranjan Balasubramanian},\n",
       "       year={2020},\n",
       "       eprint={2011.06128},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-MPQA-KBP Challenge-MediaRank'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'persent', 'pretty_name': 'PerSenT'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 356\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: persent\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: persian_ner\n",
       " \tsha: ec9e7a4cb53e11fad185f359c45da9809ef55059\n",
       " \tlastModified: 2022-07-01T11:55:07.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:fa', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset includes 250,015 tokens and 7,682 Persian sentences in total. It is available in 3 folds to be used in turn as training and test sets. The NER tags are in IOB format.\n",
       " \tcitation: @inproceedings{poostchi-etal-2016-personer,\n",
       "     title = \"{P}erso{NER}: {P}ersian Named-Entity Recognition\",\n",
       "     author = \"Poostchi, Hanieh  and\n",
       "       Zare Borzeshi, Ehsan  and\n",
       "       Abdous, Mohammad  and\n",
       "       Piccardi, Massimo\",\n",
       "     booktitle = \"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers\",\n",
       "     month = dec,\n",
       "     year = \"2016\",\n",
       "     address = \"Osaka, Japan\",\n",
       "     publisher = \"The COLING 2016 Organizing Committee\",\n",
       "     url = \"https://www.aclweb.org/anthology/C16-1319\",\n",
       "     pages = \"3381--3389\",\n",
       "     abstract = \"Named-Entity Recognition (NER) is still a challenging task for languages with low digital resources. The main difficulties arise from the scarcity of annotated corpora and the consequent problematic training of an effective NER pipeline. To abridge this gap, in this paper we target the Persian language that is spoken by a population of over a hundred million people world-wide. We first present and provide ArmanPerosNERCorpus, the first manually-annotated Persian NER corpus. Then, we introduce PersoNER, an NER pipeline for Persian that leverages a word embedding and a sequential max-margin classifier. The experimental results show that the proposed approach is capable of achieving interesting MUC7 and CoNNL scores while outperforming two alternatives based on a CRF and a recurrent neural network.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['fa'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'pretty_name': 'Persian NER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 637\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pg19\n",
       " \tsha: 4ccd0a2621c377051b744ee8dd8d74dfb8547a16\n",
       " \tlastModified: 2022-08-12T09:46:26.000Z\n",
       " \ttags: ['arxiv:1911.05507', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This repository contains the PG-19 language modeling benchmark.\n",
       " It includes a set of books extracted from the Project Gutenberg books library, that were published before 1919.\n",
       " It also contains metadata of book titles and publication dates.\n",
       " \n",
       " PG-19 is over double the size of the Billion Word benchmark and contains documents that are 20X longer, on average, than the WikiText long-range language modelling benchmark.\n",
       " Books are partitioned into a train, validation, and test set. Book metadata is stored in metadata.csv which contains (book_id, short_book_title, publication_date).\n",
       " \n",
       " Unlike prior benchmarks, we do not constrain the vocabulary size --- i.e. mapping rare words to an UNK token --- but instead release the data as an open-vocabulary benchmark. The only processing of the text that has been applied is the removal of boilerplate license text, and the mapping of offensive discriminatory words as specified by Ofcom to placeholder tokens. Users are free to model the data at the character-level, subword-level, or via any mechanism that can model an arbitrary string of text.\n",
       " To compare models we propose to continue measuring the word-level perplexity, by calculating the total likelihood of the dataset (via any chosen subword vocabulary or character-based scheme) divided by the number of tokens --- specified below in the dataset statistics table.\n",
       " One could use this dataset for benchmarking long-range language models, or use it to pre-train for other natural language processing tasks which require long-range reasoning, such as LAMBADA or NarrativeQA. We would not recommend using this dataset to train a general-purpose language model, e.g. for applications to a production-system dialogue agent, due to the dated linguistic style of old texts and the inherent biases present in historical writing.\n",
       " \tcitation: @article{raecompressive2019,\n",
       "   author = {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and\n",
       "             Hillier, Chloe and Lillicrap, Timothy P},\n",
       "   title = {Compressive Transformers for Long-Range Sequence Modelling},\n",
       "   journal = {arXiv preprint},\n",
       "   url = {https://arxiv.org/abs/1911.05507},\n",
       "   year = {2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation'], 'task_ids': ['language-modeling'], 'paperswithcode_id': 'pg-19', 'pretty_name': 'PG-19'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: pg-19\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: php\n",
       " \tsha: 8c286e7e1480dc18d961d16be71f41486dba2bb1\n",
       " \tlastModified: 2022-08-11T12:57:31.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fi', 'language:fr', 'language:he', 'language:hu', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sv', 'language:tr', 'language:tw', 'language:zh', 'language_bcp47:pt-BR', 'language_bcp47:zh-TW', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus originally extracted from http://se.php.net/download-docs.php. The original documents are written in English and have been partly translated into 21 languages. The original manuals contain about 500,000 words. The amount of actually translated texts varies for different languages between 50,000 and 380,000 words. The corpus is rather noisy and may include parts from the English original in some of the translations. The corpus is tokenized and each language pair has been sentence aligned.\n",
       " \n",
       " 23 languages, 252 bitexts\n",
       " total number of files: 71,414\n",
       " total number of tokens: 3.28M\n",
       " total number of sentence fragments: 1.38M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'es', 'fi', 'fr', 'he', 'hu', 'it', 'ja', 'ko', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'tw', 'zh'], 'language_bcp47': ['pt-BR', 'zh-TW'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'php'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 952\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: piaf\n",
       " \tsha: 52391d9d8298f177c69f5a5d96efac9a8b74f2bc\n",
       " \tlastModified: 2022-07-27T14:39:00.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:fr', 'language_bcp47:fr-FR', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Piaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.\n",
       " \tcitation: @InProceedings{keraron-EtAl:2020:LREC,\n",
       "   author    = {Keraron, Rachel  and  Lancrenon, Guillaume  and  Bras, Mathilde  and  Allary, Frédéric  and  Moyse, Gilles  and  Scialom, Thomas  and  Soriano-Morales, Edmundo-Pavel  and  Staiano, Jacopo},\n",
       "   title     = {Project PIAF: Building a Native French Question-Answering Dataset},\n",
       "   booktitle      = {Proceedings of The 12th Language Resources and Evaluation Conference},\n",
       "   month          = {May},\n",
       "   year           = {2020},\n",
       "   address        = {Marseille, France},\n",
       "   publisher      = {European Language Resources Association},\n",
       "   pages     = {5483--5492},\n",
       "   abstract  = {Motivated by the lack of data for non-English languages, in particular for the evaluation of downstream tasks such as Question Answering, we present a participatory effort to collect a native French Question Answering Dataset. Furthermore, we describe and publicly release the annotation tool developed for our collection effort, along with the data obtained and preliminary baselines.},\n",
       "   url       = {https://www.aclweb.org/anthology/2020.lrec-1.673}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['fr'], 'language_bcp47': ['fr-FR'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'Piaf'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 415\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pib\n",
       " \tsha: 960e3ed93fc2c43423ec0cabe696ef1db1e04201\n",
       " \tlastModified: 2022-07-27T14:39:00.000Z\n",
       " \ttags: ['arxiv:2008.04860', 'task_categories:translation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'multilinguality:translation', 'language:bn', 'language:en', 'language:gu', 'language:hi', 'language:ml', 'language:mr', 'language:or', 'language:pa', 'language:ta', 'language:te', 'language:ur', 'language_creators:other', 'annotations_creators:no-annotation', 'source_datasets:original', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'license:cc-by-4.0', 'configs:bn-en', 'configs:bn-gu', 'configs:bn-hi', 'configs:bn-ml', 'configs:bn-mr', 'configs:bn-or', 'configs:bn-pa', 'configs:bn-ta', 'configs:bn-te', 'configs:bn-ur', 'configs:en-gu', 'configs:en-hi', 'configs:en-ml', 'configs:en-mr', 'configs:en-or', 'configs:en-pa', 'configs:en-ta', 'configs:en-te', 'configs:en-ur', 'configs:gu-hi', 'configs:gu-ml', 'configs:gu-mr', 'configs:gu-or', 'configs:gu-pa', 'configs:gu-ta', 'configs:gu-te', 'configs:gu-ur', 'configs:hi-ml', 'configs:hi-mr', 'configs:hi-or', 'configs:hi-pa', 'configs:hi-ta', 'configs:hi-te', 'configs:hi-ur', 'configs:ml-mr', 'configs:ml-or', 'configs:ml-pa', 'configs:ml-ta', 'configs:ml-te', 'configs:ml-ur', 'configs:mr-or', 'configs:mr-pa', 'configs:mr-ta', 'configs:mr-te', 'configs:mr-ur', 'configs:or-pa', 'configs:or-ta', 'configs:or-te', 'configs:or-ur', 'configs:pa-ta', 'configs:pa-te', 'configs:pa-ur', 'configs:ta-te', 'configs:ta-ur', 'configs:te-ur']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Sentence aligned parallel corpus between 11 Indian Languages, crawled and extracted from the press information bureau\n",
       " website.\n",
       " \tcitation: @inproceedings{siripragada-etal-2020-multilingual,\n",
       "     title = \"A Multilingual Parallel Corpora Collection Effort for {I}ndian Languages\",\n",
       "     author = \"Siripragada, Shashank  and\n",
       "       Philip, Jerin  and\n",
       "       Namboodiri, Vinay P.  and\n",
       "       Jawahar, C V\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://aclanthology.org/2020.lrec-1.462\",\n",
       "     pages = \"3743--3751\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " @article{2020,\n",
       "    title={Revisiting Low Resource Status of Indian Languages in Machine Translation},\n",
       "    url={http://dx.doi.org/10.1145/3430984.3431026},\n",
       "    DOI={10.1145/3430984.3431026},\n",
       "    journal={8th ACM IKDD CODS and 26th COMAD},\n",
       "    publisher={ACM},\n",
       "    author={Philip, Jerin and Siripragada, Shashank and Namboodiri, Vinay P. and Jawahar, C. V.},\n",
       "    year={2020},\n",
       "    month={Dec}\n",
       " }\n",
       " \tcardData: {'task_categories': ['translation', 'text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'multilinguality': ['translation'], 'language': ['bn', 'en', 'gu', 'hi', 'ml', 'mr', 'or', 'pa', 'ta', 'te', 'ur'], 'language_creators': ['other'], 'annotations_creators': ['no-annotation'], 'source_datasets': ['original'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'license': ['cc-by-4.0'], 'paperswithcode_id': None, 'pretty_name': 'CVIT PIB', 'configs': ['bn-en', 'bn-gu', 'bn-hi', 'bn-ml', 'bn-mr', 'bn-or', 'bn-pa', 'bn-ta', 'bn-te', 'bn-ur', 'en-gu', 'en-hi', 'en-ml', 'en-mr', 'en-or', 'en-pa', 'en-ta', 'en-te', 'en-ur', 'gu-hi', 'gu-ml', 'gu-mr', 'gu-or', 'gu-pa', 'gu-ta', 'gu-te', 'gu-ur', 'hi-ml', 'hi-mr', 'hi-or', 'hi-pa', 'hi-ta', 'hi-te', 'hi-ur', 'ml-mr', 'ml-or', 'ml-pa', 'ml-ta', 'ml-te', 'ml-ur', 'mr-or', 'mr-pa', 'mr-ta', 'mr-te', 'mr-ur', 'or-pa', 'or-ta', 'or-te', 'or-ur', 'pa-ta', 'pa-te', 'pa-ur', 'ta-te', 'ta-ur', 'te-ur']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8719\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: piqa\n",
       " \tsha: f2b1a722a8177690b0aec31e2bc9259363bf02cc\n",
       " \tlastModified: 2022-07-01T11:55:11.000Z\n",
       " \ttags: ['arxiv:1911.11641', 'arxiv:1907.10641', 'arxiv:1904.09728', 'arxiv:1808.05326', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: To apply eyeshadow without a brush, should I use a cotton swab or a toothpick?\n",
       " Questions requiring this kind of physical commonsense pose a challenge to state-of-the-art\n",
       " natural language understanding systems. The PIQA dataset introduces the task of physical commonsense reasoning\n",
       " and a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA.\n",
       " \n",
       " Physical commonsense knowledge is a major challenge on the road to true AI-completeness,\n",
       " including robots that interact with the world and understand natural language.\n",
       " \n",
       " PIQA focuses on everyday situations with a preference for atypical solutions.\n",
       " The dataset is inspired by instructables.com, which provides users with instructions on how to build, craft,\n",
       " bake, or manipulate objects using everyday materials.\n",
       " \n",
       " The underlying task is formualted as multiple choice question answering:\n",
       " given a question `q` and two possible solutions `s1`, `s2`, a model or\n",
       " a human must choose the most appropriate solution, of which exactly one is correct.\n",
       " The dataset is further cleaned of basic artifacts using the AFLite algorithm which is an improvement of\n",
       " adversarial filtering. The dataset contains 16,000 examples for training, 2,000 for development and 3,000 for testing.\n",
       " \tcitation: @inproceedings{Bisk2020,\n",
       "   author = {Yonatan Bisk and Rowan Zellers and\n",
       "             Ronan Le Bras and Jianfeng Gao\n",
       "             and Yejin Choi},\n",
       "   title = {PIQA: Reasoning about Physical Commonsense in\n",
       "            Natural Language},\n",
       "   booktitle = {Thirty-Fourth AAAI Conference on\n",
       "                Artificial Intelligence},\n",
       "   year = {2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'piqa', 'pretty_name': 'Physical Interaction: Question Answering'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 67451\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: piqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pn_summary\n",
       " \tsha: bf56470e0045f2fa0ed6fd013eafd0ce7ae50a09\n",
       " \tlastModified: 2022-07-01T11:55:11.000Z\n",
       " \ttags: ['arxiv:2012.11204', 'annotations_creators:found', 'language_creators:found', 'language:fa', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_categories:text-classification', 'task_ids:news-articles-summarization', 'task_ids:news-articles-headline-generation', 'task_ids:text-simplification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\n",
       " It is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.\n",
       " \tcitation: @article{pnSummary, title={Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text Summarization},\n",
       " author={Mehrdad Farahani, Mohammad Gharachorloo, Mohammad Manthouri},\n",
       " year={2020},\n",
       " eprint={2012.11204},\n",
       " archivePrefix={arXiv},\n",
       " primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['fa'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization', 'text-classification'], 'task_ids': ['news-articles-summarization', 'news-articles-headline-generation', 'text-simplification', 'topic-classification'], 'paperswithcode_id': 'pn-summary', 'pretty_name': 'Persian News Summary (PnSummary)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: pn-summary\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: poem_sentiment\n",
       " \tsha: 98b26ab6629d841328ca633785e78ea8b51abf33\n",
       " \tlastModified: 2022-07-01T11:55:13.000Z\n",
       " \ttags: ['arxiv:2011.02686', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Poem Sentiment is a sentiment dataset of poem verses from Project Gutenberg. This dataset can be used for tasks such as sentiment classification or style transfer for poems.\n",
       " \tcitation: @misc{sheng2020investigating,\n",
       "       title={Investigating Societal Biases in a Poetry Composition System},\n",
       "       author={Emily Sheng and David Uthus},\n",
       "       year={2020},\n",
       "       eprint={2011.02686},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'gutenberg-poem-dataset', 'pretty_name': 'Gutenberg Poem Dataset', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'verse_text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3613\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: gutenberg-poem-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: polemo2\n",
       " \tsha: 4fb589e666579c952c3686e53d305d2a810816a2\n",
       " \tlastModified: 2022-07-01T11:55:14.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:bsd-3-clause', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The PolEmo2.0 is a set of online reviews from medicine and hotels domains. The task is to predict the sentiment of a review. There are two separate test sets, to allow for in-domain (medicine and hotels) as well as out-of-domain (products and university) validation.\n",
       " \tcitation: @inproceedings{kocon-etal-2019-multi,\n",
       " title = \"Multi-Level Sentiment Analysis of {P}ol{E}mo 2.0: Extended Corpus of Multi-Domain Consumer Reviews\",\n",
       " author = \"Koco{\\'n}, Jan and\n",
       " Milkowski, Piotr and\n",
       " Za{\\'s}ko-Zieli{\\'n}ska, Monika\",\n",
       " booktitle = \"Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)\",\n",
       " month = nov,\n",
       " year = \"2019\",\n",
       " address = \"Hong Kong, China\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " url = \"https://www.aclweb.org/anthology/K19-1092\",\n",
       " doi = \"10.18653/v1/K19-1092\",\n",
       " pages = \"980--991\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['bsd-3-clause'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'polemo2'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 479\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: poleval2019_cyberbullying\n",
       " \tsha: b5d2f8e19123f47b41b4e818174748266fc4bcaf\n",
       " \tlastModified: 2022-07-01T11:55:14.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:pl', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     In Task 6-1, the participants are to distinguish between normal/non-harmful tweets (class: 0) and tweets\n",
       "     that contain any kind of harmful information (class: 1). This includes cyberbullying, hate speech and\n",
       "     related phenomena.\n",
       " \n",
       "     In Task 6-2, the participants shall distinguish between three classes of tweets: 0 (non-harmful),\n",
       "     1 (cyberbullying), 2 (hate-speech). There are various definitions of both cyberbullying and hate-speech,\n",
       "     some of them even putting those two phenomena in the same group. The specific conditions on which we based\n",
       "     our annotations for both cyberbullying and hate-speech, which have been worked out during ten years of research\n",
       "     will be summarized in an introductory paper for the task, however, the main and definitive condition to 1\n",
       "     distinguish the two is whether the harmful action is addressed towards a private person(s) (cyberbullying),\n",
       "     or a public person/entity/large group (hate-speech).\n",
       " \tcitation: @proceedings{ogr:kob:19:poleval,\n",
       "   editor    = {Maciej Ogrodniczuk and Łukasz Kobyliński},\n",
       "   title     = {{Proceedings of the PolEval 2019 Workshop}},\n",
       "   year      = {2019},\n",
       "   address   = {Warsaw, Poland},\n",
       "   publisher = {Institute of Computer Science, Polish Academy of Sciences},\n",
       "   url       = {http://2019.poleval.pl/files/poleval2019.pdf},\n",
       "   isbn      = \"978-83-63159-28-3\"}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['pl'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': None, 'pretty_name': 'Poleval 2019 cyberbullying'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 479\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: poleval2019_mt\n",
       " \tsha: c97a27e20cfa20aa56faa5a5fdf6305e37ee7870\n",
       " \tlastModified: 2022-07-01T11:55:14.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language_creators:found', 'language:en', 'language:pl', 'language:ru', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PolEval is a SemEval-inspired evaluation campaign for natural language processing tools for Polish.Submitted solutions compete against one another within certain tasks selected by organizers, using available data and are evaluated according topre-established procedures. One of the tasks in PolEval-2019 was Machine Translation (Task-4).\n",
       " The task is to train as good as possible machine translation system, using any technology,with limited textual resources.The competition will be done for 2 language pairs, more popular English-Polish (into Polish direction) and pair that can be called low resourcedRussian-Polish (in both directions).\n",
       " \n",
       " Here, Polish-English is also made available to allow for training in both directions. However, the test data is ONLY available for English-Polish.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated', 'found'], 'language': ['en', 'pl', 'ru'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'Poleval2019Mt'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 793\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: polsum\n",
       " \tsha: 548c1604758a76fc7da86f92da1389ebe526a2e2\n",
       " \tlastModified: 2022-07-01T11:55:15.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:pl', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Polish Summaries Corpus: the corpus of Polish news summaries.\n",
       " \tcitation: @inproceedings{\n",
       "     ogro:kop:14:lrec,\n",
       "     author = \"Ogrodniczuk, Maciej and Kopeć, Mateusz\",\n",
       "     pdf = \"http://nlp.ipipan.waw.pl/Bib/ogro:kop:14:lrec.pdf\",\n",
       "     title = \"The {P}olish {S}ummaries {C}orpus\",\n",
       "     pages = \"3712--3715\",\n",
       "     crossref = \"lrec:14\"\n",
       " }\n",
       " @proceedings{\n",
       "     lrec:14,\n",
       "     editor = \"Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Loftsson, Hrafn and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios\",\n",
       "     isbn = \"978-2-9517408-8-4\",\n",
       "     title = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\n",
       "     url = \"http://www.lrec-conf.org/proceedings/lrec2014/index.html\",\n",
       "     booktitle = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\n",
       "     address = \"Reykjavík, Iceland\",\n",
       "     key = \"LREC\",\n",
       "     year = \"2014\",\n",
       "     organization = \"European Language Resources Association (ELRA)\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['pl'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'paperswithcode_id': None, 'pretty_name': 'Polish Summaries Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: polyglot_ner\n",
       " \tsha: a9e62a9662abfe4efc3935411e1cf80b52f73896\n",
       " \tlastModified: 2022-07-27T14:39:01.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:ar', 'language:bg', 'language:ca', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:lt', 'language:lv', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sr', 'language:sv', 'language:th', 'language:tl', 'language:tr', 'language:uk', 'language:vi', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:unknown', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Polyglot-NER\n",
       " A training dataset automatically generated from Wikipedia and Freebase the task\n",
       " of named entity recognition. The dataset contains the basic Wikipedia based\n",
       " training data for 40 languages we have (with coreference resolution) for the task of\n",
       " named entity recognition. The details of the procedure of generating them is outlined in\n",
       " Section 3 of the paper (https://arxiv.org/abs/1410.3791). Each config contains the data\n",
       " corresponding to a different language. For example, \"es\" includes only spanish examples.\n",
       " \tcitation: @article{polyglotner,\n",
       "          author = {Al-Rfou, Rami and Kulkarni, Vivek and Perozzi, Bryan and Skiena, Steven},\n",
       "          title = {{Polyglot-NER}: Massive Multilingual Named Entity Recognition},\n",
       "          journal = {{Proceedings of the 2015 {SIAM} International Conference on Data Mining, Vancouver, British Columbia, Canada, April 30- May 2, 2015}},\n",
       "          month     = {April},\n",
       "          year      = {2015},\n",
       "          publisher = {SIAM},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['ar', 'bg', 'ca', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'he', 'hi', 'hr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'th', 'tl', 'tr', 'uk', 'vi', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'pretty_name': 'Polyglot-NER', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'polyglot-ner'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7034\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: polyglot-ner\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: prachathai67k\n",
       " \tsha: bb297090ba3b6e1f2d9a6321b59d0870401f5ac6\n",
       " \tlastModified: 2022-07-01T11:55:17.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: `prachathai-67k`: News Article Corpus and Multi-label Text Classificdation from Prachathai.com\n",
       " The prachathai-67k dataset was scraped from the news site Prachathai.\n",
       " We filtered out those articles with less than 500 characters of body text, mostly images and cartoons.\n",
       " It contains 67,889 articles wtih 12 curated tags from August 24, 2004 to November 15, 2018.\n",
       " The dataset was originally scraped by @lukkiddd and cleaned by @cstorm125.\n",
       " You can also see preliminary exploration at https://github.com/PyThaiNLP/prachathai-67k/blob/master/exploration.ipynb\n",
       " \tcitation: @misc{prachathai67k,\n",
       "   author = {cstorm125, lukkiddd },\n",
       "   title = {prachathai67k},\n",
       "   year = {2019},\n",
       "   publisher = {GitHub},\n",
       "   journal = {GitHub repository},\n",
       "   howpublished={\\\\url{https://github.com/PyThaiNLP/prachathai-67k}},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': 'prachathai-67k', 'pretty_name': 'prachathai67k'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 436\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: prachathai-67k\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pragmeval\n",
       " \tsha: 71a7c8e872bf61f839786638a35fae37299a8c36\n",
       " \tlastModified: 2022-07-01T11:55:18.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'configs:emergent', 'configs:emobank-arousal', 'configs:emobank-dominance', 'configs:emobank-valence', 'configs:gum', 'configs:mrda', 'configs:pdtb', 'configs:persuasiveness-claimtype', 'configs:persuasiveness-eloquence', 'configs:persuasiveness-premisetype', 'configs:persuasiveness-relevance', 'configs:persuasiveness-specificity', 'configs:persuasiveness-strength', 'configs:sarcasm', 'configs:squinky-formality', 'configs:squinky-implicature', 'configs:squinky-informativeness', 'configs:stac', 'configs:switchboard', 'configs:verifiability']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Evaluation of language understanding with a 11 datasets benchmark focusing on discourse and pragmatics\n",
       " \tcitation: @misc{sileo2019discoursebased,\n",
       "       title={Discourse-Based Evaluation of Language Understanding},\n",
       "       author={Damien Sileo and Tim Van-de-Cruys and Camille Pradel and Philippe Muller},\n",
       "       year={2019},\n",
       "       eprint={1907.08672},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': None, 'pretty_name': 'pragmeval', 'configs': ['emergent', 'emobank-arousal', 'emobank-dominance', 'emobank-valence', 'gum', 'mrda', 'pdtb', 'persuasiveness-claimtype', 'persuasiveness-eloquence', 'persuasiveness-premisetype', 'persuasiveness-relevance', 'persuasiveness-specificity', 'persuasiveness-strength', 'sarcasm', 'squinky-formality', 'squinky-implicature', 'squinky-informativeness', 'stac', 'switchboard', 'verifiability']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3999\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: proto_qa\n",
       " \tsha: 4fd4176d75349958617b24cde5803600eb968435\n",
       " \tlastModified: 2022-07-01T11:55:17.000Z\n",
       " \ttags: ['arxiv:2005.00771', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:other', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is for studying computational models trained to reason about prototypical situations. Using deterministic filtering a sampling from a larger set of all transcriptions was built. It contains 9789 instances where each instance represents a survey question from Family Feud game. Each instance exactly is a question, a set of answers, and a count associated with each answer.\n",
       " Each line is a json dictionary, in which:\n",
       " 1. question - contains the question (in original and a normalized form)\n",
       " 2. answerstrings - contains the original answers provided by survey respondents (when available), along with the counts for each string. Because the FamilyFeud data has only cluster names rather than strings, those cluster names are included with 0 weight.\n",
       " 3. answer-clusters - lists clusters, with the count of each cluster and the strings included in that cluster. Each cluster is given a unique ID that can be linked to in the assessment files.\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = {ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning},\n",
       " authors={Michael Boratko, Xiang Lorraine Li, Tim O’Gorman, Rajarshi Das, Dan Le, Andrew McCallum},\n",
       " year={2020},\n",
       " publisher = {GitHub},\n",
       " journal = {GitHub repository},\n",
       " howpublished={\\\\url{https://github.com/iesl/protoqa-data}},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'other'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa', 'open-domain-qa'], 'paperswithcode_id': 'protoqa', 'pretty_name': 'ProtoQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 637\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: protoqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: psc\n",
       " \tsha: 10d34fb33ed6570fdfbb96e2b79cdf1c8b38a2ca\n",
       " \tlastModified: 2022-07-01T11:55:18.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:other', 'language:pl', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Polish Summaries Corpus contains news articles and their summaries. We used summaries of the same article as positive pairs and sampled the most similar summaries of different articles as negatives.\n",
       " \tcitation: @inproceedings{ogro:kop:14:lrec,\n",
       " title={The {P}olish {S}ummaries {C}orpus},\n",
       " author={Ogrodniczuk, Maciej and Kope{\\'c}, Mateusz},\n",
       " booktitle = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\n",
       " year = \"2014\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['other'], 'language': ['pl'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'paperswithcode_id': None, 'pretty_name': 'psc'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ptb_text_only\n",
       " \tsha: d623d9c95ed6d03970be01dfc7a260d2bd95318b\n",
       " \tlastModified: 2022-07-01T12:43:40.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is the Penn Treebank Project: Release 2 CDROM, featuring a million words of 1989 Wall Street Journal material. This corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure.\n",
       " \tcitation: @article{marcus-etal-1993-building,\n",
       "     title = \"Building a Large Annotated Corpus of {E}nglish: The {P}enn {T}reebank\",\n",
       "     author = \"Marcus, Mitchell P.  and\n",
       "       Santorini, Beatrice  and\n",
       "       Marcinkiewicz, Mary Ann\",\n",
       "     journal = \"Computational Linguistics\",\n",
       "     volume = \"19\",\n",
       "     number = \"2\",\n",
       "     year = \"1993\",\n",
       "     url = \"https://www.aclweb.org/anthology/J93-2004\",\n",
       "     pages = \"313--330\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'license_details': 'LDC User Agreement for Non-Members', 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Penn Treebank'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5715\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pubmed\n",
       " \tsha: 70a7041250ec798802acf3665f8b7b28aabd5505\n",
       " \tlastModified: 2022-07-01T12:43:40.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:text-classification-other-citation-estimation', 'task_ids:text-scoring', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: NLM produces a baseline set of MEDLINE/PubMed citation records in XML format for download on an annual basis. The annual baseline is released in December of each year. Each day, NLM produces update files that include new, revised and deleted citations. See our documentation page for more information.\n",
       " \tcitation: Courtesy of the U.S. National Library of Medicine.\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'text-classification-other-citation-estimation', 'text-scoring', 'topic-classification'], 'paperswithcode_id': 'pubmed', 'pretty_name': 'PubMed'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 577\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: pubmed\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: pubmed_qa\n",
       " \tsha: 2758044a6dba074ad39e80525b6c9e26554e29dc\n",
       " \tlastModified: 2022-07-01T11:55:20.000Z\n",
       " \ttags: ['arxiv:1909.06146', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'configs:pqa_artificial', 'configs:pqa_labeled', 'configs:pqa_unlabeled']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\n",
       " The task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\n",
       " statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\n",
       " PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\n",
       " Each PubMedQA instance is composed of (1) a question which is either an existing research article\n",
       " title or derived from one, (2) a context which is the corresponding abstract without its conclusion,\n",
       " (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\n",
       " and (4) a yes/no/maybe answer which summarizes the conclusion.\n",
       " PubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\n",
       " quantitative contents, is required to answer the questions.\n",
       " \tcitation: @inproceedings{jin2019pubmedqa,\n",
       "   title={PubMedQA: A Dataset for Biomedical Research Question Answering},\n",
       "   author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},\n",
       "   booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n",
       "   pages={2567--2577},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'pubmedqa', 'pretty_name': 'PubMedQA', 'configs': ['pqa_artificial', 'pqa_labeled', 'pqa_unlabeled']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8259\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: pubmedqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: py_ast\n",
       " \tsha: 0adab9cca7f5a150135cb117b5de5161818195c1\n",
       " \tlastModified: 2022-08-29T16:13:41.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:code', 'license:bsd-2-clause', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:text2text-generation-other-code-generation', 'task_ids:text-generation-other-code-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset consisting of parsed ASTs that were used to train and\n",
       " evaluate the DeepSyn tool.\n",
       " The Python programs are collected from GitHub repositories\n",
       " by removing duplicate files, removing project forks (copy of another existing repository)\n",
       " ,keeping only programs that parse and have at most 30'000 nodes in the AST and\n",
       " we aim to remove obfuscated files\n",
       " \tcitation: @InProceedings{OOPSLA ’16, ACM,\n",
       " title = {Probabilistic Model for Code with Decision Trees.},\n",
       " authors={Raychev, V., Bielik, P., and Vechev, M.},\n",
       " year={2016}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'PyAst', 'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['code'], 'license': ['bsd-2-clause', 'mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-generation', 'fill-mask'], 'task_ids': ['text2text-generation-other-code-generation', 'text-generation-other-code-modeling'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qa4mre\n",
       " \tsha: 79c56293a1702b317da188f9e9e21742339cbb90\n",
       " \tlastModified: 2022-10-11T15:14:07.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:ar', 'language:bg', 'language:de', 'language:en', 'language:es', 'language:it', 'language:ro', 'language_creators:found', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QA4MRE dataset was created for the CLEF 2011/2012/2013 shared tasks to promote research in\n",
       " question answering and reading comprehension. The dataset contains a supporting\n",
       " passage and a set of questions corresponding to the passage. Multiple options\n",
       " for answers are provided for each question, of which only one is correct. The\n",
       " training and test datasets are available for the main track.\n",
       " Additional gold standard documents are available for two pilot studies: one on\n",
       " alzheimers data, and the other on entrance exams data.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['ar', 'bg', 'de', 'en', 'es', 'it', 'ro'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'pretty_name': 'QA4MRE: Question Answering for Machine Reading Evaluation', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4244\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qa_srl\n",
       " \tsha: 219844ccb9fbd3b57e1d21be5cb7c075750e152f\n",
       " \tlastModified: 2022-07-01T11:55:22.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains question-answer pairs to model verbal predicate-argument structure. The questions start with wh-words (Who, What, Where, What, etc.) and contain a verb predicate in the sentence; the answers are phrases in the sentence.\n",
       " There were 2 datsets used in the paper, newswire and wikipedia. Unfortunately the newswiredataset is built from CoNLL-2009 English training set that is covered under license\n",
       " Thus, we are providing only Wikipedia training set here. Please check README.md for more details on newswire dataset.\n",
       " For the Wikipedia domain, randomly sampled sentences from the English Wikipedia (excluding questions and sentences with fewer than 10 or more than 60 words) were taken.\n",
       " This new dataset is designed to solve this great NLP task and is crafted with a lot of care.\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = {QA-SRL: Question-Answer Driven Semantic Role Labeling},\n",
       " authors={Luheng He, Mike Lewis, Luke Zettlemoyer},\n",
       " year={2015}\n",
       " publisher = {cs.washington.edu},\n",
       " howpublished={\\\\url{https://dada.cs.washington.edu/qasrl/#page-top}},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa', 'open-domain-qa'], 'paperswithcode_id': 'qa-srl', 'pretty_name': 'QA-SRL'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 759\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: qa-srl\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qa_zre\n",
       " \tsha: 54f6182045b71999fe8203c0577f8d2fb2648167\n",
       " \tlastModified: 2022-07-01T11:55:22.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-zero-shot-relation-extraction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset reducing relation extraction to simple reading comprehension questions\n",
       " \tcitation: @inproceedings{levy-etal-2017-zero,\n",
       "     title = \"Zero-Shot Relation Extraction via Reading Comprehension\",\n",
       "     author = \"Levy, Omer  and\n",
       "       Seo, Minjoon  and\n",
       "       Choi, Eunsol  and\n",
       "       Zettlemoyer, Luke\",\n",
       "     booktitle = \"Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)\",\n",
       "     month = aug,\n",
       "     year = \"2017\",\n",
       "     address = \"Vancouver, Canada\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/K17-1034\",\n",
       "     doi = \"10.18653/v1/K17-1034\",\n",
       "     pages = \"333--342\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'QaZre', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-zero-shot-relation-extraction'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 543\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qangaroo\n",
       " \tsha: 13bce00bb0ca9cb2da4809f556a2cf484ef398d7\n",
       " \tlastModified: 2022-07-01T11:55:22.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:   We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n",
       " \n",
       " Several pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n",
       " \n",
       " Our aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n",
       " \n",
       " The two QAngaroo datasets provide a training and evaluation resource for such methods.\n",
       " \tcitation: \n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': None, 'pretty_name': 'qangaroo'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 791\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qanta\n",
       " \tsha: 717587add570ebe32cd316359cb7dfe322764845\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['arxiv:1904.04792', 'annotations_creators:machine-generated', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-quizbowl']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Qanta dataset is a question answering dataset based on the academic trivia game Quizbowl.\n",
       " \tcitation: @article{Rodriguez2019QuizbowlTC,\n",
       "   title={Quizbowl: The Case for Incremental Question Answering},\n",
       "   author={Pedro Rodriguez and Shi Feng and Mohit Iyyer and He He and Jordan L. Boyd-Graber},\n",
       "   journal={ArXiv},\n",
       "   year={2019},\n",
       "   volume={abs/1904.04792}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Quizbowl', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-quizbowl'], 'paperswithcode_id': 'quizbowl'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1019\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: quizbowl\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qasc\n",
       " \tsha: 00d0656b28ec631fa6fcc8ceaa2b012e3fb692ad\n",
       " \tlastModified: 2022-09-08T14:52:33.000Z\n",
       " \ttags: ['arxiv:1910.11473', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:multiple-choice', 'task_ids:extractive-qa', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice\n",
       " questions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.\n",
       " \tcitation: @article{allenai:qasc,\n",
       "       author    = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Jansen and Ashish Sabharwal},\n",
       "       title     = {QASC: A Dataset for Question Answering via Sentence Composition},\n",
       "       journal   = {arXiv:1910.11473v2},\n",
       "       year      = {2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Question Answering via Sentence Composition (QASC)', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'multiple-choice'], 'task_ids': ['extractive-qa', 'multiple-choice-qa'], 'paperswithcode_id': 'qasc'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 32109\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: qasc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qasper\n",
       " \tsha: fdc9d8214fbab5dd782958601db4d678e6934a54\n",
       " \tlastModified: 2022-10-07T22:04:11.000Z\n",
       " \ttags: ['arxiv:2105.03011', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'language_bcp47:en-US', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|s2orc', 'task_categories:question-answering', 'task_ids:closed-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset containing 1585 papers with 5049 information-seeking questions asked by regular readers of NLP papers, and answered by a separate set of NLP practitioners.\n",
       " \tcitation: @inproceedings{Dasigi2021ADO,\n",
       "   title={A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers},\n",
       "   author={Pradeep Dasigi and Kyle Lo and Iz Beltagy and Arman Cohan and Noah A. Smith and Matt Gardner},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'QASPER', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'language_bcp47': ['en-US'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|s2orc'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': 'qasper'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 509\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: qasper\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qed\n",
       " \tsha: f81bd1ab481c1722e078112dd3b6a14f72f4a2d9\n",
       " \tlastModified: 2022-08-11T12:57:32.000Z\n",
       " \ttags: ['arxiv:2009.06354', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|natural_questions', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-explanations-in-question-answering']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QED, is a linguistically informed, extensible framework for explanations in question answering. A QED explanation specifies the relationship between a question and answer according to formal semantic notions such as referential equality, sentencehood, and entailment. It is an expertannotated dataset of QED explanations built upon a subset of the Google Natural Questions dataset.\n",
       " \tcitation: @misc{lamm2020qed,\n",
       "     title={QED: A Framework and Dataset for Explanations in Question Answering},\n",
       "     author={Matthew Lamm and Jennimaria Palomaki and Chris Alberti and Daniel Andor and Eunsol Choi and Livio Baldini Soares and Michael Collins},\n",
       "     year={2020},\n",
       "     eprint={2009.06354},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|natural_questions'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-explanations-in-question-answering'], 'paperswithcode_id': 'qed', 'pretty_name': 'QED'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 528\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: qed\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: qed_amara\n",
       " \tsha: 1ad3773a43267a1335eac784ec7742acd2b61202\n",
       " \tlastModified: 2022-08-11T14:03:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:aa', 'language:ab', 'language:ae', 'language:aeb', 'language:af', 'language:ak', 'language:am', 'language:an', 'language:ar', 'language:arq', 'language:arz', 'language:as', 'language:ase', 'language:ast', 'language:av', 'language:ay', 'language:az', 'language:ba', 'language:be', 'language:ber', 'language:bg', 'language:bh', 'language:bi', 'language:bm', 'language:bn', 'language:bnt', 'language:bo', 'language:br', 'language:bs', 'language:bug', 'language:ca', 'language:ce', 'language:ceb', 'language:ch', 'language:cho', 'language:cku', 'language:cnh', 'language:co', 'language:cr', 'language:cs', 'language:cu', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:dv', 'language:dz', 'language:ee', 'language:efi', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:ff', 'language:fi', 'language:fil', 'language:fj', 'language:fo', 'language:fr', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:gu', 'language:ha', 'language:hai', 'language:haw', 'language:haz', 'language:hch', 'language:he', 'language:hi', 'language:ho', 'language:hr', 'language:ht', 'language:hu', 'language:hup', 'language:hus', 'language:hy', 'language:hz', 'language:ia', 'language:id', 'language:ie', 'language:ig', 'language:ik', 'language:inh', 'language:io', 'language:iro', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:jv', 'language:ka', 'language:kar', 'language:ki', 'language:kj', 'language:kk', 'language:kl', 'language:km', 'language:kn', 'language:ko', 'language:kr', 'language:ksh', 'language:ku', 'language:kv', 'language:kw', 'language:ky', 'language:la', 'language:lb', 'language:lg', 'language:li', 'language:lkt', 'language:lld', 'language:ln', 'language:lo', 'language:lt', 'language:ltg', 'language:lu', 'language:luo', 'language:luy', 'language:lv', 'language:mad', 'language:mfe', 'language:mg', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mni', 'language:moh', 'language:mos', 'language:mr', 'language:ms', 'language:mt', 'language:mus', 'language:my', 'language:nb', 'language:nci', 'language:nd', 'language:ne', 'language:nl', 'language:nn', 'language:nso', 'language:nv', 'language:ny', 'language:oc', 'language:om', 'language:or', 'language:pa', 'language:pam', 'language:pap', 'language:pi', 'language:pl', 'language:pnb', 'language:prs', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:rn', 'language:ro', 'language:ru', 'language:rup', 'language:rw', 'language:sa', 'language:sc', 'language:scn', 'language:sco', 'language:sd', 'language:sg', 'language:sgn', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sm', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:st', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:te', 'language:tet', 'language:tg', 'language:th', 'language:ti', 'language:tk', 'language:tl', 'language:tlh', 'language:to', 'language:tr', 'language:ts', 'language:tt', 'language:tw', 'language:ug', 'language:uk', 'language:umb', 'language:ur', 'language:uz', 'language:ve', 'language:vi', 'language:vls', 'language:vo', 'language:wa', 'language:wo', 'language:xh', 'language:yaq', 'language:yi', 'language:yo', 'language:za', 'language:zam', 'language:zh', 'language:zu', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The QCRI Educational Domain Corpus (formerly QCRI AMARA Corpus) is an open multilingual collection of subtitles for educational videos and lectures collaboratively transcribed and translated over the AMARA web-based platform.\n",
       " Developed by: Qatar Computing Research Institute, Arabic Language Technologies Group\n",
       " The QED Corpus is made public for RESEARCH purpose only.\n",
       " The corpus is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Copyright Qatar Computing Research Institute. All rights reserved.\n",
       " 225 languages, 9,291 bitexts\n",
       " total number of files: 271,558\n",
       " total number of tokens: 371.76M\n",
       " total number of sentence fragments: 30.93M\n",
       " \tcitation: A. Abdelali, F. Guzman, H. Sajjad and S. Vogel, \"The AMARA Corpus: Building parallel language resources for the educational domain\", The Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC'14). Reykjavik, Iceland, 2014. Pp. 1856-1862. Isbn. 978-2-9517408-8-4.\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['aa', 'ab', 'ae', 'aeb', 'af', 'ak', 'am', 'an', 'ar', 'arq', 'arz', 'as', 'ase', 'ast', 'av', 'ay', 'az', 'ba', 'be', 'ber', 'bg', 'bh', 'bi', 'bm', 'bn', 'bnt', 'bo', 'br', 'bs', 'bug', 'ca', 'ce', 'ceb', 'ch', 'cho', 'cku', 'cnh', 'co', 'cr', 'cs', 'cu', 'cv', 'cy', 'da', 'de', 'dv', 'dz', 'ee', 'efi', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'ff', 'fi', 'fil', 'fj', 'fo', 'fr', 'ga', 'gd', 'gl', 'gn', 'gu', 'ha', 'hai', 'haw', 'haz', 'hch', 'he', 'hi', 'ho', 'hr', 'ht', 'hu', 'hup', 'hus', 'hy', 'hz', 'ia', 'id', 'ie', 'ig', 'ik', 'inh', 'io', 'iro', 'is', 'it', 'iu', 'ja', 'jv', 'ka', 'kar', 'ki', 'kj', 'kk', 'kl', 'km', 'kn', 'ko', 'kr', 'ksh', 'ku', 'kv', 'kw', 'ky', 'la', 'lb', 'lg', 'li', 'lkt', 'lld', 'ln', 'lo', 'lt', 'ltg', 'lu', 'luo', 'luy', 'lv', 'mad', 'mfe', 'mg', 'mi', 'mk', 'ml', 'mn', 'mni', 'moh', 'mos', 'mr', 'ms', 'mt', 'mus', 'my', 'nb', 'nci', 'nd', 'ne', 'nl', 'nn', 'nso', 'nv', 'ny', 'oc', 'om', 'or', 'pa', 'pam', 'pap', 'pi', 'pl', 'pnb', 'prs', 'ps', 'pt', 'qu', 'rm', 'rn', 'ro', 'ru', 'rup', 'rw', 'sa', 'sc', 'scn', 'sco', 'sd', 'sg', 'sgn', 'sh', 'si', 'sk', 'sl', 'sm', 'sn', 'so', 'sq', 'sr', 'st', 'sv', 'sw', 'szl', 'ta', 'te', 'tet', 'tg', 'th', 'ti', 'tk', 'tl', 'tlh', 'to', 'tr', 'ts', 'tt', 'tw', 'ug', 'uk', 'umb', 'ur', 'uz', 've', 'vi', 'vls', 'vo', 'wa', 'wo', 'xh', 'yaq', 'yi', 'yo', 'za', 'zam', 'zh', 'zu'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'QedAmara'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 946\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quac\n",
       " \tsha: d6902ea493d93d0b4d3cf0f4eff7d6e9778b5342\n",
       " \tlastModified: 2022-08-11T12:57:32.000Z\n",
       " \ttags: ['arxiv:1808.07036', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|wikipedia', 'task_categories:question-answering', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Question Answering in Context is a dataset for modeling, understanding,\n",
       " and participating in information seeking dialog. Data instances consist\n",
       " of an interactive dialog between two crowd workers: (1) a student who\n",
       " poses a sequence of freeform questions to learn as much as possible\n",
       " about a hidden Wikipedia text, and (2) a teacher who answers the questions\n",
       " by providing short excerpts (spans) from the text. QuAC introduces\n",
       " challenges not found in existing machine comprehension datasets: its\n",
       " questions are often more open-ended, unanswerable, or only meaningful\n",
       " within the dialog context.\n",
       " \tcitation: @inproceedings{choi-etal-2018-quac,\n",
       " title = \"QUAC: Question answering in context\",\n",
       " abstract = \"We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.\",\n",
       " author = \"Eunsol Choi and He He and Mohit Iyyer and Mark Yatskar and Yih, {Wen Tau} and Yejin Choi and Percy Liang and Luke Zettlemoyer\",\n",
       " year = \"2018\",\n",
       " language = \"English (US)\",\n",
       " series = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " pages = \"2174--2184\",\n",
       " editor = \"Ellen Riloff and David Chiang and Julia Hockenmaier and Jun'ichi Tsujii\",\n",
       " booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\n",
       " note = \"2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018 ; Conference date: 31-10-2018 Through 04-11-2018\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['question-answering', 'text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling', 'extractive-qa'], 'paperswithcode_id': 'quac', 'pretty_name': 'Question Answering in Context'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1430\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: quac\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quail\n",
       " \tsha: 6f9fcba47b6a07aaf82071e75408ea80e0dd53bc\n",
       " \tlastModified: 2022-08-25T13:44:00.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QuAIL is a  reading comprehension dataset. QuAIL contains 15K multi-choice questions in texts 300-350 tokens long 4 domains (news, user stories, fiction, blogs).QuAIL is balanced and annotated for question types.\\\n",
       " \tcitation: @inproceedings{DBLP:conf/aaai/RogersKDR20,\n",
       "   author    = {Anna Rogers and\n",
       "                Olga Kovaleva and\n",
       "                Matthew Downey and\n",
       "                Anna Rumshisky},\n",
       "   title     = {Getting Closer to {AI} Complete Question Answering: {A} Set of Prerequisite\n",
       "                Real Tasks},\n",
       "   booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}\n",
       "                2020, The Thirty-Second Innovative Applications of Artificial Intelligence\n",
       "                Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational\n",
       "                Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,\n",
       "                February 7-12, 2020},\n",
       "   pages     = {8722--8731},\n",
       "   publisher = {{AAAI} Press},\n",
       "   year      = {2020},\n",
       "   url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6398},\n",
       "   timestamp = {Thu, 04 Jun 2020 13:18:48 +0200},\n",
       "   biburl    = {https://dblp.org/rec/conf/aaai/RogersKDR20.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Question Answering for Artificial Intelligence (QuAIL)', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'quail'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 46972\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: quail\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quarel\n",
       " \tsha: d42a89a62f8446ea8ab298f1d8b97bdac100c63b\n",
       " \tlastModified: 2022-07-01T11:55:28.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QuaRel is a crowdsourced dataset of 2771 multiple-choice story questions, including their logical forms.\n",
       " \tcitation: @inproceedings{quarel_v1,\n",
       "     title={QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships},\n",
       "     author={Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, Ashish Sabharwal},\n",
       "     year={2018},\n",
       "     journal={arXiv:1805.05377v1}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'quarel', 'pretty_name': 'QuaRel'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 19625\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: quarel\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quartz\n",
       " \tsha: 855caa51dcc7efa158bf17b29a54235bd837192e\n",
       " \tlastModified: 2022-08-12T09:46:32.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: QuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each\n",
       " question is paired with one of 405 different background sentences (sometimes short paragraphs).\n",
       " The QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with\n",
       " one of 405 different background sentences (sometimes short paragraphs).\n",
       " The dataset is split into train (2696), dev (384) and test (784). A background sentence will only appear in a single split.\n",
       " \tcitation: @InProceedings{quartz,\n",
       "   author = {Oyvind Tafjord and Matt Gardner and Kevin Lin and Peter Clark},\n",
       "   title = {\"QUARTZ: An Open-Domain Dataset of Qualitative Relationship\n",
       " Questions\"},\n",
       "   year = {\"2019\"},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': 'quartz', 'pretty_name': 'QuaRTz'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 30320\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: quartz\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quora\n",
       " \tsha: c7c83a839e99057bf975d3949a15117e64ab12b9\n",
       " \tlastModified: 2022-09-01T05:05:20.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Quora Question Pairs', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1093\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: quoref\n",
       " \tsha: ab379b081b3a52f0c93c684d2c10f2f9658b6503\n",
       " \tlastModified: 2022-09-01T05:05:23.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:question-answering-other-coreference-resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Quoref is a QA dataset which tests the coreferential reasoning capability of reading comprehension systems. In this\n",
       " span-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard\n",
       " coreferences before selecting the appropriate span(s) in the paragraphs for answering questions.\n",
       " \tcitation: @article{allenai:quoref,\n",
       "       author    = {Pradeep Dasigi and Nelson F. Liu and Ana Marasovic and Noah A. Smith and  Matt Gardner},\n",
       "       title     = {Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning},\n",
       "       journal   = {arXiv:1908.05803v2 },\n",
       "       year      = {2019},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Quoref', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['question-answering-other-coreference-resolution'], 'paperswithcode_id': 'quoref'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 39548\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: quoref\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: race\n",
       " \tsha: cc4b3ec97dd9e0afbfbb7420648188d22aa05869\n",
       " \tlastModified: 2022-09-01T05:05:23.000Z\n",
       " \ttags: ['arxiv:1704.04683', 'annotations_creators:expert-generated', 'language:en', 'language_creators:found', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Race is a large-scale reading comprehension dataset with more than 28,000 passages and nearly 100,000 questions. The\n",
       "  dataset is collected from English examinations in China, which are designed for middle school and high school students.\n",
       " The dataset can be served as the training and test sets for machine comprehension.\n",
       " \tcitation: @article{lai2017large,\n",
       "     title={RACE: Large-scale ReAding Comprehension Dataset From Examinations},\n",
       "     author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},\n",
       "     journal={arXiv preprint arXiv:1704.04683},\n",
       "     year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'RACE', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'race'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 101523\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: race\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: re_dial\n",
       " \tsha: 01358ede7a6276b27150b4475d31ff7eb9773980\n",
       " \tlastModified: 2022-07-01T11:55:31.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:other', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-dialogue-sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ReDial (Recommendation Dialogues) is an annotated dataset of dialogues, where users\n",
       " recommend movies to each other. The dataset was collected by a team of researchers working at\n",
       " Polytechnique Montréal, MILA – Quebec AI Institute, Microsoft Research Montréal, HEC Montreal, and Element AI.\n",
       " \n",
       " The dataset allows research at the intersection of goal-directed dialogue systems\n",
       " (such as restaurant recommendation) and free-form (also called “chit-chat”) dialogue systems.\n",
       " \tcitation: @inproceedings{li2018conversational,\n",
       "   title={Towards Deep Conversational Recommendations},\n",
       "   author={Li, Raymond and Kahou, Samira Ebrahimi and Schulz, Hannes and Michalski, Vincent and Charlin, Laurent and Pal, Chris},\n",
       "   booktitle={Advances in Neural Information Processing Systems 31 (NIPS 2018)},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-classification'], 'task_ids': ['sentiment-classification', 'text-classification-other-dialogue-sentiment-classification'], 'paperswithcode_id': 'redial', 'pretty_name': 'ReDial (Recommendation Dialogues)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 363\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: redial\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: reasoning_bg\n",
       " \tsha: 9b230fde93b705e6916145b0dd2a2fafbd4472ae\n",
       " \tlastModified: 2022-08-24T04:09:35.000Z\n",
       " \ttags: ['arxiv:1908.01519', 'annotations_creators:found', 'language_creators:found', 'language:bg', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This new dataset is designed to do reading comprehension in Bulgarian language.\n",
       " \tcitation: @article{hardalov2019beyond,\n",
       "   title={Beyond english-only reading comprehension: Experiments in zero-shot multilingual transfer for bulgarian},\n",
       "   author={Hardalov, Momchil and Koychev, Ivan and Nakov, Preslav},\n",
       "   journal={arXiv preprint arXiv:1908.01519},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': None, 'pretty_name': 'ReasoningBg'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 945\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: recipe_nlg\n",
       " \tsha: cee8d7f2e2f263be8fb58cf65df9fc35e26ec129\n",
       " \tlastModified: 2022-08-12T11:14:22.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-retrieval', 'task_categories:summarization', 'task_ids:document-retrieval', 'task_ids:entity-linking-retrieval', 'task_ids:explanation-generation', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains 2231142 cooking recipes (>2 millions). It's processed in more careful way and provides more samples than any other dataset in the area.\n",
       " \tcitation: @inproceedings{bien-etal-2020-recipenlg,\n",
       " title = \"{R}ecipe{NLG}: A Cooking Recipes Dataset for Semi-Structured Text Generation\",\n",
       " author = \"Bie{'n}, Micha{l}  and\n",
       "   Gilski, Micha{l}  and\n",
       "   Maciejewska, Martyna  and\n",
       "   Taisner, Wojciech  and\n",
       "   Wisniewski, Dawid  and\n",
       "   Lawrynowicz, Agnieszka\",\n",
       " booktitle = \"Proceedings of the 13th International Conference on Natural Language Generation\",\n",
       " month = dec,\n",
       " year = \"2020\",\n",
       " address = \"Dublin, Ireland\",\n",
       " publisher = \"Association for Computational Linguistics\",\n",
       " url = \"https://www.aclweb.org/anthology/2020.inlg-1.4\",\n",
       " pages = \"22--28\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-generation', 'fill-mask', 'text-retrieval', 'summarization'], 'task_ids': ['document-retrieval', 'entity-linking-retrieval', 'explanation-generation', 'language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'recipenlg', 'pretty_name': 'RecipeNLG'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 537\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: recipenlg\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: reclor\n",
       " \tsha: aa5f496cf65315493f949f803a8c27dbc0ad5b28\n",
       " \tlastModified: 2022-01-25T15:53:14.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Logical reasoning is an important ability to examine, analyze, and critically evaluate arguments as they occur in ordinary\n",
       " language as the definition from LSAC. ReClor is a dataset extracted from logical reasoning questions of standardized graduate\n",
       " admission examinations. Empirical results show that the state-of-the-art models struggle on ReClor with poor performance\n",
       " indicating more research is needed to essentially enhance the logical reasoning ability of current models. We hope this\n",
       " dataset could help push Machine Reading Comprehension (MRC) towards more complicated reasonin\n",
       " \tcitation: @inproceedings{yu2020reclor,\n",
       "         author = {Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},\n",
       "         title = {ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},\n",
       "         booktitle = {International Conference on Learning Representations (ICLR)},\n",
       "         month = {April},\n",
       "         year = {2020}\n",
       "     }\n",
       " \tcardData: {'paperswithcode_id': 'reclor', 'pretty_name': 'ReClor'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 845\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: reclor\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: red_caps\n",
       " \tsha: 388b9dad7ed982a26f4996e5975746492638e3e8\n",
       " \tlastModified: 2022-07-01T11:55:33.000Z\n",
       " \ttags: ['arxiv:2111.11431', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:image-to-text', 'task_ids:image-captioning']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\n",
       " Images and captions from Reddit depict and describe a wide variety of objects and scenes.\n",
       " The data is collected from a manually curated set of subreddits (350 total),\n",
       " which give coarse image labels and allow steering of the dataset composition\n",
       " without labeling individual instances.\n",
       " \tcitation: @misc{desai2021redcaps,\n",
       "       title={RedCaps: web-curated image-text data created by the people, for the people},\n",
       "       author={Karan Desai and Gaurav Kaul and Zubin Aysola and Justin Johnson},\n",
       "       year={2021},\n",
       "       eprint={2111.11431},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CV}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['image-to-text'], 'task_ids': ['image-captioning'], 'paperswithcode_id': 'redcaps', 'pretty_name': 'RedCaps'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 275612\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: redcaps\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: reddit\n",
       " \tsha: 78512b74d0f840d0ba3b7ab8b1934cc9d8928b14\n",
       " \tlastModified: 2022-07-01T11:55:33.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-reddit-posts-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This corpus contains preprocessed posts from the Reddit dataset.\n",
       " The dataset consists of 3,848,330 posts with an average length of 270 words for content,\n",
       " and 28 words for the summary.\n",
       " \n",
       " Features includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\n",
       " Content is used as document and summary is used as summary.\n",
       " \tcitation: @inproceedings{volske-etal-2017-tl,\n",
       "     title = {TL;DR: Mining {R}eddit to Learn Automatic Summarization},\n",
       "     author = {V{\\\"o}lske, Michael  and Potthast, Martin  and Syed, Shahbaz  and Stein, Benno},\n",
       "     booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},\n",
       "     month = {sep},\n",
       "     year = {2017},\n",
       "     address = {Copenhagen, Denmark},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     url = {https://www.aclweb.org/anthology/W17-4508},\n",
       "     doi = {10.18653/v1/W17-4508},\n",
       "     pages = {59--63},\n",
       "     abstract = {Recent advances in automatic text summarization have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining social media for author-provided summaries, taking advantage of the common practice of appending a {``}TL;DR{''} to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is likely applicable to other social media sites and general web crawls.},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': None, 'pretty_name': 'Reddit Webis-TLDR-17', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-reddit-posts-summarization'], 'train-eval-index': [{'config': 'default', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'train_split': 'train'}, 'col_mapping': {'content': 'text', 'summary': 'target'}, 'metrics': [{'type': 'rouge', 'name': 'Rouge'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 934\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: reddit_tifu\n",
       " \tsha: 163f838e5b4e74a68f3814d6f5ab6c00377c570d\n",
       " \tlastModified: 2022-07-01T11:55:34.000Z\n",
       " \ttags: ['arxiv:1811.00783', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-reddit-posts-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Reddit dataset, where TIFU denotes the name of subbreddit /r/tifu.\n",
       " As defined in the publication, styel \"short\" uses title as summary and\n",
       " \"long\" uses tldr as summary.\n",
       " \n",
       " Features includes:\n",
       "   - document: post text without tldr.\n",
       "   - tldr: tldr line.\n",
       "   - title: trimmed title without tldr.\n",
       "   - ups: upvotes.\n",
       "   - score: score.\n",
       "   - num_comments: number of comments.\n",
       "   - upvote_ratio: upvote ratio.\n",
       " \tcitation: @misc{kim2018abstractive,\n",
       "     title={Abstractive Summarization of Reddit Posts with Multi-level Memory Networks},\n",
       "     author={Byeongchang Kim and Hyunwoo Kim and Gunhee Kim},\n",
       "     year={2018},\n",
       "     eprint={1811.00783},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Reddit TIFU', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-reddit-posts-summarization'], 'paperswithcode_id': 'reddit-tifu'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 639\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: reddit-tifu\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: refresd\n",
       " \tsha: da3bc6f08f5bd867d1b9f7b60ffc45f94f695270\n",
       " \tlastModified: 2022-07-01T11:55:35.000Z\n",
       " \ttags: ['arxiv:1907.05791', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'language:fr', 'license:mit', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|other-wikimatrix', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification', 'task_ids:semantic-similarity-scoring', 'task_ids:text-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Rationalized English-French Semantic Divergences (REFreSD) dataset consists of 1,039\n",
       "  English-French sentence-pairs annotated with sentence-level divergence judgments and token-level\n",
       "  rationales. For any questions, write to ebriakou@cs.umd.edu.\n",
       " \tcitation: @inproceedings{briakou-carpuat-2020-detecting,\n",
       "     title = \"Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank\",\n",
       "     author = \"Briakou, Eleftheria and Carpuat, Marine\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.121\",\n",
       "     pages = \"1563--1580\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['en', 'fr'], 'license': ['mit'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-wikimatrix'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification', 'semantic-similarity-scoring', 'text-scoring'], 'paperswithcode_id': 'refresd', 'pretty_name': 'Rationalized English-French Semantic Divergences'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: refresd\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: reuters21578\n",
       " \tsha: 4509de42acac9014d7d55bd2571dac4244e83dcd\n",
       " \tlastModified: 2022-07-01T11:55:35.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Reuters-21578 dataset  is one of the most widely used data collections for text\n",
       " categorization research. It is collected from the Reuters financial newswire service in 1987.\n",
       " \tcitation: @article{APTE94,\n",
       " author = {Chidanand Apt{\\'{e}} and Fred Damerau and Sholom M. Weiss},\n",
       " title = {Automated Learning of Decision Rules for Text Categorization},\n",
       " journal = {ACM Transactions on Information Systems},\n",
       " year = {1994},\n",
       " note = {To appear.}\n",
       " }\n",
       " \n",
       " @inproceedings{APTE94b,\n",
       " author = {Chidanand Apt{\\'{e}} and Fred Damerau and Sholom M. Weiss},\n",
       " title = {Toward Language Independent Automated Learning of Text Categorization Models},\n",
       " booktitle = {sigir94},\n",
       " year = {1994},\n",
       " note = {To appear.}\n",
       " }\n",
       " \n",
       " @inproceedings{HAYES8},\n",
       " author = {Philip J. Hayes and Peggy M. Anderson and Irene B. Nirenburg and\n",
       " Linda M. Schmandt},\n",
       " title = {{TCS}: A Shell for Content-Based Text Categorization},\n",
       " booktitle = {IEEE Conference on Artificial Intelligence Applications},\n",
       " year = {1990}\n",
       " }\n",
       " \n",
       " @inproceedings{HAYES90b,\n",
       " author = {Philip J. Hayes and Steven P. Weinstein},\n",
       " title = {{CONSTRUE/TIS:} A System for Content-Based Indexing of a\n",
       " Database of News Stories},\n",
       " booktitle = {Second Annual Conference on Innovative Applications of\n",
       " Artificial Intelligence},\n",
       " year = {1990}\n",
       " }\n",
       " \n",
       " @incollection{HAYES92 ,\n",
       " author = {Philip J. Hayes},\n",
       " title = {Intelligent High-Volume Text Processing using Shallow,\n",
       " Domain-Specific Techniques},\n",
       " booktitle = {Text-Based Intelligent Systems},\n",
       " publisher = {Lawrence Erlbaum},\n",
       " address =  {Hillsdale, NJ},\n",
       " year = {1992},\n",
       " editor = {Paul S. Jacobs}\n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS91c ,\n",
       " author = {David D. Lewis},\n",
       " title = {Evaluating Text Categorization},\n",
       " booktitle = {Proceedings of Speech and Natural Language Workshop},\n",
       " year = {1991},\n",
       " month = {feb},\n",
       " organization = {Defense Advanced Research Projects Agency},\n",
       " publisher = {Morgan Kaufmann},\n",
       " pages = {312--318}\n",
       " \n",
       " }\n",
       " \n",
       " @phdthesis{LEWIS91d,\n",
       " author = {David Dolan Lewis},\n",
       " title = {Representation and Learning in Information Retrieval},\n",
       " school = {Computer Science Dept.; Univ. of Massachusetts; Amherst, MA 01003},\n",
       " year = 1992},\n",
       " note = {Technical Report 91--93.}\n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS91e,\n",
       " author = {David D. Lewis},\n",
       " title = {Data Extraction as Text Categorization: An Experiment with\n",
       " the {MUC-3} Corpus},\n",
       " booktitle = {Proceedings of the Third Message Understanding Evaluation\n",
       " and Conference},\n",
       " year = {1991},\n",
       " month = {may},\n",
       " organization = {Defense Advanced Research Projects Agency},\n",
       " publisher = {Morgan Kaufmann},\n",
       " address = {Los Altos, CA}\n",
       " \n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS92b,\n",
       " author = {David D. Lewis},\n",
       " title = {An Evaluation of Phrasal and Clustered Representations on a Text\n",
       " Categorization Task},\n",
       " booktitle = {Fifteenth Annual International ACM SIGIR Conference on\n",
       " Research and Development in Information Retrieval},\n",
       " year = {1992},\n",
       " pages = {37--50}\n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS92d ,\n",
       " author = {David D. Lewis and Richard M. Tong},\n",
       " title = {Text Filtering in {MUC-3} and {MUC-4}},\n",
       " booktitle = {Proceedings of the Fourth Message Understanding Conference ({MUC-4})},\n",
       " year = {1992},\n",
       " month = {jun},\n",
       " organization = {Defense Advanced Research Projects Agency},\n",
       " publisher = {Morgan Kaufmann},\n",
       " address = {Los Altos, CA}\n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS92e,\n",
       " author = {David D. Lewis},\n",
       " title = {Feature Selection and Feature Extraction for Text Categorization},\n",
       " booktitle = {Proceedings of Speech and Natural Language Workshop},\n",
       " year = {1992},\n",
       " month = {feb} ,\n",
       " organization = {Defense Advanced Research Projects Agency},\n",
       " publisher = {Morgan Kaufmann},\n",
       " pages = {212--217}\n",
       " }\n",
       " \n",
       " @inproceedings{LEWIS94b,\n",
       " author = {David D. Lewis and Marc Ringuette},\n",
       " title = {A Comparison of Two Learning Algorithms for Text Categorization},\n",
       " booktitle = {Symposium on Document Analysis and Information Retrieval},\n",
       " year = {1994},\n",
       " organization = {ISRI; Univ. of Nevada, Las Vegas},\n",
       " address = {Las Vegas, NV},\n",
       " month = {apr},\n",
       " pages = {81--93}\n",
       " }\n",
       " \n",
       " @article{LEWIS94d,\n",
       " author = {David D. Lewis and Philip J. Hayes},\n",
       " title = {Guest Editorial},\n",
       " journal = {ACM Transactions on Information Systems},\n",
       " year = {1994},\n",
       " volume  = {12},\n",
       " number  = {3},\n",
       " pages = {231},\n",
       " month = {jul}\n",
       " }\n",
       " \n",
       " @article{SPARCKJONES76,\n",
       " author = {K. {Sparck Jones} and  C. J. {van Rijsbergen}},\n",
       " title =  {Information Retrieval Test Collections},\n",
       " journal = {Journal of Documentation},\n",
       " year = {1976},\n",
       " volume = {32},\n",
       " number = {1},\n",
       " pages = {59--75}\n",
       " }\n",
       " \n",
       " @book{WEISS91,\n",
       " author = {Sholom M. Weiss and Casimir A. Kulikowski},\n",
       " title = {Computer Systems That Learn},\n",
       " publisher = {Morgan Kaufmann},\n",
       " year = {1991},\n",
       " address = {San Mateo, CA}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Reuters-21578 Text Categorization Collection', 'language': ['en'], 'paperswithcode_id': 'reuters-21578'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 828\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: reuters-21578\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: riddle_sense\n",
       " \tsha: 9d737abf92f1eb6df03003ae9260adc2ff0ba4e0\n",
       " \tlastModified: 2022-07-01T12:43:40.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Answering such a riddle-style question is a challenging cognitive process, in that it requires\n",
       " complex commonsense reasoning abilities, an understanding of figurative language, and counterfactual reasoning\n",
       " skills, which are all important abilities for advanced natural language understanding (NLU). However,\n",
       " there is currently no dedicated datasets aiming to test these abilities. Herein, we present RiddleSense,\n",
       " a new multiple-choice question answering task, which comes with the first large dataset (5.7k examples) for answering\n",
       " riddle-style commonsense questions. We systematically evaluate a wide range of models over the challenge,\n",
       " and point out that there is a large gap between the best-supervised model and human performance — suggesting\n",
       " intriguing future research in the direction of higher-order commonsense reasoning and linguistic creativity towards\n",
       " building advanced NLU systems.\n",
       " \tcitation: @InProceedings{lin-etal-2021-riddlesense,\n",
       " title={RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge},\n",
       " author={Lin, Bill Yuchen and Wu, Ziyi and Yang, Yichi and Lee, Dong-Ho and Ren, Xiang},\n",
       " journal={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2021): Findings},\n",
       " year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'RiddleSense', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 576\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ro_sent\n",
       " \tsha: 47bb04852b16b2b9d84a9cff729c7e69dbca0fba\n",
       " \tlastModified: 2022-07-01T11:55:36.000Z\n",
       " \ttags: ['arxiv:2009.08712', 'annotations_creators:found', 'language_creators:found', 'language:ro', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is a Romanian Sentiment Analysis dataset.\n",
       " It is present in a processed form, as used by the authors of `Romanian Transformers`\n",
       " in their examples and based on the original data present in\n",
       " `https://github.com/katakonst/sentiment-analysis-tensorflow`. The original dataset is collected\n",
       " from product and movie reviews in Romanian.\n",
       " \tcitation: @article{dumitrescu2020birth,\n",
       "   title={The birth of Romanian BERT},\n",
       "   author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius and Pyysalo, Sampo},\n",
       "   journal={arXiv preprint arXiv:2009.08712},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ro'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'RoSent'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ro_sts\n",
       " \tsha: d61dd1a5b31e7f06354faadc02013209b26c6e29\n",
       " \tlastModified: 2022-08-25T10:50:26.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ro', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-sts-b', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The RO-STS (Romanian Semantic Textual Similarity) dataset contains 8628 pairs of sentences with their similarity score. It is a high-quality translation of the STS benchmark dataset.\n",
       " \tcitation: @inproceedings{dumitrescu2021liro,\n",
       "   title={Liro: Benchmark and leaderboard for romanian language tasks},\n",
       "   author={Dumitrescu, Stefan Daniel and Rebeja, Petru and Lorincz, Beata and Gaman, Mihaela and Avram, Andrei and Ilie, Mihai and Pruteanu, Andrei and Stan, Adriana and Rosia, Lorena and Iacobescu, Cristina and others},\n",
       "   booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ro'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-sts-b'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'RO-STS'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 319\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ro_sts_parallel\n",
       " \tsha: 777acdc181a27549861720962aa24f8f86e2784a\n",
       " \tlastModified: 2022-08-25T10:50:26.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'language:ro', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-sts-b', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The RO-STS-Parallel (a Parallel Romanian English dataset - translation of the Semantic Textual Similarity) contains 17256 sentences in Romanian and English. It is a high-quality translation of the English STS benchmark dataset into Romanian.\n",
       " \tcitation: @inproceedings{dumitrescu2021liro,\n",
       "   title={Liro: Benchmark and leaderboard for romanian language tasks},\n",
       "   author={Dumitrescu, Stefan Daniel and Rebeja, Petru and Lorincz, Beata and Gaman, Mihaela and Avram, Andrei and Ilie, Mihai and Pruteanu, Andrei and Stan, Adriana and Rosia, Lorena and Iacobescu, Cristina and others},\n",
       "   booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en', 'ro'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-sts-b'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'RO-STS-Parallel'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: roman_urdu\n",
       " \tsha: 9c07bba639e9615d2a0363246e27305385a9d086\n",
       " \tlastModified: 2022-07-01T11:55:38.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ur', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is an extensive compilation of Roman Urdu Dataset (Urdu written in Latin/Roman script) tagged for sentiment analysis.\n",
       " \tcitation: @InProceedings{Sharf:2018,\n",
       " title = \"Performing Natural Language Processing on Roman Urdu Datasets\",\n",
       " authors = \"Zareen Sharf and Saif Ur Rahman\",\n",
       " booktitle = \"International Journal of Computer Science and Network Security\",\n",
       " volume = \"18\",\n",
       " number = \"1\",\n",
       " pages = \"141-148\",\n",
       " year = \"2018\"\n",
       " }\n",
       " \n",
       " @misc{Dua:2019,\n",
       " author = \"Dua, Dheeru and Graff, Casey\",\n",
       " year = \"2017\",\n",
       " title = \"{UCI} Machine Learning Repository\",\n",
       " url = \"http://archive.ics.uci.edu/ml\",\n",
       " institution = \"University of California, Irvine, School of Information and Computer Sciences\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ur'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'roman-urdu-data-set', 'pretty_name': 'Roman Urdu Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: roman-urdu-data-set\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ronec\n",
       " \tsha: e5667168c253d62f251838b55e390ccdb25b42d1\n",
       " \tlastModified: 2022-07-01T11:55:39.000Z\n",
       " \ttags: ['arxiv:1909.01247', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:found', 'language:ro', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: RONEC - the Romanian Named Entity Corpus, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities. It is used for named entity recognition and represents the largest Romanian NER corpus to date.\n",
       " \tcitation: @article{dumitrescu2019introducing,\n",
       "   title={Introducing RONEC--the Romanian Named Entity Corpus},\n",
       "   author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},\n",
       "   journal={arXiv preprint arXiv:1909.01247},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'found'], 'language': ['ro'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'ronec', 'pretty_name': 'RONEC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: ronec\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ropes\n",
       " \tsha: b4945929c6731612ecb13d321e3a738bc1d3c4eb\n",
       " \tlastModified: 2022-08-11T12:57:32.000Z\n",
       " \ttags: ['arxiv:1908.05852', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|wikipedia', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ROPES (Reasoning Over Paragraph Effects in Situations) is a QA dataset\n",
       " which tests a system's ability to apply knowledge from a passage\n",
       " of text to a new situation. A system is presented a background\n",
       " passage containing a causal or qualitative relation(s) (e.g.,\n",
       " \"animal pollinators increase efficiency of fertilization in flowers\"),\n",
       " a novel situation that uses this background, and questions that require\n",
       " reasoning about effects of the relationships in the background\n",
       " passage in the background of the situation.\n",
       " \tcitation: @inproceedings{Lin2019ReasoningOP,\n",
       "   title={Reasoning Over Paragraph Effects in Situations},\n",
       "   author={Kevin Lin and Oyvind Tafjord and Peter Clark and Matt Gardner},\n",
       "   booktitle={MRQA@EMNLP},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'ROPES', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|wikipedia', 'original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'ropes'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 42876\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: ropes\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: rotten_tomatoes\n",
       " \tsha: a75cacbcba718ba1698113ec4d55a56bdf27f0dd\n",
       " \tlastModified: 2022-07-01T11:55:40.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'size_categories:1K<n<10K', 'source_datasets:original']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Movie Review Dataset.\n",
       " This is a dataset of containing 5,331 positive and 5,331 negative processed\n",
       " sentences from Rotten Tomatoes movie reviews. This data was first used in Bo\n",
       " Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for\n",
       " sentiment categorization with respect to rating scales.'', Proceedings of the\n",
       " ACL, 2005.\n",
       " \tcitation: @InProceedings{Pang+Lee:05a,\n",
       "   author =       {Bo Pang and Lillian Lee},\n",
       "   title =        {Seeing stars: Exploiting class relationships for sentiment\n",
       "                   categorization with respect to rating scales},\n",
       "   booktitle =    {Proceedings of the ACL},\n",
       "   year =         2005\n",
       " }\n",
       " \tcardData: {'pretty_name': 'RottenTomatoes - MR Movie Review Data', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'mr', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1', 'args': {'average': 'binary'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 67930\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: mr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: russian_super_glue\n",
       " \tsha: 18dfaad29b4cd8d082d4f6f090465255d508a92b\n",
       " \tlastModified: 2022-07-27T14:39:01.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:ru', 'language_bcp47:ru-RU', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'size_categories:10M<n<100M', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Recent advances in the field of universal language models and transformers require the development of a methodology for\n",
       " their broad diagnostics and testing for general intellectual skills - detection of natural language inference,\n",
       " commonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first\n",
       " time, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from\n",
       " scratch for the Russian language. We provide baselines, human level evaluation, an open-source framework for evaluating\n",
       " models and an overall leaderboard of transformer models for the Russian language.\n",
       " \tcitation: @article{shavrina2020russiansuperglue,\n",
       "                   title={RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark},\n",
       "                   author={Shavrina, Tatiana and Fenogenova, Alena and Emelyanov, Anton and Shevelev, Denis and Artemova,\n",
       "                   Ekaterina and Malykh, Valentin and Mikhailov, Vladislav and Tikhonova, Maria and Chertok, Andrey and\n",
       "                   Evlampiev, Andrey},\n",
       "                   journal={arXiv preprint arXiv:2010.15925},\n",
       "                   year={2020}\n",
       "                   }\n",
       " \tcardData: {'pretty_name': 'Russian SuperGLUE', 'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['ru'], 'language_bcp47': ['ru-RU'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '1M<n<10M', '10M<n<100M', '100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-class-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1664\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: s2orc\n",
       " \tsha: e2e0410e65fd8adac88161e16ec11e1e2a8d68c7\n",
       " \tlastModified: 2022-07-01T11:55:43.000Z\n",
       " \ttags: ['arxiv:1911.02782', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-2.0', 'multilinguality:monolingual', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:other-other-citation-recommendation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large corpus of 81.1M English-language academic papers spanning many academic disciplines.\n",
       " Rich metadata, paper abstracts, resolved bibliographic references, as well as structured full\n",
       " text for 8.1M open access papers. Full text annotated with automatically-detected inline mentions of\n",
       " citations, figures, and tables, each linked to their corresponding paper objects. Aggregated papers\n",
       " from hundreds of academic publishers and digital archives into a unified source, and create the largest\n",
       " publicly-available collection of machine-readable academic text to date.\n",
       " \tcitation: @misc{lo2020s2orc,\n",
       "       title={S2ORC: The Semantic Scholar Open Research Corpus},\n",
       "       author={Kyle Lo and Lucy Lu Wang and Mark Neumann and Rodney Kinney and Dan S. Weld},\n",
       "       year={2020},\n",
       "       eprint={1911.02782},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'multi-class-classification', 'multi-label-classification', 'other-other-citation-recommendation'], 'paperswithcode_id': 's2orc', 'pretty_name': 'S2ORC'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 354\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: s2orc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: samsum\n",
       " \tsha: b593014af13ef1ca5c318effe3ebfbd7565f76a3\n",
       " \tlastModified: 2022-07-01T11:55:43.000Z\n",
       " \ttags: ['arxiv:1911.12237', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-nc-nd-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-conversations-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SAMSum Corpus contains over 16k chat dialogues with manually annotated\n",
       " summaries.\n",
       " There are two features:\n",
       "   - dialogue: text of dialogue.\n",
       "   - summary: human written summary of the dialogue.\n",
       "   - id: id of a example.\n",
       " \tcitation: @article{gliwa2019samsum,\n",
       "   title={SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},\n",
       "   author={Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},\n",
       "   journal={arXiv preprint arXiv:1911.12237},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-nc-nd-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-conversations-summarization'], 'paperswithcode_id': 'samsum-corpus', 'pretty_name': 'SAMSum Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 28965\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: samsum-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sanskrit_classic\n",
       " \tsha: 6433475b4a064b1fc06a842db4bd8074322013dc\n",
       " \tlastModified: 2022-08-24T04:09:36.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:sa', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset combines some of the classical Sanskrit texts.\n",
       " \tcitation: @Misc{johnsonetal2014,\n",
       "  author = {Johnson, Kyle P. and Patrick Burns and John Stewart and Todd Cook},\n",
       "  title = {CLTK: The Classical Language Toolkit},\n",
       "  url = {https://github.com/cltk/cltk},\n",
       "  year = {2014--2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['sa'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'SanskritClassic'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: saudinewsnet\n",
       " \tsha: 7ba9ec3621f5fd219bdc74e6eb8a8437f8e22649\n",
       " \tlastModified: 2022-07-01T11:55:44.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains a set of 31,030 Arabic newspaper articles alongwith metadata, extracted from various online Saudi newspapers and written in MSA.\n",
       " \tcitation: @misc{hagrima2015,\n",
       " author = \"M. Alhagri\",\n",
       " title = \"Saudi Newspapers Arabic Corpus (SaudiNewsNet)\",\n",
       " year = 2015,\n",
       " url = \"http://github.com/ParallelMazen/SaudiNewsNet\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'saudinewsnet'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sberquad\n",
       " \tsha: 64f4dc31d265d136239ab181bce37cc91d34a992\n",
       " \tlastModified: 2022-07-01T11:55:45.000Z\n",
       " \ttags: ['arxiv:1912.09723', 'annotations_creators:crowdsourced', 'language_creators:found', 'language_creators:crowdsourced', 'language:ru', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Sber Question Answering Dataset (SberQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. Russian original analogue presented in Sberbank Data Science Journey 2017.\n",
       " \tcitation: @article{Efimov_2020,\n",
       "    title={SberQuAD – Russian Reading Comprehension Dataset: Description and Analysis},\n",
       "    ISBN={9783030582197},\n",
       "    ISSN={1611-3349},\n",
       "    url={http://dx.doi.org/10.1007/978-3-030-58219-7_1},\n",
       "    DOI={10.1007/978-3-030-58219-7_1},\n",
       "    journal={Experimental IR Meets Multilinguality, Multimodality, and Interaction},\n",
       "    publisher={Springer International Publishing},\n",
       "    author={Efimov, Pavel and Chertok, Andrey and Boytsov, Leonid and Braslavski, Pavel},\n",
       "    year={2020},\n",
       "    pages={3–15}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'SberQuAD', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found', 'crowdsourced'], 'language': ['ru'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'sberquad'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 647\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: sberquad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scan\n",
       " \tsha: 2fe37fb84446031429a4721fefb2114f6bc49dcf\n",
       " \tlastModified: 2022-08-11T16:23:44.000Z\n",
       " \ttags: ['arxiv:1711.00350', 'annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'license:bsd', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:other-multi-turn', 'configs:addprim_jump', 'configs:addprim_turn_left', 'configs:filler_num0', 'configs:filler_num1', 'configs:filler_num2', 'configs:filler_num3', 'configs:length', 'configs:simple', 'configs:template_around_right', 'configs:template_jump_around_right', 'configs:template_opposite_right', 'configs:template_right']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SCAN tasks with various splits.\n",
       " \n",
       " SCAN is a set of simple language-driven navigation tasks for studying\n",
       " compositional learning and zero-shot generalization.\n",
       " \n",
       " See https://github.com/brendenlake/SCAN for a description of the splits.\n",
       " \n",
       " Example usage:\n",
       " data = datasets.load_dataset('scan/length')\n",
       " \tcitation: @inproceedings{Lake2018GeneralizationWS,\n",
       "   title={Generalization without Systematicity: On the Compositional Skills of\n",
       "          Sequence-to-Sequence Recurrent Networks},\n",
       "   author={Brenden M. Lake and Marco Baroni},\n",
       "   booktitle={ICML},\n",
       "   year={2018},\n",
       "   url={https://arxiv.org/pdf/1711.00350.pdf},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['bsd'], 'multilinguality': ['monolingual'], 'pretty_name': 'SCAN', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['other-multi-turn'], 'paperswithcode_id': 'scan', 'configs': ['addprim_jump', 'addprim_turn_left', 'filler_num0', 'filler_num1', 'filler_num2', 'filler_num3', 'length', 'simple', 'template_around_right', 'template_jump_around_right', 'template_opposite_right', 'template_right']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3651\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: scan\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scb_mt_enth_2020\n",
       " \tsha: cc551c141ea793278f1a508870e900944583ca63\n",
       " \tlastModified: 2022-07-01T11:55:47.000Z\n",
       " \ttags: ['arxiv:2007.03541', 'arxiv:1909.05858', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:found', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'language_creators:found', 'language_creators:machine-generated', 'language:en', 'language:th', 'license:cc-by-sa-4.0', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: scb-mt-en-th-2020: A Large English-Thai Parallel Corpus\n",
       " The primary objective of our work is to build a large-scale English-Thai dataset for machine translation.\n",
       " We construct an English-Thai machine translation dataset with over 1 million segment pairs, curated from various sources,\n",
       " namely news, Wikipedia articles, SMS messages, task-based dialogs, web-crawled data and government documents.\n",
       " Methodology for gathering data, building parallel texts and removing noisy sentence pairs are presented in a reproducible manner.\n",
       " We train machine translation models based on this dataset. Our models' performance are comparable to that of\n",
       " Google Translation API (as of May 2020) for Thai-English and outperform Google when the Open Parallel Corpus (OPUS) is\n",
       " included in the training data for both Thai-English and English-Thai translation.\n",
       " The dataset, pre-trained models, and source code to reproduce our work are available for public use.\n",
       " \tcitation: @article{lowphansirikul2020scb,\n",
       "   title={scb-mt-en-th-2020: A Large English-Thai Parallel Corpus},\n",
       "   author={Lowphansirikul, Lalita and Polpanumas, Charin and Rutherford, Attapol T and Nutanong, Sarana},\n",
       "   journal={arXiv preprint arXiv:2007.03541},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated', 'found', 'machine-generated'], 'language_creators': ['expert-generated', 'found', 'machine-generated'], 'language': ['en', 'th'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['translation'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'scb-mt-en-th-2020', 'pretty_name': 'ScbMtEnth2020'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 519\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: scb-mt-en-th-2020\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scene_parse_150\n",
       " \tsha: 5f91f592421007cc819f4a98e63748d98af47269\n",
       " \tlastModified: 2022-07-01T11:55:47.000Z\n",
       " \ttags: ['arxiv:1608.05442', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:bsd-3-clause', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|ade20k', 'task_categories:image-segmentation', 'task_ids:instance-segmentation', 'task_ids:other-scene-parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Scene parsing is to segment and parse an image into different image regions associated with semantic categories, such as sky, road, person, and bed.\n",
       " MIT Scene Parsing Benchmark (SceneParse150) provides a standard training and evaluation platform for the algorithms of scene parsing.\n",
       " The data for this benchmark comes from ADE20K Dataset which contains more than 20K scene-centric images exhaustively annotated with objects and object parts.\n",
       " Specifically, the benchmark is divided into 20K images for training, 2K images for validation, and another batch of held-out images for testing.\n",
       " There are totally 150 semantic categories included for evaluation, which include stuffs like sky, road, grass, and discrete objects like person, car, bed.\n",
       " Note that there are non-uniform distribution of objects occuring in the images, mimicking a more natural object occurrence in daily scene.\n",
       " \tcitation: @inproceedings{zhou2017scene,\n",
       "     title={Scene Parsing through ADE20K Dataset},\n",
       "     author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},\n",
       "     booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n",
       "     year={2017}\n",
       " }\n",
       " \n",
       " @article{zhou2016semantic,\n",
       "   title={Semantic understanding of scenes through the ade20k dataset},\n",
       "   author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},\n",
       "   journal={arXiv preprint arXiv:1608.05442},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['bsd-3-clause'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|ade20k'], 'task_categories': ['image-segmentation'], 'task_ids': ['instance-segmentation', 'other-scene-parsing'], 'paperswithcode_id': 'ade20k', 'pretty_name': 'MIT Scene Parsing Benchmark'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1340\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: ade20k\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: schema_guided_dstc8\n",
       " \tsha: f742cdd7689ada81e9d3d1ff146095067ff69965\n",
       " \tlastModified: 2022-07-01T11:55:48.000Z\n",
       " \ttags: ['arxiv:1909.05855', 'arxiv:2002.01359', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:multi-class-classification', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Schema-Guided Dialogue dataset (SGD) was developed for the Dialogue State Tracking task of the Eights Dialogue Systems Technology Challenge (dstc8).\n",
       " The SGD dataset consists of over 18k annotated multi-domain, task-oriented conversations between a human and a virtual assistant.\n",
       " These conversations involve interactions with services and APIs spanning 17 domains, ranging from banks and events to media, calendar, travel, and weather.\n",
       " For most of these domains, the SGD dataset contains multiple different APIs, many of which have overlapping functionalities but different interfaces,\n",
       " which reflects common real-world scenarios.\n",
       " \tcitation: @inproceedings{aaai/RastogiZSGK20,\n",
       "   author    = {Abhinav Rastogi and\n",
       "                Xiaoxue Zang and\n",
       "                Srinivas Sunkara and\n",
       "                Raghav Gupta and\n",
       "                Pranav Khaitan},\n",
       "   title     = {Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided\n",
       "                Dialogue Dataset},\n",
       "   booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}\n",
       "                2020, The Thirty-Second Innovative Applications of Artificial Intelligence\n",
       "                Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational\n",
       "                Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,\n",
       "                February 7-12, 2020},\n",
       "   pages     = {8689--8696},\n",
       "   publisher = {{AAAI} Press},\n",
       "   year      = {2020},\n",
       "   url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6394}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'token-classification', 'text-classification'], 'task_ids': ['dialogue-modeling', 'multi-class-classification', 'parsing'], 'paperswithcode_id': 'sgd', 'pretty_name': 'Schema-Guided Dialogue'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4776\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: sgd\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scicite\n",
       " \tsha: 3779405479daf93149c6082e87b8effb29e3cd98\n",
       " \tlastModified: 2022-09-20T07:38:14.000Z\n",
       " \ttags: ['arxiv:1904.01608', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a dataset for classifying citation intents in academic papers.\n",
       " The main citation intent label for each Json object is specified with the label\n",
       " key while the citation context is specified in with a context key. Example:\n",
       " {\n",
       "  'string': 'In chacma baboons, male-infant relationships can be linked to both\n",
       "     formation of friendships and paternity success [30,31].'\n",
       "  'sectionName': 'Introduction',\n",
       "  'label': 'background',\n",
       "  'citingPaperId': '7a6b2d4b405439',\n",
       "  'citedPaperId': '9d1abadc55b5e0',\n",
       "  ...\n",
       "  }\n",
       " You may obtain the full information about the paper using the provided paper ids\n",
       " with the Semantic Scholar API (https://api.semanticscholar.org/).\n",
       " The labels are:\n",
       " Method, Background, Result\n",
       " \tcitation: @InProceedings{Cohan2019Structural,\n",
       "   author={Arman Cohan and Waleed Ammar and Madeleine Van Zuylen and Field Cady},\n",
       "   title={Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n",
       "   booktitle={NAACL},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'SciCite', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'multi-class-classification'], 'paperswithcode_id': 'scicite'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 649\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: scicite\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scielo\n",
       " \tsha: 27c80d3b39567780ffb22b9fe6ccf0424ff1b060\n",
       " \tlastModified: 2022-07-01T11:55:49.000Z\n",
       " \ttags: ['arxiv:1905.01852', 'annotations_creators:found', 'language_creators:found', 'language:en', 'language:es', 'language:pt', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'configs:en-es', 'configs:en-pt', 'configs:en-pt-es']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of full-text scientific articles collected from Scielo database in the following languages: English, Portuguese and Spanish. The corpus is sentence aligned for all language pairs, as well as trilingual aligned for a small subset of sentences. Alignment was carried out using the Hunalign algorithm.\n",
       " \tcitation: @inproceedings{soares2018large,\n",
       "   title={A Large Parallel Corpus of Full-Text Scientific Articles},\n",
       "   author={Soares, Felipe and Moreira, Viviane and Becker, Karin},\n",
       "   booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018)},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'es', 'pt'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'SciELO', 'configs': ['en-es', 'en-pt', 'en-pt-es']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 635\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scientific_papers\n",
       " \tsha: b9d902534ddabee0b188d3073ed0218508279e62\n",
       " \tlastModified: 2022-09-06T05:39:58.000Z\n",
       " \ttags: ['arxiv:1804.05685', 'annotations_creators:found', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-abstractive-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Scientific papers datasets contains two sets of long and structured documents.\n",
       " The datasets are obtained from ArXiv and PubMed OpenAccess repositories.\n",
       " \n",
       " Both \"arxiv\" and \"pubmed\" have two features:\n",
       "   - article: the body of the document, pagragraphs seperated by \"/n\".\n",
       "   - abstract: the abstract of the document, pagragraphs seperated by \"/n\".\n",
       "   - section_names: titles of sections, seperated by \"/n\".\n",
       " \tcitation: @article{Cohan_2018,\n",
       "    title={A Discourse-Aware Attention Model for Abstractive Summarization of\n",
       "             Long Documents},\n",
       "    url={http://dx.doi.org/10.18653/v1/n18-2097},\n",
       "    DOI={10.18653/v1/n18-2097},\n",
       "    journal={Proceedings of the 2018 Conference of the North American Chapter of\n",
       "           the Association for Computational Linguistics: Human Language\n",
       "           Technologies, Volume 2 (Short Papers)},\n",
       "    publisher={Association for Computational Linguistics},\n",
       "    author={Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},\n",
       "    year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'ScientificPapers', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-abstractive-summarization'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1730\n",
       " \tlikes: 19\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scifact\n",
       " \tsha: 60b87c637ea34107523a9926120411d575d5771e\n",
       " \tlastModified: 2022-10-07T13:42:31.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language:en', 'language_creators:found', 'license:cc-by-nc-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts, and annotated with labels and rationales.\n",
       " \tcitation: @inproceedings{Wadden2020FactOF,\n",
       "   title={Fact or Fiction: Verifying Scientific Claims},\n",
       "   author={David Wadden and Shanchuan Lin and Kyle Lo and Lucy Lu Wang and Madeleine van Zuylen and Arman Cohan and Hannaneh Hajishirzi},\n",
       "   booktitle={EMNLP},\n",
       "   year={2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-nc-2.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'SciFact', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': 'scifact'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 501\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: scifact\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sciq\n",
       " \tsha: ab373ea69f6110e20fbe5fca5f2441caa3715b1f\n",
       " \tlastModified: 2022-08-12T09:46:35.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-nc-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SciQ dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each. For the majority of the questions, an additional paragraph with supporting evidence for the correct answer is provided.\n",
       " \tcitation: @inproceedings{SciQ,\n",
       "     title={Crowdsourcing Multiple Choice Science Questions},\n",
       "     author={Johannes Welbl, Nelson F. Liu, Matt Gardner},\n",
       "     year={2017},\n",
       "     journal={arXiv:1707.06209v1}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-nc-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': 'sciq', 'pretty_name': 'SciQ'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 27975\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: sciq\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scitail\n",
       " \tsha: 732bdf6f105a676aac1ede7b399aca94ce828778\n",
       " \tlastModified: 2022-07-01T11:55:51.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SciTail dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question\n",
       " and the correct answer choice are converted into an assertive statement to form the hypothesis. We use information\n",
       " retrieval to obtain relevant text from a large text corpus of web sentences, and use these sentences as a premise P. We\n",
       " crowdsource the annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order to create\n",
       " the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with entails label and 16,925 examples\n",
       " with neutral label\n",
       " \tcitation: inproceedings{scitail,\n",
       "      Author = {Tushar Khot and Ashish Sabharwal and Peter Clark},\n",
       "      Booktitle = {AAAI},\n",
       "      Title = {{SciTail}: A Textual Entailment Dataset from Science Question Answering},\n",
       "      Year = {2018}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'scitail', 'pretty_name': 'SciTail'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1757\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: scitail\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: scitldr\n",
       " \tsha: ec1bd078988520a9fe2d61e3562ced9dfa43883f\n",
       " \tlastModified: 2022-07-01T11:55:52.000Z\n",
       " \ttags: ['arxiv:2004.15011', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-scientific-documents-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A new multi-target dataset of 5.4K TLDRs over 3.2K papers.\n",
       " SCITLDR contains both author-written and expert-derived TLDRs,\n",
       " where the latter are collected using a novel annotation protocol\n",
       " that produces high-quality summaries while minimizing annotation burden.\n",
       " \tcitation: @article{cachola2020tldr,\n",
       "   title={{TLDR}: Extreme Summarization of Scientific Documents},\n",
       "   author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\n",
       "   journal={arXiv:2004.15011},\n",
       "   year={2020},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-scientific-documents-summarization'], 'paperswithcode_id': 'scitldr', 'pretty_name': 'SciTLDR'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1240\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: scitldr\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: search_qa\n",
       " \tsha: cf6b8fbd8b6c1cd10456c147c7782a53c9eac7bd\n",
       " \tlastModified: 2022-09-06T05:39:59.000Z\n",
       " \ttags: ['arxiv:1704.05179', 'annotations_creators:found', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind\n",
       " CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article\n",
       " and generate a question-answer pair, but start from an existing question-answer pair, crawled from J! Archive, and augment it with text snippets retrieved by Google.\n",
       " Following this approach, we built SearchQA, which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context\n",
       "  tuple of the SearchQA comes with additional meta-data such as the snippet's URL, which we believe will be valuable resources for future research. We conduct human evaluation\n",
       "  as well as test two baseline methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a meaningful gap between the human\n",
       "  and machine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'SearchQA', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'searchqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 668\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: searchqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sede\n",
       " \tsha: 0696690deec0be650b16895d912d3f56dc7a33c8\n",
       " \tlastModified: 2022-07-01T11:55:53.000Z\n",
       " \ttags: ['arxiv:2106.05006', 'arxiv:2005.02539', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SEDE (Stack Exchange Data Explorer) is new dataset for Text-to-SQL tasks with more than 12,000 SQL queries and their\n",
       " natural language description. It's based on a real usage of users from the Stack Exchange Data Explorer platform,\n",
       " which brings complexities and challenges never seen before in any other semantic parsing dataset like\n",
       " including complex nesting, dates manipulation, numeric and text manipulation, parameters, and most\n",
       " importantly: under-specification and hidden-assumptions.\n",
       " \n",
       " Paper (NLP4Prog workshop at ACL2021): https://arxiv.org/abs/2106.05006\n",
       " \tcitation: @misc{hazoom2021texttosql,\n",
       "       title={Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data},\n",
       "       author={Moshe Hazoom and Vibhor Malik and Ben Bogin},\n",
       "       year={2021},\n",
       "       eprint={2106.05006},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'SEDE (Stack Exchange Data Explorer)', 'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'sede', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['parsing']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 386\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: sede\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: selqa\n",
       " \tsha: fffef816273f798de6e61b01175c2f4e5fef7fd7\n",
       " \tlastModified: 2022-07-01T11:55:54.000Z\n",
       " \ttags: ['arxiv:1606.00851', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SelQA dataset provides crowdsourced annotation for two selection-based question answer tasks,\n",
       " answer sentence selection and answer triggering.\n",
       " \tcitation: @InProceedings{7814688,\n",
       "   author={T. {Jurczyk} and M. {Zhai} and J. D. {Choi}},\n",
       "   booktitle={2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)},\n",
       "   title={SelQA: A New Benchmark for Selection-Based Question Answering},\n",
       "   year={2016},\n",
       "   volume={},\n",
       "   number={},\n",
       "   pages={820-827},\n",
       "   doi={10.1109/ICTAI.2016.0128}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'selqa', 'pretty_name': 'SelQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1239\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: selqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sem_eval_2010_task_8\n",
       " \tsha: a98a1d1f03b71ba21ad0f250009c3d2041a0ad58\n",
       " \tlastModified: 2022-07-01T11:55:55.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SemEval-2010 Task 8 focuses on Multi-way classification of semantic relations between pairs of nominals.\n",
       " The task was designed to compare different approaches to semantic relation classification\n",
       " and to provide a standard testbed for future research.\n",
       " \tcitation: @inproceedings{hendrickx-etal-2010-semeval,\n",
       "     title = \"{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals\",\n",
       "     author = \"Hendrickx, Iris  and\n",
       "       Kim, Su Nam  and\n",
       "       Kozareva, Zornitsa  and\n",
       "       Nakov, Preslav  and\n",
       "       {\\'O} S{\\'e}aghdha, Diarmuid  and\n",
       "       Pad{\\'o}, Sebastian  and\n",
       "       Pennacchiotti, Marco  and\n",
       "       Romano, Lorenza  and\n",
       "       Szpakowicz, Stan\",\n",
       "     booktitle = \"Proceedings of the 5th International Workshop on Semantic Evaluation\",\n",
       "     month = jul,\n",
       "     year = \"2010\",\n",
       "     address = \"Uppsala, Sweden\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/S10-1006\",\n",
       "     pages = \"33--38\",\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'semeval-2010-task-8', 'pretty_name': 'SemEval-2010 Task 8', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'sentence': 'text', 'relation': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 719\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: semeval-2010-task-8\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sem_eval_2014_task_1\n",
       " \tsha: 6207de95ae9dc8b0c6237dbfb50bb8524dccec1b\n",
       " \tlastModified: 2022-07-01T11:55:55.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-ImageFlickr and SemEval-2012 STS MSR-Video Descriptions', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:natural-language-inference', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SemEval-2014 Task 1 focuses on Evaluation of Compositional Distributional Semantic Models\n",
       " on Full Sentences through Semantic Relatedness and Entailment. The task was designed to\n",
       " predict the degree of relatedness between two sentences and to detect the entailment\n",
       " relation holding between them.\n",
       " \tcitation: @inproceedings{inproceedings,\n",
       " author = {Marelli, Marco and Bentivogli, Luisa and Baroni, Marco and Bernardi, Raffaella and Menini, Stefano and Zamparelli, Roberto},\n",
       " year = {2014},\n",
       " month = {08},\n",
       " pages = {},\n",
       " title = {SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment},\n",
       " doi = {10.3115/v1/S14-2001}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-ImageFlickr and SemEval-2012 STS MSR-Video Descriptions'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'natural-language-inference', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'SemEval 2014 - Task 1'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 679\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sem_eval_2018_task_1\n",
       " \tsha: 371e0fc109fc22a5210589e96ff9d818db249ef8\n",
       " \tlastModified: 2022-07-27T14:39:04.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ar', 'language:en', 'language:es', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-emotion-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  SemEval-2018 Task 1: Affect in Tweets: SubTask 5: Emotion Classification.\n",
       "  This is a dataset for multilabel emotion classification for tweets.\n",
       "  'Given a tweet, classify it as 'neutral or no emotion' or as one, or more, of eleven given emotions that best represent the mental state of the tweeter.'\n",
       "  It contains 22467 tweets in three languages manually annotated by crowdworkers using Best–Worst Scaling.\n",
       " \tcitation: @InProceedings{SemEval2018Task1,\n",
       "  author = {Mohammad, Saif M. and Bravo-Marquez, Felipe and Salameh, Mohammad and Kiritchenko, Svetlana},\n",
       "  title = {SemEval-2018 {T}ask 1: {A}ffect in Tweets},\n",
       "  booktitle = {Proceedings of International Workshop on Semantic Evaluation (SemEval-2018)},\n",
       "  address = {New Orleans, LA, USA},\n",
       "  year = {2018}}\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ar', 'en', 'es'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'pretty_name': 'SemEval-2018 Task 1: Affect in Tweets', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-emotion-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2229\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sem_eval_2020_task_11\n",
       " \tsha: 43f878980d59484cb10f370d224d24a9616ae094\n",
       " \tlastModified: 2022-07-01T11:55:57.000Z\n",
       " \ttags: ['arxiv:2009.02696', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_categories:token-classification', 'task_ids:text-classification-other-propaganda-technique-classification', 'task_ids:token-classification-other-propaganda-span-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Propagandistic news articles use specific techniques to convey their message,\n",
       " such as whataboutism, red Herring, and name calling, among many others.\n",
       " The Propaganda Techniques Corpus (PTC) allows to study automatic algorithms to\n",
       " detect them. We provide a permanent leaderboard to allow researchers both to\n",
       " advertise their progress and to be up-to-speed with the state of the art on the\n",
       " tasks offered (see below for a definition).\n",
       " \tcitation: @misc{martino2020semeval2020,\n",
       "       title={SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles},\n",
       "       author={G. Da San Martino and A. Barrón-Cedeño and H. Wachsmuth and R. Petrov and P. Nakov},\n",
       "       year={2020},\n",
       "       eprint={2009.02696},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification', 'token-classification'], 'task_ids': ['text-classification-other-propaganda-technique-classification', 'token-classification-other-propaganda-span-identification'], 'paperswithcode_id': None, 'pretty_name': 'SemEval-2020 Task 11'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sent_comp\n",
       " \tsha: 3575a07057c52ec5bad2776b2f60bb713b02600d\n",
       " \tlastModified: 2022-07-01T11:55:57.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-sentence-compression']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large corpus of uncompressed and compressed sentences from news articles.\n",
       " \tcitation: @inproceedings{filippova-altun-2013-overcoming,\n",
       "     title = \"Overcoming the Lack of Parallel Data in Sentence Compression\",\n",
       "     author = \"Filippova, Katja  and\n",
       "       Altun, Yasemin\",\n",
       "     booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct,\n",
       "     year = \"2013\",\n",
       "     address = \"Seattle, Washington, USA\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D13-1155\",\n",
       "     pages = \"1481--1491\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-sentence-compression'], 'paperswithcode_id': 'sentence-compression', 'pretty_name': 'Google Sentence Compression'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 573\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: sentence-compression\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: senti_lex\n",
       " \tsha: b4b1500498766eb4789d736d6a009b65c7112ca9\n",
       " \tlastModified: 2022-07-01T11:55:58.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:af', 'language:an', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:cs', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gu', 'language:he', 'language:hi', 'language:hr', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mk', 'language:mr', 'language:ms', 'language:mt', 'language:nl', 'language:nn', 'language:no', 'language:pl', 'language:pt', 'language:rm', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:wa', 'language:yi', 'language:zh', 'language:zhw', 'license:gpl-3.0', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'configs:no', 'configs:af', 'configs:an', 'configs:ar', 'configs:az', 'configs:be', 'configs:bg', 'configs:bn', 'configs:br', 'configs:bs', 'configs:ca', 'configs:cs', 'configs:cy', 'configs:da', 'configs:de', 'configs:el', 'configs:eo', 'configs:es', 'configs:et', 'configs:eu', 'configs:fa', 'configs:fi', 'configs:fo', 'configs:fr', 'configs:fy', 'configs:ga', 'configs:gd', 'configs:gl', 'configs:gu', 'configs:he', 'configs:hi', 'configs:hr', 'configs:ht', 'configs:hu', 'configs:hy', 'configs:ia', 'configs:id', 'configs:io', 'configs:is', 'configs:it', 'configs:ja', 'configs:ka', 'configs:km', 'configs:kn', 'configs:ko', 'configs:ku', 'configs:ky', 'configs:la', 'configs:lb', 'configs:lt', 'configs:lv', 'configs:mk', 'configs:mr', 'configs:ms', 'configs:mt', 'configs:nl', 'configs:nn', 'configs:pl', 'configs:pt', 'configs:rm', 'configs:ro', 'configs:ru', 'configs:sk', 'configs:sl', 'configs:sq', 'configs:sr', 'configs:sv', 'configs:sw', 'configs:ta', 'configs:te', 'configs:th', 'configs:tk', 'configs:tl', 'configs:tr', 'configs:uk', 'configs:ur', 'configs:uz', 'configs:vi', 'configs:vo', 'configs:wa', 'configs:yi', 'configs:zh', 'configs:zhw']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset add sentiment lexicons for 81 languages generated via graph propagation based on a knowledge graph--a graphical representation of real-world entities and the links between them.\n",
       " \tcitation: @inproceedings{inproceedings,\n",
       " author = {Chen, Yanqing and Skiena, Steven},\n",
       " year = {2014},\n",
       " month = {06},\n",
       " pages = {383-389},\n",
       " title = {Building Sentiment Lexicons for All Major Languages},\n",
       " volume = {2},\n",
       " journal = {52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014 - Proceedings of the Conference},\n",
       " doi = {10.3115/v1/P14-2063}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['af', 'an', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'ia', 'id', 'io', 'is', 'it', 'ja', 'ka', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lt', 'lv', 'mk', 'mr', 'ms', 'mt', 'nl', 'nn', 'no', 'pl', 'pt', 'rm', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'wa', 'yi', 'zh', 'zhw'], 'license': ['gpl-3.0'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'SentiWS', 'configs': ['no', 'af', 'an', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gu', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'ia', 'id', 'io', 'is', 'it', 'ja', 'ka', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lt', 'lv', 'mk', 'mr', 'ms', 'mt', 'nl', 'nn', 'pl', 'pt', 'rm', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'uk', 'ur', 'uz', 'vi', 'vo', 'wa', 'yi', 'zh', 'zhw']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 12973\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: senti_ws\n",
       " \tsha: 48005606e44c36385c8fa95c854d900775af68fe\n",
       " \tlastModified: 2022-07-19T12:42:03.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language:de', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:sentiment-scoring', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, and pos-tagging. The POS tags are [\"NN\", \"VVINF\", \"ADJX\", \"ADV\"] -> [\"noun\", \"verb\", \"adjective\", \"adverb\"], and positive and negative polarity bearing words are weighted within the interval of [-1, 1].\n",
       " \tcitation: @INPROCEEDINGS{remquahey2010,\n",
       " title = {SentiWS -- a Publicly Available German-language Resource for Sentiment Analysis},\n",
       " booktitle = {Proceedings of the 7th International Language Resources and Evaluation (LREC'10)},\n",
       " author = {Remus, R. and Quasthoff, U. and Heyer, G.},\n",
       " year = {2010}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['found'], 'language': ['de'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification', 'text-classification'], 'task_ids': ['text-scoring', 'sentiment-scoring', 'part-of-speech'], 'paperswithcode_id': None, 'pretty_name': 'SentiWS'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 478\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sentiment140\n",
       " \tsha: 039960a63c634983e62dd04dbb529540268bc194\n",
       " \tlastModified: 2022-07-01T11:55:59.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Sentiment140 consists of Twitter messages with emoticons, which are used as noisy labels for\n",
       " sentiment classification. For more detailed information please refer to the paper.\n",
       " \tcitation: @article{go2009twitter,\n",
       "   title={Twitter sentiment classification using distant supervision},\n",
       "   author={Go, Alec and Bhayani, Richa and Huang, Lei},\n",
       "   journal={CS224N project report, Stanford},\n",
       "   volume={1},\n",
       "   number={12},\n",
       "   pages={2009},\n",
       "   year={2009}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'sentiment140', 'pretty_name': 'Sentiment140', 'train-eval-index': [{'config': 'sentiment140', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'sentiment': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 793\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: sentiment140\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sepedi_ner\n",
       " \tsha: 58dd8df4259a7f64807c1e757ce6027beb5af98c\n",
       " \tlastModified: 2022-07-01T12:43:42.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:nso', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{sepedi_ner,\n",
       "   author    = {D.J. Prinsloo and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT Sepedi Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/328},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['nso'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Sepedi NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sesotho_ner_corpus\n",
       " \tsha: 50eb550ad82e4701675ccd24f5142176e50017b3\n",
       " \tlastModified: 2022-07-01T12:43:42.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:st', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{sesotho_ner_corpus,\n",
       "   author    = {M. Setaka and\n",
       "                 Roald Eiselen},\n",
       "   title     = {NCHLT Sesotho Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/334},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['st'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Sesotho NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: setimes\n",
       " \tsha: bd3dc6a205d2880ab4607260a75011e75a6bea2a\n",
       " \tlastModified: 2022-08-11T12:57:34.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:bs', 'language:el', 'language:en', 'language:hr', 'language:mk', 'language:ro', 'language:sq', 'language:sr', 'language:tr', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SETimes – A Parallel Corpus of English and South-East European Languages\n",
       " The corpus is based on the content published on the SETimes.com news portal. The news portal publishes “news and views from Southeast Europe” in ten languages: Bulgarian, Bosnian, Greek, English, Croatian, Macedonian, Romanian, Albanian and Serbian. This version of the corpus tries to solve the issues present in an older version of the corpus (published inside OPUS, described in the LREC 2010 paper by Francis M. Tyers and Murat Serdar Alperen). The following procedures were applied to resolve existing issues:\n",
       " \n",
       " - stricter extraction process – no HTML residues present\n",
       " - language identification on every non-English document – non-English online documents contain English material in case the article was not translated into that language\n",
       " - resolving encoding issues in Croatian and Serbian – diacritics were partially lost due to encoding errors – text was rediacritized.\n",
       " \tcitation: None\n",
       " \tcardData: {'pretty_name': 'SETimes – A Parallel Corpus of English and South-East European Languages', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'bs', 'el', 'en', 'hr', 'mk', 'ro', 'sq', 'sr', 'tr'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7126\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: setswana_ner_corpus\n",
       " \tsha: 071ab5502f233389d859385d6914ae1f220fa30d\n",
       " \tlastModified: 2022-07-01T12:43:42.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:tn', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{sepedi_ner_corpus,\n",
       "   author    = {S.S.B.M. Phakedi and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT Setswana Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/341},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['tn'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Setswana NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 320\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sharc\n",
       " \tsha: cce230d2dd6011a39931bd223f7cd8a29c9ee021\n",
       " \tlastModified: 2022-08-11T12:57:34.000Z\n",
       " \ttags: ['arxiv:1809.01494', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-conversational-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ShARC is a Conversational Question Answering dataset focussing on question answering from texts containing rules. The goal is to answer questions by possibly asking follow-up questions first. It is assumed assume that the question is often underspecified, in the sense that the question does not provide enough information to be answered directly. However, an agent can use the supporting rule text to infer what needs to be asked in order to determine the final answer.\n",
       " \tcitation: @misc{saeidi2018interpretation,\n",
       "       title={Interpretation of Natural Language Rules in Conversational Machine Reading},\n",
       "       author={Marzieh Saeidi and Max Bartolo and Patrick Lewis and Sameer Singh and Tim Rocktäschel and Mike Sheldon and Guillaume Bouchard and Sebastian Riedel},\n",
       "       year={2018},\n",
       "       eprint={1809.01494},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-conversational-qa'], 'paperswithcode_id': 'sharc', 'pretty_name': 'Shaping Answers with Rules through Conversation'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 321\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: sharc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sharc_modified\n",
       " \tsha: 3830efe0dacbce34f1357690db10bbc0027da0c4\n",
       " \tlastModified: 2022-07-01T11:56:02.000Z\n",
       " \ttags: ['arxiv:1909.03759', 'arxiv:2009.06354', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|sharc', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-conversational-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ShARC, a conversational QA task, requires a system to answer user questions based on rules expressed in natural language text. However, it is found that in the ShARC dataset there are multiple spurious patterns that could be exploited by neural models. SharcModified is a new dataset which reduces the patterns identified in the original dataset. To reduce the sensitivity of neural models, for each occurence of an instance conforming to any of the patterns, we automatically construct alternatives where we choose to either replace the current instance with an alternative instance which does not exhibit the pattern; or retain the original instance. The modified ShARC has two versions sharc-mod and history-shuffled. For morre details refer to Appendix A.3 .\n",
       " \tcitation: @inproceedings{verma-etal-2020-neural,\n",
       "     title = \"Neural Conversational {QA}: Learning to Reason vs Exploiting Patterns\",\n",
       "     author = \"Verma, Nikhil  and\n",
       "       Sharma, Abhishek  and\n",
       "       Madan, Dhiraj  and\n",
       "       Contractor, Danish  and\n",
       "       Kumar, Harshit  and\n",
       "       Joshi, Sachindra\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.589\",\n",
       "     pages = \"7263--7269\",\n",
       "     abstract = \"Neural Conversational QA tasks such as ShARC require systems to answer questions based on the contents of a given passage. On studying recent state-of-the-art models on the ShARC QA task, we found indications that the model(s) learn spurious clues/patterns in the data-set. Further, a heuristic-based program, built to exploit these patterns, had comparative performance to that of the neural models. In this paper we share our findings about the four types of patterns in the ShARC corpus and how the neural models exploit them. Motivated by the above findings, we create and share a modified data-set that has fewer spurious patterns than the original data-set, consequently allowing models to learn better.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|sharc'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-conversational-qa'], 'paperswithcode_id': None, 'pretty_name': 'SharcModified'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 784\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sick\n",
       " \tsha: b1794e0a4b5ba0f11be4a79d1d43a316b54394c0\n",
       " \tlastModified: 2022-07-01T11:56:03.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|image-flickr-8k', 'source_datasets:extended|semeval2012-sts-msr-video', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Shared and internationally recognized benchmarks are fundamental for the development of any computational system.\n",
       " We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them.\n",
       " SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs.\n",
       " By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral).\n",
       " The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes.\n",
       " \tcitation: @inproceedings{marelli-etal-2014-sick,\n",
       "     title = \"A {SICK} cure for the evaluation of compositional distributional semantic models\",\n",
       "     author = \"Marelli, Marco  and\n",
       "       Menini, Stefano  and\n",
       "       Baroni, Marco  and\n",
       "       Bentivogli, Luisa  and\n",
       "       Bernardi, Raffaella  and\n",
       "       Zamparelli, Roberto\",\n",
       "     booktitle = \"Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)\",\n",
       "     month = may,\n",
       "     year = \"2014\",\n",
       "     address = \"Reykjavik, Iceland\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf\",\n",
       "     pages = \"216--223\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|image-flickr-8k', 'extended|semeval2012-sts-msr-video'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'sick', 'pretty_name': 'Sentences Involving Compositional Knowledge'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4313\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: sick\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: silicone\n",
       " \tsha: 315c1940e95f44e0c1ab1cb0d53e0817e58494b1\n",
       " \tlastModified: 2022-07-01T11:56:04.000Z\n",
       " \ttags: ['arxiv:2009.11152', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:sentiment-classification', 'task_ids:text-classification-other-dialogue-act-classification', 'task_ids:text-classification-other-emotion-classification', 'task_ids:text-scoring', 'configs:dyda_da', 'configs:dyda_e', 'configs:iemocap', 'configs:maptask', 'configs:meld_e', 'configs:meld_s', 'configs:mrda', 'configs:oasis', 'configs:sem', 'configs:swda']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection\n",
       "  of resources for training, evaluating, and analyzing natural language understanding systems\n",
       "  specifically designed for spoken language. All datasets are in the English language and cover a\n",
       "  variety of domains including daily life, scripted scenarios, joint task completion, phone call\n",
       "  conversations, and televsion dialogue. Some datasets additionally include emotion and/or sentimant\n",
       "  labels.\n",
       " \tcitation: @inproceedings{chapuis-etal-2020-hierarchical,\n",
       "     title = \"Hierarchical Pre-training for Sequence Labelling in Spoken Dialog\",\n",
       "     author = \"Chapuis, Emile  and\n",
       "       Colombo, Pierre  and\n",
       "       Manica, Matteo  and\n",
       "       Labeau, Matthieu  and\n",
       "       Clavel, Chlo{\\'e}\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.239\",\n",
       "     doi = \"10.18653/v1/2020.findings-emnlp.239\",\n",
       "     pages = \"2636--2648\",\n",
       "     abstract = \"Sequence labelling tasks like Dialog Act and Emotion/Sentiment identification are a\n",
       "         key component of spoken dialog systems. In this work, we propose a new approach to learn\n",
       "         generic representations adapted to spoken dialog, which we evaluate on a new benchmark we\n",
       "         call Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE benchmark (SILICONE).\n",
       "         SILICONE is model-agnostic and contains 10 different datasets of various sizes.\n",
       "         We obtain our representations with a hierarchical encoder based on transformer architectures,\n",
       "         for which we extend two well-known pre-training objectives. Pre-training is performed on\n",
       "         OpenSubtitles: a large corpus of spoken dialog containing over 2.3 billion of tokens. We\n",
       "         demonstrate how hierarchical encoders achieve competitive results with consistently fewer\n",
       "         parameters compared to state-of-the-art models and we show their importance for both\n",
       "         pre-training and fine-tuning.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['dialogue-modeling', 'language-modeling', 'masked-language-modeling', 'sentiment-classification', 'text-classification-other-dialogue-act-classification', 'text-classification-other-emotion-classification', 'text-scoring'], 'paperswithcode_id': None, 'pretty_name': 'SILICONE Benchmark', 'configs': ['dyda_da', 'dyda_e', 'iemocap', 'maptask', 'meld_e', 'meld_s', 'mrda', 'oasis', 'sem', 'swda']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1921\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: simple_questions_v2\n",
       " \tsha: e6dbd486e8070b01eaca9ff0d13814ee60a9d81a\n",
       " \tlastModified: 2022-07-01T12:43:43.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SimpleQuestions is a dataset for simple QA, which consists\n",
       " of a total of 108,442 questions written in natural language by human\n",
       " English-speaking annotators each paired with a corresponding fact,\n",
       " formatted as (subject, relationship, object), that provides the answer\n",
       " but also a complete explanation.  Fast have been extracted from the\n",
       " Knowledge Base Freebase (freebase.com).  We randomly shuffle these\n",
       " questions and use 70% of them (75910) as training set, 10% as\n",
       " validation set (10845), and the remaining 20% as test set.\n",
       " \tcitation: @misc{bordes2015largescale,\n",
       "       title={Large-scale Simple Question Answering with Memory Networks},\n",
       "       author={Antoine Bordes and Nicolas Usunier and Sumit Chopra and Jason Weston},\n",
       "       year={2015},\n",
       "       eprint={1506.02075},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.LG}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'simplequestions', 'pretty_name': 'SimpleQuestions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 634\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: simplequestions\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: siswati_ner_corpus\n",
       " \tsha: 5c2cfe37d16d6f71ba6665aae20bf20e091fb883\n",
       " \tlastModified: 2022-07-01T12:43:44.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:ss', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.\n",
       " \tcitation: @inproceedings{siswati_ner_corpus,\n",
       "   author    = {B.B. Malangwane and\n",
       "                M.N. Kekana and\n",
       "                S.S. Sedibe and\n",
       "                B.C. Ndhlovu and\n",
       "               Roald Eiselen},\n",
       "   title     = {NCHLT Siswati Named Entity Annotated Corpus},\n",
       "   booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portorož, Slovenia.},\n",
       "   year      = {2016},\n",
       "   url       = {https://repo.sadilar.org/handle/20.500.12185/346},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ss'], 'license': ['other'], 'license_details': 'Creative Commons Attribution 2.5 South Africa License', 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Siswati NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 318\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: smartdata\n",
       " \tsha: 659c5f44ddf089e57da727d9cf84f3582680a588\n",
       " \tlastModified: 2022-07-01T11:56:06.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:de', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: DFKI SmartData Corpus is a dataset of 2598 German-language documents\n",
       " which has been annotated with fine-grained geo-entities, such as streets,\n",
       " stops and routes, as well as standard named entity types. It has also\n",
       " been annotated with a set of 15 traffic- and industry-related n-ary\n",
       " relations and events, such as Accidents, Traffic jams, Acquisitions,\n",
       " and Strikes. The corpus consists of newswire texts, Twitter messages,\n",
       " and traffic reports from radio stations, police and railway companies.\n",
       " It allows for training and evaluating both named entity recognition\n",
       " algorithms that aim for fine-grained typing of geo-entities, as well\n",
       " as n-ary relation extraction systems.\n",
       " \tcitation: @InProceedings{SCHIERSCH18.85,\n",
       "   author = {Martin Schiersch and Veselina Mironova and Maximilian Schmitt and Philippe Thomas and Aleksandra Gabryszak and Leonhard Hennig},\n",
       "   title = \"{A German Corpus for Fine-Grained Named Entity Recognition and Relation Extraction of Traffic and Industry Events}\",\n",
       "   booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n",
       "   year = {2018},\n",
       "   month = {May 7-12, 2018},\n",
       "   address = {Miyazaki, Japan},\n",
       "   editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and Hélène Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {979-10-95546-00-9},\n",
       "   language = {english}\n",
       "   }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['de'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'SmartData'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sms_spam\n",
       " \tsha: 497f2eb74a6316b9fa04477574abb31ecf800d50\n",
       " \tlastModified: 2022-07-01T11:56:06.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:found', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-nus-sms-corpus', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SMS Spam Collection v.1 is a public set of SMS labeled messages that have been collected for mobile phone spam research.\n",
       " It has one collection composed by 5,574 English, real and non-enconded messages, tagged according being legitimate (ham) or spam.\n",
       " \tcitation: @inproceedings{Almeida2011SpamFiltering,\n",
       "   title={Contributions to the Study of SMS Spam Filtering: New Collection and Results},\n",
       "   author={Tiago A. Almeida and Jose Maria Gomez Hidalgo and Akebo Yamakami},\n",
       "   year={2011},\n",
       "   booktitle = \"Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11)\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'found'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-nus-sms-corpus'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': 'sms-spam-collection-data-set', 'pretty_name': 'SMS Spam Collection Data Set', 'train-eval-index': [{'config': 'plain_text', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train'}, 'col_mapping': {'sms': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3775\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: sms-spam-collection-data-set\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: snips_built_in_intents\n",
       " \tsha: 158eed35ce43e62acfae4ed7a9cc059b65026d00\n",
       " \tlastModified: 2022-07-01T11:56:06.000Z\n",
       " \ttags: ['arxiv:1805.10190', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Snips' built in intents dataset was initially used to compare different voice assistants and released as a public dataset hosted at\n",
       " https://github.com/sonos/nlu-benchmark 2016-12-built-in-intents. The dataset contains 328 utterances over 10 intent classes. The\n",
       " related paper mentioned on the github page is https://arxiv.org/abs/1805.10190 and a related Medium post is\n",
       " https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d .\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1805-10190,\n",
       "   author    = {Alice Coucke and\n",
       "                Alaa Saade and\n",
       "                Adrien Ball and\n",
       "                Th{\\'{e}}odore Bluche and\n",
       "                Alexandre Caulier and\n",
       "                David Leroy and\n",
       "                Cl{\\'{e}}ment Doumouro and\n",
       "                Thibault Gisselbrecht and\n",
       "                Francesco Caltagirone and\n",
       "                Thibaut Lavril and\n",
       "                Ma{\\\"{e}}l Primet and\n",
       "                Joseph Dureau},\n",
       "   title     = {Snips Voice Platform: an embedded Spoken Language Understanding system\n",
       "                for private-by-design voice interfaces},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1805.10190},\n",
       "   year      = {2018},\n",
       "   url       = {http://arxiv.org/abs/1805.10190},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1805.10190},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:46:59 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-1805-10190.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification'], 'paperswithcode_id': 'snips', 'pretty_name': 'SNIPS Natural Language Understanding benchmark', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': None, 'train_split': 'train', 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1468\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: snips\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: snli\n",
       " \tsha: 3089f17891dc1b0d0f225c1e9c11dee3ead97be9\n",
       " \tlastModified: 2022-07-01T11:56:08.000Z\n",
       " \ttags: ['arxiv:1909.02209', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-flicker-30k', 'source_datasets:extended|other-visual-genome', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:multi-input-text-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SNLI corpus (version 1.0) is a collection of 570k human-written English\n",
       " sentence pairs manually labeled for balanced classification with the labels\n",
       " entailment, contradiction, and neutral, supporting the task of natural language\n",
       " inference (NLI), also known as recognizing textual entailment (RTE).\n",
       " \tcitation: @inproceedings{snli:emnlp2015,\n",
       "     Author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\n",
       "     Booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n",
       "     Publisher = {Association for Computational Linguistics},\n",
       "     Title = {A large annotated corpus for learning natural language inference},\n",
       "     Year = {2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-flicker-30k', 'extended|other-visual-genome'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'multi-input-text-classification'], 'paperswithcode_id': 'snli', 'pretty_name': 'Stanford Natural Language Inference'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7975\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: snli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: snow_simplified_japanese_corpus\n",
       " \tsha: 67559d3eca394f4c7d0ad96f8f02be59fa183b1f\n",
       " \tlastModified: 2022-07-01T11:56:08.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'annotations_creators:other', 'language_creators:found', 'language:en', 'language:ja', 'license:cc-by-4.0', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: About SNOW T15: The simplified corpus for the Japanese language. The corpus has 50,000 manually simplified and aligned sentences. This corpus contains the original sentences, simplified sentences and English translation of the original sentences. It can be used for automatic text simplification as well as translating simple Japanese into English and vice-versa. The core vocabulary is restricted to 2,000 words where it is selected by accounting for several factors such as meaning preservation, variation, simplicity and the UniDic word segmentation criterion.\n",
       " For details, refer to the explanation page of Japanese simplification (http://www.jnlp.org/research/Japanese_simplification). The original texts are from \"small_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods\", which is a bilingual corpus for machine translation. About SNOW T23: An expansion corpus of 35,000 sentences rewritten in easy Japanese (simple Japanese vocabulary) based on SNOW T15. The original texts are from \"Tanaka Corpus\" (http://www.edrdg.org/wiki/index.php/Tanaka_Corpus).\n",
       " \tcitation: @inproceedings{maruyama-yamamoto-2018-simplified,\n",
       "     title = \"Simplified Corpus with Core Vocabulary\",\n",
       "     author = \"Maruyama, Takumi  and\n",
       "       Yamamoto, Kazuhide\",\n",
       "     booktitle = \"Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)\",\n",
       "     month = may,\n",
       "     year = \"2018\",\n",
       "     address = \"Miyazaki, Japan\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"https://www.aclweb.org/anthology/L18-1185\",\n",
       " }\n",
       " \n",
       " @inproceedings{yamamoto-2017-simplified-japanese,\n",
       "     title = \"やさしい⽇本語対訳コーパスの構築\",\n",
       "     author = \"⼭本 和英  and\n",
       "       丸⼭ 拓海  and\n",
       "       ⾓張 ⻯晴  and\n",
       "       稲岡 夢⼈  and\n",
       "       ⼩川 耀⼀朗  and\n",
       "       勝⽥ 哲弘  and\n",
       "       髙橋 寛治\",\n",
       "     booktitle = \"言語処理学会第23回年次大会\",\n",
       "     month = 3月,\n",
       "     year = \"2017\",\n",
       "     address = \"茨城, 日本\",\n",
       "     publisher = \"言語処理学会\",\n",
       "     url = \"https://www.anlp.jp/proceedings/annual_meeting/2017/pdf_dir/B5-1.pdf\",\n",
       " }\n",
       " \n",
       " @inproceedings{katsuta-yamamoto-2018-crowdsourced,\n",
       "     title = \"Crowdsourced Corpus of Sentence Simplification with Core Vocabulary\",\n",
       "     author = \"Katsuta, Akihiro  and\n",
       "       Yamamoto, Kazuhide\",\n",
       "     booktitle = \"Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)\",\n",
       "     month = may,\n",
       "     year = \"2018\",\n",
       "     address = \"Miyazaki, Japan\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"https://www.aclweb.org/anthology/L18-1072\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'other'], 'language_creators': ['found'], 'language': ['en', 'ja'], 'license': ['cc-by-4.0'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'SNOW T15 and T23 (simplified Japanese corpus)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 489\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: so_stacksample\n",
       " \tsha: dcaa288c049c850d9ec7b2d4292887c2abef2de5\n",
       " \tlastModified: 2022-07-01T11:56:09.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:abstractive-qa', 'task_ids:open-domain-abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset with the text of 10% of questions and answers from the Stack Overflow programming Q&A website.\n",
       " \n",
       " This is organized as three tables:\n",
       " \n",
       " Questions contains the title, body, creation date, closed date (if applicable), score, and owner ID for all non-deleted Stack Overflow questions whose Id is a multiple of 10.\n",
       " Answers contains the body, creation date, score, and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table.\n",
       " Tags contains the tags on each of these questions.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['abstractive-qa', 'open-domain-abstractive-qa'], 'paperswithcode_id': None, 'pretty_name': 'SO StackSample'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 627\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: social_bias_frames\n",
       " \tsha: a1d7a07042f156a6b8a0cfdbc1ad70a542c04a48\n",
       " \tlastModified: 2022-07-01T11:56:09.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-classification', 'task_ids:text2text-generation-other-explanation-generation', 'task_ids:hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Social Bias Frames is a new way of representing the biases and offensiveness that are implied in language.\n",
       " For example, these frames are meant to distill the implication that \"women (candidates) are less qualified\"\n",
       " behind the statement \"we shouldn’t lower our standards to hire more women.\"\n",
       " \tcitation: @inproceedings{sap2020socialbiasframes,\n",
       "    title={Social Bias Frames: Reasoning about Social and Power Implications of Language},\n",
       "    author={Sap, Maarten and Gabriel, Saadia and Qin, Lianhui and Jurafsky, Dan and Smith, Noah A and Choi, Yejin},\n",
       "    year={2020},\n",
       "    booktitle={ACL},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Social Bias Frames', 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-classification'], 'task_ids': ['text2text-generation-other-explanation-generation', 'hate-speech-detection'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 391\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: social_i_qa\n",
       " \tsha: bb26d786a03692ab5d8838652185fded6f905673\n",
       " \tlastModified: 2022-07-01T11:56:10.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We introduce Social IQa: Social Interaction QA, a new question-answering benchmark for testing social commonsense intelligence. Contrary to many prior benchmarks that focus on physical or taxonomic knowledge, Social IQa focuses on reasoning about people’s actions and their social implications. For example, given an action like \"Jesse saw a concert\" and a question like \"Why did Jesse do this?\", humans can easily infer that Jesse wanted \"to see their favorite performer\" or \"to enjoy the music\", and not \"to see what's happening inside\" or \"to see if it works\". The actions in Social IQa span a wide variety of social situations, and answer candidates contain both human-curated answers and adversarially-filtered machine-generated candidates. Social IQa contains over 37,000 QA pairs for evaluating models’ abilities to reason about the social implications of everyday events and situations. (Less)\n",
       " \tcitation: \n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'social-iqa', 'pretty_name': 'Social Interaction QA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 23660\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: social-iqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sofc_materials_articles\n",
       " \tsha: 72f333dfcb5b2b9a9f8ceab9c5e30d22bfc5569c\n",
       " \tlastModified: 2022-08-11T12:57:34.000Z\n",
       " \ttags: ['arxiv:2006.03039', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:named-entity-recognition', 'task_ids:slot-filling', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The SOFC-Exp corpus consists of 45 open-access scholarly articles annotated by domain experts.\n",
       " A corpus and an inter-annotator agreement study demonstrate the complexity of the suggested\n",
       " named entity recognition and slot filling tasks as well as high annotation quality is presented\n",
       " in the accompanying paper.\n",
       " \tcitation: @misc{friedrich2020sofcexp,\n",
       "       title={The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain},\n",
       "       author={Annemarie Friedrich and Heike Adel and Federico Tomazic and Johannes Hingerl and Renou Benteau and Anika Maruscyk and Lukas Lange},\n",
       "       year={2020},\n",
       "       eprint={2006.03039},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'token-classification', 'text-classification'], 'task_ids': ['named-entity-recognition', 'slot-filling', 'topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'SofcMaterialsArticles'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sogou_news\n",
       " \tsha: 737c2ae1394cdde0c1e3bcdbf0a937ffc665272e\n",
       " \tlastModified: 2022-05-04T18:34:57.000Z\n",
       " \ttags: ['arxiv:1509.01626']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Sogou News dataset is a mixture of 2,909,551 news articles from the SogouCA and SogouCS news corpora, in 5 categories.\n",
       " The number of training samples selected for each class is 90,000 and testing 12,000. Note that the Chinese characters have been converted to Pinyin.\n",
       " classification labels of the news are determined by their domain names in the URL. For example, the news with\n",
       " URL http://sports.sohu.com is categorized as a sport class.\n",
       " \tcitation: @misc{zhang2015characterlevel,\n",
       "     title={Character-level Convolutional Networks for Text Classification},\n",
       "     author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n",
       "     year={2015},\n",
       "     eprint={1509.01626},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.LG}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Sogou News', 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: spanish_billion_words\n",
       " \tsha: 22d6dde55f686cb007bd1d7f48d1d00675cbef66\n",
       " \tlastModified: 2022-07-01T11:56:11.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:es', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:other-other-pretraining-language-models']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An unannotated Spanish corpus of nearly 1.5 billion words, compiled from different resources from the web.\n",
       " This resources include the spanish portions of SenSem, the Ancora Corpus, some OPUS Project Corpora and the Europarl,\n",
       " the Tibidabo Treebank, the IULA Spanish LSP Treebank, and dumps from the Spanish Wikipedia, Wikisource and Wikibooks.\n",
       " This corpus is a compilation of 100 text files. Each line of these files represents one of the 50 million sentences from the corpus.\n",
       " \tcitation: @misc{cardellinoSBWCE,\n",
       "      author = {Cardellino, Cristian},\n",
       "      title = {Spanish {B}illion {W}ords {C}orpus and {E}mbeddings},\n",
       "      url = {https://crscardellino.github.io/SBWCE/},\n",
       "      month = {August},\n",
       "      year = {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['es'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'other-other-pretraining-language-models'], 'paperswithcode_id': 'sbwce', 'pretty_name': 'Spanish Billion Word Corpus and Embeddings'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: sbwce\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: spc\n",
       " \tsha: b9c9e39deaefaab2892d7d94674a30a801e81e51\n",
       " \tlastModified: 2022-08-11T12:57:35.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:af', 'language:el', 'language:en', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:af-en', 'configs:el-en', 'configs:en-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of parallel corpora collected by Hercules Dalianis and his research group for bilingual dictionary construction.\n",
       " More information in: Hercules Dalianis, Hao-chun Xing, Xin Zhang: Creating a Reusable English-Chinese Parallel Corpus for Bilingual Dictionary Construction, In Proceedings of LREC2010 (source: http://people.dsv.su.se/~hercules/SEC/) and Konstantinos Charitakis (2007): Using Parallel Corpora to Create a Greek-English Dictionary with UPLUG, In Proceedings of NODALIDA 2007. Afrikaans-English: Aldin Draghoender and Mattias Kanhov: Creating a reusable English – Afrikaans parallel corpora for bilingual dictionary construction\n",
       " \n",
       " 4 languages, 3 bitexts\n",
       " total number of files: 6\n",
       " total number of tokens: 1.32M\n",
       " total number of sentence fragments: 0.15M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'el', 'en', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'spc', 'configs': ['af-en', 'el-en', 'en-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 634\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: species_800\n",
       " \tsha: 6dbaa7e6e44b2dcfa136d2b1f0ebb8387f145d1d\n",
       " \tlastModified: 2022-07-01T11:56:12.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: We have developed an efficient algorithm and implementation of a dictionary-based approach to named entity recognition,\n",
       " which we here use to identifynames of species and other taxa in text. The tool, SPECIES, is more than an order of\n",
       " magnitude faster and as accurate as existing tools. The precision and recall was assessed both on an existing gold-standard\n",
       " corpus and on a new corpus of 800 abstracts, which were manually annotated after the development of the tool. The corpus\n",
       " comprises abstracts from journals selected to represent many taxonomic groups, which gives insights into which types of\n",
       " organism names are hard to detect and which are easy. Finally, we have tagged organism names in the entire Medline database\n",
       " and developed a web resource, ORGANISMS, that makes the results accessible to the broad community of biologists.\n",
       " \tcitation: @article{pafilis2013species,\n",
       "          title={The SPECIES and ORGANISMS resources for fast and accurate identification of taxonomic names in text},\n",
       "          author={Pafilis, Evangelos and Frankild, Sune P and Fanini, Lucia and Faulwetter, Sarah and Pavloudi, Christina and Vasileiadou, Aikaterini and Arvanitidis, Christos and Jensen, Lars Juhl},\n",
       "          journal={PloS one},\n",
       "          volume={8},\n",
       "          number={6},\n",
       "          pages={e65390},\n",
       "          year={2013},\n",
       "          publisher={Public Library of Science}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'species800'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 605\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: speech_commands\n",
       " \tsha: bceaa805b036f8bb47545c58443227b87eea60ee\n",
       " \tlastModified: 2022-08-12T04:27:55.000Z\n",
       " \ttags: ['arxiv:1804.03209', 'annotations_creators:other', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:audio-classification', 'task_ids:keyword-spotting', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'configs:v0.01', 'configs:v0.02']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a set of one-second .wav audio files, each containing a single spoken\n",
       " English word or background noise. These words are from a small set of commands, and are spoken by a\n",
       " variety of different speakers. This data set is designed to help train simple\n",
       " machine learning models. This dataset is covered in more detail at\n",
       " [https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n",
       " \n",
       " Version 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n",
       " 64,727 audio files.\n",
       " \n",
       " In version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
       " \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n",
       " \"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n",
       " \n",
       " \n",
       " In version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n",
       " \n",
       " In both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
       " \"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\n",
       " it is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\n",
       " from unrecognized ones.\n",
       " \n",
       " The `_silence_` class contains a set of longer audio clips that are either recordings or\n",
       " a mathematical simulation of noise.\n",
       " \tcitation: @article{speechcommandsv2,\n",
       "    author = { {Warden}, P.},\n",
       "     title = \"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}\",\n",
       "   journal = {ArXiv e-prints},\n",
       "   archivePrefix = \"arXiv\",\n",
       "   eprint = {1804.03209},\n",
       "   primaryClass = \"cs.CL\",\n",
       "   keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n",
       "     year = 2018,\n",
       "     month = apr,\n",
       "     url = {https://arxiv.org/abs/1804.03209},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'SpeechCommands', 'source_datasets': ['original'], 'task_categories': ['audio-classification'], 'task_ids': ['keyword-spotting'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'configs': ['v0.01', 'v0.02']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 691\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: spider\n",
       " \tsha: 177e69f41c5e57dff0a01b4066fdddf819bbb534\n",
       " \tlastModified: 2022-07-01T11:56:13.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-text-to-sql']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Spider is a large-scale complex and cross-domain semantic parsing and text-toSQL dataset annotated by 11 college students\n",
       " \tcitation: @article{yu2018spider,\n",
       "   title={Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task},\n",
       "   author={Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and others},\n",
       "   journal={arXiv preprint arXiv:1809.08887},\n",
       "   year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'machine-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-text-to-sql'], 'paperswithcode_id': 'spider-1', 'pretty_name': 'Spider'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1107\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: spider-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad\n",
       " \tsha: d04f25d7823ef492730bfcf7ae02f363c2373a28\n",
       " \tlastModified: 2022-07-01T11:56:14.000Z\n",
       " \ttags: ['arxiv:1606.05250', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|wikipedia', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
       " \tcitation: @article{2016arXiv160605250R,\n",
       "        author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
       "                  Konstantin and {Liang}, Percy},\n",
       "         title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2016,\n",
       "           eid = {arXiv:1606.05250},\n",
       "         pages = {arXiv:1606.05250},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1606.05250},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'SQuAD', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'squad', 'train-eval-index': [{'config': 'plain_text', 'task': 'question-answering', 'task_id': 'extractive_question_answering', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'question': 'question', 'context': 'context', 'answers': {'text': 'text', 'answer_start': 'answer_start'}}, 'metrics': [{'type': 'squad', 'name': 'SQuAD'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 124958\n",
       " \tlikes: 30\n",
       " \tpaperswithcode_id: squad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_adversarial\n",
       " \tsha: 7c19bac9a2db353c59d67b286067d95329845582\n",
       " \tlastModified: 2022-07-01T11:56:15.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|squad', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Here are two different adversaries, each of which uses a different procedure to pick the sentence it adds to the paragraph:\n",
       " AddSent: Generates up to five candidate adversarial sentences that don't answer the question, but have a lot of words in common with the question. Picks the one that most confuses the model.\n",
       " AddOneSent: Similar to AddSent, but just picks one of the candidate sentences at random. This adversary is does not query the model in any way.\n",
       " \tcitation: @inproceedings{jia-liang-2017-adversarial,\n",
       "     title = \"Adversarial Examples for Evaluating Reading Comprehension Systems\",\n",
       "     author = \"Jia, Robin  and\n",
       "       Liang, Percy\",\n",
       "     booktitle = \"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = sep,\n",
       "     year = \"2017\",\n",
       "     address = \"Copenhagen, Denmark\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D17-1215\",\n",
       "     doi = \"10.18653/v1/D17-1215\",\n",
       "     pages = \"2021--2031\",\n",
       "     abstract = \"Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|squad'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': None, 'pretty_name': \"'Adversarial Examples for SQuAD'\"}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 835\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_es\n",
       " \tsha: 60f9fee9093cbe67218a653e83e0ec2d3fc31af5\n",
       " \tlastModified: 2022-08-12T09:46:36.000Z\n",
       " \ttags: ['arxiv:1912.05200', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:es', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|squad', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: automatic translation of the Stanford Question Answering Dataset (SQuAD) v2 into Spanish\n",
       " \tcitation: @article{2016arXiv160605250R,\n",
       "        author = {Casimiro Pio , Carrino and  Marta R. , Costa-jussa and  Jose A. R. , Fonollosa},\n",
       "         title = \"{Automatic Spanish Translation of the SQuAD Dataset for Multilingual\n",
       " Question Answering}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2019,\n",
       "           eid = {arXiv:1912.05200v1},\n",
       "         pages = {arXiv:1912.05200v1},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1912.05200v2},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['es'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|squad'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'squad-es', 'pretty_name': 'SQuAD-es'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 607\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: squad-es\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_it\n",
       " \tsha: 3e9c1b19ce6e0de82e6db95c1661cf64aa0d6249\n",
       " \tlastModified: 2022-07-27T14:39:05.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:it', 'language_bcp47:it-IT', 'license:unknown', 'multilinguality:monolingual', 'size_categories:unknown', 'source_datasets:extended|squad', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SQuAD-it is derived from the SQuAD dataset and it is obtained through semi-automatic translation of the SQuAD dataset\n",
       " into Italian. It represents a large-scale dataset for open question answering processes on factoid questions in Italian.\n",
       "  The dataset contains more than 60,000 question/answer pairs derived from the original English dataset. The dataset is\n",
       "  split into training and test sets to support the replicability of the benchmarking of QA systems:\n",
       " \tcitation: @InProceedings{10.1007/978-3-030-03840-3_29,\n",
       "     author={Croce, Danilo and Zelenanska, Alexandra and Basili, Roberto},\n",
       "     editor={Ghidini, Chiara and Magnini, Bernardo and Passerini, Andrea and Traverso, Paolo\",\n",
       "     title={Neural Learning for Question Answering in Italian},\n",
       "     booktitle={AI*IA 2018 -- Advances in Artificial Intelligence},\n",
       "     year={2018},\n",
       "     publisher={Springer International Publishing},\n",
       "     address={Cham},\n",
       "     pages={389--402},\n",
       "     isbn={978-3-030-03840-3}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['it'], 'language_bcp47': ['it-IT'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['unknown'], 'source_datasets': ['extended|squad'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa', 'extractive-qa'], 'paperswithcode_id': 'squad-it', 'pretty_name': 'SQuAD-it'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 511\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: squad-it\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_kor_v1\n",
       " \tsha: d4f55584de91d117c935458d2a75cad8ea8d1207\n",
       " \tlastModified: 2022-07-01T12:43:44.000Z\n",
       " \ttags: ['arxiv:1909.07005', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:ko', 'license:cc-by-nd-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KorQuAD 1.0 is a large-scale Korean dataset for machine reading comprehension task consisting of human generated questions for Wikipedia articles. We benchmark the data collecting process of SQuADv1.0 and crowdsourced 70,000+ question-answer pairs. 1,637 articles and 70,079 pairs of question answers were collected. 1,420 articles are used for the training set, 140 for the dev set, and 77 for the test set. 60,407 question-answer pairs are for the training set, 5,774 for the dev set, and 3,898 for the test set.\n",
       " \tcitation: @article{lim2019korquad1,\n",
       "   title={Korquad1. 0: Korean qa dataset for machine reading comprehension},\n",
       "   author={Lim, Seungyoung and Kim, Myungji and Lee, Jooyoul},\n",
       "   journal={arXiv preprint arXiv:1909.07005},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ko'], 'license': ['cc-by-nd-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'korquad', 'pretty_name': 'The Korean Question Answering Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2046\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: korquad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_kor_v2\n",
       " \tsha: 2b448f95d61f27fcd6b2695dd20c5f6fe257f627\n",
       " \tlastModified: 2022-07-01T12:43:44.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:ko', 'license:cc-by-nd-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|squad_kor_v1', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: KorQuAD 2.0 is a Korean question and answering dataset consisting of a total of 100,000+ pairs. There are three major differences from KorQuAD 1.0, which is the standard Korean Q & A data. The first is that a given document is a whole Wikipedia page, not just one or two paragraphs. Second, because the document also contains tables and lists, it is necessary to understand the document structured with HTML tags. Finally, the answer can be a long text covering not only word or phrase units, but paragraphs, tables, and lists. As a baseline model, BERT Multilingual is used, released by Google as an open source. It shows 46.0% F1 score, a very low score compared to 85.7% of the human F1 score. It indicates that this data is a challenging task. Additionally, we increased the performance by no-answer data augmentation. Through the distribution of this data, we intend to extend the limit of MRC that was limited to plain text to real world tasks of various lengths and formats.\n",
       " \tcitation: @article{NODE09353166,\n",
       "     author={Youngmin Kim,Seungyoung Lim;Hyunjeong Lee;Soyoon Park;Myungji Kim},\n",
       "     title={{KorQuAD 2.0: Korean QA Dataset for Web Document Machine Comprehension}},\n",
       "     booltitle={{Journal of KIISE 제47권 제6호}},\n",
       "     journal={{Journal of KIISE}},\n",
       "     volume={{47}},\n",
       "     issue={{6}},\n",
       "     publisher={The Korean Institute of Information Scientists and Engineers},\n",
       "     year={2020},\n",
       "     ISSN={{2383-630X}},\n",
       "     pages={577-586},\n",
       "     url={http://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE09353166}}\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ko'], 'license': ['cc-by-nd-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|squad_kor_v1', 'original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': None, 'pretty_name': 'KorQuAD v2.1'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 608\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_v1_pt\n",
       " \tsha: 6714ad5422a0f154b6c6bf5587761f9da34fde5e\n",
       " \tlastModified: 2022-07-01T11:56:17.000Z\n",
       " \ttags: ['arxiv:1606.05250', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:pt', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Portuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.\n",
       " \tcitation: @article{2016arXiv160605250R,\n",
       "        author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
       "                  Konstantin and {Liang}, Percy},\n",
       "         title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2016,\n",
       "           eid = {arXiv:1606.05250},\n",
       "         pages = {arXiv:1606.05250},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1606.05250},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['pt'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'SquadV1Pt'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 403\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squad_v2\n",
       " \tsha: c1d4cc585397cb96d2f33cd87690099f243ac802\n",
       " \tlastModified: 2022-07-01T11:56:17.000Z\n",
       " \ttags: ['arxiv:1606.05250', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers\n",
       "  to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but\n",
       "  also determine when no answer is supported by the paragraph and abstain from answering.\n",
       " \tcitation: @article{2016arXiv160605250R,\n",
       "        author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
       "                  Konstantin and {Liang}, Percy},\n",
       "         title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2016,\n",
       "           eid = {arXiv:1606.05250},\n",
       "         pages = {arXiv:1606.05250},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1606.05250},\n",
       " }\n",
       " \tcardData: {'pretty_name': 'SQuAD2.0', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa', 'extractive-qa'], 'paperswithcode_id': 'squad', 'train-eval-index': [{'config': 'squad_v2', 'task': 'question-answering', 'task_id': 'extractive_question_answering', 'splits': {'train_split': 'train', 'eval_split': 'validation'}, 'col_mapping': {'question': 'question', 'context': 'context', 'answers': {'text': 'text', 'answer_start': 'answer_start'}}, 'metrics': [{'type': 'squad_v2', 'name': 'SQuAD v2'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 50680\n",
       " \tlikes: 9\n",
       " \tpaperswithcode_id: squad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: squadshifts\n",
       " \tsha: 706313963821d0abc831549e24ec420a01a54270\n",
       " \tlastModified: 2022-10-03T09:24:59.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:crowdsourced', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{pmlr-v119-miller20a,\n",
       "   title = {The Effect of Natural Distribution Shift on Question Answering Models},\n",
       "   author = {Miller, John and Krauth, Karl and Recht, Benjamin and Schmidt, Ludwig},\n",
       "   booktitle = {Proceedings of the 37th International Conference on Machine Learning},\n",
       "   pages = {6905--6916},\n",
       "   year = {2020},\n",
       "   editor = {III, Hal Daumé and Singh, Aarti},\n",
       "   volume = {119},\n",
       "   series = {Proceedings of Machine Learning Research},\n",
       "   month = {13--18 Jul},\n",
       "   publisher = {PMLR},\n",
       "   pdf = {http://proceedings.mlr.press/v119/miller20a/miller20a.pdf},\n",
       "   url = {https://proceedings.mlr.press/v119/miller20a.html},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['crowdsourced', 'found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'SQuAD-shifts', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'squad-shifts'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4793\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: squad-shifts\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: srwac\n",
       " \tsha: 28e3538808283fefea3f35fbc7d859cf0e4e7a33\n",
       " \tlastModified: 2022-07-01T11:56:19.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:sr', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100M<n<1B', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Serbian web corpus srWaC was built by crawling the .rs top-level domain in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Serbian vs. Croatian).\n",
       " Version 1.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 1.1 contains newer and better linguistic annotations.\n",
       " \tcitation: @misc{11356/1063,\n",
       "  title = {Serbian web corpus {srWaC} 1.1},\n",
       "  author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n",
       "  url = {http://hdl.handle.net/11356/1063},\n",
       "  note = {Slovenian language resource repository {CLARIN}.{SI}},\n",
       "  copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n",
       "  year = {2016} }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['sr'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100M<n<1B'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'SrWac'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 320\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: sst\n",
       " \tsha: 15c608a24352ced323e39ff3199dfe3f5c58cd92\n",
       " \tlastModified: 2022-07-01T11:56:20.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring', 'configs:default', 'configs:dictionary', 'configs:ptb']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Stanford Sentiment Treebank, the first corpus with fully labeled parse trees that allows for a\n",
       " complete analysis of the compositional effects of sentiment in language.\n",
       " \tcitation: @inproceedings{socher-etal-2013-recursive,\n",
       "     title = \"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\",\n",
       "     author = \"Socher, Richard and Perelygin, Alex and Wu, Jean and\n",
       "       Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher\",\n",
       "     booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct,\n",
       "     year = \"2013\",\n",
       "     address = \"Seattle, Washington, USA\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D13-1170\",\n",
       "     pages = \"1631--1642\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'sentiment-classification', 'sentiment-scoring'], 'paperswithcode_id': 'sst', 'pretty_name': 'Stanford Sentiment Treebank', 'configs': ['default', 'dictionary', 'ptb']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7476\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: sst\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: stereoset\n",
       " \tsha: 078f71c20be97c69ce72d2c1dcaf391052c3f648\n",
       " \tlastModified: 2022-07-01T11:56:21.000Z\n",
       " \ttags: ['arxiv:2004.09456', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-stereotype-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Stereoset is a dataset that measures stereotype bias in language models. Stereoset consists of 17,000 sentences that\n",
       " measures model preferences across gender, race, religion, and profession.\n",
       " \tcitation: @article{nadeem2020Stereoset,\n",
       "   title={Stereoset: Measuring stereotypical bias in pretrained language models},\n",
       "   author={Nadeem, Moin and Bethke, Anna and Reddy, Siva},\n",
       "   journal={arXiv preprint arXiv:2004.09456},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-stereotype-detection'], 'paperswithcode_id': 'stereoset', 'pretty_name': 'StereoSet'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 811\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: stereoset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: story_cloze\n",
       " \tsha: e52b8b9c7bc05f5e61db4ea10c1f16d6946ec4e9\n",
       " \tlastModified: 2022-07-06T15:45:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-story-completion']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Story Cloze Test' is a commonsense reasoning framework for evaluating story understanding,\n",
       " story generation, and script learning.This test requires a system to choose the correct ending\n",
       " to a four-sentence story.\n",
       " \tcitation: @inproceedings{mostafazadeh2017lsdsem,\n",
       "   title={Lsdsem 2017 shared task: The story cloze test},\n",
       "   author={Mostafazadeh, Nasrin and Roth, Michael and Louis, Annie and Chambers, Nathanael and Allen, James},\n",
       "   booktitle={Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},\n",
       "   pages={46--51},\n",
       "   year={2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-story-completion'], 'paperswithcode_id': None, 'pretty_name': 'Story Cloze Test'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 41267\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: stsb_mt_sv\n",
       " \tsha: c85a9634b21c357b82caae0f3faa158d82dc5a21\n",
       " \tlastModified: 2022-07-01T11:56:22.000Z\n",
       " \ttags: ['arxiv:2009.03116', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:sv', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-sts-b', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @article{isbister2020not,\n",
       "   title={Why Not Simply Translate? A First Swedish Evaluation Benchmark for Semantic Similarity},\n",
       "   author={Isbister, Tim and Sahlgren, Magnus},\n",
       "   journal={arXiv preprint arXiv:2009.03116},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['sv'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-sts-b'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'Swedish Machine Translated STS-B'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 319\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: stsb_multi_mt\n",
       " \tsha: 9dc6f37b0db92617b9dbaa3197783e3af13f89ea\n",
       " \tlastModified: 2022-07-27T14:39:05.000Z\n",
       " \ttags: ['arxiv:1708.00055', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:found', 'language_creators:machine-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:zh', 'license:other', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-sts-b', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: These are different multilingual translations and the English original of the STSbenchmark dataset. Translation has been done with deepl.com.\n",
       " \tcitation: @InProceedings{huggingface:dataset:stsb_multi_mt,\n",
       " title = {Machine translated multilingual STS benchmark dataset.},\n",
       " author={Philip May},\n",
       " year={2021},\n",
       " url={https://github.com/PhilipMay/stsb-multi-mt}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'found', 'machine-generated'], 'language': ['de', 'en', 'es', 'fr', 'it', 'nl', 'pl', 'pt', 'ru', 'zh'], 'license': ['other'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-sts-b'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'STSb Multi MT'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 9825\n",
       " \tlikes: 10\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: style_change_detection\n",
       " \tsha: 0412c321b20a624b5e015d98f707e7fb6acc95c4\n",
       " \tlastModified: 2022-05-04T18:35:01.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The goal of the style change detection task is to identify text positions within a given multi-author document at which the author switches. Detecting these positions is a crucial part of the authorship identification process, and for multi-author document analysis in general.\n",
       " \n",
       " Access to the dataset needs to be requested from zenodo.\n",
       " \tcitation: @inproceedings{bevendorff2020shared,\n",
       "   title={Shared Tasks on Authorship Analysis at PAN 2020},\n",
       "   author={Bevendorff, Janek and Ghanem, Bilal and Giachanou, Anastasia and Kestemont, Mike and Manjavacas, Enrique and Potthast, Martin and Rangel, Francisco and Rosso, Paolo and Specht, G{\\\"u}nther and Stamatatos, Efstathios and others},\n",
       "   booktitle={European Conference on Information Retrieval},\n",
       "   pages={508--516},\n",
       "   year={2020},\n",
       "   organization={Springer}\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': None, 'pretty_name': 'StyleChangeDetection'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 480\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: subjqa\n",
       " \tsha: 6a13b3bff80e92113d88e0f7824c4d45b31c58ab\n",
       " \tlastModified: 2022-07-01T11:56:23.000Z\n",
       " \ttags: ['arxiv:2004.14283', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'source_datasets:extended|yelp_review_full', 'source_datasets:extended|other-amazon_reviews_ucsd', 'source_datasets:extended|other-tripadvisor_reviews', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SubjQA is a question answering dataset that focuses on subjective questions and answers.\n",
       " The dataset consists of roughly 10,000 questions over reviews from 6 different domains: books, movies, grocery,\n",
       " electronics, TripAdvisor (i.e. hotels), and restaurants.\n",
       " \tcitation: @inproceedings{bjerva20subjqa,\n",
       "     title = \"SubjQA: A Dataset for Subjectivity and Review Comprehension\",\n",
       "     author = \"Bjerva, Johannes  and\n",
       "       Bhutani, Nikita  and\n",
       "       Golahn, Behzad  and\n",
       "       Tan, Wang-Chiew  and\n",
       "       Augenstein, Isabelle\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = November,\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original', 'extended|yelp_review_full', 'extended|other-amazon_reviews_ucsd', 'extended|other-tripadvisor_reviews'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'subjqa', 'pretty_name': 'subjqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2485\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: subjqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: super_glue\n",
       " \tsha: 8aaf7d095b10a801e83786f3520d3b92480c824a\n",
       " \tlastModified: 2022-08-22T08:58:59.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language:en', 'language_creators:other', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other', 'tags:superglue', 'tags:NLU', 'tags:natural language understanding', 'task_categories:text-classification', 'task_categories:token-classification', 'task_categories:question-answering', 'task_ids:natural-language-inference', 'task_ids:word-sense-disambiguation', 'task_ids:coreference-resolution', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SuperGLUE (https://super.gluebenchmark.com/) is a new benchmark styled after\n",
       " GLUE with a new set of more difficult language understanding tasks, improved\n",
       " resources, and a new public leaderboard.\n",
       " \tcitation: @article{wang2019superglue,\n",
       "   title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},\n",
       "   author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},\n",
       "   journal={arXiv preprint arXiv:1905.00537},\n",
       "   year={2019}\n",
       " }\n",
       " \n",
       " Note that each SuperGLUE dataset has its own citation. Please see the source to\n",
       " get the correct citation for each contained dataset.\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['other'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'superglue', 'pretty_name': 'SuperGLUE', 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other'], 'tags': ['superglue', 'NLU', 'natural language understanding'], 'task_categories': ['text-classification', 'token-classification', 'question-answering'], 'task_ids': ['natural-language-inference', 'word-sense-disambiguation', 'coreference-resolution', 'extractive-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2262581\n",
       " \tlikes: 26\n",
       " \tpaperswithcode_id: superglue\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: superb\n",
       " \tsha: 2b3abee57884d6aa1273325508e793d9ebddd135\n",
       " \tlastModified: 2022-07-01T11:56:24.000Z\n",
       " \ttags: ['arxiv:2105.01051', 'annotations_creators:other', 'language_creators:other', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:unknown', 'source_datasets:original', 'source_datasets:extended|librispeech_asr', 'source_datasets:extended|other-librimix', 'source_datasets:extended|other-speech_commands', 'task_categories:automatic-speech-recognition', 'task_categories:audio-classification', 'task_ids:keyword-spotting', 'task_ids:audio-classification-other-query-by-example-spoken-term-detection', 'task_ids:speaker-identification', 'task_ids:audio-classification-other-automatic-speaker-verification', 'task_ids:audio-classification-other-speaker-diarization', 'task_ids:audio-intent-classification', 'task_ids:other-audio-slot-filling', 'task_ids:audio-emotion-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Self-supervised learning (SSL) has proven vital for advancing research in\n",
       " natural language processing (NLP) and computer vision (CV). The paradigm\n",
       " pretrains a shared model on large volumes of unlabeled data and achieves\n",
       " state-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\n",
       " speech processing community lacks a similar setup to systematically explore the\n",
       " paradigm. To bridge this gap, we introduce Speech processing Universal\n",
       " PERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\n",
       " performance of a shared model across a wide range of speech processing tasks\n",
       " with minimal architecture changes and labeled data. Among multiple usages of the\n",
       " shared model, we especially focus on extracting the representation learned from\n",
       " SSL due to its preferable re-usability. We present a simple framework to solve\n",
       " SUPERB tasks by learning task-specialized lightweight prediction heads on top of\n",
       " the frozen shared model. Our results demonstrate that the framework is promising\n",
       " as SSL representations show competitive generalizability and accessibility\n",
       " across SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a\n",
       " benchmark toolkit to fuel the research in representation learning and general\n",
       " speech processing.\n",
       " \n",
       " Note that in order to limit the required storage for preparing this dataset, the\n",
       " audio is stored in the .wav format and is not converted to a float32 array. To\n",
       " convert the audio file to a float32 array, please make use of the `.map()`\n",
       " function as follows:\n",
       " \n",
       " \n",
       " ```python\n",
       " import soundfile as sf\n",
       " \n",
       " def map_to_array(batch):\n",
       "     speech_array, _ = sf.read(batch[\"file\"])\n",
       "     batch[\"speech\"] = speech_array\n",
       "     return batch\n",
       " \n",
       " dataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n",
       " ```\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2105-01051,\n",
       "   author    = {Shu{-}Wen Yang and\n",
       "                Po{-}Han Chi and\n",
       "                Yung{-}Sung Chuang and\n",
       "                Cheng{-}I Jeff Lai and\n",
       "                Kushal Lakhotia and\n",
       "                Yist Y. Lin and\n",
       "                Andy T. Liu and\n",
       "                Jiatong Shi and\n",
       "                Xuankai Chang and\n",
       "                Guan{-}Ting Lin and\n",
       "                Tzu{-}Hsien Huang and\n",
       "                Wei{-}Cheng Tseng and\n",
       "                Ko{-}tik Lee and\n",
       "                Da{-}Rong Liu and\n",
       "                Zili Huang and\n",
       "                Shuyan Dong and\n",
       "                Shang{-}Wen Li and\n",
       "                Shinji Watanabe and\n",
       "                Abdelrahman Mohamed and\n",
       "                Hung{-}yi Lee},\n",
       "   title     = {{SUPERB:} Speech processing Universal PERformance Benchmark},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2105.01051},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2105.01051},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2105.01051},\n",
       "   timestamp = {Thu, 01 Jul 2021 13:30:22 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2105-01051.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['other'], 'language_creators': ['other'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'SUPERB', 'size_categories': ['unknown'], 'source_datasets': ['original', 'extended|librispeech_asr', 'extended|other-librimix', 'extended|other-speech_commands'], 'task_categories': ['automatic-speech-recognition', 'audio-classification'], 'task_ids': ['keyword-spotting', 'audio-classification-other-query-by-example-spoken-term-detection', 'speaker-identification', 'audio-classification-other-automatic-speaker-verification', 'audio-classification-other-speaker-diarization', 'audio-intent-classification', 'other-audio-slot-filling', 'audio-emotion-recognition']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3294\n",
       " \tlikes: 10\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: svhn\n",
       " \tsha: 59f0836f05b5dcbdcf3465c32035800772844d8d\n",
       " \tlastModified: 2022-07-01T11:56:25.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'annotations_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:image-classification', 'task_categories:object-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting.\n",
       " It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images)\n",
       " and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
       " \tcitation: @article{netzer2011reading,\n",
       "   title={Reading digits in natural images with unsupervised feature learning},\n",
       "   author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},\n",
       "   year={2011}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated', 'expert-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['image-classification', 'object-detection'], 'task_ids': [], 'paperswithcode_id': 'svhn', 'pretty_name': 'Street View House Numbers'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 188\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: svhn\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swag\n",
       " \tsha: f0b467ffa7ab0ee2761ba668cf797afaca8ef93b\n",
       " \tlastModified: 2022-08-11T12:57:36.000Z\n",
       " \ttags: ['arxiv:1808.05326', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:natural-language-inference']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Given a partial description like \"she opened the hood of the car,\"\n",
       " humans can reason about the situation and anticipate what might come\n",
       " next (\"then, she examined the engine\"). SWAG (Situations With Adversarial Generations)\n",
       " is a large-scale dataset for this task of grounded commonsense\n",
       " inference, unifying natural language inference and physically grounded reasoning.\n",
       " \n",
       " The dataset consists of 113k multiple choice questions about grounded situations\n",
       " (73k training, 20k validation, 20k test).\n",
       " Each question is a video caption from LSMDC or ActivityNet Captions,\n",
       " with four answer choices about what might happen next in the scene.\n",
       " The correct answer is the (real) video caption for the next event in the video;\n",
       " the three incorrect answers are adversarially generated and human verified,\n",
       " so as to fool machines but not humans. SWAG aims to be a benchmark for\n",
       " evaluating grounded commonsense NLI and for learning representations.\n",
       " \n",
       " The full data contain more information,\n",
       " but the regular configuration will be more interesting for modeling\n",
       " (note that the regular data are shuffled). The test set for leaderboard submission\n",
       " is under the regular configuration.\n",
       " \tcitation: @inproceedings{zellers2018swagaf,\n",
       "     title={SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference},\n",
       "     author={Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},\n",
       "     booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference'], 'paperswithcode_id': 'swag', 'pretty_name': 'Situations With Adversarial Generations'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 11260\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: swag\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swahili\n",
       " \tsha: d9cd7cf104306cdc1d9a094fabd25a7b61a29c36\n",
       " \tlastModified: 2022-07-01T11:56:26.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:sw', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Swahili dataset developed specifically for language modeling task.\n",
       " The dataset contains 28,000 unique words with 6.84M, 970k, and 2M words for the train,\n",
       " valid and test partitions respectively which represent the ratio 80:10:10.\n",
       " The entire dataset is lowercased, has no punctuation marks and,\n",
       " the start and end of sentence markers have been incorporated to facilitate easy tokenization during language modeling.\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = Language modeling data for Swahili (Version 1),\n",
       " authors={Shivachi Casper Shikali, & Mokhosi Refuoe.\n",
       " },\n",
       " year={2019},\n",
       " link = http://doi.org/10.5281/zenodo.3553423\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['sw'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'swahili'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swahili_news\n",
       " \tsha: 6a3920d3cd3e2125633e2dd031a579a8faf425f8\n",
       " \tlastModified: 2022-07-01T11:56:27.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:sw', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Swahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\n",
       " \n",
       " News contributes to education, technology, and the economic growth of a country, and news in local languages plays an important cultural role in many Africa countries. In the modern age, African languages in news and other spheres are at risk of being lost as English becomes the dominant language in online spaces.\n",
       " \n",
       " The Swahili news dataset was created to reduce the gap of using the Swahili language to create NLP technologies and help AI practitioners in Tanzania and across Africa continent to practice their NLP skills to solve different problems in organizations or societies related to Swahili language. Swahili News were collected from different websites that provide news in the Swahili language. I was able to find some websites that provide news in Swahili only and others in different languages including Swahili.\n",
       " \n",
       " The dataset was created for a specific task of text classification, this means each news content can be categorized into six different topics (Local news, International news , Finance news, Health news, Sports news, and Entertainment news). The dataset comes with a specified train/test split. The train set contains 75% of the dataset and test set contains 25% of the dataset.\n",
       " \tcitation: @dataset{davis_david_2020_5514203,\n",
       "   author       = {Davis David},\n",
       "   title        = {Swahili : News Classification Dataset},\n",
       "   month        = dec,\n",
       "   year         = 2020,\n",
       "   note         = {{The news version contains both train and test sets.}},\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {0.2},\n",
       "   doi          = {10.5281/zenodo.5514203},\n",
       "   url          = {https://doi.org/10.5281/zenodo.5514203}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['sw'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': None, 'pretty_name': 'Swahili : News Classification Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swda\n",
       " \tsha: 9d193a9826a2e03df7cae16e575ac258fa3ec11e\n",
       " \tlastModified: 2022-08-30T11:14:43.000Z\n",
       " \ttags: ['arxiv:1811.05021', 'arxiv:1711.05568', 'arxiv:1709.04250', 'arxiv:1805.06280', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-Switchboard-1 Telephone Speech Corpus, Release 2', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Switchboard Dialog Act Corpus (SwDA) extends the Switchboard-1 Telephone Speech Corpus, Release 2 with\n",
       " turn/utterance-level dialog-act tags. The tags summarize syntactic, semantic, and pragmatic information about the\n",
       " associated turn. The SwDA project was undertaken at UC Boulder in the late 1990s.\n",
       " The SwDA is not inherently linked to the Penn Treebank 3 parses of Switchboard, and it is far from straightforward to\n",
       " align the two resources. In addition, the SwDA is not distributed with the Switchboard's tables of metadata about the\n",
       " conversations and their participants.\n",
       " \tcitation: @techreport{Jurafsky-etal:1997,\n",
       "     Address = {Boulder, CO},\n",
       "     Author = {Jurafsky, Daniel and Shriberg, Elizabeth and Biasca, Debra},\n",
       "     Institution = {University of Colorado, Boulder Institute of Cognitive Science},\n",
       "     Number = {97-02},\n",
       "     Title = {Switchboard {SWBD}-{DAMSL} Shallow-Discourse-Function Annotation Coders Manual, Draft 13},\n",
       "     Year = {1997}}\n",
       " \n",
       " @article{Shriberg-etal:1998,\n",
       "     Author = {Shriberg, Elizabeth and Bates, Rebecca and Taylor, Paul and Stolcke, Andreas and Jurafsky, Daniel and Ries, Klaus and Coccaro, Noah and Martin, Rachel and Meteer, Marie and Van Ess-Dykema, Carol},\n",
       "     Journal = {Language and Speech},\n",
       "     Number = {3--4},\n",
       "     Pages = {439--487},\n",
       "     Title = {Can Prosody Aid the Automatic Classification of Dialog Acts in Conversational Speech?},\n",
       "     Volume = {41},\n",
       "     Year = {1998}}\n",
       " \n",
       " @article{Stolcke-etal:2000,\n",
       "     Author = {Stolcke, Andreas and Ries, Klaus and Coccaro, Noah and Shriberg, Elizabeth and Bates, Rebecca and Jurafsky, Daniel and Taylor, Paul and Martin, Rachel and Meteer, Marie and Van Ess-Dykema, Carol},\n",
       "     Journal = {Computational Linguistics},\n",
       "     Number = {3},\n",
       "     Pages = {339--371},\n",
       "     Title = {Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech},\n",
       "     Volume = {26},\n",
       "     Year = {2000}}\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-Switchboard-1 Telephone Speech Corpus, Release 2'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification'], 'paperswithcode_id': None, 'pretty_name': 'The Switchboard Dialog Act Corpus (SwDA)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 440\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swedish_medical_ner\n",
       " \tsha: 963abbd6d1a1fe495c35d8f388b71ec4f942522d\n",
       " \tlastModified: 2022-07-27T14:39:05.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'annotations_creators:expert-generated', 'language_creators:found', 'language:sv', 'language_bcp47:sv-SE', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: SwedMedNER is a dataset for training and evaluating Named Entity Recognition systems on medical texts in Swedish.\n",
       " It is derived from medical articles on the Swedish Wikipedia, Läkartidningen, and 1177 Vårdguiden.\n",
       " \tcitation: @inproceedings{almgrenpavlovmogren2016bioner,\n",
       "   title={Named Entity Recognition in Swedish Medical Journals with Deep Bidirectional Character-Based LSTMs},\n",
       "   author={Simon Almgren, Sean Pavlov, Olof Mogren},\n",
       "   booktitle={Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM 2016)},\n",
       "   pages={1},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated', 'expert-generated'], 'language_creators': ['found'], 'language': ['sv'], 'language_bcp47': ['sv-SE'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'pretty_name': 'SwedMedNER'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 631\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swedish_ner_corpus\n",
       " \tsha: bcf0c6129b7c5837db79b7669804929e1b898603\n",
       " \tlastModified: 2022-08-11T12:57:35.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:sv', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Webbnyheter 2012 from Spraakbanken, semi-manually annotated and adapted for CoreNLP Swedish NER. Semi-manually defined in this case as: Bootstrapped from Swedish Gazetters then manually correcte/reviewed by two independent native speaking swedish annotators. No annotator agreement calculated.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['sv'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Swedish NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 383\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swedish_reviews\n",
       " \tsha: 29a7be986f176e11b8a0357936ae4c43286de9e3\n",
       " \tlastModified: 2022-07-01T11:56:29.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:sv', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['sv'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Swedish Reviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: swiss_judgment_prediction\n",
       " \tsha: 4aafe38b68591e7055bd846220445141eef6f5ac\n",
       " \tlastModified: 2022-09-29T14:32:26.000Z\n",
       " \ttags: ['arxiv:2110.00806', 'arxiv:2209.12325', 'annotations_creators:found', 'language_creators:found', 'language:de', 'language:fr', 'language:it', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-judgement-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Swiss-Judgment-Prediction is a multilingual, diachronic dataset of 85K Swiss Federal Supreme Court (FSCS) cases annotated with the respective binarized judgment outcome (approval/dismissal), posing a challenging text classification task. We also provide additional metadata, i.e., the publication year, the legal area and the canton of origin per case, to promote robustness and fairness studies on the critical area of legal NLP.\n",
       " \tcitation: @InProceedings{niklaus-etal-2021-swiss,\n",
       "   author = {Niklaus, Joel\n",
       "                 and Chalkidis, Ilias\n",
       "                 and Stürmer, Matthias},\n",
       "   title = {Swiss-Court-Predict: A Multilingual Legal Judgment Prediction Benchmark},\n",
       "   booktitle = {Proceedings of the 2021 Natural Legal Language Processing Workshop},\n",
       "   year = {2021},\n",
       "   location = {Punta Cana, Dominican Republic},\n",
       " }\n",
       " @misc{niklaus2022empirical,\n",
       "     title={An Empirical Study on Cross-X Transfer for Legal Judgment Prediction},\n",
       "     author={Joel Niklaus and Matthias Stürmer and Ilias Chalkidis},\n",
       "     year={2022},\n",
       "     eprint={2209.12325},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Swiss-Judgment-Prediction', 'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['de', 'fr', 'it', 'en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-judgement-prediction']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1032\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tab_fact\n",
       " \tsha: 2a3ddf89704b8da7a01c3abe22ff2b9e17311693\n",
       " \tlastModified: 2022-08-11T12:57:36.000Z\n",
       " \ttags: ['arxiv:1909.02164', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The problem of verifying whether a textual hypothesis holds the truth based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are restricted to dealing with unstructured textual evidence (e.g., sentences and passages, a pool of passages), while verification using structured forms of evidence, such as tables, graphs, and databases, remains unexplored. TABFACT is large scale dataset with 16k Wikipedia tables as evidence for 118k human annotated statements designed for fact verification with semi-structured evidence. The statements are labeled as either ENTAILED or REFUTED. TABFACT is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning.\n",
       " \tcitation: @inproceedings{2019TabFactA,\n",
       "   title={TabFact : A Large-scale Dataset for Table-based Fact Verification},\n",
       "   author={Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou and William Yang Wang},\n",
       "   booktitle = {International Conference on Learning Representations (ICLR)},\n",
       "   address = {Addis Ababa, Ethiopia},\n",
       "   month = {April},\n",
       "   year = {2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking'], 'paperswithcode_id': 'tabfact', 'pretty_name': 'TabFact'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1491\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: tabfact\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tamilmixsentiment\n",
       " \tsha: 413357d8933d29a989fdbd6eb0a8ab750f32240c\n",
       " \tlastModified: 2022-07-01T11:56:31.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:ta', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The first gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. Train: 11,335 Validation: 1,260 and Test: 3,149.  This makes the largest general domain sentiment dataset for this relatively low-resource language with code-mixing phenomenon.  The dataset contains all the three types of code-mixed sentences - Inter-Sentential switch, Intra-Sentential switch and Tag switching. Most comments were written in Roman script with either Tamil grammar with English lexicon or English grammar with Tamil lexicon. Some comments were written in Tamil script with English expressions in between.\n",
       " \tcitation: @inproceedings{chakravarthi-etal-2020-corpus,\n",
       "     title = \"Corpus Creation for Sentiment Analysis in Code-Mixed {T}amil-{E}nglish Text\",\n",
       "     author = \"Chakravarthi, Bharathi Raja  and\n",
       "       Muralidaran, Vigneshwaran  and\n",
       "       Priyadharshini, Ruba  and\n",
       "       McCrae, John Philip\",\n",
       "     booktitle = \"Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.sltu-1.28\",\n",
       "     pages = \"202--210\",\n",
       "     abstract = \"Understanding the sentiment of a comment from a video or an image is an essential task in many applications. Sentiment analysis of a text can be useful for various decision-making processes. One such application is to analyse the popular sentiments of videos on social media based on viewer comments. However, comments from social media do not follow strict rules of grammar, and they contain mixing of more than one language, often written in non-native scripts. Non-availability of annotated code-mixed data for a low-resourced language like Tamil also adds difficulty to this problem. To overcome this, we created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. In this paper, we describe the process of creating the corpus and assigning polarities. We present inter-annotator agreement and show the results of sentiment analysis trained on this corpus as a benchmark.\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-35-1\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'ta'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Tamilmixsentiment'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tanzil\n",
       " \tsha: 047fb9ea52b1a232393c99de0c8d1463d8a87b6c\n",
       " \tlastModified: 2022-08-11T12:57:37.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:am', 'language:ar', 'language:az', 'language:bg', 'language:bn', 'language:bs', 'language:cs', 'language:de', 'language:dv', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:ha', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:ku', 'language:ml', 'language:ms', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sd', 'language:so', 'language:sq', 'language:sv', 'language:sw', 'language:ta', 'language:tg', 'language:th', 'language:tr', 'language:tt', 'language:ug', 'language:ur', 'language:uz', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of Quran translations compiled by the Tanzil project\n",
       " The translations provided at this page are for non-commercial purposes only. If used otherwise, you need to obtain necessary permission from the translator or the publisher.\n",
       " \n",
       " If you are using more than three of the following translations in a website or application, we require you to put a link back to this page to make sure that subsequent users have access to the latest updates.\n",
       " \n",
       " 42 languages, 878 bitexts\n",
       " total number of files: 105\n",
       " total number of tokens: 22.33M\n",
       " total number of sentence fragments: 1.01M\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['am', 'ar', 'az', 'bg', 'bn', 'bs', 'cs', 'de', 'dv', 'en', 'es', 'fa', 'fr', 'ha', 'hi', 'id', 'it', 'ja', 'ko', 'ku', 'ml', 'ms', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sd', 'so', 'sq', 'sv', 'sw', 'ta', 'tg', 'th', 'tr', 'tt', 'ug', 'ur', 'uz', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'tanzil'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 936\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tapaco\n",
       " \tsha: 52d318e5efb840464b5f1da50079e16116320cb6\n",
       " \tlastModified: 2022-07-27T14:39:06.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:ber', 'language:bg', 'language:bn', 'language:br', 'language:ca', 'language:cbk', 'language:cmn', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fi', 'language:fr', 'language:gl', 'language:gos', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jbo', 'language:kab', 'language:ko', 'language:kw', 'language:la', 'language:lfn', 'language:lt', 'language:mk', 'language:mr', 'language:nb', 'language:nds', 'language:nl', 'language:orv', 'language:ota', 'language:pes', 'language:pl', 'language:pt', 'language:rn', 'language:ro', 'language:ru', 'language:sl', 'language:sr', 'language:sv', 'language:tk', 'language:tl', 'language:tlh', 'language:tok', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:vi', 'language:vo', 'language:war', 'language:wuu', 'language:yue', 'license:cc-by-2.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:1M<n<10M', 'size_categories:n<1K', 'source_datasets:extended|other-tatoeba', 'task_categories:text2text-generation', 'task_categories:translation', 'task_categories:text-classification', 'task_ids:text2text-generation-other-paraphrase-generation', 'task_ids:semantic-similarity-classification', 'configs:af', 'configs:all_languages', 'configs:ar', 'configs:az', 'configs:be', 'configs:ber', 'configs:bg', 'configs:bn', 'configs:br', 'configs:ca', 'configs:cbk', 'configs:cmn', 'configs:cs', 'configs:da', 'configs:de', 'configs:el', 'configs:en', 'configs:eo', 'configs:es', 'configs:et', 'configs:eu', 'configs:fi', 'configs:fr', 'configs:gl', 'configs:gos', 'configs:he', 'configs:hi', 'configs:hr', 'configs:hu', 'configs:hy', 'configs:ia', 'configs:id', 'configs:ie', 'configs:io', 'configs:is', 'configs:it', 'configs:ja', 'configs:jbo', 'configs:kab', 'configs:ko', 'configs:kw', 'configs:la', 'configs:lfn', 'configs:lt', 'configs:mk', 'configs:mr', 'configs:nb', 'configs:nds', 'configs:nl', 'configs:orv', 'configs:ota', 'configs:pes', 'configs:pl', 'configs:pt', 'configs:rn', 'configs:ro', 'configs:ru', 'configs:sl', 'configs:sr', 'configs:sv', 'configs:tk', 'configs:tl', 'configs:tlh', 'configs:tok', 'configs:tr', 'configs:tt', 'configs:ug', 'configs:uk', 'configs:ur', 'configs:vi', 'configs:vo', 'configs:war', 'configs:wuu', 'configs:yue']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. Tatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences and translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a graph with Tatoeba sentences and equivalence links between sentences “meaning the same thing”. This graph is then traversed to extract sets of paraphrases. Several language-independent filters and pruning steps are applied to remove uninteresting sentences. A manual evaluation performed on three languages shows that between half and three quarters of inferred paraphrases are correct and that most remaining ones are either correct but trivial, or near-paraphrases that neutralize a morphological distinction. The corpus contains a total of 1.9 million sentences, with 200 – 250 000 sentences per language. It covers a range of languages for which, to our knowledge,no other paraphrase dataset exists.\n",
       " \tcitation: @dataset{scherrer_yves_2020_3707949,\n",
       "   author       = {Scherrer, Yves},\n",
       "   title        = {{TaPaCo: A Corpus of Sentential Paraphrases for 73 Languages}},\n",
       "   month        = mar,\n",
       "   year         = 2020,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {1.0},\n",
       "   doi          = {10.5281/zenodo.3707949},\n",
       "   url          = {https://doi.org/10.5281/zenodo.3707949}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['af', 'ar', 'az', 'be', 'ber', 'bg', 'bn', 'br', 'ca', 'cbk', 'cmn', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fi', 'fr', 'gl', 'gos', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jbo', 'kab', 'ko', 'kw', 'la', 'lfn', 'lt', 'mk', 'mr', 'nb', 'nds', 'nl', 'orv', 'ota', 'pes', 'pl', 'pt', 'rn', 'ro', 'ru', 'sl', 'sr', 'sv', 'tk', 'tl', 'tlh', 'tok', 'tr', 'tt', 'ug', 'uk', 'ur', 'vi', 'vo', 'war', 'wuu', 'yue'], 'license': ['cc-by-2.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', '1M<n<10M', 'n<1K'], 'source_datasets': ['extended|other-tatoeba'], 'task_categories': ['text2text-generation', 'translation', 'text-classification'], 'task_ids': ['text2text-generation-other-paraphrase-generation', 'semantic-similarity-classification'], 'paperswithcode_id': 'tapaco', 'pretty_name': 'TaPaCo Corpus', 'configs': ['af', 'all_languages', 'ar', 'az', 'be', 'ber', 'bg', 'bn', 'br', 'ca', 'cbk', 'cmn', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fi', 'fr', 'gl', 'gos', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jbo', 'kab', 'ko', 'kw', 'la', 'lfn', 'lt', 'mk', 'mr', 'nb', 'nds', 'nl', 'orv', 'ota', 'pes', 'pl', 'pt', 'rn', 'ro', 'ru', 'sl', 'sr', 'sv', 'tk', 'tl', 'tlh', 'tok', 'tr', 'tt', 'ug', 'uk', 'ur', 'vi', 'vo', 'war', 'wuu', 'yue']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 11773\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: tapaco\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tashkeela\n",
       " \tsha: 1981331a298b8c99bf84163cbfdb979f1c0c0837\n",
       " \tlastModified: 2022-07-01T11:56:33.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'license:gpl-2.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:other-diacritics-prediction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Arabic vocalized texts.\n",
       " it contains 75 million of fully vocalized words mainly97 books from classical and modern Arabic language.\n",
       " \tcitation: @article{zerrouki2017tashkeela,\n",
       "   title={Tashkeela: Novel corpus of Arabic vocalized texts, data for auto-diacritization systems},\n",
       "   author={Zerrouki, Taha and Balla, Amar},\n",
       "   journal={Data in brief},\n",
       "   volume={11},\n",
       "   pages={147},\n",
       "   year={2017},\n",
       "   publisher={Elsevier}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ar'], 'license': ['gpl-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'other-diacritics-prediction'], 'paperswithcode_id': None, 'pretty_name': 'Tashkeela'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 320\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: taskmaster1\n",
       " \tsha: ef3e1f8f32ce7e42468ed3f74983786d5239d42f\n",
       " \tlastModified: 2022-07-01T11:56:33.000Z\n",
       " \ttags: ['arxiv:1909.05358', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Taskmaster-1 is a  goal-oriented conversational dataset. It includes 13,215 task-based dialogs comprising six domains. Two procedures were used to create this collection, each with unique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is \"self-dialog\" in which crowdsourced workers write the entire dialog themselves.\n",
       " \tcitation: @inproceedings{48484,\n",
       " title\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\n",
       " author\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\n",
       " year\t= {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'taskmaster-1', 'pretty_name': 'Taskmaster-1'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 711\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: taskmaster-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: taskmaster2\n",
       " \tsha: a6206350852055e28372283d31cadf22e9676f23\n",
       " \tlastModified: 2022-08-11T12:57:37.000Z\n",
       " \ttags: ['arxiv:1909.05358', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Taskmaster is dataset for goal oriented conversations. The Taskmaster-2 dataset consists of 17,289 dialogs in the seven domains which include restaurants, food ordering, movies, hotels, flights, music and sports. Unlike Taskmaster-1, which includes both written \"self-dialogs\" and spoken two-person dialogs, Taskmaster-2 consists entirely of spoken two-person dialogs. In addition, while Taskmaster-1 is almost exclusively task-based, Taskmaster-2 contains a good number of search- and recommendation-oriented dialogs. All dialogs in this release were created using a Wizard of Oz (WOz) methodology in which crowdsourced workers played the role of a 'user' and trained call center operators played the role of the 'assistant'. In this way, users were led to believe they were interacting with an automated system that “spoke” using text-to-speech (TTS) even though it was in fact a human behind the scenes. As a result, users could express themselves however they chose in the context of an automated interface.\n",
       " \tcitation: @inproceedings{48484,\n",
       " title\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\n",
       " author\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\n",
       " year\t= {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': 'taskmaster-2', 'pretty_name': 'Taskmaster-2'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1817\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: taskmaster-2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: taskmaster3\n",
       " \tsha: 4989509760636c5ac5b76f6d12766e0ca8ff0dc1\n",
       " \tlastModified: 2022-08-11T12:57:38.000Z\n",
       " \ttags: ['arxiv:1909.05358', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:dialogue-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Taskmaster is dataset for goal oriented conversations. The Taskmaster-3 dataset consists of 23,757 movie ticketing dialogs. By \"movie ticketing\" we mean conversations where the customer's goal is to purchase tickets after deciding on theater, time, movie name, number of tickets, and date, or opt out of the transaction. This collection was created using the \"self-dialog\" method. This means a single, crowd-sourced worker is paid to create a conversation writing turns for both speakers, i.e. the customer and the ticketing agent.\n",
       " \tcitation: @inproceedings{48484,\n",
       " title\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\n",
       " author\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\n",
       " year\t= {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['dialogue-modeling'], 'paperswithcode_id': None, 'pretty_name': 'taskmaster3'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 505\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tatoeba\n",
       " \tsha: 0210f630bffae575913108e341df858373eeb932\n",
       " \tlastModified: 2022-08-11T14:03:46.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ab', 'language:acm', 'language:ady', 'language:af', 'language:afb', 'language:afh', 'language:aii', 'language:ain', 'language:ajp', 'language:akl', 'language:aln', 'language:am', 'language:an', 'language:ang', 'language:aoz', 'language:apc', 'language:ar', 'language:arq', 'language:ary', 'language:arz', 'language:as', 'language:ast', 'language:avk', 'language:awa', 'language:ayl', 'language:az', 'language:ba', 'language:bal', 'language:bar', 'language:be', 'language:ber', 'language:bg', 'language:bho', 'language:bjn', 'language:bm', 'language:bn', 'language:bo', 'language:br', 'language:brx', 'language:bs', 'language:bua', 'language:bvy', 'language:bzt', 'language:ca', 'language:cay', 'language:cbk', 'language:ce', 'language:ceb', 'language:ch', 'language:chg', 'language:chn', 'language:cho', 'language:chr', 'language:cjy', 'language:ckb', 'language:ckt', 'language:cmn', 'language:co', 'language:code', 'language:cpi', 'language:crh', 'language:crk', 'language:cs', 'language:csb', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:dng', 'language:drt', 'language:dsb', 'language:dtp', 'language:dv', 'language:dws', 'language:ee', 'language:egl', 'language:el', 'language:emx', 'language:en', 'language:enm', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:ext', 'language:fi', 'language:fj', 'language:fkv', 'language:fo', 'language:fr', 'language:frm', 'language:fro', 'language:frr', 'language:fuc', 'language:fur', 'language:fuv', 'language:fy', 'language:ga', 'language:gag', 'language:gan', 'language:gbm', 'language:gcf', 'language:gd', 'language:gil', 'language:gl', 'language:gn', 'language:gom', 'language:gos', 'language:got', 'language:grc', 'language:gsw', 'language:gu', 'language:gv', 'language:ha', 'language:hak', 'language:haw', 'language:hbo', 'language:he', 'language:hi', 'language:hif', 'language:hil', 'language:hnj', 'language:hoc', 'language:hr', 'language:hrx', 'language:hsb', 'language:hsn', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:iba', 'language:id', 'language:ie', 'language:ig', 'language:ii', 'language:ike', 'language:ilo', 'language:io', 'language:is', 'language:it', 'language:izh', 'language:ja', 'language:jam', 'language:jbo', 'language:jdt', 'language:jpa', 'language:jv', 'language:ka', 'language:kaa', 'language:kab', 'language:kam', 'language:kek', 'language:kha', 'language:kjh', 'language:kk', 'language:kl', 'language:km', 'language:kmr', 'language:kn', 'language:ko', 'language:koi', 'language:kpv', 'language:krc', 'language:krl', 'language:ksh', 'language:ku', 'language:kum', 'language:kw', 'language:kxi', 'language:ky', 'language:la', 'language:laa', 'language:lad', 'language:lb', 'language:ldn', 'language:lfn', 'language:lg', 'language:lij', 'language:liv', 'language:lkt', 'language:lld', 'language:lmo', 'language:ln', 'language:lo', 'language:lt', 'language:ltg', 'language:lut', 'language:lv', 'language:lzh', 'language:lzz', 'language:mad', 'language:mai', 'language:max', 'language:mdf', 'language:mfe', 'language:mg', 'language:mgm', 'language:mh', 'language:mhr', 'language:mi', 'language:mic', 'language:min', 'language:mk', 'language:ml', 'language:mn', 'language:mni', 'language:mnw', 'language:moh', 'language:mr', 'language:mt', 'language:mvv', 'language:mwl', 'language:mww', 'language:my', 'language:myv', 'language:na', 'language:nah', 'language:nan', 'language:nb', 'language:nch', 'language:nds', 'language:ngt', 'language:ngu', 'language:niu', 'language:nl', 'language:nlv', 'language:nn', 'language:nog', 'language:non', 'language:nov', 'language:npi', 'language:nst', 'language:nus', 'language:nv', 'language:ny', 'language:nys', 'language:oar', 'language:oc', 'language:ofs', 'language:ood', 'language:or', 'language:orv', 'language:os', 'language:osp', 'language:ota', 'language:otk', 'language:pa', 'language:pag', 'language:pal', 'language:pam', 'language:pap', 'language:pau', 'language:pcd', 'language:pdc', 'language:pes', 'language:phn', 'language:pi', 'language:pl', 'language:pms', 'language:pnb', 'language:ppl', 'language:prg', 'language:ps', 'language:pt', 'language:qu', 'language:quc', 'language:qya', 'language:rap', 'language:rif', 'language:rm', 'language:rn', 'language:ro', 'language:rom', 'language:ru', 'language:rue', 'language:rw', 'language:sa', 'language:sah', 'language:sc', 'language:scn', 'language:sco', 'language:sd', 'language:sdh', 'language:se', 'language:sg', 'language:sgs', 'language:shs', 'language:shy', 'language:si', 'language:sjn', 'language:sl', 'language:sm', 'language:sma', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:stq', 'language:su', 'language:sux', 'language:sv', 'language:swg', 'language:swh', 'language:syc', 'language:ta', 'language:te', 'language:tet', 'language:tg', 'language:th', 'language:thv', 'language:ti', 'language:tig', 'language:tk', 'language:tl', 'language:tlh', 'language:tly', 'language:tmr', 'language:tmw', 'language:tn', 'language:to', 'language:toi', 'language:tok', 'language:tpi', 'language:tpw', 'language:tr', 'language:ts', 'language:tt', 'language:tts', 'language:tvl', 'language:ty', 'language:tyv', 'language:tzl', 'language:udm', 'language:ug', 'language:uk', 'language:umb', 'language:ur', 'language:uz', 'language:vec', 'language:vep', 'language:vi', 'language:vo', 'language:vro', 'language:wa', 'language:war', 'language:wo', 'language:wuu', 'language:xal', 'language:xh', 'language:xqa', 'language:yi', 'language:yo', 'language:yue', 'language:zlm', 'language:zsm', 'language:zu', 'language:zza', 'license:cc-by-2.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of translated sentences from Tatoeba\n",
       " 359 languages, 3,403 bitexts\n",
       " total number of files: 750\n",
       " total number of tokens: 65.54M\n",
       " total number of sentence fragments: 8.96M\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ab', 'acm', 'ady', 'af', 'afb', 'afh', 'aii', 'ain', 'ajp', 'akl', 'aln', 'am', 'an', 'ang', 'aoz', 'apc', 'ar', 'arq', 'ary', 'arz', 'as', 'ast', 'avk', 'awa', 'ayl', 'az', 'ba', 'bal', 'bar', 'be', 'ber', 'bg', 'bho', 'bjn', 'bm', 'bn', 'bo', 'br', 'brx', 'bs', 'bua', 'bvy', 'bzt', 'ca', 'cay', 'cbk', 'ce', 'ceb', 'ch', 'chg', 'chn', 'cho', 'chr', 'cjy', 'ckb', 'ckt', 'cmn', 'co', 'code', 'cpi', 'crh', 'crk', 'cs', 'csb', 'cv', 'cy', 'da', 'de', 'dng', 'drt', 'dsb', 'dtp', 'dv', 'dws', 'ee', 'egl', 'el', 'emx', 'en', 'enm', 'eo', 'es', 'et', 'eu', 'ext', 'fi', 'fj', 'fkv', 'fo', 'fr', 'frm', 'fro', 'frr', 'fuc', 'fur', 'fuv', 'fy', 'ga', 'gag', 'gan', 'gbm', 'gcf', 'gd', 'gil', 'gl', 'gn', 'gom', 'gos', 'got', 'grc', 'gsw', 'gu', 'gv', 'ha', 'hak', 'haw', 'hbo', 'he', 'hi', 'hif', 'hil', 'hnj', 'hoc', 'hr', 'hrx', 'hsb', 'hsn', 'ht', 'hu', 'hy', 'ia', 'iba', 'id', 'ie', 'ig', 'ii', 'ike', 'ilo', 'io', 'is', 'it', 'izh', 'ja', 'jam', 'jbo', 'jdt', 'jpa', 'jv', 'ka', 'kaa', 'kab', 'kam', 'kek', 'kha', 'kjh', 'kk', 'kl', 'km', 'kmr', 'kn', 'ko', 'koi', 'kpv', 'krc', 'krl', 'ksh', 'ku', 'kum', 'kw', 'kxi', 'ky', 'la', 'laa', 'lad', 'lb', 'ldn', 'lfn', 'lg', 'lij', 'liv', 'lkt', 'lld', 'lmo', 'ln', 'lo', 'lt', 'ltg', 'lut', 'lv', 'lzh', 'lzz', 'mad', 'mai', 'max', 'mdf', 'mfe', 'mg', 'mgm', 'mh', 'mhr', 'mi', 'mic', 'min', 'mk', 'ml', 'mn', 'mni', 'mnw', 'moh', 'mr', 'mt', 'mvv', 'mwl', 'mww', 'my', 'myv', 'na', 'nah', 'nan', 'nb', 'nch', 'nds', 'ngt', 'ngu', 'niu', 'nl', 'nlv', 'nn', 'nog', 'non', 'nov', 'npi', 'nst', 'nus', 'nv', 'ny', 'nys', 'oar', 'oc', 'ofs', 'ood', 'or', 'orv', 'os', 'osp', 'ota', 'otk', 'pa', 'pag', 'pal', 'pam', 'pap', 'pau', 'pcd', 'pdc', 'pes', 'phn', 'pi', 'pl', 'pms', 'pnb', 'ppl', 'prg', 'ps', 'pt', 'qu', 'quc', 'qya', 'rap', 'rif', 'rm', 'rn', 'ro', 'rom', 'ru', 'rue', 'rw', 'sa', 'sah', 'sc', 'scn', 'sco', 'sd', 'sdh', 'se', 'sg', 'sgs', 'shs', 'shy', 'si', 'sjn', 'sl', 'sm', 'sma', 'sn', 'so', 'sq', 'sr', 'stq', 'su', 'sux', 'sv', 'swg', 'swh', 'syc', 'ta', 'te', 'tet', 'tg', 'th', 'thv', 'ti', 'tig', 'tk', 'tl', 'tlh', 'tly', 'tmr', 'tmw', 'tn', 'to', 'toi', 'tok', 'tpi', 'tpw', 'tr', 'ts', 'tt', 'tts', 'tvl', 'ty', 'tyv', 'tzl', 'udm', 'ug', 'uk', 'umb', 'ur', 'uz', 'vec', 'vep', 'vi', 'vo', 'vro', 'wa', 'war', 'wo', 'wuu', 'xal', 'xh', 'xqa', 'yi', 'yo', 'yue', 'zlm', 'zsm', 'zu', 'zza'], 'license': ['cc-by-2.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'tatoeba', 'pretty_name': 'Tatoeba'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2815\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: tatoeba\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ted_hrlr\n",
       " \tsha: 659fabbbc602455d478f794b232f785bdd2538a7\n",
       " \tlastModified: 2022-09-01T05:05:23.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:az', 'language:be', 'language:en', 'language:es', 'language:fr', 'language:gl', 'language:he', 'language:it', 'language:pt', 'language:ru', 'language:tr', 'language_creators:expert-generated', 'license:cc-by-nc-nd-4.0', 'multilinguality:translation', 'size_categories:1M<n<10M', 'source_datasets:extended|ted_talks_iwslt', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Data sets derived from TED talk transcripts for comparing similar language pairs\n",
       " where one is high resource and the other is low resource.\n",
       " \tcitation: @inproceedings{Ye2018WordEmbeddings,\n",
       "   author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
       "   title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
       "   booktitle = {HLT-NAACL},\n",
       "   year    = {2018},\n",
       "   }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['az', 'be', 'en', 'es', 'fr', 'gl', 'he', 'it', 'pt', 'ru', 'tr'], 'language_creators': ['expert-generated'], 'license': ['cc-by-nc-nd-4.0'], 'multilinguality': ['translation'], 'pretty_name': 'TEDHrlr', 'size_categories': ['1M<n<10M'], 'source_datasets': ['extended|ted_talks_iwslt'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3218\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ted_iwlst2013\n",
       " \tsha: 1dadbcc2fdce9d3ea549cc1c1d50c7166159af64\n",
       " \tlastModified: 2022-08-11T12:57:38.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fa', 'language:fr', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sl', 'language:tr', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'configs:ar-en', 'configs:de-en', 'configs:en-es', 'configs:en-fa', 'configs:en-fr', 'configs:en-it', 'configs:en-nl', 'configs:en-pl', 'configs:en-pt', 'configs:en-ro', 'configs:en-ru', 'configs:en-sl', 'configs:en-tr', 'configs:en-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A parallel corpus of TED talk subtitles provided by CASMACAT: http://www.casmacat.eu/corpus/ted2013.html. The files are originally provided by https://wit3.fbk.eu.\n",
       " \n",
       " 15 languages, 14 bitexts\n",
       " total number of files: 28\n",
       " total number of tokens: 67.67M\n",
       " total number of sentence fragments: 3.81M\n",
       " \tcitation: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'de', 'en', 'es', 'fa', 'fr', 'it', 'nl', 'pl', 'pt', 'ro', 'ru', 'sl', 'tr', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'TedIwlst2013', 'configs': ['ar-en', 'de-en', 'en-es', 'en-fa', 'en-fr', 'en-it', 'en-nl', 'en-pl', 'en-pt', 'en-ro', 'en-ru', 'en-sl', 'en-tr', 'en-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ted_multi\n",
       " \tsha: 6f842ca258ab718b493cb6754d9e68be6c9d8a0e\n",
       " \tlastModified: 2022-05-04T18:35:02.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Massively multilingual (60 language) data set derived from TED Talk transcripts.\n",
       " Each record consists of parallel arrays of language and text. Missing and\n",
       " incomplete translations will be filtered out.\n",
       " \tcitation: @InProceedings{qi-EtAl:2018:N18-2,\n",
       "   author    = {Qi, Ye  and  Sachan, Devendra  and  Felix, Matthieu  and  Padmanabhan, Sarguna  and  Neubig, Graham},\n",
       "   title     = {When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\n",
       "   booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\n",
       "   month     = {June},\n",
       "   year      = {2018},\n",
       "   address   = {New Orleans, Louisiana},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {529--535},\n",
       "   abstract  = {The performance of Neural Machine Translation (NMT) systems often suffers in low-resource scenarios where sufficiently large-scale parallel corpora cannot be obtained. Pre-trained word embeddings have proven to be invaluable for improving performance in natural language analysis tasks, which often suffer from paucity of data. However, their utility for NMT has not been extensively explored. In this work, we perform five sets of experiments that analyze when we can expect pre-trained word embeddings to help in NMT tasks. We show that such embeddings can be surprisingly effective in some cases -- providing gains of up to 20 BLEU points in the most favorable setting.},\n",
       "   url       = {http://www.aclweb.org/anthology/N18-2084}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'TEDMulti', 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 744\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ted_talks_iwslt\n",
       " \tsha: b4a329f0a0baab2f7d272b43e36a71a93ca0716f\n",
       " \tlastModified: 2022-09-30T15:42:04.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:af', 'language:am', 'language:ar', 'language:arq', 'language:art', 'language:as', 'language:ast', 'language:az', 'language:be', 'language:bg', 'language:bi', 'language:bn', 'language:bo', 'language:bs', 'language:ca', 'language:ceb', 'language:cnh', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fil', 'language:fr', 'language:ga', 'language:gl', 'language:gu', 'language:ha', 'language:he', 'language:hi', 'language:hr', 'language:ht', 'language:hu', 'language:hup', 'language:hy', 'language:id', 'language:ig', 'language:inh', 'language:is', 'language:it', 'language:ja', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ku', 'language:ky', 'language:la', 'language:lb', 'language:lo', 'language:lt', 'language:ltg', 'language:lv', 'language:mg', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:ne', 'language:nl', 'language:nn', 'language:oc', 'language:pa', 'language:pl', 'language:ps', 'language:pt', 'language:ro', 'language:ru', 'language:rup', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tl', 'language:tlh', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:zh', 'language_bcp47:art-x-bork', 'language_bcp47:fr-CA', 'language_bcp47:pt-BR', 'language_bcp47:zh-CN', 'language_bcp47:zh-TW', 'license:cc-by-nc-nd-4.0', 'multilinguality:translation', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation', 'configs:de_ja_2014', 'configs:de_ja_2015', 'configs:de_ja_2016', 'configs:eu_ca_2014', 'configs:eu_ca_2015', 'configs:eu_ca_2016', 'configs:fr-ca_hi_2014', 'configs:fr-ca_hi_2015', 'configs:fr-ca_hi_2016', 'configs:nl_en_2014', 'configs:nl_en_2015', 'configs:nl_en_2016', 'configs:nl_hi_2014', 'configs:nl_hi_2015', 'configs:nl_hi_2016']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The core of WIT3 is the TED Talks corpus, that basically redistributes the original content published by the TED Conference website (http://www.ted.com). Since 2007,\n",
       " the TED Conference, based in California, has been posting all video recordings of its talks together with subtitles in English\n",
       " and their translations in more than 80 languages. Aside from its cultural and social relevance, this content, which is published under the Creative Commons BYNC-ND license, also represents a precious\n",
       " language resource for the machine translation research community, thanks to its size, variety of topics, and covered languages.\n",
       " This effort repurposes the original content in a way which is more convenient for machine translation researchers.\n",
       " \tcitation: @inproceedings{cettolo-etal-2012-wit3,\n",
       "     title = \"{WIT}3: Web Inventory of Transcribed and Translated Talks\",\n",
       "     author = \"Cettolo, Mauro  and\n",
       "       Girardi, Christian  and\n",
       "       Federico, Marcello\",\n",
       "     booktitle = \"Proceedings of the 16th Annual conference of the European Association for Machine Translation\",\n",
       "     month = may # \" 28{--}30\",\n",
       "     year = \"2012\",\n",
       "     address = \"Trento, Italy\",\n",
       "     publisher = \"European Association for Machine Translation\",\n",
       "     url = \"https://www.aclweb.org/anthology/2012.eamt-1.60\",\n",
       "     pages = \"261--268\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['af', 'am', 'ar', 'arq', 'art', 'as', 'ast', 'az', 'be', 'bg', 'bi', 'bn', 'bo', 'bs', 'ca', 'ceb', 'cnh', 'cs', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fil', 'fr', 'ga', 'gl', 'gu', 'ha', 'he', 'hi', 'hr', 'ht', 'hu', 'hup', 'hy', 'id', 'ig', 'inh', 'is', 'it', 'ja', 'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', 'lt', 'ltg', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'ne', 'nl', 'nn', 'oc', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'rup', 'sh', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'sv', 'sw', 'szl', 'ta', 'te', 'tg', 'th', 'tl', 'tlh', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'zh'], 'language_bcp47': ['art-x-bork', 'fr-CA', 'pt-BR', 'zh-CN', 'zh-TW'], 'license': ['cc-by-nc-nd-4.0'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'Web Inventory of Transcribed & Translated (WIT) Ted Talks', 'configs': ['de_ja_2014', 'de_ja_2015', 'de_ja_2016', 'eu_ca_2014', 'eu_ca_2015', 'eu_ca_2016', 'fr-ca_hi_2014', 'fr-ca_hi_2015', 'fr-ca_hi_2016', 'nl_en_2014', 'nl_en_2015', 'nl_en_2016', 'nl_hi_2014', 'nl_hi_2015', 'nl_hi_2016']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2621\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: telugu_books\n",
       " \tsha: bd6b41ffb757a8f41f30a0ca6f3e900fe2376add\n",
       " \tlastModified: 2022-07-01T11:56:37.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:te', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is created by scraping telugu novels from teluguone.com this dataset can be used for nlp tasks like topic modeling, word embeddings, transfer learning etc\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title = {Indic NLP - Natural Language Processing for Indian Languages},\n",
       " authors = {Sudalai Rajkumar, Anusha Motamarri},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['te'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'TeluguBooks'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 318\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: telugu_news\n",
       " \tsha: 4118f6c445af1543b94ad4e1f1e4e16194dd14ef\n",
       " \tlastModified: 2022-08-24T04:09:37.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:other', 'language:te', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:multi-class-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset contains Telugu language news articles along with respective\n",
       " topic labels (business, editorial, entertainment, nation, sport) extracted from\n",
       " the daily Andhra Jyoti. This dataset could be used to build Classification and Language Models.\n",
       " \tcitation: @InProceedings{kaggle:dataset,\n",
       " title = {Telugu News - Natural Language Processing for Indian Languages},\n",
       " authors={Sudalai Rajkumar, Anusha Motamarri},\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['other'], 'language': ['te'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'multi-class-classification', 'topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'TeluguNews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 320\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tep_en_fa_para\n",
       " \tsha: 2c563ac714b233922f80597a125bed596ec6983d\n",
       " \tlastModified: 2022-07-01T11:56:38.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:fa', 'license:unknown', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TEP: Tehran English-Persian parallel corpus. The first free Eng-Per corpus, provided by the Natural Language and Text Processing Laboratory, University of Tehran.\n",
       " \tcitation: @InProceedings{“TEP: Tehran English-Persian Parallel Corpus”,\n",
       " title = {TEP: Tehran English-Persian Parallel Corpus”, in proceedings of 12th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2011)},\n",
       " authors={M. T. Pilevar, H. Faili, and A. H. Pilevar, },\n",
       " year={2011}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'fa'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'TepEnFaPara'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 321\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: text2log\n",
       " \tsha: 34db183432c4adb098fc324239efbb3a8744f52d\n",
       " \tlastModified: 2022-07-01T11:56:39.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The dataset contains about 100,000 simple English sentences selected and filtered from enTenTen15 and their translation into First Order Logic (FOL) Lambda Dependency-based Compositional Semantics using ccg2lambda.\n",
       " \tcitation: @INPROCEEDINGS{9401852,  author={Levkovskyi, Oleksii and Li, Wei},  booktitle={SoutheastCon 2021},   title={Generating Predicate Logic Expressions from Natural Language},   year={2021},  volume={},  number={},  pages={1-8},  doi={10.1109/SoutheastCon45413.2021.9401852}}\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'text2log', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: thai_toxicity_tweet\n",
       " \tsha: 0f5230d19861f08f6051b48186abe933102fd7c0\n",
       " \tlastModified: 2022-07-01T11:56:40.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:cc-by-nc-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Thai Toxicity Tweet Corpus contains 3,300 tweets annotated by humans with guidelines including a 44-word dictionary.\n",
       " The author obtained 2,027 and 1,273 toxic and non-toxic tweets, respectively; these were labeled by three annotators. The result of corpus\n",
       " analysis indicates that tweets that include toxic words are not always toxic. Further, it is more likely that a tweet is toxic, if it contains\n",
       " toxic words indicating their original meaning. Moreover, disagreements in annotation are primarily because of sarcasm, unclear existing\n",
       " target, and word sense ambiguity.\n",
       " \n",
       " Notes from data cleaner: The data is included into [huggingface/datasets](https://www.github.com/huggingface/datasets) in Dec 2020.\n",
       " By this time, 506 of the tweets are not available publicly anymore. We denote these by `TWEET_NOT_FOUND` in `tweet_text`.\n",
       " Processing can be found at [this PR](https://github.com/tmu-nlp/ThaiToxicityTweetCorpus/pull/1).\n",
       " \tcitation: @article{sirihattasak2019annotation,\n",
       "   title={Annotation and Classification of Toxicity for Thai Twitter},\n",
       "   author={Sirihattasak, Sugan and Komachi, Mamoru and Ishikawa, Hiroshi},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['cc-by-nc-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'ThaiToxicityTweet'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 660\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: thainer\n",
       " \tsha: 18d072efcbac1cfd9afd72a03a53869617eeedfb\n",
       " \tlastModified: 2022-07-19T12:42:03.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language_creators:expert-generated', 'language:th', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-tirasaroj-aroonmanakun', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ThaiNER (v1.3) is a 6,456-sentence named entity recognition dataset created from expanding the 2,258-sentence\n",
       " [unnamed dataset](http://pioneer.chula.ac.th/~awirote/Data-Nutcha.zip) by\n",
       " [Tirasaroj and Aroonmanakun (2012)](http://pioneer.chula.ac.th/~awirote/publications/).\n",
       " It is used to train NER taggers in [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp).\n",
       " The NER tags are annotated by [Tirasaroj and Aroonmanakun (2012)]((http://pioneer.chula.ac.th/~awirote/publications/))\n",
       " for 2,258 sentences and the rest by [@wannaphong](https://github.com/wannaphong/).\n",
       " The POS tags are done by [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp)'s `perceptron` engine trained on `orchid_ud`.\n",
       " [@wannaphong](https://github.com/wannaphong/) is now the only maintainer of this dataset.\n",
       " \tcitation: @misc{Wannaphong Phatthiyaphaibun_2019,\n",
       "     title={wannaphongcom/thai-ner: ThaiNER 1.3},\n",
       "     url={https://zenodo.org/record/3550546},\n",
       "     DOI={10.5281/ZENODO.3550546},\n",
       "     abstractNote={Thai Named Entity Recognition},\n",
       "     publisher={Zenodo},\n",
       "     author={Wannaphong Phatthiyaphaibun},\n",
       "     year={2019},\n",
       "     month={Nov}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['found', 'expert-generated'], 'language': ['th'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-tirasaroj-aroonmanakun'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition', 'part-of-speech'], 'paperswithcode_id': None, 'pretty_name': 'thainer'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 359\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: thaiqa_squad\n",
       " \tsha: 638f50164d3d9d87e34c61beccd4050f65fd2826\n",
       " \tlastModified: 2022-08-24T04:09:37.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:cc-by-nc-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-thaiqa', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: `thaiqa_squad` is an open-domain, extractive question answering dataset (4,000 questions in `train` and 74 questions in `dev`) in\n",
       " [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format, originally created by [NECTEC](https://www.nectec.or.th/en/) from\n",
       " Wikipedia articles and adapted to [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format by [PyThaiNLP](https://github.com/PyThaiNLP/).\n",
       " \tcitation: No clear citation guidelines from source:\n",
       " https://aiforthai.in.th/corpus.php\n",
       " SQuAD version:\n",
       " https://github.com/PyThaiNLP/thaiqa_squad\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['cc-by-nc-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-thaiqa'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'thaiqa-squad'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 346\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: thaisum\n",
       " \tsha: b2d5394703a3adf38f616b1e2af63eb68f690ad0\n",
       " \tlastModified: 2022-07-01T11:56:42.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:th', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath,\n",
       " ThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs\n",
       " written by journalists.\n",
       " \tcitation: @mastersthesis{chumpolsathien_2020,\n",
       "     title={Using Knowledge Distillation from Keyword Extraction to Improve the Informativeness of Neural Cross-lingual Summarization},\n",
       "     author={Chumpolsathien, Nakhun},\n",
       "     year={2020},\n",
       "     school={Beijing Institute of Technology}\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['th'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization', 'text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'ThaiSum'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 374\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: the_pile\n",
       " \tsha: 79dddea46c0dae1bcb23d79d0a599e9ea84d8e87\n",
       " \tlastModified: 2022-10-10T11:46:34.000Z\n",
       " \ttags: ['arxiv:2101.00027', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:unknown', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Pile is a 825 GiB diverse, open source language modelling data set that consists of 22 smaller, high-quality\n",
       " datasets combined together.\n",
       " \tcitation: @misc{gao2020pile,\n",
       "       title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling},\n",
       "       author={Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy},\n",
       "       year={2020},\n",
       "       eprint={2101.00027},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'The Pile', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2702\n",
       " \tlikes: 11\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: the_pile_books3\n",
       " \tsha: 91fe399ed7335fd7240f030f4006dc9b3d4fd9fe\n",
       " \tlastModified: 2022-07-01T11:56:43.000Z\n",
       " \ttags: ['arxiv:2101.00027', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is Shawn Presser's work and is part of EleutherAi/The Pile dataset. This dataset contains all of bibliotik in plain .txt form, aka 197,000 books processed in exactly the same way as did for bookcorpusopen (a.k.a. books1). seems to be similar to OpenAI's mysterious \"books2\" dataset referenced in their papers. Unfortunately OpenAI will not give details, so we know very little about any differences. People suspect it's \"all of libgen\", but it's purely conjecture.\n",
       " \tcitation: @article{pile,\n",
       "     title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n",
       "     author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n",
       "     journal={arXiv preprint arXiv:2101.00027},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Books3', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 361\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: the_pile_openwebtext2\n",
       " \tsha: 4f322d225797146145ec38aba9c504ce864467ed\n",
       " \tlastModified: 2022-08-11T16:23:45.000Z\n",
       " \ttags: ['arxiv:2101.00027', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:text-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: OpenWebText2 is part of EleutherAi/The Pile dataset and is an enhanced version of the original OpenWebTextCorpus covering all Reddit submissions from 2005 up until April 2020, with further months becoming available after the corresponding PushShift dump files are released.\n",
       " \tcitation: @article{pile,\n",
       "     title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n",
       "     author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n",
       "     journal={arXiv preprint arXiv:2101.00027},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'OpenWebText2', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'text-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'text-scoring']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 203\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: the_pile_stack_exchange\n",
       " \tsha: 20a52b99a8d2ee7191bfa2254480834344fc8e54\n",
       " \tlastModified: 2022-08-14T10:29:20.000Z\n",
       " \ttags: ['arxiv:2101.00027', 'annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset is part of EleutherAI/The Pile dataset and is a dataset for Language Models from processing stackexchange data dump, which is an anonymized dump of all user-contributed content on the Stack Exchange network.\n",
       " \tcitation: @article{pile,\n",
       "     title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n",
       "     author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n",
       "     journal={arXiv preprint arXiv:2101.00027},\n",
       "     year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Stack Exchange', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tilde_model\n",
       " \tsha: ed91f1446ae2c637f23fd19de1a0a229e69e07d6\n",
       " \tlastModified: 2022-08-11T12:57:38.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:bg', 'language:cs', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:fi', 'language:fr', 'language:hr', 'language:hu', 'language:is', 'language:it', 'language:lt', 'language:lv', 'language:mt', 'language:nl', 'language:no', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sk', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:tr', 'language:uk', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is the Tilde MODEL Corpus – Multilingual Open Data for European Languages.\n",
       " \n",
       " The data has been collected from sites allowing free use and reuse of its content, as well as from Public Sector web sites. The activities have been undertaken as part of the ODINE Open Data Incubator for Europe, which aims to support the next generation of digital businesses and fast-track the development of new products and services. The corpus includes the following parts:\n",
       " Tilde MODEL - EESC is a multilingual corpus compiled from document texts of European Economic and Social Committee document portal. Source: http://dm.eesc.europa.eu/\n",
       " Tilde MODEL - RAPID multilingual parallel corpus is compiled from all press releases of Press Release Database of European Commission released between 1975 and end of 2016 as available from http://europa.eu/rapid/\n",
       " Tilde MODEL - ECB multilingual parallel corpus is compiled from the multilingual pages of European Central Bank web site http://ebc.europa.eu/\n",
       " Tilde MODEL - EMA is a corpus compiled from texts of European Medicines Agency document portal as available in http://www.ema.europa.eu/ at the end of 2016\n",
       " Tilde MODEL - World Bank is a corpus compiled from texts of World Bank as available in http://www.worldbank.org/ in 2017\n",
       " Tilde MODEL - AirBaltic.com Travel Destinations is a multilingual parallel corpus compiled from description texts of AirBaltic.com travel destinations as available in https://www.airbaltic.com/en/destinations/ in 2017\n",
       " Tilde MODEL - LiveRiga.com is a multilingual parallel corpus compiled from Riga tourist attractions description texts of http://liveriga.com/ web site in 2017\n",
       " Tilde MODEL - Lithuanian National Philharmonic Society is a parallel corpus compiled from texts of Lithuanian National Philharmonic Society web site http://www.filharmonija.lt/ in 2017\n",
       " Tilde MODEL - mupa.hu is a parallel corpus from texts of Müpa Budapest - web site of Hungarian national culture house and concert venue https://www.mupa.hu/en/ compiled in spring of 2017\n",
       " Tilde MODEL - fold.lv is a parallel corpus from texts of fold.lv portal http://www.fold.lv/en/ of the best of Latvian and foreign creative industries as compiled in spring of 2017\n",
       " Tilde MODEL - czechtourism.com is a multilingual parallel corpus from texts of http://czechtourism.com/ portal compiled in spring of 2017\n",
       " 30 languages, 274 bitexts\n",
       " total number of files: 125\n",
       " total number of tokens: 1.43G\n",
       " total number of sentence fragments: 62.44M\n",
       " \tcitation: Roberts Rozis, Raivis Skadins, 2017, Tilde MODEL - Multilingual Open Data for EU Languages. Proceedings of the 21th Nordic Conference of Computational Linguistics NODALIDA 2017\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hr', 'hu', 'is', 'it', 'lt', 'lv', 'mt', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sq', 'sr', 'sv', 'tr', 'uk'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'tilde-model-corpus', 'pretty_name': 'Tilde Multilingual Open Data for European Languages'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 947\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: tilde-model-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: time_dial\n",
       " \tsha: d868e77b4b162ee36c8490e81f7aa528d90a2df2\n",
       " \tlastModified: 2022-07-01T11:56:45.000Z\n",
       " \ttags: ['arxiv:2106.04571', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification', 'task_ids:text-classification-other-dialog-act-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TimeDial presents a crowdsourced English challenge set, for temporal commonsense reasoning, formulated\n",
       " as a multiple choice cloze task with around 1.5k carefully curated dialogs. The dataset is derived from\n",
       " the DailyDialog (Li et al., 2017), which is a multi-turn dialog corpus.\n",
       " \n",
       " In order to establish strong baselines and provide information on future model development, we\n",
       " conducted extensive experiments with state-of-the-art LMs. While humans can easily answer these\n",
       " questions (97.8%), the best T5 model variant struggles on this challenge set (73%). Moreover, our\n",
       " qualitative error analyses show that the models often rely on shallow, spurious features (particularly text\n",
       " matching), instead of truly doing reasoning over the context.\n",
       " \tcitation: @inproceedings{qin-etal-2021-timedial,\n",
       "     title = \"{TimeDial: Temporal Commonsense Reasoning in Dialog}\",\n",
       "     author = \"Qin, Lianhui and Gupta, Aditya and Upadhyay, Shyam and He, Luheng and Choi, Yejin and Faruqui, Manaal\",\n",
       "     booktitle = \"Proc. of ACL\",\n",
       "     year = \"2021\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'TimeDial: Temporal Commonsense Reasoning in Dialog', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification', 'text-classification-other-dialog-act-classification'], 'paperswithcode_id': 'timedial'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 319\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: timedial\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: times_of_india_news_headlines\n",
       " \tsha: ab6e93eba9fe7afa7d9edb60b9916639cfbe9278\n",
       " \tlastModified: 2022-07-01T11:56:47.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:en', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:text-retrieval', 'task_ids:document-retrieval', 'task_ids:fact-checking-retrieval', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.\n",
       " \tcitation: @data{DVN/DPQMQH_2020,\n",
       " author = {Kulkarni, Rohit},\n",
       " publisher = {Harvard Dataverse},\n",
       " title = {{Times of India News Headlines}},\n",
       " year = {2020},\n",
       " version = {V1},\n",
       " doi = {10.7910/DVN/DPQMQH},\n",
       " url = {https://doi.org/10.7910/DVN/DPQMQH}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'text-retrieval'], 'task_ids': ['document-retrieval', 'fact-checking-retrieval', 'text-simplification'], 'paperswithcode_id': None, 'pretty_name': 'Times of India News Headlines'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: timit_asr\n",
       " \tsha: 9ddd9641d196d15a30489a1a2ab46cf4d1b63e65\n",
       " \tlastModified: 2022-07-01T12:43:45.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The TIMIT corpus of reading speech has been developed to provide speech data for acoustic-phonetic research studies\n",
       " and for the evaluation of automatic speech recognition systems.\n",
       " \n",
       " TIMIT contains high quality recordings of 630 individuals/speakers with 8 different American English dialects,\n",
       " with each individual reading upto 10 phonetically rich sentences.\n",
       " \n",
       " More info on TIMIT dataset can be understood from the \"README\" which can be found here:\n",
       " https://catalog.ldc.upenn.edu/docs/LDC93S1/readme.txt\n",
       " \tcitation: @inproceedings{\n",
       "   title={TIMIT Acoustic-Phonetic Continuous Speech Corpus},\n",
       "   author={Garofolo, John S., et al},\n",
       "   ldc_catalog_no={LDC93S1},\n",
       "   DOI={https://doi.org/10.35111/17gk-bn40},\n",
       "   journal={Linguistic Data Consortium, Philadelphia},\n",
       "   year={1983}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'TIMIT', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['other'], 'license_details': 'LDC-User-Agreement-for-Non-Members', 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'paperswithcode_id': 'timit', 'train-eval-index': [{'config': 'clean', 'task': 'automatic-speech-recognition', 'task_id': 'speech_recognition', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'file': 'path', 'text': 'text'}, 'metrics': [{'type': 'wer', 'name': 'WER'}, {'type': 'cer', 'name': 'CER'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2102\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: timit\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tiny_shakespeare\n",
       " \tsha: eadd80f6d44f7082631902b698cf344c45c56cac\n",
       " \tlastModified: 2022-05-04T18:35:02.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: 40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n",
       " \n",
       " To use for e.g. character modelling:\n",
       " \n",
       " ```\n",
       " d = datasets.load_dataset(name='tiny_shakespeare')['train']\n",
       " d = d.map(lambda x: datasets.Value('strings').unicode_split(x['text'], 'UTF-8'))\n",
       " # train split includes vocabulary for other splits\n",
       " vocabulary = sorted(set(next(iter(d)).numpy()))\n",
       " d = d.map(lambda x: {'cur_char': x[:-1], 'next_char': x[1:]})\n",
       " d = d.unbatch()\n",
       " seq_len = 100\n",
       " batch_size = 2\n",
       " d = d.batch(seq_len)\n",
       " d = d.batch(batch_size)\n",
       " ```\n",
       " \tcitation: @misc{\n",
       "   author={Karpathy, Andrej},\n",
       "   title={char-rnn},\n",
       "   year={2015},\n",
       "   howpublished={\\\\url{https://github.com/karpathy/char-rnn}}\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': None, 'pretty_name': 'TinyShakespeare'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1660\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tlc\n",
       " \tsha: 7d58a90083326d8c3bcccfe9d35b74934bd41d99\n",
       " \tlastModified: 2022-07-01T11:56:48.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:no-annotation', 'language_creators:expert-generated', 'language:th', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Thai Literature Corpora (TLC): Corpora of machine-ingestible Thai classical literature texts.\n",
       " \n",
       " Release: 6/25/19\n",
       " \n",
       " It consists of two datasets:\n",
       " \n",
       " ## TLC set\n",
       " It is texts from [Vajirayana Digital Library](https://vajirayana.org/), stored by chapters and stanzas (non-tokenized).\n",
       " \n",
       " tlc v.2.0 (6/17/19 : a total of 34 documents, 292,270 lines, 31,790,734 characters)\n",
       " tlc v.1.0 (6/11/19 : a total of 25 documents, 113,981 lines, 28,775,761 characters)\n",
       " \n",
       " ## TNHC set\n",
       " It is texts from Thai National Historical Corpus, stored by lines (manually tokenized).\n",
       " \n",
       " tnhc v.1.0 (6/25/19 : a total of 47 documents, 756,478 lines, 13,361,142 characters)\n",
       " \tcitation: @misc{\n",
       "   author={Sawatphol, Jitkapat},\n",
       "   title={Thai Literature Corpora},\n",
       "   year={2019},\n",
       "   howpublished={\\\\url{https://attapol.github.io/tlc.html}}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Thai Literature Corpora (TLC)', 'annotations_creators': ['expert-generated', 'no-annotation'], 'language_creators': ['expert-generated'], 'language': ['th'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 634\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tmu_gfm_dataset\n",
       " \tsha: 54aa17e648a49535e8280bc91c39611821c60902\n",
       " \tlastModified: 2022-07-01T11:56:48.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-grammatical-error-correction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset for GEC metrics with manual evaluations of grammaticality, fluency, and meaning preservation for system outputs. More detail about the creation of the dataset can be found in Yoshimura et al. (2020).\n",
       " \tcitation: @inproceedings{yoshimura-etal-2020-reference,\n",
       "     title = \"{SOME}: Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction\",\n",
       "     author = \"Yoshimura, Ryoma  and\n",
       "       Kaneko, Masahiro  and\n",
       "       Kajiwara, Tomoyuki  and\n",
       "       Komachi, Mamoru\",\n",
       "     booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\n",
       "     month = dec,\n",
       "     year = \"2020\",\n",
       "     address = \"Barcelona, Spain (Online)\",\n",
       "     publisher = \"International Committee on Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.coling-main.573\",\n",
       "     pages = \"6516--6522\",\n",
       "     abstract = \"We propose a reference-less metric trained on manual evaluations of system outputs for grammatical error correction (GEC). Previous studies have shown that reference-less metrics are promising; however, existing metrics are not optimized for manual evaluations of the system outputs because no dataset of the system output exists with manual evaluation. This study manually evaluates outputs of GEC systems to optimize the metrics. Experimental results show that the proposed metric improves correlation with the manual evaluation in both system- and sentence-level meta-evaluation. Our dataset and metric will be made publicly available.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-grammatical-error-correction'], 'paperswithcode_id': None, 'pretty_name': 'TMU-GFM-Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 527\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: told-br\n",
       " \tsha: d31c200625d96c8bf81fc231377d8666fc8082c4\n",
       " \tlastModified: 2022-07-27T14:39:09.000Z\n",
       " \ttags: ['arxiv:2010.04543', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:pt', 'language_bcp47:pt-BR', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced\n",
       " by 42 annotators selected from a pool of 129 volunteers. Annotators were selected aiming\n",
       " to create a plural group in terms of demographics (ethnicity, sexual orientation, age, gender).\n",
       " Each tweet was labeled by three annotators in 6 possible categories:\n",
       " LGBTQ+phobia,Xenophobia, Obscene, Insult, Misogyny and Racism.\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2010-04543,\n",
       "   author    = {Joao Augusto Leite and\n",
       "                Diego F. Silva and\n",
       "                Kalina Bontcheva and\n",
       "                Carolina Scarton},\n",
       "   title     = {Toxic Language Detection in Social Media for Brazilian Portuguese:\n",
       "                New Dataset and Multilingual Analysis},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2010.04543},\n",
       "   year      = {2020},\n",
       "   url       = {https://arxiv.org/abs/2010.04543},\n",
       "   eprinttype = {arXiv},\n",
       "   eprint    = {2010.04543},\n",
       "   timestamp = {Tue, 15 Dec 2020 16:10:16 +0100},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04543.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['pt'], 'language_bcp47': ['pt-BR'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'ToLD-Br', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-detection'], 'paperswithcode_id': 'told-br'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 477\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: told-br\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: totto\n",
       " \tsha: 74daf1803d935e4d31613152ab9ca067b4f649b3\n",
       " \tlastModified: 2022-07-01T11:56:51.000Z\n",
       " \ttags: ['arxiv:2004.14373', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:table-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ToTTo is an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description.\n",
       " \tcitation: @inproceedings{parikh2020totto,\n",
       "   title={{ToTTo}: A Controlled Table-To-Text Generation Dataset},\n",
       "   author={Parikh, Ankur P and Wang, Xuezhi and Gehrmann, Sebastian and Faruqui, Manaal and Dhingra, Bhuwan and Yang, Diyi and Das, Dipanjan},\n",
       "   booktitle={Proceedings of EMNLP},\n",
       "   year={2020}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['table-to-text'], 'task_ids': [], 'paperswithcode_id': 'totto', 'pretty_name': 'ToTTo'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1019\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: totto\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: trec\n",
       " \tsha: 1f97567bdd2adedefe8abdaa9bd6ee0e6725b458\n",
       " \tlastModified: 2022-08-22T16:14:46.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language:en', 'language_creators:expert-generated', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Text REtrieval Conference (TREC) Question Classification dataset contains 5500 labeled questions in training set and another 500 for test set.\n",
       " \n",
       " The dataset has 6 coarse class labels and 50 fine class labels. Average length of each sentence is 10, vocabulary size of 8700.\n",
       " \n",
       " Data are collected from four sources: 4,500 English questions published by USC (Hovy et al., 2001), about 500 manually constructed questions for a few rare classes, 894 TREC 8 and TREC 9 questions, and also 500 questions from TREC 10 which serves as the test set. These questions were manually labeled.\n",
       " \tcitation: @inproceedings{li-roth-2002-learning,\n",
       "     title = \"Learning Question Classifiers\",\n",
       "     author = \"Li, Xin  and\n",
       "       Roth, Dan\",\n",
       "     booktitle = \"{COLING} 2002: The 19th International Conference on Computational Linguistics\",\n",
       "     year = \"2002\",\n",
       "     url = \"https://www.aclweb.org/anthology/C02-1150\",\n",
       " }\n",
       " @inproceedings{hovy-etal-2001-toward,\n",
       "     title = \"Toward Semantics-Based Answer Pinpointing\",\n",
       "     author = \"Hovy, Eduard  and\n",
       "       Gerber, Laurie  and\n",
       "       Hermjakob, Ulf  and\n",
       "       Lin, Chin-Yew  and\n",
       "       Ravichandran, Deepak\",\n",
       "     booktitle = \"Proceedings of the First International Conference on Human Language Technology Research\",\n",
       "     year = \"2001\",\n",
       "     url = \"https://www.aclweb.org/anthology/H01-1069\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language': ['en'], 'language_creators': ['expert-generated'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Text Retrieval Conference Question Answering', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'paperswithcode_id': 'trecqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 85203\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: trecqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: trivia_qa\n",
       " \tsha: 826e3a12bac7b0bc83ff0c9288658b71d3146e3f\n",
       " \tlastModified: 2022-07-01T11:56:51.000Z\n",
       " \ttags: ['arxiv:1705.03551', 'annotations_creators:crowdsourced', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text2text-generation', 'task_ids:open-domain-qa', 'task_ids:open-domain-abstractive-qa', 'task_ids:extractive-qa', 'task_ids:abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TriviaqQA is a reading comprehension dataset containing over 650K\n",
       " question-answer-evidence triples. TriviaqQA includes 95K question-answer\n",
       " pairs authored by trivia enthusiasts and independently gathered evidence\n",
       " documents, six per question on average, that provide high quality distant\n",
       " supervision for answering the questions.\n",
       " \tcitation: @article{2017arXivtriviaqa,\n",
       "        author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},\n",
       "                  Daniel and {Zettlemoyer}, Luke},\n",
       "         title = \"{triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2017,\n",
       "           eid = {arXiv:1705.03551},\n",
       "         pages = {arXiv:1705.03551},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1705.03551},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'triviaqa', 'pretty_name': 'TriviaQA', 'size_categories': ['10K<n<100K', '100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text2text-generation'], 'task_ids': ['open-domain-qa', 'open-domain-abstractive-qa', 'extractive-qa', 'abstractive-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 67838\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: triviaqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tsac\n",
       " \tsha: fb3d9fea01c15809f64d9cd5b3ad2fd275998f2c\n",
       " \tlastModified: 2022-07-01T11:56:52.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:aeb', 'license:lgpl-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Tunisian Sentiment Analysis Corpus.\n",
       " \n",
       " About 17k user comments manually annotated to positive and negative polarities. This corpus is collected from Facebook users comments written on official pages of Tunisian radios and TV channels namely Mosaique FM, JawhraFM, Shemes FM, HiwarElttounsi TV and Nessma TV. The corpus is collected from a period spanning January 2015 until June 2016.\n",
       " \tcitation: @inproceedings{medhaffar-etal-2017-sentiment,\n",
       "     title = \"Sentiment Analysis of {T}unisian Dialects: Linguistic Ressources and Experiments\",\n",
       "     author = \"Medhaffar, Salima  and\n",
       "       Bougares, Fethi  and\n",
       "       Est{`e}ve, Yannick  and\n",
       "       Hadrich-Belguith, Lamia\",\n",
       "     booktitle = \"Proceedings of the Third {A}rabic Natural Language Processing Workshop\",\n",
       "     month = apr,\n",
       "     year = \"2017\",\n",
       "     address = \"Valencia, Spain\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/W17-1307\",\n",
       "     doi = \"10.18653/v1/W17-1307\",\n",
       "     pages = \"55--61\",\n",
       "     abstract = \"Dialectal Arabic (DA) is significantly different from the Arabic language taught in schools and used in written communication and formal speech (broadcast news, religion, politics, etc.). There are many existing researches in the field of Arabic language Sentiment Analysis (SA); however, they are generally restricted to Modern Standard Arabic (MSA) or some dialects of economic or political interest. In this paper we are interested in the SA of the Tunisian Dialect. We utilize Machine Learning techniques to determine the polarity of comments written in Tunisian Dialect. First, we evaluate the SA systems performances with models trained using freely available MSA and Multi-dialectal data sets. We then collect and annotate a Tunisian Dialect corpus of 17.000 comments from Facebook. This corpus allows us a significant accuracy improvement compared to the best model trained on other Arabic dialects or MSA data. We believe that this first freely available corpus will be valuable to researchers working in the field of Tunisian Sentiment Analysis and similar areas.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['aeb'], 'license': ['lgpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'tsac', 'pretty_name': 'Tunisian Sentiment Analysis Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 346\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: tsac\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ttc4900\n",
       " \tsha: dcbdfcd94914f89ccf7ca087afafe158d9339930\n",
       " \tlastModified: 2022-07-01T11:56:53.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-news-category-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The data set is taken from kemik group\n",
       " http://www.kemik.yildiz.edu.tr/\n",
       " The data are pre-processed for the text categorization, collocations are found, character set is corrected, and so forth.\n",
       " We named TTC4900 by mimicking the name convention of TTC 3600 dataset shared by the study http://journals.sagepub.com/doi/abs/10.1177/0165551515620551\n",
       " \n",
       " If you use the dataset in a paper, please refer https://www.kaggle.com/savasy/ttc4900 as footnote and cite one of the papers as follows:\n",
       " \n",
       " - A Comparison of Different Approaches to Document Representation in Turkish Language, SDU Journal of Natural and Applied Science, Vol 22, Issue 2, 2018\n",
       " - A comparative analysis of text classification for Turkish language, Pamukkale University Journal of Engineering Science Volume 25 Issue 5, 2018\n",
       " - A Knowledge-poor Approach to Turkish Text Categorization with a Comparative Analysis, Proceedings of CICLING 2014, Springer LNCS, Nepal, 2014.\n",
       " \tcitation: @article{doi:10.5505/pajes.2018.15931,\n",
       " author = {Yıldırım, Savaş and Yıldız, Tuğba},\n",
       " title = {A comparative analysis of text classification for Turkish language},\n",
       " journal = {Pamukkale Univ Muh Bilim Derg},\n",
       " volume = {24},\n",
       " number = {5},\n",
       " pages = {879-886},\n",
       " year = {2018},\n",
       " doi = {10.5505/pajes.2018.15931},\n",
       " note ={doi: 10.5505/pajes.2018.15931},\n",
       " \n",
       " URL = {https://dx.doi.org/10.5505/pajes.2018.15931},\n",
       " eprint = {https://dx.doi.org/10.5505/pajes.2018.15931}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-news-category-classification'], 'paperswithcode_id': None, 'pretty_name': 'TTC4900 - A Benchmark Data for Turkish Text Categorization'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tunizi\n",
       " \tsha: b925197e14a5f754196016517a7e60f18b4dc7bf\n",
       " \tlastModified: 2022-08-11T12:57:39.000Z\n",
       " \ttags: ['arxiv:2004.14303', 'annotations_creators:expert-generated', 'language_creators:found', 'language:aeb', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: On social media, Arabic speakers tend to express themselves in their own local dialect. To do so, Tunisians use \"Tunisian Arabizi\", which consists in supplementing numerals to the Latin script rather than the Arabic alphabet. TUNIZI is the first Tunisian Arabizi Dataset including 3K sentences, balanced, covering different topics, preprocessed and annotated as positive and negative.\n",
       " \tcitation: @inproceedings{Chayma2020,\n",
       " title={TUNIZI: a Tunisian Arabizi sentiment analysis Dataset},\n",
       " author={Fourati, Chayma and Messaoudi, Abir and Haddad, Hatem},\n",
       " booktitle={AfricaNLP Workshop, Putting Africa on the NLP Map. ICLR 2020, Virtual Event},\n",
       " volume = {arXiv:3091079},\n",
       " year = {2020},\n",
       " url = {https://arxiv.org/submit/3091079},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['aeb'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'tunizi', 'pretty_name': 'TUNIZI'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: tunizi\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tuple_ie\n",
       " \tsha: 0746a6fb6e5d5a2b8c986fa85f902149a8c4c5a3\n",
       " \tlastModified: 2022-07-01T11:56:54.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:machine-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:other', 'task_ids:other-other-open-information-extraction']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The TupleInf Open IE dataset contains Open IE tuples extracted from 263K sentences that were used by the solver in “Answering Complex Questions Using Open Information Extraction” (referred as Tuple KB, T). These sentences were collected from a large Web corpus using training questions from 4th and 8th grade as queries. This dataset contains 156K sentences collected for 4th grade questions and 107K sentences for 8th grade questions. Each sentence is followed by the Open IE v4 tuples using their simple format.\n",
       " \tcitation: @article{Khot2017AnsweringCQ,\n",
       "   title={Answering Complex Questions Using Open Information Extraction},\n",
       "   author={Tushar Khot and A. Sabharwal and Peter Clark},\n",
       "   journal={ArXiv},\n",
       "   year={2017},\n",
       "   volume={abs/1704.05572}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['other'], 'task_ids': ['other-other-open-information-extraction'], 'paperswithcode_id': 'tupleinf-open-ie-dataset', 'pretty_name': 'TupleInf Open IE'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 634\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: tupleinf-open-ie-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turk\n",
       " \tsha: 114e52a4f03874c39d531c8e8708108b160dd0ec\n",
       " \tlastModified: 2022-07-01T12:43:46.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TURKCorpus is a dataset for evaluating sentence simplification systems that focus on lexical paraphrasing,\n",
       " as described in \"Optimizing Statistical Machine Translation for Text Simplification\". The corpus is composed of 2000 validation and 359 test original sentences that were each simplified 8 times by different annotators.\n",
       " \tcitation:  @article{Xu-EtAl:2016:TACL,\n",
       "  author = {Wei Xu and Courtney Napoles and Ellie Pavlick and Quanze Chen and Chris Callison-Burch},\n",
       "  title = {Optimizing Statistical Machine Translation for Text Simplification},\n",
       "  journal = {Transactions of the Association for Computational Linguistics},\n",
       "  volume = {4},\n",
       "  year = {2016},\n",
       "  url = {https://cocoxu.github.io/publications/tacl2016-smt-simplification.pdf},\n",
       "  pages = {401--415}\n",
       "  }\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text-simplification'], 'paperswithcode_id': None, 'pretty_name': 'TURK'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 663\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turkic_xwmt\n",
       " \tsha: ef2e4403da09246628c235b265bcafb1643a60e0\n",
       " \tlastModified: 2022-07-01T11:56:55.000Z\n",
       " \ttags: ['arxiv:2109.04593', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:az', 'language:ba', 'language:en', 'language:kaa', 'language:kk', 'language:ky', 'language:ru', 'language:sah', 'language:tr', 'language:uz', 'license:mit', 'multilinguality:translation', 'size_categories:n<1K', 'task_categories:translation', 'source_datasets:extended|WMT 2020 News Translation Task', 'configs:az-ba', 'configs:az-en', 'configs:az-kaa', 'configs:az-kk', 'configs:az-ky', 'configs:az-ru', 'configs:az-sah', 'configs:az-tr', 'configs:az-uz', 'configs:ba-az', 'configs:ba-en', 'configs:ba-kaa', 'configs:ba-kk', 'configs:ba-ky', 'configs:ba-ru', 'configs:ba-sah', 'configs:ba-tr', 'configs:ba-uz', 'configs:en-az', 'configs:en-ba', 'configs:en-kaa', 'configs:en-kk', 'configs:en-ky', 'configs:en-ru', 'configs:en-sah', 'configs:en-tr', 'configs:en-uz', 'configs:kaa-az', 'configs:kaa-ba', 'configs:kaa-en', 'configs:kaa-kk', 'configs:kaa-ky', 'configs:kaa-ru', 'configs:kaa-sah', 'configs:kaa-tr', 'configs:kaa-uz', 'configs:kk-az', 'configs:kk-ba', 'configs:kk-en', 'configs:kk-kaa', 'configs:kk-ky', 'configs:kk-ru', 'configs:kk-sah', 'configs:kk-tr', 'configs:kk-uz', 'configs:ky-az', 'configs:ky-ba', 'configs:ky-en', 'configs:ky-kaa', 'configs:ky-kk', 'configs:ky-ru', 'configs:ky-sah', 'configs:ky-tr', 'configs:ky-uz', 'configs:ru-az', 'configs:ru-ba', 'configs:ru-en', 'configs:ru-kaa', 'configs:ru-kk', 'configs:ru-ky', 'configs:ru-sah', 'configs:ru-tr', 'configs:ru-uz', 'configs:sah-az', 'configs:sah-ba', 'configs:sah-en', 'configs:sah-kaa', 'configs:sah-kk', 'configs:sah-ky', 'configs:sah-ru', 'configs:sah-tr', 'configs:sah-uz', 'configs:tr-az', 'configs:tr-ba', 'configs:tr-en', 'configs:tr-kaa', 'configs:tr-kk', 'configs:tr-ky', 'configs:tr-ru', 'configs:tr-sah', 'configs:tr-uz', 'configs:uz-az', 'configs:uz-ba', 'configs:uz-en', 'configs:uz-kaa', 'configs:uz-kk', 'configs:uz-ky', 'configs:uz-ru', 'configs:uz-sah', 'configs:uz-tr']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A Large-Scale Study of Machine Translation in Turkic Languages\n",
       " \tcitation: @inproceedings{mirzakhalov2021large,\n",
       "   title={A Large-Scale Study of Machine Translation in Turkic Languages},\n",
       "   author={Mirzakhalov, Jamshidbek and Babu, Anoop and Ataman, Duygu and Kariev, Sherzod and Tyers, Francis and Abduraufov, Otabek and Hajili, Mammad and Ivanova, Sardana and Khaytbaev, Abror and Laverghetta Jr, Antonio and others},\n",
       "   booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},\n",
       "   pages={5876--5890},\n",
       "   year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['az', 'ba', 'en', 'kaa', 'kk', 'ky', 'ru', 'sah', 'tr', 'uz'], 'license': ['mit'], 'multilinguality': ['translation'], 'pretty_name': 'turkic_xwmt', 'size_categories': ['n<1K'], 'task_categories': ['translation'], 'task_ids': [], 'source_datasets': ['extended|WMT 2020 News Translation Task'], 'configs': ['az-ba', 'az-en', 'az-kaa', 'az-kk', 'az-ky', 'az-ru', 'az-sah', 'az-tr', 'az-uz', 'ba-az', 'ba-en', 'ba-kaa', 'ba-kk', 'ba-ky', 'ba-ru', 'ba-sah', 'ba-tr', 'ba-uz', 'en-az', 'en-ba', 'en-kaa', 'en-kk', 'en-ky', 'en-ru', 'en-sah', 'en-tr', 'en-uz', 'kaa-az', 'kaa-ba', 'kaa-en', 'kaa-kk', 'kaa-ky', 'kaa-ru', 'kaa-sah', 'kaa-tr', 'kaa-uz', 'kk-az', 'kk-ba', 'kk-en', 'kk-kaa', 'kk-ky', 'kk-ru', 'kk-sah', 'kk-tr', 'kk-uz', 'ky-az', 'ky-ba', 'ky-en', 'ky-kaa', 'ky-kk', 'ky-ru', 'ky-sah', 'ky-tr', 'ky-uz', 'ru-az', 'ru-ba', 'ru-en', 'ru-kaa', 'ru-kk', 'ru-ky', 'ru-sah', 'ru-tr', 'ru-uz', 'sah-az', 'sah-ba', 'sah-en', 'sah-kaa', 'sah-kk', 'sah-ky', 'sah-ru', 'sah-tr', 'sah-uz', 'tr-az', 'tr-ba', 'tr-en', 'tr-kaa', 'tr-kk', 'tr-ky', 'tr-ru', 'tr-sah', 'tr-uz', 'uz-az', 'uz-ba', 'uz-en', 'uz-kaa', 'uz-kk', 'uz-ky', 'uz-ru', 'uz-sah', 'uz-tr']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 14091\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turkish_movie_sentiment\n",
       " \tsha: 1c08beb8f6fbda1f27f64170e987ad8eb7a6a109\n",
       " \tlastModified: 2022-07-01T11:56:56.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'task_ids:sentiment-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This data set is a dataset from kaggle consisting of Turkish movie reviews and scored between 0-5.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification', 'sentiment-scoring'], 'paperswithcode_id': None, 'pretty_name': 'TurkishMovieSentiment: This dataset contains turkish movie reviews.'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turkish_ner\n",
       " \tsha: 09d2355e6dcf24fdbc267d0b47784e234011c0a4\n",
       " \tlastModified: 2022-07-01T11:56:56.000Z\n",
       " \ttags: ['arxiv:1702.02363', 'annotations_creators:machine-generated', 'language_creators:expert-generated', 'language:tr', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Turkish Wikipedia Named-Entity Recognition and Text Categorization\n",
       " (TWNERTC) dataset is a collection of automatically categorized and annotated\n",
       " sentences obtained from Wikipedia. The authors constructed large-scale\n",
       " gazetteers by using a graph crawler algorithm to extract\n",
       " relevant entity and domain information\n",
       " from a semantic knowledge base, Freebase.\n",
       " The constructed gazetteers contains approximately\n",
       " 300K entities with thousands of fine-grained entity types\n",
       " under 77 different domains.\n",
       " \tcitation: @InProceedings@article{DBLP:journals/corr/SahinTYES17,\n",
       "   author    = {H. Bahadir Sahin and\n",
       "                Caglar Tirkaz and\n",
       "                Eray Yildiz and\n",
       "                Mustafa Tolga Eren and\n",
       "                Omer Ozan Sonmez},\n",
       "   title     = {Automatically Annotated Turkish Corpus for Named Entity Recognition\n",
       "                and Text Categorization using Large-Scale Gazetteers},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1702.02363},\n",
       "   year      = {2017},\n",
       "   url       = {http://arxiv.org/abs/1702.02363},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1702.02363},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:46:36 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/SahinTYES17.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['expert-generated'], 'language': ['tr'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'TurkishNer'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turkish_product_reviews\n",
       " \tsha: 859a3b4e41ea0e182ca1e9860a76d0624a74b955\n",
       " \tlastModified: 2022-07-01T11:56:58.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:tr', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Turkish Product Reviews.\n",
       " This repository contains 235.165 product reviews collected online. There are 220.284 positive, 14881 negative reviews.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['tr'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Turkish Product Reviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 458\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turkish_shrinked_ner\n",
       " \tsha: ec99540a94831a2eb5bc0b176280e425b6ad65a9\n",
       " \tlastModified: 2022-07-01T11:56:58.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:expert-generated', 'language:tr', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-turkish_ner', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Shrinked version (48 entity type) of the turkish_ner.\n",
       " \n",
       " Original turkish_ner dataset: Automatically annotated Turkish corpus for named entity recognition and text categorization using large-scale gazetteers. The constructed gazetteers contains approximately 300K entities with thousands of fine-grained entity types under 25 different domains.\n",
       " \n",
       " Shrinked entity types are: academic, academic_person, aircraft, album_person, anatomy, animal, architect_person, capital, chemical, clothes, country, culture, currency, date, food, genre, government, government_person, language, location, material, measure, medical, military, military_person, nation, newspaper, organization, organization_person, person, production_art_music, production_art_music_person, quantity, religion, science, shape, ship, software, space, space_person, sport, sport_name, sport_person, structure, subject, tech, train, vehicle\n",
       " \tcitation: \\\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['expert-generated'], 'language': ['tr'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-turkish_ner'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'TurkishShrinkedNer'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: turku_ner_corpus\n",
       " \tsha: e1106f2994a9e39ea76ac8fc1304b67b0ea5b135\n",
       " \tlastModified: 2022-08-11T12:57:39.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:fi', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: An open, broad-coverage corpus for Finnish named entity recognition presented in Luoma et al. (2020) A Broad-coverage Corpus for Finnish Named Entity Recognition.\n",
       " \tcitation: @inproceedings{luoma-etal-2020-broad,\n",
       " title = \"A Broad-coverage Corpus for {F}innish Named Entity Recognition\",\n",
       " author = {Luoma, Jouni and Oinonen, Miika and Pyyk{\\\"o}nen, Maria and Laippala, Veronika and Pyysalo, Sampo},\n",
       " booktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\n",
       " year = \"2020\",\n",
       " url = \"https://www.aclweb.org/anthology/2020.lrec-1.567\",\n",
       " pages = \"4615--4624\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Turku NER corpus', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['fi'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tweet_eval\n",
       " \tsha: 7db18c1583b4e0a4014a5a3b0490f2a3a189c772\n",
       " \tlastModified: 2022-07-01T11:56:59.000Z\n",
       " \ttags: ['arxiv:2010.12421', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:extended|other-tweet-datasets', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification', 'task_ids:sentiment-classification', 'configs:emoji', 'configs:emotion', 'configs:hate', 'configs:irony', 'configs:offensive', 'configs:sentiment', 'configs:stance_abortion', 'configs:stance_atheism', 'configs:stance_climate', 'configs:stance_feminist', 'configs:stance_hillary']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TweetEval consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. All tasks have been unified into the same benchmark, with each dataset presented in the same format and with fixed training, validation and test splits.\n",
       " \tcitation: @inproceedings{barbieri2020tweeteval,\n",
       "   title={{TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification}},\n",
       "   author={Barbieri, Francesco and Camacho-Collados, Jose and Espinosa-Anke, Luis and Neves, Leonardo},\n",
       "   booktitle={Proceedings of Findings of EMNLP},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['extended|other-tweet-datasets'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'multi-class-classification', 'sentiment-classification'], 'paperswithcode_id': 'tweeteval', 'pretty_name': 'TweetEval', 'train-eval-index': [{'config': 'emotion', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}, {'config': 'hate', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 binary', 'args': {'average': 'binary'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}, {'config': 'irony', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 binary', 'args': {'average': 'binary'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}, {'config': 'offensive', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 binary', 'args': {'average': 'binary'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}, {'config': 'sentiment', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}], 'configs': ['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 38529\n",
       " \tlikes: 24\n",
       " \tpaperswithcode_id: tweeteval\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tweet_qa\n",
       " \tsha: f2739c6d27b5059529cf535e08c4f31d57f7f744\n",
       " \tlastModified: 2022-07-01T11:57:00.000Z\n",
       " \ttags: ['arxiv:1907.06292', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TweetQA is the first dataset for QA on social media data by leveraging news media and crowdsourcing.\n",
       " \tcitation: @inproceedings{xiong2019tweetqa,\n",
       "   title={TweetQA: A Social Media Focused Question Answering Dataset},\n",
       "   author={Xiong, Wenhan and Wu, Jiawei and Wang, Hong and Kulkarni, Vivek and Yu, Mo and Guo, Xiaoxiao and Chang, Shiyu and Wang, William Yang},\n",
       "   booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'tweetqa', 'pretty_name': 'TweetQA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 661\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: tweetqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tweets_ar_en_parallel\n",
       " \tsha: 223f35163ef17bec56fcf20f8b8928405701f5d0\n",
       " \tlastModified: 2022-07-01T11:57:00.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:no-annotation', 'language_creators:found', 'language:ar', 'language:en', 'license:apache-2.0', 'multilinguality:translation', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'task_ids:translation-other-tweets-translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     Twitter users often post parallel tweets—tweets that contain the same content but are\n",
       "     written in different languages. Parallel tweets can be an important resource for developing\n",
       "     machine translation (MT) systems among other natural language processing (NLP) tasks. This\n",
       "     resource is a result of a generic method for collecting parallel tweets. Using the method,\n",
       "     we compiled a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts\n",
       "     who post English-Arabic tweets regularly. Additionally, we annotate a subset of Twitter accounts\n",
       "     with their countries of origin and topic of interest, which provides insights about the population\n",
       "     who post parallel tweets.\n",
       " \tcitation: @inproceedings{Mubarak2020bilingualtweets,\n",
       " title={Constructing a Bilingual Corpus of Parallel Tweets},\n",
       " author={Mubarak, Hamdy and Hassan, Sabit and Abdelali, Ahmed},\n",
       " booktitle={Proceedings of 13th Workshop on Building and Using Comparable Corpora (BUCC)},\n",
       " address={Marseille, France},\n",
       " year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'no-annotation'], 'language_creators': ['found'], 'language': ['ar', 'en'], 'license': ['apache-2.0'], 'multilinguality': ['translation'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': ['translation-other-tweets-translation'], 'paperswithcode_id': 'bilingual-corpus-of-arabic-english-parallel', 'pretty_name': 'Bilingual Corpus of Arabic-English Parallel Tweets'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 636\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: bilingual-corpus-of-arabic-english-parallel\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tweets_hate_speech_detection\n",
       " \tsha: 4e4b258b04ed4e92386cbeb2534a149e9aacaa4e\n",
       " \tlastModified: 2022-07-01T11:57:02.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n",
       " \n",
       " Formally, given a training sample of tweets and labels, where label ‘1’ denotes the tweet is racist/sexist and label ‘0’ denotes the tweet is not racist/sexist, your objective is to predict the labels on the given test dataset.\n",
       " \tcitation: @InProceedings{Z\n",
       " Roshan Sharma:dataset,\n",
       " title = {Sentimental Analysis of Tweets for Detecting Hate/Racist Speeches},\n",
       " authors={Roshan Sharma},\n",
       " year={2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Tweets Hate Speech Detection', 'train-eval-index': [{'config': 'default', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train'}, 'col_mapping': {'tweet': 'text', 'label': 'target', 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 binary', 'args': {'average': 'binary'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1571\n",
       " \tlikes: 6\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: twi_text_c3\n",
       " \tsha: 765446c1a749cd911a1303b94aeba9eae9d14dd6\n",
       " \tlastModified: 2022-07-01T11:57:02.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:tw', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Twi Text C3 is the largest Twi texts collected and used to train FastText embeddings in the\n",
       " YorubaTwi Embedding paper: https://www.aclweb.org/anthology/2020.lrec-1.335/\n",
       " \tcitation: @inproceedings{alabi-etal-2020-massive,\n",
       "     title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of Yoruba and {T}wi\",\n",
       "     author = \"Alabi, Jesujoba  and\n",
       "       Amponsah-Kaakyire, Kwabena  and\n",
       "       Adelani, David  and\n",
       "       Espa{\\\\~n}a-Bonet, Cristina\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n",
       "     pages = \"2754--2762\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['tw'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Twi Text C3'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: twi_wordsim353\n",
       " \tsha: 6d718324d7d4e0d9b7de698ec52f7d73d2393a56\n",
       " \tlastModified: 2022-07-01T11:57:02.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'language:tw', 'license:unknown', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A translation of the word pair similarity dataset wordsim-353 to Twi.\n",
       " \n",
       " The dataset was presented in the paper\n",
       " Alabi et al.: Massive vs. Curated Embeddings for Low-Resourced\n",
       " Languages: the Case of Yorùbá and Twi (LREC 2020).\n",
       " \tcitation: @inproceedings{alabi-etal-2020-massive,\n",
       "     title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Y}or{\\\\`u}b{\\\\'a} and {T}wi\",\n",
       "     author = \"Alabi, Jesujoba  and\n",
       "       Amponsah-Kaakyire, Kwabena  and\n",
       "       Adelani, David  and\n",
       "       Espa{\\\\~n}a-Bonet, Cristina\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n",
       "     pages = \"2754--2762\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en', 'tw'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'Yorùbá Wordsim-353'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: tydiqa\n",
       " \tsha: a7d90498a0cf4cd81fe84e053b9f7368c70bd5de\n",
       " \tlastModified: 2022-07-27T14:39:09.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'language:bn', 'language:en', 'language:fi', 'language:id', 'language:ja', 'language:ko', 'language:ru', 'language:sw', 'language:te', 'language:th', 'license:apache-2.0', 'multilinguality:multilingual', 'size_categories:unknown', 'source_datasets:extended|wikipedia', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\n",
       " The languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\n",
       " expresses -- such that we expect models performing well on this set to generalize across a large number of the languages\n",
       " in the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\n",
       " information-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\n",
       " don’t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\n",
       " the use of translation (unlike MLQA and XQuAD).\n",
       " \tcitation: @article{tydiqa,\n",
       " title   = {TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},\n",
       " author  = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki}\n",
       " year    = {2020},\n",
       " journal = {Transactions of the Association for Computational Linguistics}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'TyDi QA', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar', 'bn', 'en', 'fi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th'], 'license': ['apache-2.0'], 'multilinguality': ['multilingual'], 'size_categories': ['unknown'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'tydi-qa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3122\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: tydi-qa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ubuntu_dialogs_corpus\n",
       " \tsha: b64922619ef8262e9a2217dfd434a8ff5706ba39\n",
       " \tlastModified: 2022-09-15T17:12:40.000Z\n",
       " \ttags: ['arxiv:1506.08909', 'annotations_creators:found', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:conversational', 'task_ids:dialogue-generation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter.\n",
       " \tcitation: @article{DBLP:journals/corr/LowePSP15,\n",
       "   author    = {Ryan Lowe and\n",
       "                Nissan Pow and\n",
       "                Iulian Serban and\n",
       "                Joelle Pineau},\n",
       "   title     = {The Ubuntu Dialogue Corpus: {A} Large Dataset for Research in Unstructured\n",
       "                Multi-Turn Dialogue Systems},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1506.08909},\n",
       "   year      = {2015},\n",
       "   url       = {http://arxiv.org/abs/1506.08909},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1506.08909},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:48:23 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/LowePSP15.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'UDC (Ubuntu Dialogue Corpus)', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['conversational'], 'task_ids': ['dialogue-generation'], 'paperswithcode_id': 'ubuntu-dialogue-corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 510\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: ubuntu-dialogue-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: udhr\n",
       " \tsha: 50932e7beba4bd6f1b4b10c56dcd54d95a0d1cca\n",
       " \tlastModified: 2022-07-27T14:39:09.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:aa', 'language:ab', 'language:ace', 'language:acu', 'language:ada', 'language:ady', 'language:af', 'language:agr', 'language:aii', 'language:ajg', 'language:als', 'language:alt', 'language:am', 'language:amc', 'language:ame', 'language:ami', 'language:amr', 'language:ar', 'language:arl', 'language:arn', 'language:ast', 'language:auc', 'language:ay', 'language:az', 'language:ban', 'language:bax', 'language:bba', 'language:bci', 'language:be', 'language:bem', 'language:bfa', 'language:bg', 'language:bho', 'language:bi', 'language:bik', 'language:bin', 'language:blt', 'language:bm', 'language:bn', 'language:bo', 'language:boa', 'language:br', 'language:bs', 'language:buc', 'language:bug', 'language:bum', 'language:ca', 'language:cab', 'language:cak', 'language:cbi', 'language:cbr', 'language:cbs', 'language:cbt', 'language:cbu', 'language:ccp', 'language:ceb', 'language:cfm', 'language:ch', 'language:chj', 'language:chk', 'language:chr', 'language:cic', 'language:cjk', 'language:cjs', 'language:cjy', 'language:ckb', 'language:cnh', 'language:cni', 'language:cnr', 'language:co', 'language:cof', 'language:cot', 'language:cpu', 'language:crh', 'language:cri', 'language:crs', 'language:cs', 'language:csa', 'language:csw', 'language:ctd', 'language:cy', 'language:da', 'language:dag', 'language:ddn', 'language:de', 'language:dga', 'language:dip', 'language:duu', 'language:dv', 'language:dyo', 'language:dyu', 'language:dz', 'language:ee', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:ese', 'language:et', 'language:eu', 'language:eve', 'language:evn', 'language:fa', 'language:fat', 'language:fi', 'language:fj', 'language:fkv', 'language:fo', 'language:fon', 'language:fr', 'language:fuf', 'language:fur', 'language:fuv', 'language:fvr', 'language:fy', 'language:ga', 'language:gaa', 'language:gag', 'language:gan', 'language:gd', 'language:gjn', 'language:gkp', 'language:gl', 'language:gld', 'language:gn', 'language:gsw', 'language:gu', 'language:guc', 'language:guu', 'language:gv', 'language:gyr', 'language:ha', 'language:hak', 'language:haw', 'language:he', 'language:hi', 'language:hil', 'language:hlt', 'language:hmn', 'language:hms', 'language:hna', 'language:hni', 'language:hnj', 'language:hns', 'language:hr', 'language:hsb', 'language:hsn', 'language:ht', 'language:hu', 'language:hus', 'language:huu', 'language:hy', 'language:ia', 'language:ibb', 'language:id', 'language:idu', 'language:ig', 'language:ii', 'language:ijs', 'language:ilo', 'language:io', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:jiv', 'language:jv', 'language:ka', 'language:kaa', 'language:kbd', 'language:kbp', 'language:kde', 'language:kdh', 'language:kea', 'language:kek', 'language:kg', 'language:kha', 'language:kjh', 'language:kk', 'language:kkh', 'language:kl', 'language:km', 'language:kmb', 'language:kn', 'language:ko', 'language:koi', 'language:koo', 'language:kqn', 'language:kqs', 'language:kr', 'language:kri', 'language:krl', 'language:ktu', 'language:ku', 'language:kwi', 'language:ky', 'language:la', 'language:lad', 'language:lah', 'language:lb', 'language:lg', 'language:lia', 'language:lij', 'language:lld', 'language:ln', 'language:lns', 'language:lo', 'language:lob', 'language:lot', 'language:loz', 'language:lt', 'language:lua', 'language:lue', 'language:lun', 'language:lus', 'language:lv', 'language:mad', 'language:mag', 'language:mai', 'language:mam', 'language:man', 'language:maz', 'language:mcd', 'language:mcf', 'language:men', 'language:mfq', 'language:mg', 'language:mh', 'language:mi', 'language:mic', 'language:min', 'language:miq', 'language:mk', 'language:ml', 'language:mn', 'language:mnw', 'language:mor', 'language:mos', 'language:mr', 'language:mt', 'language:mto', 'language:mxi', 'language:mxv', 'language:my', 'language:mzi', 'language:nan', 'language:nb', 'language:nba', 'language:nds', 'language:ne', 'language:ng', 'language:nhn', 'language:nio', 'language:niu', 'language:niv', 'language:njo', 'language:nku', 'language:nl', 'language:nn', 'language:not', 'language:nr', 'language:nso', 'language:nv', 'language:ny', 'language:nym', 'language:nyn', 'language:nzi', 'language:oaa', 'language:oc', 'language:ojb', 'language:oki', 'language:om', 'language:orh', 'language:os', 'language:ote', 'language:pa', 'language:pam', 'language:pap', 'language:pau', 'language:pbb', 'language:pcd', 'language:pcm', 'language:pis', 'language:piu', 'language:pl', 'language:pon', 'language:pov', 'language:ppl', 'language:prq', 'language:ps', 'language:pt', 'language:qu', 'language:quc', 'language:qug', 'language:quh', 'language:quy', 'language:qva', 'language:qvc', 'language:qvh', 'language:qvm', 'language:qvn', 'language:qwh', 'language:qxn', 'language:qxu', 'language:rar', 'language:rgn', 'language:rm', 'language:rmn', 'language:rn', 'language:ro', 'language:ru', 'language:rup', 'language:rw', 'language:sa', 'language:sah', 'language:sc', 'language:sco', 'language:se', 'language:sey', 'language:sg', 'language:shk', 'language:shn', 'language:shp', 'language:si', 'language:sk', 'language:skr', 'language:sl', 'language:slr', 'language:sm', 'language:sn', 'language:snk', 'language:snn', 'language:so', 'language:sr', 'language:srr', 'language:ss', 'language:st', 'language:su', 'language:suk', 'language:sus', 'language:sv', 'language:sw', 'language:swb', 'language:ta', 'language:taj', 'language:tbz', 'language:tca', 'language:tdt', 'language:te', 'language:tem', 'language:tet', 'language:tg', 'language:th', 'language:ti', 'language:tiv', 'language:tk', 'language:tl', 'language:tly', 'language:tn', 'language:to', 'language:tob', 'language:toi', 'language:toj', 'language:top', 'language:tpi', 'language:tr', 'language:ts', 'language:tsz', 'language:tt', 'language:tw', 'language:ty', 'language:tyv', 'language:tzh', 'language:tzm', 'language:tzo', 'language:udu', 'language:ug', 'language:uk', 'language:umb', 'language:und', 'language:ur', 'language:ura', 'language:uz', 'language:vai', 'language:ve', 'language:vec', 'language:vep', 'language:vi', 'language:vmw', 'language:wa', 'language:war', 'language:wo', 'language:wuu', 'language:wwa', 'language:xh', 'language:xsm', 'language:yad', 'language:yao', 'language:yap', 'language:yi', 'language:ykg', 'language:yo', 'language:yrk', 'language:yua', 'language:yue', 'language:za', 'language:zam', 'language:zdj', 'language:zgh', 'language:zh', 'language:zlm', 'language:zro', 'language:ztu', 'language:zu', 'language_bcp47:az-Cyrl', 'language_bcp47:az-Latn', 'language_bcp47:bs-Cyrl', 'language_bcp47:bs-Latn', 'language_bcp47:ckb-Latn', 'language_bcp47:de-1901', 'language_bcp47:de-1996', 'language_bcp47:el-monoton', 'language_bcp47:el-polyton', 'language_bcp47:fa-AF', 'language_bcp47:fuf-Adlm', 'language_bcp47:ha-NE', 'language_bcp47:ha-NG', 'language_bcp47:jv-Java', 'language_bcp47:kg-AO', 'language_bcp47:kkh-Lana', 'language_bcp47:mn-Cyrl', 'language_bcp47:pt-BR', 'language_bcp47:pt-PT', 'language_bcp47:rm-puter', 'language_bcp47:rm-rumgr', 'language_bcp47:rm-surmiran', 'language_bcp47:rm-sursilv', 'language_bcp47:rm-sutsilv', 'language_bcp47:rm-vallader', 'language_bcp47:sa-Gran', 'language_bcp47:sr-Cyrl', 'language_bcp47:sr-Latn', 'language_bcp47:ta-LK', 'language_bcp47:tk-Cyrl', 'language_bcp47:tk-Latn', 'language_bcp47:tw-akuapem', 'language_bcp47:tw-asante', 'language_bcp47:ug-Arab', 'language_bcp47:ug-Latn', 'language_bcp47:uz-Cyrl', 'language_bcp47:uz-Latn', 'language_bcp47:vi-Hani', 'language_bcp47:zh-Hant', 'language_bcp47:zlm-Arab', 'language_bcp47:zlm-Latn', 'license:unknown', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Universal Declaration of Human Rights (UDHR) is a milestone document in the history of human rights. Drafted by\n",
       " representatives with different legal and cultural backgrounds from all regions of the world, it set out, for the\n",
       " first time, fundamental human rights to be universally protected. The Declaration was adopted by the UN General\n",
       " Assembly in Paris on 10 December 1948 during its 183rd plenary meeting. The dataset includes translations of the\n",
       " document in 464+ languages and dialects.\n",
       " \n",
       " © 1996 – 2009 The Office of the High Commissioner for Human Rights\n",
       " \n",
       " This plain text version prepared by the “UDHR in Unicode” project, https://www.unicode.org/udhr.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['aa', 'ab', 'ace', 'acu', 'ada', 'ady', 'af', 'agr', 'aii', 'ajg', 'als', 'alt', 'am', 'amc', 'ame', 'ami', 'amr', 'ar', 'arl', 'arn', 'ast', 'auc', 'ay', 'az', 'ban', 'bax', 'bba', 'bci', 'be', 'bem', 'bfa', 'bg', 'bho', 'bi', 'bik', 'bin', 'blt', 'bm', 'bn', 'bo', 'boa', 'br', 'bs', 'buc', 'bug', 'bum', 'ca', 'cab', 'cak', 'cbi', 'cbr', 'cbs', 'cbt', 'cbu', 'ccp', 'ceb', 'cfm', 'ch', 'chj', 'chk', 'chr', 'cic', 'cjk', 'cjs', 'cjy', 'ckb', 'cnh', 'cni', 'cnr', 'co', 'cof', 'cot', 'cpu', 'crh', 'cri', 'crs', 'cs', 'csa', 'csw', 'ctd', 'cy', 'da', 'dag', 'ddn', 'de', 'dga', 'dip', 'duu', 'dv', 'dyo', 'dyu', 'dz', 'ee', 'el', 'en', 'eo', 'es', 'ese', 'et', 'eu', 'eve', 'evn', 'fa', 'fat', 'fi', 'fj', 'fkv', 'fo', 'fon', 'fr', 'fuf', 'fur', 'fuv', 'fvr', 'fy', 'ga', 'gaa', 'gag', 'gan', 'gd', 'gjn', 'gkp', 'gl', 'gld', 'gn', 'gsw', 'gu', 'guc', 'guu', 'gv', 'gyr', 'ha', 'hak', 'haw', 'he', 'hi', 'hil', 'hlt', 'hmn', 'hms', 'hna', 'hni', 'hnj', 'hns', 'hr', 'hsb', 'hsn', 'ht', 'hu', 'hus', 'huu', 'hy', 'ia', 'ibb', 'id', 'idu', 'ig', 'ii', 'ijs', 'ilo', 'io', 'is', 'it', 'iu', 'ja', 'jiv', 'jv', 'ka', 'kaa', 'kbd', 'kbp', 'kde', 'kdh', 'kea', 'kek', 'kg', 'kha', 'kjh', 'kk', 'kkh', 'kl', 'km', 'kmb', 'kn', 'ko', 'koi', 'koo', 'kqn', 'kqs', 'kr', 'kri', 'krl', 'ktu', 'ku', 'kwi', 'ky', 'la', 'lad', 'lah', 'lb', 'lg', 'lia', 'lij', 'lld', 'ln', 'lns', 'lo', 'lob', 'lot', 'loz', 'lt', 'lua', 'lue', 'lun', 'lus', 'lv', 'mad', 'mag', 'mai', 'mam', 'man', 'maz', 'mcd', 'mcf', 'men', 'mfq', 'mg', 'mh', 'mi', 'mic', 'min', 'miq', 'mk', 'ml', 'mn', 'mnw', 'mor', 'mos', 'mr', 'mt', 'mto', 'mxi', 'mxv', 'my', 'mzi', 'nan', 'nb', 'nba', 'nds', 'ne', 'ng', 'nhn', 'nio', 'niu', 'niv', 'njo', 'nku', 'nl', 'nn', 'not', 'nr', 'nso', 'nv', 'ny', 'nym', 'nyn', 'nzi', 'oaa', 'oc', 'ojb', 'oki', 'om', 'orh', 'os', 'ote', 'pa', 'pam', 'pap', 'pau', 'pbb', 'pcd', 'pcm', 'pis', 'piu', 'pl', 'pon', 'pov', 'ppl', 'prq', 'ps', 'pt', 'qu', 'quc', 'qug', 'quh', 'quy', 'qva', 'qvc', 'qvh', 'qvm', 'qvn', 'qwh', 'qxn', 'qxu', 'rar', 'rgn', 'rm', 'rmn', 'rn', 'ro', 'ru', 'rup', 'rw', 'sa', 'sah', 'sc', 'sco', 'se', 'sey', 'sg', 'shk', 'shn', 'shp', 'si', 'sk', 'skr', 'sl', 'slr', 'sm', 'sn', 'snk', 'snn', 'so', 'sr', 'srr', 'ss', 'st', 'su', 'suk', 'sus', 'sv', 'sw', 'swb', 'ta', 'taj', 'tbz', 'tca', 'tdt', 'te', 'tem', 'tet', 'tg', 'th', 'ti', 'tiv', 'tk', 'tl', 'tly', 'tn', 'to', 'tob', 'toi', 'toj', 'top', 'tpi', 'tr', 'ts', 'tsz', 'tt', 'tw', 'ty', 'tyv', 'tzh', 'tzm', 'tzo', 'udu', 'ug', 'uk', 'umb', 'und', 'ur', 'ura', 'uz', 'vai', 've', 'vec', 'vep', 'vi', 'vmw', 'wa', 'war', 'wo', 'wuu', 'wwa', 'xh', 'xsm', 'yad', 'yao', 'yap', 'yi', 'ykg', 'yo', 'yrk', 'yua', 'yue', 'za', 'zam', 'zdj', 'zgh', 'zh', 'zlm', 'zro', 'ztu', 'zu'], 'language_bcp47': ['az-Cyrl', 'az-Latn', 'bs-Cyrl', 'bs-Latn', 'ckb-Latn', 'de-1901', 'de-1996', 'el-monoton', 'el-polyton', 'fa-AF', 'fuf-Adlm', 'ha-NE', 'ha-NG', 'jv-Java', 'kg-AO', 'kkh-Lana', 'mn-Cyrl', 'pt-BR', 'pt-PT', 'rm-puter', 'rm-rumgr', 'rm-surmiran', 'rm-sursilv', 'rm-sutsilv', 'rm-vallader', 'sa-Gran', 'sr-Cyrl', 'sr-Latn', 'ta-LK', 'tk-Cyrl', 'tk-Latn', 'tw-akuapem', 'tw-asante', 'ug-Arab', 'ug-Latn', 'uz-Cyrl', 'uz-Latn', 'vi-Hani', 'zh-Hant', 'zlm-Arab', 'zlm-Latn'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'The Universal Declaration of Human Rights (UDHR)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: um005\n",
       " \tsha: b25ac6e70381cc11b35c4ae6b7324c5764fbd187\n",
       " \tlastModified: 2022-08-11T12:57:39.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:other', 'language:en', 'language:ur', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: UMC005 English-Urdu is a parallel corpus of texts in English and Urdu language with sentence alignments. The corpus can be used for experiments with statistical machine translation.\n",
       " \n",
       " The texts come from four different sources:\n",
       " - Quran\n",
       " - Bible\n",
       " - Penn Treebank (Wall Street Journal)\n",
       " - Emille corpus\n",
       " \n",
       " The authors provide the religious texts of Quran and Bible for direct download. Because of licensing reasons, Penn and Emille texts cannot be redistributed freely. However, if you already hold a license for the original corpora, we are able to provide scripts that will recreate our data on your disk. Our modifications include but are not limited to the following:\n",
       " \n",
       " - Correction of Urdu translations and manual sentence alignment of the Emille texts.\n",
       " - Manually corrected sentence alignment of the other corpora.\n",
       " - Our data split (training-development-test) so that our published experiments can be reproduced.\n",
       " - Tokenization (optional, but needed to reproduce our experiments).\n",
       " - Normalization (optional) of e.g. European vs. Urdu numerals, European vs. Urdu punctuation, removal of Urdu diacritics.\n",
       " \tcitation: @unpublished{JaZeWordOrderIssues2011,\n",
       " author      = {Bushra Jawaid and Daniel Zeman},\n",
       " title       = {Word-Order Issues in {English}-to-{Urdu} Statistical Machine Translation},\n",
       " year        = {2011},\n",
       " journal     = {The Prague Bulletin of Mathematical Linguistics},\n",
       " number      = {95},\n",
       " institution = {Univerzita Karlova},\n",
       " address     = {Praha, Czechia},\n",
       " issn        = {0032-6585},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['other'], 'language': ['en', 'ur'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'umc005-english-urdu', 'pretty_name': 'UMC005 English-Urdu'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 632\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: umc005-english-urdu\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: un_ga\n",
       " \tsha: 40a9ce2f2153b2f76e2238050411e10eee662295\n",
       " \tlastModified: 2022-07-01T11:57:06.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:en', 'language:es', 'language:fr', 'language:ru', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation', 'configs:ar-to-en', 'configs:ar-to-es', 'configs:ar-to-fr', 'configs:ar-to-ru', 'configs:ar-to-zh', 'configs:en-to-es', 'configs:en-to-fr', 'configs:en-to-ru', 'configs:en-to-zh', 'configs:es-to-fr', 'configs:es-to-ru', 'configs:es-to-zh', 'configs:fr-to-ru', 'configs:fr-to-zh', 'configs:ru-to-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: United nations general assembly resolutions: A six-language parallel corpus.\n",
       " This is a collection of translated documents from the United Nations originally compiled into a translation memory by Alexandre Rafalovitch, Robert Dale (see http://uncorpora.org).\n",
       " 6 languages, 15 bitexts\n",
       " total number of files: 6\n",
       " total number of tokens: 18.87M\n",
       " total number of sentence fragments: 0.44M\n",
       " \tcitation: @inproceedings{title = \"United Nations General Assembly Resolutions: a six-language parallel corpus\",\n",
       " abstract = \"In this paper we describe a six-ways parallel public-domain corpus consisting of 2100 United Nations General Assembly Resolutions with translations in the six official languages of the United Nations, with an average of around 3 million tokens per language. The corpus is available in a preprocessed, formatting-normalized TMX format with paragraphs aligned across multiple languages. We describe the background to the corpus and its content, the process of its construction, and some of its interesting properties.\",\n",
       " author = \"Alexandre Rafalovitch and Robert Dale\",\n",
       " year = \"2009\",\n",
       " language = \"English\",\n",
       " booktitle = \"MT Summit XII proceedings\",\n",
       " publisher = \"International Association of Machine Translation\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'en', 'es', 'fr', 'ru', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'UnGa', 'configs': ['ar-to-en', 'ar-to-es', 'ar-to-fr', 'ar-to-ru', 'ar-to-zh', 'en-to-es', 'en-to-fr', 'en-to-ru', 'en-to-zh', 'es-to-fr', 'es-to-ru', 'es-to-zh', 'fr-to-ru', 'fr-to-zh', 'ru-to-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2493\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: un_multi\n",
       " \tsha: dd560324baac74da4875902df6bf787600a9b5a2\n",
       " \tlastModified: 2022-07-01T11:57:06.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:ru', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:translation', 'configs:ar-de', 'configs:ar-en', 'configs:ar-es', 'configs:ar-fr', 'configs:ar-ru', 'configs:ar-zh', 'configs:de-en', 'configs:de-es', 'configs:de-fr', 'configs:de-ru', 'configs:de-zh', 'configs:en-es', 'configs:en-fr', 'configs:en-ru', 'configs:en-zh', 'configs:es-fr', 'configs:es-ru', 'configs:es-zh', 'configs:fr-ru', 'configs:fr-zh', 'configs:ru-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is a collection of translated documents from the United Nations. This corpus is available in all 6 official languages of the UN, consisting of around 300 million words per language\n",
       " \tcitation: @inproceedings{eisele-chen-2010-multiun,\n",
       "     title = \"{M}ulti{UN}: A Multilingual Corpus from United Nation Documents\",\n",
       "     author = \"Eisele, Andreas  and\n",
       "       Chen, Yu\",\n",
       "     booktitle = \"Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)\",\n",
       "     month = may,\n",
       "     year = \"2010\",\n",
       "     address = \"Valletta, Malta\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"http://www.lrec-conf.org/proceedings/lrec2010/pdf/686_Paper.pdf\",\n",
       "     abstract = \"This paper describes the acquisition, preparation and properties of a corpus extracted from the official documents of the United Nations (UN). This corpus is available in all 6 official languages of the UN, consisting of around 300 million words per language. We describe the methods we used for crawling, document formatting, and sentence alignment. This corpus also includes a common test set for machine translation. We present the results of a French-Chinese machine translation experiment performed on this corpus.\",\n",
       " }\n",
       " \n",
       " @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J�rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'de', 'en', 'es', 'fr', 'ru', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'multiun', 'pretty_name': 'Multilingual Corpus from United Nation Documents', 'configs': ['ar-de', 'ar-en', 'ar-es', 'ar-fr', 'ar-ru', 'ar-zh', 'de-en', 'de-es', 'de-fr', 'de-ru', 'de-zh', 'en-es', 'en-fr', 'en-ru', 'en-zh', 'es-fr', 'es-ru', 'es-zh', 'fr-ru', 'fr-zh', 'ru-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3480\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: multiun\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: un_pc\n",
       " \tsha: 123b1621873c9af83a2f70175a2ab0e042fc05d0\n",
       " \tlastModified: 2022-07-01T11:57:06.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:ar', 'language:en', 'language:es', 'language:fr', 'language:ru', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'task_categories:translation', 'configs:ar-en', 'configs:ar-es', 'configs:ar-fr', 'configs:ar-ru', 'configs:ar-zh', 'configs:en-es', 'configs:en-fr', 'configs:en-ru', 'configs:en-zh', 'configs:es-fr', 'configs:es-ru', 'configs:es-zh', 'configs:fr-ru', 'configs:fr-zh', 'configs:ru-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This parallel corpus consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish.\n",
       " \tcitation: @inproceedings{ziemski-etal-2016-united,\n",
       "     title = \"The {U}nited {N}ations Parallel Corpus v1.0\",\n",
       "     author = \"Ziemski, Micha{\\\\l}  and\n",
       "       Junczys-Dowmunt, Marcin  and\n",
       "       Pouliquen, Bruno\",\n",
       "     booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n",
       "     month = may,\n",
       "     year = \"2016\",\n",
       "     address = \"Portoro{\\v{z}}, Slovenia\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"https://www.aclweb.org/anthology/L16-1561\",\n",
       "     pages = \"3530--3534\",\n",
       "     abstract = \"This paper describes the creation process and statistics of the official United Nations Parallel Corpus, the first parallel corpus composed from United Nations documents published by the original data creator. The parallel corpus presented consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish. The corpus is freely available for download under a liberal license. Apart from the pairwise aligned documents, a fully aligned subcorpus for the six official UN languages is distributed. We provide baseline BLEU scores of our Moses-based SMT systems trained with the full data of language pairs involving English and for all possible translation directions of the six-way subcorpus.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['ar', 'en', 'es', 'fr', 'ru', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': 'united-nations-parallel-corpus', 'pretty_name': 'United Nations Parallel Corpus', 'configs': ['ar-en', 'ar-es', 'ar-fr', 'ar-ru', 'ar-zh', 'en-es', 'en-fr', 'en-ru', 'en-zh', 'es-fr', 'es-ru', 'es-zh', 'fr-ru', 'fr-zh', 'ru-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2881\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: united-nations-parallel-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: universal_dependencies\n",
       " \tsha: e458bbdcb2ee985ba9bac686d4af5ab0a1334268\n",
       " \tlastModified: 2022-07-27T14:39:11.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:af', 'language:aii', 'language:ajp', 'language:akk', 'language:am', 'language:apu', 'language:aqz', 'language:ar', 'language:be', 'language:bg', 'language:bho', 'language:bm', 'language:br', 'language:bxr', 'language:ca', 'language:ckt', 'language:cop', 'language:cs', 'language:cu', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fro', 'language:ga', 'language:gd', 'language:gl', 'language:got', 'language:grc', 'language:gsw', 'language:gun', 'language:gv', 'language:he', 'language:hi', 'language:hr', 'language:hsb', 'language:hu', 'language:hy', 'language:id', 'language:is', 'language:it', 'language:ja', 'language:kfm', 'language:kk', 'language:kmr', 'language:ko', 'language:koi', 'language:kpv', 'language:krl', 'language:la', 'language:lt', 'language:lv', 'language:lzh', 'language:mdf', 'language:mr', 'language:mt', 'language:myu', 'language:myv', 'language:nl', 'language:no', 'language:nyq', 'language:olo', 'language:orv', 'language:otk', 'language:pcm', 'language:pl', 'language:pt', 'language:ro', 'language:ru', 'language:sa', 'language:sk', 'language:sl', 'language:sme', 'language:sms', 'language:soj', 'language:sq', 'language:sr', 'language:sv', 'language:swl', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tpn', 'language:tr', 'language:ug', 'language:uk', 'language:ur', 'language:vi', 'language:wbp', 'language:wo', 'language:yo', 'language:yue', 'language:zh', 'license:unknown', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:parsing', 'task_ids:token-classification-other-constituency-parsing', 'task_ids:token-classification-other-dependency-parsing', 'configs:af_afribooms', 'configs:aii_as', 'configs:ajp_madar', 'configs:akk_pisandub', 'configs:akk_riao', 'configs:am_att', 'configs:apu_ufpa', 'configs:aqz_tudet', 'configs:ar_nyuad', 'configs:ar_padt', 'configs:ar_pud', 'configs:be_hse', 'configs:bg_btb', 'configs:bho_bhtb', 'configs:bm_crb', 'configs:br_keb', 'configs:bxr_bdt', 'configs:ca_ancora', 'configs:ckt_hse', 'configs:cop_scriptorium', 'configs:cs_cac', 'configs:cs_cltt', 'configs:cs_fictree', 'configs:cs_pdt', 'configs:cs_pud', 'configs:cu_proiel', 'configs:cy_ccg', 'configs:da_ddt', 'configs:de_gsd', 'configs:de_hdt', 'configs:de_lit', 'configs:de_pud', 'configs:el_gdt', 'configs:en_esl', 'configs:en_ewt', 'configs:en_gum', 'configs:en_gumreddit', 'configs:en_lines', 'configs:en_partut', 'configs:en_pronouns', 'configs:en_pud', 'configs:es_ancora', 'configs:es_gsd', 'configs:es_pud', 'configs:et_edt', 'configs:et_ewt', 'configs:eu_bdt', 'configs:fa_perdt', 'configs:fa_seraji', 'configs:fi_ftb', 'configs:fi_ood', 'configs:fi_pud', 'configs:fi_tdt', 'configs:fo_farpahc', 'configs:fo_oft', 'configs:fr_fqb', 'configs:fr_ftb', 'configs:fr_gsd', 'configs:fr_partut', 'configs:fr_pud', 'configs:fr_sequoia', 'configs:fr_spoken', 'configs:fro_srcmf', 'configs:ga_idt', 'configs:gd_arcosg', 'configs:gl_ctg', 'configs:gl_treegal', 'configs:got_proiel', 'configs:grc_perseus', 'configs:grc_proiel', 'configs:gsw_uzh', 'configs:gun_dooley', 'configs:gun_thomas', 'configs:gv_cadhan', 'configs:he_htb', 'configs:hi_hdtb', 'configs:hi_pud', 'configs:hr_set', 'configs:hsb_ufal', 'configs:hu_szeged', 'configs:hy_armtdp', 'configs:id_csui', 'configs:id_gsd', 'configs:id_pud', 'configs:is_icepahc', 'configs:is_pud', 'configs:it_isdt', 'configs:it_partut', 'configs:it_postwita', 'configs:it_pud', 'configs:it_twittiro', 'configs:it_vit', 'configs:ja_bccwj', 'configs:ja_gsd', 'configs:ja_modern', 'configs:ja_pud', 'configs:kfm_aha', 'configs:kk_ktb', 'configs:kmr_mg', 'configs:ko_gsd', 'configs:ko_kaist', 'configs:ko_pud', 'configs:koi_uh', 'configs:kpv_ikdp', 'configs:kpv_lattice', 'configs:krl_kkpp', 'configs:la_ittb', 'configs:la_llct', 'configs:la_perseus', 'configs:la_proiel', 'configs:lt_alksnis', 'configs:lt_hse', 'configs:lv_lvtb', 'configs:lzh_kyoto', 'configs:mdf_jr', 'configs:mr_ufal', 'configs:mt_mudt', 'configs:myu_tudet', 'configs:myv_jr', 'configs:nl_alpino', 'configs:nl_lassysmall', 'configs:no_bokmaal', 'configs:no_nynorsk', 'configs:no_nynorsklia', 'configs:nyq_aha', 'configs:olo_kkpp', 'configs:orv_rnc', 'configs:orv_torot', 'configs:otk_tonqq', 'configs:pcm_nsc', 'configs:pl_lfg', 'configs:pl_pdb', 'configs:pl_pud', 'configs:pt_bosque', 'configs:pt_gsd', 'configs:pt_pud', 'configs:qhe_hiencs', 'configs:qtd_sagt', 'configs:ro_nonstandard', 'configs:ro_rrt', 'configs:ro_simonero', 'configs:ru_gsd', 'configs:ru_pud', 'configs:ru_syntagrus', 'configs:ru_taiga', 'configs:sa_ufal', 'configs:sa_vedic', 'configs:sk_snk', 'configs:sl_ssj', 'configs:sl_sst', 'configs:sme_giella', 'configs:sms_giellagas', 'configs:soj_aha', 'configs:sq_tsa', 'configs:sr_set', 'configs:sv_lines', 'configs:sv_pud', 'configs:sv_talbanken', 'configs:swl_sslc', 'configs:ta_mwtt', 'configs:ta_ttb', 'configs:te_mtg', 'configs:th_pud', 'configs:tl_trg', 'configs:tl_ugnayan', 'configs:tpn_tudet', 'configs:tr_boun', 'configs:tr_gb', 'configs:tr_imst', 'configs:tr_pud', 'configs:ug_udt', 'configs:uk_iu', 'configs:ur_udtb', 'configs:vi_vtb', 'configs:wbp_ufal', 'configs:wo_wtb', 'configs:yo_ytb', 'configs:yue_hk', 'configs:zh_cfl', 'configs:zh_gsd', 'configs:zh_gsdsimp', 'configs:zh_hk', 'configs:zh_pud']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008).\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['af', 'aii', 'ajp', 'akk', 'am', 'apu', 'aqz', 'ar', 'be', 'bg', 'bho', 'bm', 'br', 'bxr', 'ca', 'ckt', 'cop', 'cs', 'cu', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fro', 'ga', 'gd', 'gl', 'got', 'grc', 'gsw', 'gun', 'gv', 'he', 'hi', 'hr', 'hsb', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'kfm', 'kk', 'kmr', 'ko', 'koi', 'kpv', 'krl', 'la', 'lt', 'lv', 'lzh', 'mdf', 'mr', 'mt', 'myu', 'myv', 'nl', 'no', 'nyq', 'olo', 'orv', 'otk', 'pcm', 'pl', 'pt', 'ro', 'ru', 'sa', 'sk', 'sl', 'sme', 'sms', 'soj', 'sq', 'sr', 'sv', 'swl', 'ta', 'te', 'th', 'tl', 'tpn', 'tr', 'ug', 'uk', 'ur', 'vi', 'wbp', 'wo', 'yo', 'yue', 'zh'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['parsing', 'token-classification-other-constituency-parsing', 'token-classification-other-dependency-parsing'], 'paperswithcode_id': 'universal-dependencies', 'pretty_name': 'Universal Dependencies Treebank', 'configs': ['af_afribooms', 'aii_as', 'ajp_madar', 'akk_pisandub', 'akk_riao', 'am_att', 'apu_ufpa', 'aqz_tudet', 'ar_nyuad', 'ar_padt', 'ar_pud', 'be_hse', 'bg_btb', 'bho_bhtb', 'bm_crb', 'br_keb', 'bxr_bdt', 'ca_ancora', 'ckt_hse', 'cop_scriptorium', 'cs_cac', 'cs_cltt', 'cs_fictree', 'cs_pdt', 'cs_pud', 'cu_proiel', 'cy_ccg', 'da_ddt', 'de_gsd', 'de_hdt', 'de_lit', 'de_pud', 'el_gdt', 'en_esl', 'en_ewt', 'en_gum', 'en_gumreddit', 'en_lines', 'en_partut', 'en_pronouns', 'en_pud', 'es_ancora', 'es_gsd', 'es_pud', 'et_edt', 'et_ewt', 'eu_bdt', 'fa_perdt', 'fa_seraji', 'fi_ftb', 'fi_ood', 'fi_pud', 'fi_tdt', 'fo_farpahc', 'fo_oft', 'fr_fqb', 'fr_ftb', 'fr_gsd', 'fr_partut', 'fr_pud', 'fr_sequoia', 'fr_spoken', 'fro_srcmf', 'ga_idt', 'gd_arcosg', 'gl_ctg', 'gl_treegal', 'got_proiel', 'grc_perseus', 'grc_proiel', 'gsw_uzh', 'gun_dooley', 'gun_thomas', 'gv_cadhan', 'he_htb', 'hi_hdtb', 'hi_pud', 'hr_set', 'hsb_ufal', 'hu_szeged', 'hy_armtdp', 'id_csui', 'id_gsd', 'id_pud', 'is_icepahc', 'is_pud', 'it_isdt', 'it_partut', 'it_postwita', 'it_pud', 'it_twittiro', 'it_vit', 'ja_bccwj', 'ja_gsd', 'ja_modern', 'ja_pud', 'kfm_aha', 'kk_ktb', 'kmr_mg', 'ko_gsd', 'ko_kaist', 'ko_pud', 'koi_uh', 'kpv_ikdp', 'kpv_lattice', 'krl_kkpp', 'la_ittb', 'la_llct', 'la_perseus', 'la_proiel', 'lt_alksnis', 'lt_hse', 'lv_lvtb', 'lzh_kyoto', 'mdf_jr', 'mr_ufal', 'mt_mudt', 'myu_tudet', 'myv_jr', 'nl_alpino', 'nl_lassysmall', 'no_bokmaal', 'no_nynorsk', 'no_nynorsklia', 'nyq_aha', 'olo_kkpp', 'orv_rnc', 'orv_torot', 'otk_tonqq', 'pcm_nsc', 'pl_lfg', 'pl_pdb', 'pl_pud', 'pt_bosque', 'pt_gsd', 'pt_pud', 'qhe_hiencs', 'qtd_sagt', 'ro_nonstandard', 'ro_rrt', 'ro_simonero', 'ru_gsd', 'ru_pud', 'ru_syntagrus', 'ru_taiga', 'sa_ufal', 'sa_vedic', 'sk_snk', 'sl_ssj', 'sl_sst', 'sme_giella', 'sms_giellagas', 'soj_aha', 'sq_tsa', 'sr_set', 'sv_lines', 'sv_pud', 'sv_talbanken', 'swl_sslc', 'ta_mwtt', 'ta_ttb', 'te_mtg', 'th_pud', 'tl_trg', 'tl_ugnayan', 'tpn_tudet', 'tr_boun', 'tr_gb', 'tr_imst', 'tr_pud', 'ug_udt', 'uk_iu', 'ur_udtb', 'vi_vtb', 'wbp_ufal', 'wo_wtb', 'yo_ytb', 'yue_hk', 'zh_cfl', 'zh_gsd', 'zh_gsdsimp', 'zh_hk', 'zh_pud']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2844\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: universal-dependencies\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: universal_morphologies\n",
       " \tsha: bd42a801aa242bc70bf2d99e5a5e2f4e1a116fe3\n",
       " \tlastModified: 2022-07-01T11:57:07.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:ady', 'language:ang', 'language:ar', 'language:arn', 'language:ast', 'language:az', 'language:ba', 'language:be', 'language:bg', 'language:bn', 'language:bo', 'language:br', 'language:ca', 'language:ckb', 'language:crh', 'language:cs', 'language:csb', 'language:cu', 'language:cy', 'language:da', 'language:de', 'language:dsb', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:frm', 'language:fro', 'language:frr', 'language:fur', 'language:fy', 'language:ga', 'language:gal', 'language:gd', 'language:gmh', 'language:gml', 'language:got', 'language:grc', 'language:gv', 'language:hai', 'language:he', 'language:hi', 'language:hu', 'language:hy', 'language:is', 'language:it', 'language:izh', 'language:ka', 'language:kbd', 'language:kjh', 'language:kk', 'language:kl', 'language:klr', 'language:kmr', 'language:kn', 'language:krl', 'language:kw', 'language:la', 'language:liv', 'language:lld', 'language:lt', 'language:lud', 'language:lv', 'language:mk', 'language:mt', 'language:mwf', 'language:nap', 'language:nb', 'language:nds', 'language:nl', 'language:nn', 'language:nv', 'language:oc', 'language:olo', 'language:osx', 'language:pl', 'language:ps', 'language:pt', 'language:qu', 'language:ro', 'language:ru', 'language:sa', 'language:sga', 'language:sh', 'language:sl', 'language:sme', 'language:sq', 'language:sv', 'language:swc', 'language:syc', 'language:te', 'language:tg', 'language:tk', 'language:tr', 'language:tt', 'language:uk', 'language:ur', 'language:uz', 'language:vec', 'language:vep', 'language:vot', 'language:xcl', 'language:xno', 'language:yi', 'language:zu', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:token-classification-other-morphology', 'configs:ady', 'configs:ang', 'configs:ara', 'configs:arn', 'configs:ast', 'configs:aze', 'configs:bak', 'configs:bel', 'configs:ben', 'configs:bod', 'configs:bre', 'configs:bul', 'configs:cat', 'configs:ces', 'configs:chu', 'configs:ckb', 'configs:cor', 'configs:crh', 'configs:csb', 'configs:cym', 'configs:dan', 'configs:deu', 'configs:dsb', 'configs:ell', 'configs:eng', 'configs:est', 'configs:eus', 'configs:fao', 'configs:fas', 'configs:fin', 'configs:fra', 'configs:frm', 'configs:fro', 'configs:frr', 'configs:fry', 'configs:fur', 'configs:gal', 'configs:gla', 'configs:gle', 'configs:glv', 'configs:gmh', 'configs:gml', 'configs:got', 'configs:grc', 'configs:hai', 'configs:hbs', 'configs:heb', 'configs:hin', 'configs:hun', 'configs:hye', 'configs:isl', 'configs:ita', 'configs:izh', 'configs:kal', 'configs:kan', 'configs:kat', 'configs:kaz', 'configs:kbd', 'configs:kjh', 'configs:klr', 'configs:kmr', 'configs:krl', 'configs:lat', 'configs:lav', 'configs:lit', 'configs:liv', 'configs:lld', 'configs:lud', 'configs:mkd', 'configs:mlt', 'configs:mwf', 'configs:nap', 'configs:nav', 'configs:nds', 'configs:nld', 'configs:nno', 'configs:nob', 'configs:oci', 'configs:olo', 'configs:osx', 'configs:pol', 'configs:por', 'configs:pus', 'configs:que', 'configs:ron', 'configs:rus', 'configs:san', 'configs:sga', 'configs:slv', 'configs:sme', 'configs:spa', 'configs:sqi', 'configs:swc', 'configs:swe', 'configs:syc', 'configs:tat', 'configs:tel', 'configs:tgk', 'configs:tuk', 'configs:tur', 'configs:ukr', 'configs:urd', 'configs:uzb', 'configs:vec', 'configs:vep', 'configs:vot', 'configs:xcl', 'configs:xno', 'configs:yid', 'configs:zul']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Universal Morphology (UniMorph) project is a collaborative effort to improve how NLP handles complex morphology in the world’s languages.\n",
       " The goal of UniMorph is to annotate morphological data in a universal schema that allows an inflected word from any language to be defined by its lexical meaning,\n",
       " typically carried by the lemma, and by a rendering of its inflectional form in terms of a bundle of morphological features from our schema.\n",
       " The specification of the schema is described in Sylak-Glassman (2016).\n",
       " \tcitation: @article{sylak2016composition,\n",
       "   title={The composition and use of the universal morphological feature schema (unimorph schema)},\n",
       "   author={Sylak-Glassman, John},\n",
       "   journal={Johns Hopkins University},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ady', 'ang', 'ar', 'arn', 'ast', 'az', 'ba', 'be', 'bg', 'bn', 'bo', 'br', 'ca', 'ckb', 'crh', 'cs', 'csb', 'cu', 'cy', 'da', 'de', 'dsb', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'frm', 'fro', 'frr', 'fur', 'fy', 'ga', 'gal', 'gd', 'gmh', 'gml', 'got', 'grc', 'gv', 'hai', 'he', 'hi', 'hu', 'hy', 'is', 'it', 'izh', 'ka', 'kbd', 'kjh', 'kk', 'kl', 'klr', 'kmr', 'kn', 'krl', 'kw', 'la', 'liv', 'lld', 'lt', 'lud', 'lv', 'mk', 'mt', 'mwf', 'nap', 'nb', 'nds', 'nl', 'nn', 'nv', 'oc', 'olo', 'osx', 'pl', 'ps', 'pt', 'qu', 'ro', 'ru', 'sa', 'sga', 'sh', 'sl', 'sme', 'sq', 'sv', 'swc', 'syc', 'te', 'tg', 'tk', 'tr', 'tt', 'uk', 'ur', 'uz', 'vec', 'vep', 'vot', 'xcl', 'xno', 'yi', 'zu'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K', '1K<n<10K', 'n<1K'], 'source_datasets': ['original'], 'task_categories': ['token-classification', 'text-classification'], 'task_ids': ['multi-class-classification', 'multi-label-classification', 'token-classification-other-morphology'], 'paperswithcode_id': None, 'pretty_name': 'UniversalMorphologies', 'configs': ['ady', 'ang', 'ara', 'arn', 'ast', 'aze', 'bak', 'bel', 'ben', 'bod', 'bre', 'bul', 'cat', 'ces', 'chu', 'ckb', 'cor', 'crh', 'csb', 'cym', 'dan', 'deu', 'dsb', 'ell', 'eng', 'est', 'eus', 'fao', 'fas', 'fin', 'fra', 'frm', 'fro', 'frr', 'fry', 'fur', 'gal', 'gla', 'gle', 'glv', 'gmh', 'gml', 'got', 'grc', 'hai', 'hbs', 'heb', 'hin', 'hun', 'hye', 'isl', 'ita', 'izh', 'kal', 'kan', 'kat', 'kaz', 'kbd', 'kjh', 'klr', 'kmr', 'krl', 'lat', 'lav', 'lit', 'liv', 'lld', 'lud', 'mkd', 'mlt', 'mwf', 'nap', 'nav', 'nds', 'nld', 'nno', 'nob', 'oci', 'olo', 'osx', 'pol', 'por', 'pus', 'que', 'ron', 'rus', 'san', 'sga', 'slv', 'sme', 'spa', 'sqi', 'swc', 'swe', 'syc', 'tat', 'tel', 'tgk', 'tuk', 'tur', 'ukr', 'urd', 'uzb', 'vec', 'vep', 'vot', 'xcl', 'xno', 'yid', 'zul']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 16834\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: urdu_fake_news\n",
       " \tsha: 9dde2aba2e0807e2f17674f2b869b9e50f8093b1\n",
       " \tlastModified: 2022-07-01T11:57:09.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ur', 'license:unknown', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking', 'task_ids:intent-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Urdu fake news datasets that contain news of 5 different news domains.\n",
       " These domains are Sports, Health, Technology, Entertainment, and Business.\n",
       " The real news are collected by combining manual approaches.\n",
       " \tcitation: @article{MaazUrdufake2020,\n",
       " author = {Amjad, Maaz and Sidorov, Grigori and Zhila, Alisa and  G’{o}mez-Adorno, Helena and Voronkov, Ilia  and Gelbukh, Alexander},\n",
       " title = {Bend the Truth: A Benchmark Dataset for Fake News Detection in Urdu and Its Evaluation},\n",
       " journal={Journal of Intelligent & Fuzzy Systems},\n",
       " volume={39},\n",
       " number={2},\n",
       " pages={2457-2469},\n",
       " doi = {10.3233/JIFS-179905},\n",
       " year={2020},\n",
       " publisher={IOS Press}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ur'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking', 'intent-classification'], 'paperswithcode_id': None, 'pretty_name': 'Bend the Truth (Urdu Fake News)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: urdu_sentiment_corpus\n",
       " \tsha: a872f449b7234b37f005b5c6ccf698052a2b5944\n",
       " \tlastModified: 2022-07-01T11:57:09.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:ur', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: “Urdu Sentiment Corpus” (USC) shares the dat of Urdu tweets for the sentiment analysis and polarity detection.\n",
       " The dataset is consisting of tweets and overall, the dataset is comprising over 17, 185 tokens\n",
       " with 52% records as positive, and 48 % records as negative.\n",
       " \tcitation: @inproceedings{khan2020usc,\n",
       "   title={Urdu Sentiment Corpus (v1.0): Linguistic Exploration and Visualization of Labeled Datasetfor Urdu Sentiment Analysis.},\n",
       "   author={Khan, Muhammad Yaseen and Nizami, Muhammad Suffian},\n",
       "   booktitle={2020 IEEE 2nd International Conference On Information Science & Communication Technology (ICISCT)},\n",
       "   pages={},\n",
       "   year={2020},\n",
       "   organization={IEEE}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['ur'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': 'urdu-sentiment-corpus', 'pretty_name': 'Urdu Sentiment Corpus (USC)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: urdu-sentiment-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: vctk\n",
       " \tsha: 9d4dd268786c796539729afaec37a8268dc3dfc4\n",
       " \tlastModified: 2022-07-01T11:57:09.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents.\n",
       " \tcitation: @inproceedings{Veaux2017CSTRVC,\n",
       "     title        = {CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit},\n",
       "     author       = {Christophe Veaux and Junichi Yamagishi and Kirsten MacDonald},\n",
       "     year         = 2017\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'VCTK', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': [], 'paperswithcode_id': 'vctk', 'train-eval-index': [{'config': 'main', 'task': 'automatic-speech-recognition', 'task_id': 'speech_recognition', 'splits': {'train_split': 'train'}, 'col_mapping': {'file': 'path', 'text': 'text'}, 'metrics': [{'type': 'wer', 'name': 'WER'}, {'type': 'cer', 'name': 'CER'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 347\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: vctk\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: vivos\n",
       " \tsha: ecddd2af104300b6d4135ac34de4ef174af3c0f0\n",
       " \tlastModified: 2022-09-12T07:14:46.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:vi', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:automatic-speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " VIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for\n",
       " Vietnamese Automatic Speech Recognition task.\n",
       " The corpus was prepared by AILAB, a computer science lab of VNUHCM - University of Science, with Prof. Vu Hai Quan is the head of.\n",
       " We publish this corpus in hope to attract more scientists to solve Vietnamese speech recognition problems.\n",
       " \tcitation: \\\n",
       " @inproceedings{luong-vu-2016-non,\n",
       "     title = \"A non-expert {K}aldi recipe for {V}ietnamese Speech Recognition System\",\n",
       "     author = \"Luong, Hieu-Thi  and\n",
       "       Vu, Hai-Quan\",\n",
       "     booktitle = \"Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016)\",\n",
       "     month = dec,\n",
       "     year = \"2016\",\n",
       "     address = \"Osaka, Japan\",\n",
       "     publisher = \"The COLING 2016 Organizing Committee\",\n",
       "     url = \"https://aclanthology.org/W16-5207\",\n",
       "     pages = \"51--55\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'VIVOS', 'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['vi'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: web_nlg\n",
       " \tsha: d156094f6cd718206d13e120de2332682ee5624d\n",
       " \tlastModified: 2022-07-01T12:43:46.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:crowdsourced', 'language:en', 'language:ru', 'license:cc-by-sa-3.0', 'license:cc-by-nc-sa-4.0', 'license:gfdl', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-db_pedia', 'source_datasets:original', 'task_categories:tabular-to-text', 'task_ids:rdf-to-text', 'configs:release_v1', 'configs:release_v2', 'configs:release_v2.1', 'configs:release_v2.1_constrained', 'configs:release_v2_constrained', 'configs:release_v3.0_en', 'configs:release_v3.0_ru', 'configs:webnlg_challenge_2017']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The WebNLG challenge consists in mapping data to text. The training data consists\n",
       " of Data/Text pairs where the data is a set of triples extracted from DBpedia and the text is a verbalisation\n",
       " of these triples. For instance, given the 3 DBpedia triples shown in (a), the aim is to generate a text such as (b).\n",
       " \n",
       " a. (John_E_Blaha birthDate 1942_08_26) (John_E_Blaha birthPlace San_Antonio) (John_E_Blaha occupation Fighter_pilot)\n",
       " b. John E Blaha, born in San Antonio on 1942-08-26, worked as a fighter pilot\n",
       " \n",
       " As the example illustrates, the task involves specific NLG subtasks such as sentence segmentation\n",
       " (how to chunk the input data into sentences), lexicalisation (of the DBpedia properties),\n",
       " aggregation (how to avoid repetitions) and surface realisation\n",
       " (how to build a syntactically correct and natural sounding text).\n",
       " \tcitation: @inproceedings{web_nlg,\n",
       "   author    = {Claire Gardent and\n",
       "                Anastasia Shimorina and\n",
       "                Shashi Narayan and\n",
       "                Laura Perez{-}Beltrachini},\n",
       "   editor    = {Regina Barzilay and\n",
       "                Min{-}Yen Kan},\n",
       "   title     = {Creating Training Corpora for {NLG} Micro-Planners},\n",
       "   booktitle = {Proceedings of the 55th Annual Meeting of the\n",
       "                Association for Computational Linguistics,\n",
       "                {ACL} 2017, Vancouver, Canada, July 30 - August 4,\n",
       "                Volume 1: Long Papers},\n",
       "   pages     = {179--188},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year      = {2017},\n",
       "   url       = {https://doi.org/10.18653/v1/P17-1017},\n",
       "   doi       = {10.18653/v1/P17-1017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['crowdsourced'], 'language': ['en', 'ru'], 'license': ['cc-by-sa-3.0', 'cc-by-nc-sa-4.0', 'gfdl'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-db_pedia', 'original'], 'task_categories': ['tabular-to-text'], 'task_ids': ['rdf-to-text'], 'paperswithcode_id': 'webnlg', 'pretty_name': 'WebNLG', 'configs': ['release_v1', 'release_v2', 'release_v2.1', 'release_v2.1_constrained', 'release_v2_constrained', 'release_v3.0_en', 'release_v3.0_ru', 'webnlg_challenge_2017']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2377\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: webnlg\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: web_of_science\n",
       " \tsha: b7dd29d58ed3b8ad40ff6b50150c8a746667006d\n",
       " \tlastModified: 2022-07-01T11:57:13.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Web Of Science (WOS) dataset is a collection of data  of published papers\n",
       " available from the Web of Science. WOS has been released in three versions: WOS-46985, WOS-11967 and WOS-5736. WOS-46985 is the\n",
       " full dataset. WOS-11967 and WOS-5736 are two subsets of WOS-46985.\n",
       " \tcitation: @inproceedings{kowsari2017HDLTex,\n",
       " title={HDLTex: Hierarchical Deep Learning for Text Classification},\n",
       " author={Kowsari, Kamran and Brown, Donald E and Heidarysafa, Mojtaba and Jafari Meimandi, Kiana and and Gerber, Matthew S and Barnes, Laura E},\n",
       " booktitle={Machine Learning and Applications (ICMLA), 2017 16th IEEE International Conference on},\n",
       " year={2017},\n",
       " organization={IEEE}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'web-of-science-dataset', 'pretty_name': 'Web of Science Dataset'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1430\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: web-of-science-dataset\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: web_questions\n",
       " \tsha: b278139df50bb5e50b894044eed62bb8d467e302\n",
       " \tlastModified: 2022-08-26T04:42:19.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset consists of 6,642 question/answer pairs.\n",
       " The questions are supposed to be answerable by Freebase, a large knowledge graph.\n",
       " The questions are mostly centered around a single named entity.\n",
       " The questions are popular ones asked on the web (at least in 2013).\n",
       " \tcitation: @inproceedings{berant-etal-2013-semantic,\n",
       "     title = \"Semantic Parsing on {F}reebase from Question-Answer Pairs\",\n",
       "     author = \"Berant, Jonathan  and\n",
       "       Chou, Andrew  and\n",
       "       Frostig, Roy  and\n",
       "       Liang, Percy\",\n",
       "     booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct,\n",
       "     year = \"2013\",\n",
       "     address = \"Seattle, Washington, USA\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/D13-1160\",\n",
       "     pages = \"1533--1544\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'WebQuestions', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'webquestions'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 18097\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: webquestions\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: weibo_ner\n",
       " \tsha: 0dcb08266f4faeb95f3a8fd3a5ee54742350cc2b\n",
       " \tlastModified: 2022-07-01T11:57:13.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:zh', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Tags: PER(人名), LOC(地点名), GPE(行政区名), ORG(机构名)\n",
       " Label\tTag\tMeaning\n",
       " PER\tPER.NAM\t名字（张三）\n",
       " PER.NOM\t代称、类别名（穷人）\n",
       " LOC\tLOC.NAM\t特指名称（紫玉山庄）\n",
       " LOC.NOM\t泛称（大峡谷、宾馆）\n",
       " GPE\tGPE.NAM\t行政区的名称（北京）\n",
       " ORG\tORG.NAM\t特定机构名称（通惠医院）\n",
       " ORG.NOM\t泛指名称、统称（文艺公司）\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['zh'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'weibo-ner', 'pretty_name': 'Weibo NER', 'train-eval-index': [{'config': 'default', 'task': 'token-classification', 'task_id': 'entity_extraction', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'tokens': 'tokens', 'ner_tags': 'tags'}, 'metrics': [{'type': 'seqeval', 'name': 'seqeval'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 400\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: weibo-ner\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wi_locness\n",
       " \tsha: 312ab230f40161a58adc59754431a392401d4c49\n",
       " \tlastModified: 2022-07-01T12:43:47.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'license:other', 'multilinguality:monolingual', 'multilinguality:other-language-learner', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-grammatical-error-correction', 'configs:locness', 'configs:wi']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Write & Improve (Yannakoudakis et al., 2018) is an online web platform that assists non-native\n",
       " English students with their writing. Specifically, students from around the world submit letters,\n",
       " stories, articles and essays in response to various prompts, and the W&I system provides instant\n",
       " feedback. Since W&I went live in 2014, W&I annotators have manually annotated some of these\n",
       " submissions and assigned them a CEFR level.\n",
       " \tcitation: @inproceedings{bryant-etal-2019-bea,\n",
       "     title = \"The {BEA}-2019 Shared Task on Grammatical Error Correction\",\n",
       "     author = \"Bryant, Christopher  and\n",
       "         Felice, Mariano  and\n",
       "         Andersen, {\\\\O}istein E.  and\n",
       "         Briscoe, Ted\",\n",
       "     booktitle = \"Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications\",\n",
       "     month = aug,\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/W19-4406\",\n",
       "     doi = \"10.18653/v1/W19-4406\",\n",
       "     pages = \"52--75\",\n",
       "     abstract = \"This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC). As with the CoNLL-2014 shared task, participants are required to correct all types of errors in test data. One of the main contributions of the BEA-2019 shared task is the introduction of a new dataset, the Write{\\\\&}Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities. Another contribution is the introduction of tracks, which control the amount of annotated data available to participants. Systems are evaluated in terms of ERRANT F{\\\\_}0.5, which allows us to report a much wider range of performance statistics. The competition was hosted on Codalab and remains open for further submissions on the blind test set.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['monolingual', 'other-language-learner'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-grammatical-error-correction'], 'paperswithcode_id': 'locness-corpus', 'pretty_name': 'Cambridge English Write & Improve + LOCNESS', 'configs': ['locness', 'wi']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 522\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: locness-corpus\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wider_face\n",
       " \tsha: 2551e875f892e8ebb5b7e67553bd28d49ec53e48\n",
       " \tlastModified: 2022-07-01T11:57:14.000Z\n",
       " \ttags: ['arxiv:1511.06523', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'license:cc-by-nc-nd-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-wider', 'task_categories:object-detection', 'task_ids:face-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WIDER FACE dataset is a face detection benchmark dataset, of which images are\n",
       " selected from the publicly available WIDER dataset. We choose 32,203 images and\n",
       " label 393,703 faces with a high degree of variability in scale, pose and\n",
       " occlusion as depicted in the sample images. WIDER FACE dataset is organized\n",
       " based on 61 event classes. For each event class, we randomly select 40%/10%/50%\n",
       " data as training, validation and testing sets. We adopt the same evaluation\n",
       " metric employed in the PASCAL VOC dataset. Similar to MALF and Caltech datasets,\n",
       " we do not release bounding box ground truth for the test images. Users are\n",
       " required to submit final prediction files, which we shall proceed to evaluate.\n",
       " \tcitation: @inproceedings{yang2016wider,\n",
       "     Author = {Yang, Shuo and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},\n",
       "     Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
       "     Title = {WIDER FACE: A Face Detection Benchmark},\n",
       "     Year = {2016}}\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-nc-nd-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-wider'], 'task_categories': ['object-detection'], 'task_ids': ['face-detection'], 'paperswithcode_id': 'wider-face-1', 'pretty_name': 'WIDER FACE'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 398\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: wider-face-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki40b\n",
       " \tsha: ad69a2012e02164ec5bffa586f80a194391ee4e8\n",
       " \tlastModified: 2022-07-01T11:57:14.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Clean-up text for 40+ Wikipedia languages editions of pages\n",
       " correspond to entities. The datasets have train/dev/test splits per language.\n",
       " The dataset is cleaned up by page filtering to remove disambiguation pages,\n",
       " redirect pages, deleted pages, and non-entity pages. Each example contains the\n",
       " wikidata id of the entity, and the full Wikipedia article after page processing\n",
       " that removes non-content sections and structured objects.\n",
       " \tcitation: \n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'wiki-40b', 'pretty_name': 'Wiki-40B'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 6951\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: wiki-40b\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_asp\n",
       " \tsha: b8f0ac095cb7f8d39bc8e997df4da115c0f45526\n",
       " \tlastModified: 2022-08-11T12:57:40.000Z\n",
       " \ttags: ['arxiv:2011.07832', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization-other-aspect-based-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiAsp is a multi-domain, aspect-based summarization dataset in the encyclopedic\n",
       " domain. In this task, models are asked to summarize cited reference documents of a\n",
       " Wikipedia article into aspect-based summaries. Each of the 20 domains include 10\n",
       " domain-specific pre-defined aspects.\n",
       " \tcitation: @article{hayashi20tacl,\n",
       "   title   = {WikiAsp: A Dataset for Multi-domain Aspect-based Summarization},\n",
       "   authors = {Hiroaki Hayashi and Prashant Budania and Peng Wang and Chris Ackerson and Raj Neervannan and Graham Neubig},\n",
       "   journal = {Transactions of the Association for Computational Linguistics (TACL)},\n",
       "   year    = {2020},\n",
       "   url     = {https://arxiv.org/abs/2011.07832}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-aspect-based-summarization'], 'paperswithcode_id': 'wikiasp', 'pretty_name': 'WikiAsp'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3496\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: wikiasp\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_atomic_edits\n",
       " \tsha: 5d9c47bfc0b417139dac8b66278cda39cdfb9a43\n",
       " \tlastModified: 2022-08-11T14:03:50.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:ja', 'language:ru', 'language:zh', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:summarization', 'configs:chinese_deletions', 'configs:chinese_insertions', 'configs:english_deletions', 'configs:english_insertions', 'configs:french_deletions', 'configs:french_insertions', 'configs:german_deletions', 'configs:german_insertions', 'configs:italian_deletions', 'configs:italian_insertions', 'configs:japanese_deletions', 'configs:japanese_insertions', 'configs:russian_deletions', 'configs:russian_insertions', 'configs:spanish_deletions', 'configs:spanish_insertions']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A dataset of atomic wikipedia edits containing insertions and deletions of a contiguous chunk of text in a sentence. This dataset contains ~43 million edits across 8 languages.\n",
       " \n",
       " An atomic edit is defined as an edit e applied to a natural language expression S as the insertion, deletion, or substitution of a sub-expression P such that both the original expression S and the resulting expression e(S) are well-formed semantic constituents (MacCartney, 2009). In this corpus, we release such atomic insertions and deletions made to sentences in wikipedia.\n",
       " \tcitation: @InProceedings{WikiAtomicEdits,\n",
       "   title = {{WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse}},\n",
       "   author = {Faruqui, Manaal and Pavlick, Ellie and Tenney, Ian and Das, Dipanjan},\n",
       "   booktitle = {Proc. of EMNLP},\n",
       "   year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['de', 'en', 'es', 'fr', 'it', 'ja', 'ru', 'zh'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M', '10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': [], 'paperswithcode_id': 'wikiatomicedits', 'pretty_name': 'WikiAtomicEdits', 'configs': ['chinese_deletions', 'chinese_insertions', 'english_deletions', 'english_insertions', 'french_deletions', 'french_insertions', 'german_deletions', 'german_insertions', 'italian_deletions', 'italian_insertions', 'japanese_deletions', 'japanese_insertions', 'russian_deletions', 'russian_insertions', 'spanish_deletions', 'spanish_insertions']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2662\n",
       " \tlikes: 6\n",
       " \tpaperswithcode_id: wikiatomicedits\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_auto\n",
       " \tsha: fb726e8515d6c637fdd39eedbdd5966a5824f899\n",
       " \tlastModified: 2022-07-01T11:57:17.000Z\n",
       " \ttags: ['arxiv:2005.02324', 'annotations_creators:crowdsourced', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:extended|other-wikipedia', 'task_categories:text2text-generation', 'task_ids:text-simplification', 'configs:auto', 'configs:auto_acl', 'configs:auto_full_no_split', 'configs:auto_full_with_split', 'configs:manual']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiAuto provides a set of aligned sentences from English Wikipedia and Simple English Wikipedia\n",
       " as a resource to train sentence simplification systems. The authors first crowd-sourced a set of manual alignments\n",
       " between sentences in a subset of the Simple English Wikipedia and their corresponding versions in English Wikipedia\n",
       " (this corresponds to the `manual` config), then trained a neural CRF system to predict these alignments.\n",
       " The trained model was then applied to the other articles in Simple English Wikipedia with an English counterpart to\n",
       " create a larger corpus of aligned sentences (corresponding to the `auto`, `auto_acl`, `auto_full_no_split`, and `auto_full_with_split`  configs here).\n",
       " \tcitation: @inproceedings{acl/JiangMLZX20,\n",
       "   author    = {Chao Jiang and\n",
       "                Mounica Maddela and\n",
       "                Wuwei Lan and\n",
       "                Yang Zhong and\n",
       "                Wei Xu},\n",
       "   editor    = {Dan Jurafsky and\n",
       "                Joyce Chai and\n",
       "                Natalie Schluter and\n",
       "                Joel R. Tetreault},\n",
       "   title     = {Neural {CRF} Model for Sentence Alignment in Text Simplification},\n",
       "   booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational\n",
       "                Linguistics, {ACL} 2020, Online, July 5-10, 2020},\n",
       "   pages     = {7943--7960},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   year      = {2020},\n",
       "   url       = {https://www.aclweb.org/anthology/2020.acl-main.709/}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'machine-generated'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['extended|other-wikipedia'], 'task_categories': ['text2text-generation'], 'task_ids': ['text-simplification'], 'paperswithcode_id': None, 'pretty_name': 'WikiAuto', 'configs': ['auto', 'auto_acl', 'auto_full_no_split', 'auto_full_with_split', 'manual']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1050\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_bio\n",
       " \tsha: 9737fa242e97f3c98669521ecf52cb3966a15a80\n",
       " \tlastModified: 2022-07-01T11:57:17.000Z\n",
       " \ttags: ['arxiv:1603.07771', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:table-to-text']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This dataset gathers 728,321 biographies from wikipedia. It aims at evaluating text generation\n",
       " algorithms. For each article, we provide the first paragraph and the infobox (both tokenized).\n",
       " For each article, we extracted the first paragraph (text), the infobox (structured data). Each\n",
       " infobox is encoded as a list of (field name, field value) pairs. We used Stanford CoreNLP\n",
       " (http://stanfordnlp.github.io/CoreNLP/) to preprocess the data, i.e. we broke the text into\n",
       " sentences and tokenized both the text and the field values. The dataset was randomly split in\n",
       " three subsets train (80%), valid (10%), test (10%).\n",
       " \tcitation: @article{DBLP:journals/corr/LebretGA16,\n",
       "   author    = {R{\\'{e}}mi Lebret and\n",
       "                David Grangier and\n",
       "                Michael Auli},\n",
       "   title     = {Generating Text from Structured Data with Application to the Biography\n",
       "                Domain},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1603.07771},\n",
       "   year      = {2016},\n",
       "   url       = {http://arxiv.org/abs/1603.07771},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1603.07771},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/LebretGA16.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['table-to-text'], 'task_ids': [], 'paperswithcode_id': 'wikibio', 'pretty_name': 'WikiBio'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 18491\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikibio\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_dpr\n",
       " \tsha: 5e4eac5aad900a4b958e30a563af1f3cb968d849\n",
       " \tlastModified: 2022-07-01T12:43:47.000Z\n",
       " \ttags: ['arxiv:2004.04906', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'license:cc-by-sa-3.0', 'license:gfdl', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:other-text-search', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:other-neural-search', 'source_datasets:original', 'multilinguality:multilingual', 'size_categories:10M<n<100M', 'language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This is the wikipedia split used to evaluate the Dense Passage Retrieval (DPR) model.\n",
       " It contains 21M passages from wikipedia along with their DPR embeddings.\n",
       " The wikipedia articles were split into multiple, disjoint text blocks of 100 words as passages.\n",
       " \tcitation: @misc{karpukhin2020dense,\n",
       "     title={Dense Passage Retrieval for Open-Domain Question Answering},\n",
       "     author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},\n",
       "     year={2020},\n",
       "     eprint={2004.04906},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'pretty_name': 'Wiki-DPR', 'paperswithcode_id': None, 'license': ['cc-by-sa-3.0', 'gfdl'], 'task_categories': ['text-generation', 'fill-mask', 'other-text-search'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'other-neural-search'], 'source_datasets': ['original'], 'multilinguality': ['multilingual'], 'size_categories': ['10M<n<100M'], 'language': ['en']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7858\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_hop\n",
       " \tsha: 8d04ac10664d489d3d8f8b5f38d61fbfb2919bce\n",
       " \tlastModified: 2022-08-11T12:57:44.000Z\n",
       " \ttags: ['arxiv:1710.06481', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa', 'task_ids:question-answering-other-multi-hop']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiHop is open-domain and based on Wikipedia articles; the goal is to recover Wikidata information by hopping through documents. The goal is to answer text understanding queries by combining multiple facts that are spread across different documents.\n",
       " \tcitation: @misc{welbl2018constructing,\n",
       "       title={Constructing Datasets for Multi-hop Reading Comprehension Across Documents},\n",
       "       author={Johannes Welbl and Pontus Stenetorp and Sebastian Riedel},\n",
       "       year={2018},\n",
       "       eprint={1710.06481},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa', 'question-answering-other-multi-hop'], 'paperswithcode_id': 'wikihop', 'pretty_name': 'WikiHop'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 43374\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: wikihop\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_lingua\n",
       " \tsha: 07363c2ce4bb9a622629800769dff9ff31c2024d\n",
       " \tlastModified: 2022-07-01T11:57:20.000Z\n",
       " \ttags: ['arxiv:2010.03093', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-3.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:summarization', 'configs:arabic', 'configs:chinese', 'configs:czech', 'configs:dutch', 'configs:english', 'configs:french', 'configs:german', 'configs:hindi', 'configs:indonesian', 'configs:italian', 'configs:japanese', 'configs:korean', 'configs:portuguese', 'configs:russian', 'configs:spanish', 'configs:thai', 'configs:turkish', 'configs:vietnamese']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiLingua is a large-scale multilingual dataset for the evaluation of\n",
       " crosslingual abstractive summarization systems. The dataset includes ~770k\n",
       " article and summary pairs in 18 languages from WikiHow. The gold-standard\n",
       " article-summary alignments across languages was done by aligning the images\n",
       " that are used to describe each how-to step in an article.\n",
       " \tcitation: @article{ladhak-wiki-2020,\n",
       "   title   = {WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\n",
       "   authors = {Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\n",
       "   journal = {arXiv preprint arXiv:2010.03093},\n",
       "   year    = {2020},\n",
       "   url     = {https://arxiv.org/abs/2010.03093}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar', 'cs', 'de', 'en', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pt', 'ru', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-3.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': [], 'paperswithcode_id': 'wikilingua', 'pretty_name': 'WikiLingua', 'configs': ['arabic', 'chinese', 'czech', 'dutch', 'english', 'french', 'german', 'hindi', 'indonesian', 'italian', 'japanese', 'korean', 'portuguese', 'russian', 'spanish', 'thai', 'turkish', 'vietnamese']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3105\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: wikilingua\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_movies\n",
       " \tsha: 0528aa75f389e71eda44bc766b723f5da2dcc471\n",
       " \tlastModified: 2022-08-24T04:09:37.000Z\n",
       " \ttags: ['arxiv:1606.03126', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:closed-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The WikiMovies dataset consists of roughly 100k (templated) questions over 75k entities based on questions with answers in the open movie database (OMDb).\n",
       " \tcitation: @misc{miller2016keyvalue,\n",
       "       title={Key-Value Memory Networks for Directly Reading Documents},\n",
       "       author={Alexander Miller and Adam Fisch and Jesse Dodge and Amir-Hossein Karimi and Antoine Bordes and Jason Weston},\n",
       "       year={2016},\n",
       "       eprint={1606.03126},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'WikiMovies', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['closed-domain-qa'], 'paperswithcode_id': 'wikimovies'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikimovies\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_qa\n",
       " \tsha: bb281babcc2e7c12aef3fd2190b0030dd0075d05\n",
       " \tlastModified: 2022-09-06T05:40:01.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'license:other', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wiki Question Answering corpus from Microsoft\n",
       " \tcitation: @InProceedings{YangYihMeek:EMNLP2015:WikiQA,\n",
       "        author = {{Yi}, Yang and {Wen-tau},  Yih and {Christopher} Meek},\n",
       "         title = \"{WikiQA: A Challenge Dataset for Open-Domain Question Answering}\",\n",
       "       journal = {Association for Computational Linguistics},\n",
       "          year = 2015,\n",
       "           doi = {10.18653/v1/D15-1237},\n",
       "         pages = {2013–2018},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found'], 'license': ['other'], 'multilinguality': ['monolingual'], 'pretty_name': 'WikiQA', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'wikiqa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 40533\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: wikiqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_qa_ar\n",
       " \tsha: 807fb36d690e3629a48f42f23435224b18910c9b\n",
       " \tlastModified: 2022-07-01T11:57:21.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:ar', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Arabic Version of WikiQA by automatic automatic machine translators and crowdsourced the selection of the best one to be incorporated into the corpus\n",
       " \tcitation: @InProceedings{YangYihMeek:EMNLP2015:WikiQA,\n",
       "        author = {{Yi}, Yang and {Wen-tau},  Yih and {Christopher} Meek},\n",
       "         title = \"{WikiQA: A Challenge Dataset for Open-Domain Question Answering}\",\n",
       "       journal = {Association for Computational Linguistics},\n",
       "          year = 2015,\n",
       "           doi = {10.18653/v1/D15-1237},\n",
       "         pages = {2013–2018},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'wikiqaar', 'pretty_name': 'English-Arabic Wikipedia Question-Answering'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikiqaar\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_snippets\n",
       " \tsha: 0cfb20e2b2764508f72cadacc46650064f749869\n",
       " \tlastModified: 2022-08-11T16:23:45.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10M<n<100M', 'source_datasets:extended|wiki40b', 'source_datasets:extended|wikipedia', 'task_categories:text-generation', 'task_categories:other', 'task_ids:language-modeling', 'task_ids:other-text-search']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wikipedia version split into plain text snippets for dense semantic indexing.\n",
       " \tcitation: @ONLINE {wikidump,\n",
       "     author = {Wikimedia Foundation},\n",
       "     title  = {Wikimedia Downloads},\n",
       "     url    = {https://dumps.wikimedia.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'pretty_name': 'WikiSnippets', 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|wiki40b', 'extended|wikipedia'], 'task_categories': ['text-generation', 'other'], 'task_ids': ['language-modeling', 'other-text-search'], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1062\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_source\n",
       " \tsha: 445aac05d51f9addb305bd6d3d523b78c434069d\n",
       " \tlastModified: 2022-08-11T12:57:47.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'language:sv', 'license:unknown', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: 2 languages, total number of files: 132\n",
       " total number of tokens: 1.80M\n",
       " total number of sentence fragments: 78.36k\n",
       " \tcitation: @InProceedings{TIEDEMANN12.463,\n",
       "   author = {J{\\\"o}rg Tiedemann},\n",
       "   title = {Parallel Data, Tools and Interfaces in OPUS},\n",
       "   booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n",
       "   year = {2012},\n",
       "   month = {may},\n",
       "   date = {23-25},\n",
       "   address = {Istanbul, Turkey},\n",
       "   editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {978-2-9517408-7-7},\n",
       "   language = {english}\n",
       "  }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en', 'sv'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'pretty_name': 'WikiSource'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 321\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_split\n",
       " \tsha: 172e439c66045594494c91dbbf14169f0b78e197\n",
       " \tlastModified: 2022-09-06T05:40:01.000Z\n",
       " \ttags: ['arxiv:1808.09468', 'annotations_creators:machine-generated', 'language:en', 'language_creators:found', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-split-and-rephrase']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: One million English sentences, each split into two sentences that together preserve the original meaning, extracted from Wikipedia\n",
       " Google's WikiSplit dataset was constructed automatically from the publicly available Wikipedia revision history. Although\n",
       " the dataset contains some inherent noise, it can serve as valuable training data for models that split or merge sentences.\n",
       " \tcitation: @InProceedings{BothaEtAl2018,\n",
       "   title = {{Learning To Split and Rephrase From Wikipedia Edit History}},\n",
       "   author = {Botha, Jan A and Faruqui, Manaal and Alex, John and Baldridge, Jason and Das, Dipanjan},\n",
       "   booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},\n",
       "   pages = {to appear},\n",
       "   note = {arXiv preprint arXiv:1808.09468},\n",
       "   year = {2018}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language': ['en'], 'language_creators': ['found'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'WikiSplit', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-split-and-rephrase'], 'paperswithcode_id': 'wikisplit'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 605\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikisplit\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiki_summary\n",
       " \tsha: 4038835150cc47e9359704cd192651d6a5d79bf4\n",
       " \tlastModified: 2022-08-11T16:23:45.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:fa', 'license:apache-2.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_categories:translation', 'task_categories:question-answering', 'task_categories:summarization', 'task_ids:abstractive-qa', 'task_ids:explanation-generation', 'task_ids:extractive-qa', 'task_ids:open-domain-qa', 'task_ids:open-domain-abstractive-qa', 'task_ids:text-simplification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: \\\n",
       " The dataset extracted from Persian Wikipedia into the form of articles and highlights and cleaned the dataset into pairs of articles and highlights and reduced the articles' length (only version 1.0.0) and highlights' length to a maximum of 512 and 128, respectively, suitable for parsBERT.\n",
       " \tcitation: \\\n",
       " @misc{Bert2BertWikiSummaryPersian,\n",
       "   author = {Mehrdad Farahani},\n",
       "   title = {Summarization using Bert2Bert model on WikiSummary dataset},\n",
       "   year = {2020},\n",
       "   publisher = {GitHub},\n",
       "   journal = {GitHub repository},\n",
       "   howpublished = {https://github.com/m3hrdadfi/wiki-summary},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['fa'], 'license': ['apache-2.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation', 'translation', 'question-answering', 'summarization'], 'task_ids': ['abstractive-qa', 'explanation-generation', 'extractive-qa', 'open-domain-qa', 'open-domain-abstractive-qa', 'text-simplification'], 'pretty_name': 'WikiSummary'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikiann\n",
       " \tsha: 89d089624b6323d69dcd9e5eb2def0551887a73a\n",
       " \tlastModified: 2022-07-27T14:39:11.000Z\n",
       " \ttags: ['arxiv:1902.00193', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language:ace', 'language:af', 'language:als', 'language:am', 'language:an', 'language:ang', 'language:ar', 'language:arc', 'language:arz', 'language:as', 'language:ast', 'language:ay', 'language:az', 'language:ba', 'language:bar', 'language:be', 'language:bg', 'language:bh', 'language:bn', 'language:bo', 'language:br', 'language:bs', 'language:ca', 'language:cbk', 'language:cdo', 'language:ce', 'language:ceb', 'language:ckb', 'language:co', 'language:crh', 'language:cs', 'language:csb', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:diq', 'language:dv', 'language:el', 'language:eml', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:ext', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:frr', 'language:fur', 'language:fy', 'language:ga', 'language:gan', 'language:gd', 'language:gl', 'language:gn', 'language:gu', 'language:hak', 'language:he', 'language:hi', 'language:hr', 'language:hsb', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ig', 'language:ilo', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jbo', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:ksh', 'language:ku', 'language:ky', 'language:la', 'language:lb', 'language:li', 'language:lij', 'language:lmo', 'language:ln', 'language:lt', 'language:lv', 'language:lzh', 'language:mg', 'language:mhr', 'language:mi', 'language:min', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:mwl', 'language:my', 'language:mzn', 'language:nan', 'language:nap', 'language:nds', 'language:ne', 'language:nl', 'language:nn', 'language:no', 'language:nov', 'language:oc', 'language:or', 'language:os', 'language:pa', 'language:pdc', 'language:pl', 'language:pms', 'language:pnb', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:ro', 'language:ru', 'language:rw', 'language:sa', 'language:sah', 'language:scn', 'language:sco', 'language:sd', 'language:sgs', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:so', 'language:sq', 'language:sr', 'language:su', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:te', 'language:tg', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vec', 'language:vep', 'language:vi', 'language:vls', 'language:vo', 'language:vro', 'language:wa', 'language:war', 'language:wuu', 'language:xmf', 'language:yi', 'language:yo', 'language:yue', 'language:zea', 'language:zh', 'language_bcp47:be-tarask', 'language_bcp47:en-basiceng', 'language_bcp47:jv-x-bms', 'license:unknown', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition', 'configs:no', 'configs:ace', 'configs:af', 'configs:als', 'configs:am', 'configs:an', 'configs:ang', 'configs:ar', 'configs:arc', 'configs:arz', 'configs:as', 'configs:ast', 'configs:ay', 'configs:az', 'configs:ba', 'configs:bar', 'configs:be', 'configs:bg', 'configs:bh', 'configs:bn', 'configs:bo', 'configs:br', 'configs:bs', 'configs:ca', 'configs:cdo', 'configs:ce', 'configs:ceb', 'configs:ckb', 'configs:co', 'configs:crh', 'configs:cs', 'configs:csb', 'configs:cv', 'configs:cy', 'configs:da', 'configs:de', 'configs:diq', 'configs:dv', 'configs:el', 'configs:en', 'configs:eo', 'configs:es', 'configs:et', 'configs:eu', 'configs:ext', 'configs:fa', 'configs:fi', 'configs:fo', 'configs:fr', 'configs:frr', 'configs:fur', 'configs:fy', 'configs:ga', 'configs:gan', 'configs:gd', 'configs:gl', 'configs:gn', 'configs:gu', 'configs:hak', 'configs:he', 'configs:hi', 'configs:hr', 'configs:hsb', 'configs:hu', 'configs:hy', 'configs:ia', 'configs:id', 'configs:ig', 'configs:ilo', 'configs:io', 'configs:is', 'configs:it', 'configs:ja', 'configs:jbo', 'configs:jv', 'configs:ka', 'configs:kk', 'configs:km', 'configs:kn', 'configs:ko', 'configs:ksh', 'configs:ku', 'configs:ky', 'configs:la', 'configs:lb', 'configs:li', 'configs:lij', 'configs:lmo', 'configs:ln', 'configs:lt', 'configs:lv', 'configs:mg', 'configs:mhr', 'configs:mi', 'configs:min', 'configs:mk', 'configs:ml', 'configs:mn', 'configs:mr', 'configs:ms', 'configs:mt', 'configs:mwl', 'configs:my', 'configs:mzn', 'configs:nap', 'configs:nds', 'configs:ne', 'configs:nl', 'configs:nn', 'configs:nov', 'configs:oc', 'configs:or', 'configs:os', 'configs:other-bat-smg', 'configs:other-be-x-old', 'configs:other-cbk-zam', 'configs:other-eml', 'configs:other-fiu-vro', 'configs:other-map-bms', 'configs:other-simple', 'configs:other-zh-classical', 'configs:other-zh-min-nan', 'configs:other-zh-yue', 'configs:pa', 'configs:pdc', 'configs:pl', 'configs:pms', 'configs:pnb', 'configs:ps', 'configs:pt', 'configs:qu', 'configs:rm', 'configs:ro', 'configs:ru', 'configs:rw', 'configs:sa', 'configs:sah', 'configs:scn', 'configs:sco', 'configs:sd', 'configs:sh', 'configs:si', 'configs:sk', 'configs:sl', 'configs:so', 'configs:sq', 'configs:sr', 'configs:su', 'configs:sv', 'configs:sw', 'configs:szl', 'configs:ta', 'configs:te', 'configs:tg', 'configs:th', 'configs:tk', 'configs:tl', 'configs:tr', 'configs:tt', 'configs:ug', 'configs:uk', 'configs:ur', 'configs:uz', 'configs:vec', 'configs:vep', 'configs:vi', 'configs:vls', 'configs:vo', 'configs:wa', 'configs:war', 'configs:wuu', 'configs:xmf', 'configs:yi', 'configs:yo', 'configs:zea', 'configs:zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles annotated with LOC (location), PER (person), and ORG (organisation) tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of Rahimi et al. (2019), which supports 176 of the 282 languages from the original WikiANN corpus.\n",
       " \tcitation: @inproceedings{pan-etal-2017-cross,\n",
       "     title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\n",
       "     author = \"Pan, Xiaoman  and\n",
       "       Zhang, Boliang  and\n",
       "       May, Jonathan  and\n",
       "       Nothman, Joel  and\n",
       "       Knight, Kevin  and\n",
       "       Ji, Heng\",\n",
       "     booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
       "     month = jul,\n",
       "     year = \"2017\",\n",
       "     address = \"Vancouver, Canada\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P17-1178\",\n",
       "     doi = \"10.18653/v1/P17-1178\",\n",
       "     pages = \"1946--1958\",\n",
       "     abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of new KB mining methods: generating {``}silver-standard{''} annotations by transferring annotations from English to other languages through cross-lingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from cross-lingual links. Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['crowdsourced'], 'language': ['ace', 'af', 'als', 'am', 'an', 'ang', 'ar', 'arc', 'arz', 'as', 'ast', 'ay', 'az', 'ba', 'bar', 'be', 'bg', 'bh', 'bn', 'bo', 'br', 'bs', 'ca', 'cbk', 'cdo', 'ce', 'ceb', 'ckb', 'co', 'crh', 'cs', 'csb', 'cv', 'cy', 'da', 'de', 'diq', 'dv', 'el', 'eml', 'en', 'eo', 'es', 'et', 'eu', 'ext', 'fa', 'fi', 'fo', 'fr', 'frr', 'fur', 'fy', 'ga', 'gan', 'gd', 'gl', 'gn', 'gu', 'hak', 'he', 'hi', 'hr', 'hsb', 'hu', 'hy', 'ia', 'id', 'ig', 'ilo', 'io', 'is', 'it', 'ja', 'jbo', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ksh', 'ku', 'ky', 'la', 'lb', 'li', 'lij', 'lmo', 'ln', 'lt', 'lv', 'lzh', 'mg', 'mhr', 'mi', 'min', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'mwl', 'my', 'mzn', 'nan', 'nap', 'nds', 'ne', 'nl', 'nn', 'no', 'nov', 'oc', 'or', 'os', 'pa', 'pdc', 'pl', 'pms', 'pnb', 'ps', 'pt', 'qu', 'rm', 'ro', 'ru', 'rw', 'sa', 'sah', 'scn', 'sco', 'sd', 'sgs', 'sh', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'szl', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vec', 'vep', 'vi', 'vls', 'vo', 'vro', 'wa', 'war', 'wuu', 'xmf', 'yi', 'yo', 'yue', 'zea', 'zh'], 'language_bcp47': ['be-tarask', 'en-basiceng', 'jv-x-bms'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': 'wikiann-1', 'pretty_name': 'WikiANN', 'configs': ['no', 'ace', 'af', 'als', 'am', 'an', 'ang', 'ar', 'arc', 'arz', 'as', 'ast', 'ay', 'az', 'ba', 'bar', 'be', 'bg', 'bh', 'bn', 'bo', 'br', 'bs', 'ca', 'cdo', 'ce', 'ceb', 'ckb', 'co', 'crh', 'cs', 'csb', 'cv', 'cy', 'da', 'de', 'diq', 'dv', 'el', 'en', 'eo', 'es', 'et', 'eu', 'ext', 'fa', 'fi', 'fo', 'fr', 'frr', 'fur', 'fy', 'ga', 'gan', 'gd', 'gl', 'gn', 'gu', 'hak', 'he', 'hi', 'hr', 'hsb', 'hu', 'hy', 'ia', 'id', 'ig', 'ilo', 'io', 'is', 'it', 'ja', 'jbo', 'jv', 'ka', 'kk', 'km', 'kn', 'ko', 'ksh', 'ku', 'ky', 'la', 'lb', 'li', 'lij', 'lmo', 'ln', 'lt', 'lv', 'mg', 'mhr', 'mi', 'min', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'mwl', 'my', 'mzn', 'nap', 'nds', 'ne', 'nl', 'nn', 'nov', 'oc', 'or', 'os', 'other-bat-smg', 'other-be-x-old', 'other-cbk-zam', 'other-eml', 'other-fiu-vro', 'other-map-bms', 'other-simple', 'other-zh-classical', 'other-zh-min-nan', 'other-zh-yue', 'pa', 'pdc', 'pl', 'pms', 'pnb', 'ps', 'pt', 'qu', 'rm', 'ro', 'ru', 'rw', 'sa', 'sah', 'scn', 'sco', 'sd', 'sh', 'si', 'sk', 'sl', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'szl', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vec', 'vep', 'vi', 'vls', 'vo', 'wa', 'war', 'wuu', 'xmf', 'yi', 'yo', 'zea', 'zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 54624\n",
       " \tlikes: 15\n",
       " \tpaperswithcode_id: wikiann-1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikicorpus\n",
       " \tsha: 1a3b8b62182091535f53195f254e85112d97b986\n",
       " \tlastModified: 2022-07-19T12:42:03.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'annotations_creators:no-annotation', 'language_creators:found', 'language:ca', 'language:en', 'language:es', 'license:gfdl', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'size_categories:10M<n<100M', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:fill-mask', 'task_categories:text-classification', 'task_categories:text-generation', 'task_categories:token-classification', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'task_ids:part-of-speech', 'task_ids:text-classification-other-word-sense-disambiguation', 'task_ids:token-classification-other-lemmatization', 'configs:raw_ca', 'configs:raw_en', 'configs:raw_es', 'configs:tagged_ca', 'configs:tagged_en', 'configs:tagged_es']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Wikicorpus is a trilingual corpus (Catalan, Spanish, English) that contains large portions of the Wikipedia (based on a 2006 dump) and has been automatically enriched with linguistic information. In its present version, it contains over 750 million words.\n",
       " \tcitation: @inproceedings{reese-etal-2010-wikicorpus,\n",
       "     title = \"{W}ikicorpus: A Word-Sense Disambiguated Multilingual {W}ikipedia Corpus\",\n",
       "     author = \"Reese, Samuel  and\n",
       "       Boleda, Gemma  and\n",
       "       Cuadros, Montse  and\n",
       "       Padr{\\'o}, Llu{\\'i}s  and\n",
       "       Rigau, German\",\n",
       "     booktitle = \"Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)\",\n",
       "     month = may,\n",
       "     year = \"2010\",\n",
       "     address = \"Valletta, Malta\",\n",
       "     publisher = \"European Language Resources Association (ELRA)\",\n",
       "     url = \"http://www.lrec-conf.org/proceedings/lrec2010/pdf/222_Paper.pdf\",\n",
       "     abstract = \"This article presents a new freely available trilingual corpus (Catalan, Spanish, English) that contains large portions of the Wikipedia and has been automatically enriched with linguistic information. To our knowledge, this is the largest such corpus that is freely available to the community: In its present version, it contains over 750 million words. The corpora have been annotated with lemma and part of speech information using the open source library FreeLing. Also, they have been sense annotated with the state of the art Word Sense Disambiguation algorithm UKB. As UKB assigns WordNet senses, and WordNet has been aligned across languages via the InterLingual Index, this sort of annotation opens the way to massive explorations in lexical semantics that were not possible before. We present a first attempt at creating a trilingual lexical resource from the sense-tagged Wikipedia corpora, namely, WikiNet. Moreover, we present two by-products of the project that are of use for the NLP community: An open source Java-based parser for Wikipedia pages developed for the construction of the corpus, and the integration of the WSD algorithm UKB in FreeLing.\",\n",
       " }\n",
       " \tcardData: {'pretty_name': 'Wikicorpus', 'annotations_creators': ['machine-generated', 'no-annotation'], 'language_creators': ['found'], 'language': ['ca', 'en', 'es'], 'license': ['gfdl'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M', '10M<n<100M', '1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['fill-mask', 'text-classification', 'text-generation', 'token-classification'], 'task_ids': ['language-modeling', 'masked-language-modeling', 'part-of-speech', 'text-classification-other-word-sense-disambiguation', 'token-classification-other-lemmatization'], 'paperswithcode_id': None, 'configs': ['raw_ca', 'raw_en', 'raw_es', 'tagged_ca', 'tagged_en', 'tagged_es']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1401\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikihow\n",
       " \tsha: 7d6f5fbad57f76e71cf5cbe20bd5fe7c5f5f7d20\n",
       " \tlastModified: 2022-01-25T15:53:44.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WikiHow is a new large-scale dataset using the online WikiHow\n",
       " (http://www.wikihow.com/) knowledge base.\n",
       " \n",
       " There are two features:\n",
       "   - text: wikihow answers texts.\n",
       "   - headline: bold lines as summary.\n",
       " \n",
       " There are two separate versions:\n",
       "   - all: consisting of the concatenation of all paragraphs as the articles and\n",
       "          the bold lines as the reference summaries.\n",
       "   - sep: consisting of each paragraph and its summary.\n",
       " \n",
       " Download \"wikihowAll.csv\" and \"wikihowSep.csv\" from\n",
       " https://github.com/mahnazkoupaee/WikiHow-Dataset and place them in manual folder\n",
       " https://www.tensorflow.org/datasets/api_docs/python/tfds/download/DownloadConfig.\n",
       " Train/validation/test splits are provided by the authors.\n",
       " Preprocessing is applied to remove short articles\n",
       " (abstract length < 0.75 article length) and clean up extra commas.\n",
       " \tcitation: @misc{koupaee2018wikihow,\n",
       "     title={WikiHow: A Large Scale Text Summarization Dataset},\n",
       "     author={Mahnaz Koupaee and William Yang Wang},\n",
       "     year={2018},\n",
       "     eprint={1810.09305},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'paperswithcode_id': 'wikihow', 'pretty_name': 'WikiHow'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1709\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikihow\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikipedia\n",
       " \tsha: ec1654a95e435fbf39a695eca3b67949250a9290\n",
       " \tlastModified: 2022-07-27T14:51:47.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'license:cc-by-sa-3.0', 'license:gfdl', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling', 'source_datasets:original', 'multilinguality:multilingual', 'size_categories:n<1K', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'size_categories:1M<n<10M', 'language:aa', 'language:ab', 'language:ace', 'language:af', 'language:ak', 'language:als', 'language:am', 'language:an', 'language:ang', 'language:ar', 'language:arc', 'language:arz', 'language:as', 'language:ast', 'language:atj', 'language:av', 'language:ay', 'language:az', 'language:azb', 'language:ba', 'language:bar', 'language:bcl', 'language:be', 'language:bg', 'language:bh', 'language:bi', 'language:bjn', 'language:bm', 'language:bn', 'language:bo', 'language:bpy', 'language:br', 'language:bs', 'language:bug', 'language:bxr', 'language:ca', 'language:cbk', 'language:cdo', 'language:ce', 'language:ceb', 'language:ch', 'language:cho', 'language:chr', 'language:chy', 'language:ckb', 'language:co', 'language:cr', 'language:crh', 'language:cs', 'language:csb', 'language:cu', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:din', 'language:diq', 'language:dsb', 'language:dty', 'language:dv', 'language:dz', 'language:ee', 'language:el', 'language:eml', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:ext', 'language:fa', 'language:ff', 'language:fi', 'language:fj', 'language:fo', 'language:fr', 'language:frp', 'language:frr', 'language:fur', 'language:fy', 'language:ga', 'language:gag', 'language:gan', 'language:gd', 'language:gl', 'language:glk', 'language:gn', 'language:gom', 'language:gor', 'language:got', 'language:gu', 'language:gv', 'language:ha', 'language:hak', 'language:haw', 'language:he', 'language:hi', 'language:hif', 'language:ho', 'language:hr', 'language:hsb', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:ig', 'language:ii', 'language:ik', 'language:ilo', 'language:inh', 'language:io', 'language:is', 'language:it', 'language:iu', 'language:ja', 'language:jam', 'language:jbo', 'language:jv', 'language:ka', 'language:kaa', 'language:kab', 'language:kbd', 'language:kbp', 'language:kg', 'language:ki', 'language:kj', 'language:kk', 'language:kl', 'language:km', 'language:kn', 'language:ko', 'language:koi', 'language:krc', 'language:ks', 'language:ksh', 'language:ku', 'language:kv', 'language:kw', 'language:ky', 'language:la', 'language:lad', 'language:lb', 'language:lbe', 'language:lez', 'language:lfn', 'language:lg', 'language:li', 'language:lij', 'language:lmo', 'language:ln', 'language:lo', 'language:lrc', 'language:lt', 'language:ltg', 'language:lv', 'language:lzh', 'language:mai', 'language:mdf', 'language:mg', 'language:mh', 'language:mhr', 'language:mi', 'language:min', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:mrj', 'language:ms', 'language:mt', 'language:mus', 'language:mwl', 'language:my', 'language:myv', 'language:mzn', 'language:na', 'language:nah', 'language:nan', 'language:nap', 'language:nds', 'language:ne', 'language:new', 'language:ng', 'language:nl', 'language:nn', 'language:no', 'language:nov', 'language:nrf', 'language:nso', 'language:nv', 'language:ny', 'language:oc', 'language:olo', 'language:om', 'language:or', 'language:os', 'language:pa', 'language:pag', 'language:pam', 'language:pap', 'language:pcd', 'language:pdc', 'language:pfl', 'language:pi', 'language:pih', 'language:pl', 'language:pms', 'language:pnb', 'language:pnt', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:rmy', 'language:rn', 'language:ro', 'language:ru', 'language:rue', 'language:rup', 'language:rw', 'language:sa', 'language:sah', 'language:sat', 'language:sc', 'language:scn', 'language:sco', 'language:sd', 'language:se', 'language:sg', 'language:sgs', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sm', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:srn', 'language:ss', 'language:st', 'language:stq', 'language:su', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:tcy', 'language:tdt', 'language:te', 'language:tg', 'language:th', 'language:ti', 'language:tk', 'language:tl', 'language:tn', 'language:to', 'language:tpi', 'language:tr', 'language:ts', 'language:tt', 'language:tum', 'language:tw', 'language:ty', 'language:tyv', 'language:udm', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:ve', 'language:vec', 'language:vep', 'language:vi', 'language:vls', 'language:vo', 'language:vro', 'language:wa', 'language:war', 'language:wo', 'language:wuu', 'language:xal', 'language:xh', 'language:xmf', 'language:yi', 'language:yo', 'language:yue', 'language:za', 'language:zea', 'language:zh', 'language:zu', 'language_bcp47:nds-nl', 'configs:20220301.aa', 'configs:20220301.ab', 'configs:20220301.ace', 'configs:20220301.ady', 'configs:20220301.af', 'configs:20220301.ak', 'configs:20220301.als', 'configs:20220301.am', 'configs:20220301.an', 'configs:20220301.ang', 'configs:20220301.ar', 'configs:20220301.arc', 'configs:20220301.arz', 'configs:20220301.as', 'configs:20220301.ast', 'configs:20220301.atj', 'configs:20220301.av', 'configs:20220301.ay', 'configs:20220301.az', 'configs:20220301.azb', 'configs:20220301.ba', 'configs:20220301.bar', 'configs:20220301.bat-smg', 'configs:20220301.bcl', 'configs:20220301.be', 'configs:20220301.be-x-old', 'configs:20220301.bg', 'configs:20220301.bh', 'configs:20220301.bi', 'configs:20220301.bjn', 'configs:20220301.bm', 'configs:20220301.bn', 'configs:20220301.bo', 'configs:20220301.bpy', 'configs:20220301.br', 'configs:20220301.bs', 'configs:20220301.bug', 'configs:20220301.bxr', 'configs:20220301.ca', 'configs:20220301.cbk-zam', 'configs:20220301.cdo', 'configs:20220301.ce', 'configs:20220301.ceb', 'configs:20220301.ch', 'configs:20220301.cho', 'configs:20220301.chr', 'configs:20220301.chy', 'configs:20220301.ckb', 'configs:20220301.co', 'configs:20220301.cr', 'configs:20220301.crh', 'configs:20220301.cs', 'configs:20220301.csb', 'configs:20220301.cu', 'configs:20220301.cv', 'configs:20220301.cy', 'configs:20220301.da', 'configs:20220301.de', 'configs:20220301.din', 'configs:20220301.diq', 'configs:20220301.dsb', 'configs:20220301.dty', 'configs:20220301.dv', 'configs:20220301.dz', 'configs:20220301.ee', 'configs:20220301.el', 'configs:20220301.eml', 'configs:20220301.en', 'configs:20220301.eo', 'configs:20220301.es', 'configs:20220301.et', 'configs:20220301.eu', 'configs:20220301.ext', 'configs:20220301.fa', 'configs:20220301.ff', 'configs:20220301.fi', 'configs:20220301.fiu-vro', 'configs:20220301.fj', 'configs:20220301.fo', 'configs:20220301.fr', 'configs:20220301.frp', 'configs:20220301.frr', 'configs:20220301.fur', 'configs:20220301.fy', 'configs:20220301.ga', 'configs:20220301.gag', 'configs:20220301.gan', 'configs:20220301.gd', 'configs:20220301.gl', 'configs:20220301.glk', 'configs:20220301.gn', 'configs:20220301.gom', 'configs:20220301.gor', 'configs:20220301.got', 'configs:20220301.gu', 'configs:20220301.gv', 'configs:20220301.ha', 'configs:20220301.hak', 'configs:20220301.haw', 'configs:20220301.he', 'configs:20220301.hi', 'configs:20220301.hif', 'configs:20220301.ho', 'configs:20220301.hr', 'configs:20220301.hsb', 'configs:20220301.ht', 'configs:20220301.hu', 'configs:20220301.hy', 'configs:20220301.ia', 'configs:20220301.id', 'configs:20220301.ie', 'configs:20220301.ig', 'configs:20220301.ii', 'configs:20220301.ik', 'configs:20220301.ilo', 'configs:20220301.inh', 'configs:20220301.io', 'configs:20220301.is', 'configs:20220301.it', 'configs:20220301.iu', 'configs:20220301.ja', 'configs:20220301.jam', 'configs:20220301.jbo', 'configs:20220301.jv', 'configs:20220301.ka', 'configs:20220301.kaa', 'configs:20220301.kab', 'configs:20220301.kbd', 'configs:20220301.kbp', 'configs:20220301.kg', 'configs:20220301.ki', 'configs:20220301.kj', 'configs:20220301.kk', 'configs:20220301.kl', 'configs:20220301.km', 'configs:20220301.kn', 'configs:20220301.ko', 'configs:20220301.koi', 'configs:20220301.krc', 'configs:20220301.ks', 'configs:20220301.ksh', 'configs:20220301.ku', 'configs:20220301.kv', 'configs:20220301.kw', 'configs:20220301.ky', 'configs:20220301.la', 'configs:20220301.lad', 'configs:20220301.lb', 'configs:20220301.lbe', 'configs:20220301.lez', 'configs:20220301.lfn', 'configs:20220301.lg', 'configs:20220301.li', 'configs:20220301.lij', 'configs:20220301.lmo', 'configs:20220301.ln', 'configs:20220301.lo', 'configs:20220301.lrc', 'configs:20220301.lt', 'configs:20220301.ltg', 'configs:20220301.lv', 'configs:20220301.mai', 'configs:20220301.map-bms', 'configs:20220301.mdf', 'configs:20220301.mg', 'configs:20220301.mh', 'configs:20220301.mhr', 'configs:20220301.mi', 'configs:20220301.min', 'configs:20220301.mk', 'configs:20220301.ml', 'configs:20220301.mn', 'configs:20220301.mr', 'configs:20220301.mrj', 'configs:20220301.ms', 'configs:20220301.mt', 'configs:20220301.mus', 'configs:20220301.mwl', 'configs:20220301.my', 'configs:20220301.myv', 'configs:20220301.mzn', 'configs:20220301.na', 'configs:20220301.nah', 'configs:20220301.nap', 'configs:20220301.nds', 'configs:20220301.nds-nl', 'configs:20220301.ne', 'configs:20220301.new', 'configs:20220301.ng', 'configs:20220301.nl', 'configs:20220301.nn', 'configs:20220301.no', 'configs:20220301.nov', 'configs:20220301.nrm', 'configs:20220301.nso', 'configs:20220301.nv', 'configs:20220301.ny', 'configs:20220301.oc', 'configs:20220301.olo', 'configs:20220301.om', 'configs:20220301.or', 'configs:20220301.os', 'configs:20220301.pa', 'configs:20220301.pag', 'configs:20220301.pam', 'configs:20220301.pap', 'configs:20220301.pcd', 'configs:20220301.pdc', 'configs:20220301.pfl', 'configs:20220301.pi', 'configs:20220301.pih', 'configs:20220301.pl', 'configs:20220301.pms', 'configs:20220301.pnb', 'configs:20220301.pnt', 'configs:20220301.ps', 'configs:20220301.pt', 'configs:20220301.qu', 'configs:20220301.rm', 'configs:20220301.rmy', 'configs:20220301.rn', 'configs:20220301.ro', 'configs:20220301.roa-rup', 'configs:20220301.roa-tara', 'configs:20220301.ru', 'configs:20220301.rue', 'configs:20220301.rw', 'configs:20220301.sa', 'configs:20220301.sah', 'configs:20220301.sat', 'configs:20220301.sc', 'configs:20220301.scn', 'configs:20220301.sco', 'configs:20220301.sd', 'configs:20220301.se', 'configs:20220301.sg', 'configs:20220301.sh', 'configs:20220301.si', 'configs:20220301.simple', 'configs:20220301.sk', 'configs:20220301.sl', 'configs:20220301.sm', 'configs:20220301.sn', 'configs:20220301.so', 'configs:20220301.sq', 'configs:20220301.sr', 'configs:20220301.srn', 'configs:20220301.ss', 'configs:20220301.st', 'configs:20220301.stq', 'configs:20220301.su', 'configs:20220301.sv', 'configs:20220301.sw', 'configs:20220301.szl', 'configs:20220301.ta', 'configs:20220301.tcy', 'configs:20220301.te', 'configs:20220301.tet', 'configs:20220301.tg', 'configs:20220301.th', 'configs:20220301.ti', 'configs:20220301.tk', 'configs:20220301.tl', 'configs:20220301.tn', 'configs:20220301.to', 'configs:20220301.tpi', 'configs:20220301.tr', 'configs:20220301.ts', 'configs:20220301.tt', 'configs:20220301.tum', 'configs:20220301.tw', 'configs:20220301.ty', 'configs:20220301.tyv', 'configs:20220301.udm', 'configs:20220301.ug', 'configs:20220301.uk', 'configs:20220301.ur', 'configs:20220301.uz', 'configs:20220301.ve', 'configs:20220301.vec', 'configs:20220301.vep', 'configs:20220301.vi', 'configs:20220301.vls', 'configs:20220301.vo', 'configs:20220301.wa', 'configs:20220301.war', 'configs:20220301.wo', 'configs:20220301.wuu', 'configs:20220301.xal', 'configs:20220301.xh', 'configs:20220301.xmf', 'configs:20220301.yi', 'configs:20220301.yo', 'configs:20220301.za', 'configs:20220301.zea', 'configs:20220301.zh', 'configs:20220301.zh-classical', 'configs:20220301.zh-min-nan', 'configs:20220301.zh-yue', 'configs:20220301.zu']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wikipedia dataset containing cleaned articles of all languages.\n",
       " The datasets are built from the Wikipedia dump\n",
       " (https://dumps.wikimedia.org/) with one split per language. Each example\n",
       " contains the content of one full Wikipedia article with cleaning to strip\n",
       " markdown and unwanted sections (references, etc.).\n",
       " \tcitation: @ONLINE {wikidump,\n",
       "     author = {Wikimedia Foundation},\n",
       "     title  = {Wikimedia Downloads},\n",
       "     url    = {https://dumps.wikimedia.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'pretty_name': 'Wikipedia', 'paperswithcode_id': None, 'license': ['cc-by-sa-3.0', 'gfdl'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'source_datasets': ['original'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K', '1K<n<10K', '10K<n<100K', '100K<n<1M', '1M<n<10M'], 'language': ['aa', 'ab', 'ace', 'af', 'ak', 'als', 'am', 'an', 'ang', 'ar', 'arc', 'arz', 'as', 'ast', 'atj', 'av', 'ay', 'az', 'azb', 'ba', 'bar', 'bcl', 'be', 'bg', 'bh', 'bi', 'bjn', 'bm', 'bn', 'bo', 'bpy', 'br', 'bs', 'bug', 'bxr', 'ca', 'cbk', 'cdo', 'ce', 'ceb', 'ch', 'cho', 'chr', 'chy', 'ckb', 'co', 'cr', 'crh', 'cs', 'csb', 'cu', 'cv', 'cy', 'da', 'de', 'din', 'diq', 'dsb', 'dty', 'dv', 'dz', 'ee', 'el', 'eml', 'en', 'eo', 'es', 'et', 'eu', 'ext', 'fa', 'ff', 'fi', 'fj', 'fo', 'fr', 'frp', 'frr', 'fur', 'fy', 'ga', 'gag', 'gan', 'gd', 'gl', 'glk', 'gn', 'gom', 'gor', 'got', 'gu', 'gv', 'ha', 'hak', 'haw', 'he', 'hi', 'hif', 'ho', 'hr', 'hsb', 'ht', 'hu', 'hy', 'ia', 'id', 'ie', 'ig', 'ii', 'ik', 'ilo', 'inh', 'io', 'is', 'it', 'iu', 'ja', 'jam', 'jbo', 'jv', 'ka', 'kaa', 'kab', 'kbd', 'kbp', 'kg', 'ki', 'kj', 'kk', 'kl', 'km', 'kn', 'ko', 'koi', 'krc', 'ks', 'ksh', 'ku', 'kv', 'kw', 'ky', 'la', 'lad', 'lb', 'lbe', 'lez', 'lfn', 'lg', 'li', 'lij', 'lmo', 'ln', 'lo', 'lrc', 'lt', 'ltg', 'lv', 'lzh', 'mai', 'mdf', 'mg', 'mh', 'mhr', 'mi', 'min', 'mk', 'ml', 'mn', 'mr', 'mrj', 'ms', 'mt', 'mus', 'mwl', 'my', 'myv', 'mzn', 'na', 'nah', 'nan', 'nap', 'nds', 'ne', 'new', 'ng', 'nl', 'nn', 'no', 'nov', 'nrf', 'nso', 'nv', 'ny', 'oc', 'olo', 'om', 'or', 'os', 'pa', 'pag', 'pam', 'pap', 'pcd', 'pdc', 'pfl', 'pi', 'pih', 'pl', 'pms', 'pnb', 'pnt', 'ps', 'pt', 'qu', 'rm', 'rmy', 'rn', 'ro', 'ru', 'rue', 'rup', 'rw', 'sa', 'sah', 'sat', 'sc', 'scn', 'sco', 'sd', 'se', 'sg', 'sgs', 'sh', 'si', 'sk', 'sl', 'sm', 'sn', 'so', 'sq', 'sr', 'srn', 'ss', 'st', 'stq', 'su', 'sv', 'sw', 'szl', 'ta', 'tcy', 'tdt', 'te', 'tg', 'th', 'ti', 'tk', 'tl', 'tn', 'to', 'tpi', 'tr', 'ts', 'tt', 'tum', 'tw', 'ty', 'tyv', 'udm', 'ug', 'uk', 'ur', 'uz', 've', 'vec', 'vep', 'vi', 'vls', 'vo', 'vro', 'wa', 'war', 'wo', 'wuu', 'xal', 'xh', 'xmf', 'yi', 'yo', 'yue', 'za', 'zea', 'zh', 'zu'], 'language_bcp47': ['nds-nl'], 'configs': ['20220301.aa', '20220301.ab', '20220301.ace', '20220301.ady', '20220301.af', '20220301.ak', '20220301.als', '20220301.am', '20220301.an', '20220301.ang', '20220301.ar', '20220301.arc', '20220301.arz', '20220301.as', '20220301.ast', '20220301.atj', '20220301.av', '20220301.ay', '20220301.az', '20220301.azb', '20220301.ba', '20220301.bar', '20220301.bat-smg', '20220301.bcl', '20220301.be', '20220301.be-x-old', '20220301.bg', '20220301.bh', '20220301.bi', '20220301.bjn', '20220301.bm', '20220301.bn', '20220301.bo', '20220301.bpy', '20220301.br', '20220301.bs', '20220301.bug', '20220301.bxr', '20220301.ca', '20220301.cbk-zam', '20220301.cdo', '20220301.ce', '20220301.ceb', '20220301.ch', '20220301.cho', '20220301.chr', '20220301.chy', '20220301.ckb', '20220301.co', '20220301.cr', '20220301.crh', '20220301.cs', '20220301.csb', '20220301.cu', '20220301.cv', '20220301.cy', '20220301.da', '20220301.de', '20220301.din', '20220301.diq', '20220301.dsb', '20220301.dty', '20220301.dv', '20220301.dz', '20220301.ee', '20220301.el', '20220301.eml', '20220301.en', '20220301.eo', '20220301.es', '20220301.et', '20220301.eu', '20220301.ext', '20220301.fa', '20220301.ff', '20220301.fi', '20220301.fiu-vro', '20220301.fj', '20220301.fo', '20220301.fr', '20220301.frp', '20220301.frr', '20220301.fur', '20220301.fy', '20220301.ga', '20220301.gag', '20220301.gan', '20220301.gd', '20220301.gl', '20220301.glk', '20220301.gn', '20220301.gom', '20220301.gor', '20220301.got', '20220301.gu', '20220301.gv', '20220301.ha', '20220301.hak', '20220301.haw', '20220301.he', '20220301.hi', '20220301.hif', '20220301.ho', '20220301.hr', '20220301.hsb', '20220301.ht', '20220301.hu', '20220301.hy', '20220301.ia', '20220301.id', '20220301.ie', '20220301.ig', '20220301.ii', '20220301.ik', '20220301.ilo', '20220301.inh', '20220301.io', '20220301.is', '20220301.it', '20220301.iu', '20220301.ja', '20220301.jam', '20220301.jbo', '20220301.jv', '20220301.ka', '20220301.kaa', '20220301.kab', '20220301.kbd', '20220301.kbp', '20220301.kg', '20220301.ki', '20220301.kj', '20220301.kk', '20220301.kl', '20220301.km', '20220301.kn', '20220301.ko', '20220301.koi', '20220301.krc', '20220301.ks', '20220301.ksh', '20220301.ku', '20220301.kv', '20220301.kw', '20220301.ky', '20220301.la', '20220301.lad', '20220301.lb', '20220301.lbe', '20220301.lez', '20220301.lfn', '20220301.lg', '20220301.li', '20220301.lij', '20220301.lmo', '20220301.ln', '20220301.lo', '20220301.lrc', '20220301.lt', '20220301.ltg', '20220301.lv', '20220301.mai', '20220301.map-bms', '20220301.mdf', '20220301.mg', '20220301.mh', '20220301.mhr', '20220301.mi', '20220301.min', '20220301.mk', '20220301.ml', '20220301.mn', '20220301.mr', '20220301.mrj', '20220301.ms', '20220301.mt', '20220301.mus', '20220301.mwl', '20220301.my', '20220301.myv', '20220301.mzn', '20220301.na', '20220301.nah', '20220301.nap', '20220301.nds', '20220301.nds-nl', '20220301.ne', '20220301.new', '20220301.ng', '20220301.nl', '20220301.nn', '20220301.no', '20220301.nov', '20220301.nrm', '20220301.nso', '20220301.nv', '20220301.ny', '20220301.oc', '20220301.olo', '20220301.om', '20220301.or', '20220301.os', '20220301.pa', '20220301.pag', '20220301.pam', '20220301.pap', '20220301.pcd', '20220301.pdc', '20220301.pfl', '20220301.pi', '20220301.pih', '20220301.pl', '20220301.pms', '20220301.pnb', '20220301.pnt', '20220301.ps', '20220301.pt', '20220301.qu', '20220301.rm', '20220301.rmy', '20220301.rn', '20220301.ro', '20220301.roa-rup', '20220301.roa-tara', '20220301.ru', '20220301.rue', '20220301.rw', '20220301.sa', '20220301.sah', '20220301.sat', '20220301.sc', '20220301.scn', '20220301.sco', '20220301.sd', '20220301.se', '20220301.sg', '20220301.sh', '20220301.si', '20220301.simple', '20220301.sk', '20220301.sl', '20220301.sm', '20220301.sn', '20220301.so', '20220301.sq', '20220301.sr', '20220301.srn', '20220301.ss', '20220301.st', '20220301.stq', '20220301.su', '20220301.sv', '20220301.sw', '20220301.szl', '20220301.ta', '20220301.tcy', '20220301.te', '20220301.tet', '20220301.tg', '20220301.th', '20220301.ti', '20220301.tk', '20220301.tl', '20220301.tn', '20220301.to', '20220301.tpi', '20220301.tr', '20220301.ts', '20220301.tt', '20220301.tum', '20220301.tw', '20220301.ty', '20220301.tyv', '20220301.udm', '20220301.ug', '20220301.uk', '20220301.ur', '20220301.uz', '20220301.ve', '20220301.vec', '20220301.vep', '20220301.vi', '20220301.vls', '20220301.vo', '20220301.wa', '20220301.war', '20220301.wo', '20220301.wuu', '20220301.xal', '20220301.xh', '20220301.xmf', '20220301.yi', '20220301.yo', '20220301.za', '20220301.zea', '20220301.zh', '20220301.zh-classical', '20220301.zh-min-nan', '20220301.zh-yue', '20220301.zu']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 28865\n",
       " \tlikes: 54\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikisql\n",
       " \tsha: cdd69f601c9857990bdc617f91f31d205745288c\n",
       " \tlastModified: 2022-09-06T05:40:02.000Z\n",
       " \ttags: ['arxiv:1709.00103', 'annotations_creators:crowdsourced', 'language:en', 'language_creators:found', 'language_creators:machine-generated', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text2text-generation', 'task_ids:text2text-generation-other-text-to-sql']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A large crowd-sourced dataset for developing natural language interfaces for relational databases\n",
       " \tcitation: @article{zhongSeq2SQL2017,\n",
       "   author    = {Victor Zhong and\n",
       "                Caiming Xiong and\n",
       "                Richard Socher},\n",
       "   title     = {Seq2SQL: Generating Structured Queries from Natural Language using\n",
       "                Reinforcement Learning},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1709.00103},\n",
       "   year      = {2017}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language': ['en'], 'language_creators': ['found', 'machine-generated'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'WikiSQL', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text2text-generation'], 'task_ids': ['text2text-generation-other-text-to-sql'], 'paperswithcode_id': 'wikisql'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 4534\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: wikisql\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikitext\n",
       " \tsha: 5fd4d9082bb70e404577ba24ce0969092f18f281\n",
       " \tlastModified: 2022-07-01T12:43:48.000Z\n",
       " \ttags: ['arxiv:1609.07843', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-sa-3.0', 'license:gfdl', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:  The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\n",
       "  Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike\n",
       "  License.\n",
       " \tcitation: @misc{merity2016pointer,\n",
       "       title={Pointer Sentinel Mixture Models},\n",
       "       author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},\n",
       "       year={2016},\n",
       "       eprint={1609.07843},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-sa-3.0', 'gfdl'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'wikitext-2', 'pretty_name': 'WikiText', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 345145\n",
       " \tlikes: 29\n",
       " \tpaperswithcode_id: wikitext-2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wikitext_tl39\n",
       " \tsha: a616b9e4856f527fa4bce78cea4557ca9c304710\n",
       " \tlastModified: 2022-07-01T11:57:28.000Z\n",
       " \ttags: ['arxiv:1907.00409', 'annotations_creators:no-annotation', 'language_creators:found', 'language:fil', 'language:tl', 'license:gpl-3.0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large scale, unlabeled text dataset with 39 Million tokens in the training set. Inspired by the original WikiText Long Term Dependency dataset (Merity et al., 2016). TL means \"Tagalog.\" Originally published in Cruz & Cheng (2019).\n",
       " \tcitation: @article{cruz2019evaluating,\n",
       "   title={Evaluating Language Model Finetuning Techniques for Low-resource Languages},\n",
       "   author={Cruz, Jan Christian Blaise and Cheng, Charibeth},\n",
       "   journal={arXiv preprint arXiv:1907.00409},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['fil', 'tl'], 'license': ['gpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': 'wikitext-tl-39', 'pretty_name': 'WikiText-TL-39'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 319\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wikitext-tl-39\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wili_2018\n",
       " \tsha: 15be5a43d67971c484e99ba4ed5d8fcc2c51e912\n",
       " \tlastModified: 2022-07-27T14:39:13.000Z\n",
       " \ttags: ['arxiv:1801.07779', 'annotations_creators:no-annotation', 'language_creators:found', 'language:ace', 'language:af', 'language:als', 'language:am', 'language:an', 'language:ang', 'language:ar', 'language:arz', 'language:as', 'language:ast', 'language:av', 'language:ay', 'language:az', 'language:azb', 'language:ba', 'language:bar', 'language:bcl', 'language:be', 'language:bg', 'language:bho', 'language:bjn', 'language:bn', 'language:bo', 'language:bpy', 'language:br', 'language:bs', 'language:bxr', 'language:ca', 'language:cbk', 'language:cdo', 'language:ce', 'language:ceb', 'language:chr', 'language:ckb', 'language:co', 'language:crh', 'language:cs', 'language:csb', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:diq', 'language:dsb', 'language:dty', 'language:dv', 'language:egl', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:ext', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:frp', 'language:fur', 'language:fy', 'language:ga', 'language:gag', 'language:gd', 'language:gl', 'language:glk', 'language:gn', 'language:gu', 'language:gv', 'language:ha', 'language:hak', 'language:he', 'language:hi', 'language:hif', 'language:hr', 'language:hsb', 'language:ht', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:ig', 'language:ilo', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jam', 'language:jbo', 'language:jv', 'language:ka', 'language:kaa', 'language:kab', 'language:kbd', 'language:kk', 'language:km', 'language:kn', 'language:ko', 'language:koi', 'language:kok', 'language:krc', 'language:ksh', 'language:ku', 'language:kv', 'language:kw', 'language:ky', 'language:la', 'language:lad', 'language:lb', 'language:lez', 'language:lg', 'language:li', 'language:lij', 'language:lmo', 'language:ln', 'language:lo', 'language:lrc', 'language:lt', 'language:ltg', 'language:lv', 'language:lzh', 'language:mai', 'language:map', 'language:mdf', 'language:mg', 'language:mhr', 'language:mi', 'language:min', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:mrj', 'language:ms', 'language:mt', 'language:mwl', 'language:my', 'language:myv', 'language:mzn', 'language:nan', 'language:nap', 'language:nb', 'language:nci', 'language:nds', 'language:ne', 'language:new', 'language:nl', 'language:nn', 'language:nrm', 'language:nso', 'language:nv', 'language:oc', 'language:olo', 'language:om', 'language:or', 'language:os', 'language:pa', 'language:pag', 'language:pam', 'language:pap', 'language:pcd', 'language:pdc', 'language:pfl', 'language:pl', 'language:pnb', 'language:ps', 'language:pt', 'language:qu', 'language:rm', 'language:ro', 'language:roa', 'language:ru', 'language:rue', 'language:rup', 'language:rw', 'language:sa', 'language:sah', 'language:sc', 'language:scn', 'language:sco', 'language:sd', 'language:sgs', 'language:sh', 'language:si', 'language:sk', 'language:sl', 'language:sme', 'language:sn', 'language:so', 'language:sq', 'language:sr', 'language:srn', 'language:stq', 'language:su', 'language:sv', 'language:sw', 'language:szl', 'language:ta', 'language:tcy', 'language:te', 'language:tet', 'language:tg', 'language:th', 'language:tk', 'language:tl', 'language:tn', 'language:to', 'language:tr', 'language:tt', 'language:tyv', 'language:udm', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vec', 'language:vep', 'language:vi', 'language:vls', 'language:vo', 'language:vro', 'language:wa', 'language:war', 'language:wo', 'language:wuu', 'language:xh', 'language:xmf', 'language:yi', 'language:yo', 'language:zea', 'language:zh', 'language_bcp47:be-tarask', 'language_bcp47:map-bms', 'language_bcp47:nds-nl', 'language_bcp47:roa-tara', 'language_bcp47:zh-yue', 'license:odbl', 'multilinguality:multilingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-language-identification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: It is a benchmark dataset for language identification and contains 235000 paragraphs of 235 languages\n",
       " \tcitation: @dataset{thoma_martin_2018_841984,\n",
       "   author       = {Thoma, Martin},\n",
       "   title        = {{WiLI-2018 - Wikipedia Language Identification database}},\n",
       "   month        = jan,\n",
       "   year         = 2018,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {1.0.0},\n",
       "   doi          = {10.5281/zenodo.841984},\n",
       "   url          = {https://doi.org/10.5281/zenodo.841984}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['ace', 'af', 'als', 'am', 'an', 'ang', 'ar', 'arz', 'as', 'ast', 'av', 'ay', 'az', 'azb', 'ba', 'bar', 'bcl', 'be', 'bg', 'bho', 'bjn', 'bn', 'bo', 'bpy', 'br', 'bs', 'bxr', 'ca', 'cbk', 'cdo', 'ce', 'ceb', 'chr', 'ckb', 'co', 'crh', 'cs', 'csb', 'cv', 'cy', 'da', 'de', 'diq', 'dsb', 'dty', 'dv', 'egl', 'el', 'en', 'eo', 'es', 'et', 'eu', 'ext', 'fa', 'fi', 'fo', 'fr', 'frp', 'fur', 'fy', 'ga', 'gag', 'gd', 'gl', 'glk', 'gn', 'gu', 'gv', 'ha', 'hak', 'he', 'hi', 'hif', 'hr', 'hsb', 'ht', 'hu', 'hy', 'ia', 'id', 'ie', 'ig', 'ilo', 'io', 'is', 'it', 'ja', 'jam', 'jbo', 'jv', 'ka', 'kaa', 'kab', 'kbd', 'kk', 'km', 'kn', 'ko', 'koi', 'kok', 'krc', 'ksh', 'ku', 'kv', 'kw', 'ky', 'la', 'lad', 'lb', 'lez', 'lg', 'li', 'lij', 'lmo', 'ln', 'lo', 'lrc', 'lt', 'ltg', 'lv', 'lzh', 'mai', 'map', 'mdf', 'mg', 'mhr', 'mi', 'min', 'mk', 'ml', 'mn', 'mr', 'mrj', 'ms', 'mt', 'mwl', 'my', 'myv', 'mzn', 'nan', 'nap', 'nb', 'nci', 'nds', 'ne', 'new', 'nl', 'nn', 'nrm', 'nso', 'nv', 'oc', 'olo', 'om', 'or', 'os', 'pa', 'pag', 'pam', 'pap', 'pcd', 'pdc', 'pfl', 'pl', 'pnb', 'ps', 'pt', 'qu', 'rm', 'ro', 'roa', 'ru', 'rue', 'rup', 'rw', 'sa', 'sah', 'sc', 'scn', 'sco', 'sd', 'sgs', 'sh', 'si', 'sk', 'sl', 'sme', 'sn', 'so', 'sq', 'sr', 'srn', 'stq', 'su', 'sv', 'sw', 'szl', 'ta', 'tcy', 'te', 'tet', 'tg', 'th', 'tk', 'tl', 'tn', 'to', 'tr', 'tt', 'tyv', 'udm', 'ug', 'uk', 'ur', 'uz', 'vec', 'vep', 'vi', 'vls', 'vo', 'vro', 'wa', 'war', 'wo', 'wuu', 'xh', 'xmf', 'yi', 'yo', 'zea', 'zh'], 'language_bcp47': ['be-tarask', 'map-bms', 'nds-nl', 'roa-tara', 'zh-yue'], 'license': ['odbl'], 'multilinguality': ['multilingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-language-identification'], 'paperswithcode_id': 'wili-2018', 'pretty_name': 'Wili2018'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wili-2018\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wino_bias\n",
       " \tsha: 850f89c2269edf2077c5ffa039009edb063b5f7c\n",
       " \tlastModified: 2022-07-07T13:12:26.000Z\n",
       " \ttags: ['arxiv:1804.06876', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:coreference-resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WinoBias, a Winograd-schema dataset for coreference resolution focused on gender bias.\n",
       " The corpus contains Winograd-schema style sentences with entities corresponding to people\n",
       " referred by their occupation (e.g. the nurse, the doctor, the carpenter).\n",
       " \tcitation: @article{DBLP:journals/corr/abs-1804-06876,\n",
       "   author    = {Jieyu Zhao and\n",
       "                Tianlu Wang and\n",
       "                Mark Yatskar and\n",
       "                Vicente Ordonez and\n",
       "                Kai{-}Wei Chang},\n",
       "   title     = {Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/1804.06876},\n",
       "   year      = {2018},\n",
       "   url       = {http://arxiv.org/abs/1804.06876},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {1804.06876},\n",
       "   timestamp = {Mon, 13 Aug 2018 16:47:01 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-1804-06876.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['coreference-resolution'], 'paperswithcode_id': 'winobias', 'pretty_name': 'WinoBias'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 189332\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: winobias\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: winograd_wsc\n",
       " \tsha: a804f91af29bce594f3fe6cc8667ec516f57214b\n",
       " \tlastModified: 2022-08-25T13:44:03.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:multiple-choice', 'task_ids:multiple-choice-coreference-resolution']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is\n",
       " resolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its\n",
       " resolution. The schema takes its name from a well-known example by Terry Winograd:\n",
       " \n",
       " > The city councilmen refused the demonstrators a permit because they [feared/advocated] violence.\n",
       " \n",
       " If the word is ``feared'', then ``they'' presumably refers to the city council; if it is ``advocated'' then ``they''\n",
       " presumably refers to the demonstrators.\n",
       " \tcitation: @inproceedings{levesque2012winograd,\n",
       "   title={The winograd schema challenge},\n",
       "   author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},\n",
       "   booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},\n",
       "   year={2012},\n",
       "   organization={Citeseer}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['multiple-choice'], 'task_ids': ['multiple-choice-coreference-resolution'], 'paperswithcode_id': 'wsc', 'pretty_name': 'Winograd Schema Challenge'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1457\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wsc\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: winogrande\n",
       " \tsha: 0f4f457acaf2f2d1e66f7e9cc5d3cdd905f11add\n",
       " \tlastModified: 2022-07-01T11:57:31.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WinoGrande is a new collection of 44k problems, inspired by Winograd Schema Challenge (Levesque, Davis, and Morgenstern\n",
       "  2011), but adjusted to improve the scale and robustness against the dataset-specific bias. Formulated as a\n",
       " fill-in-a-blank task with binary options, the goal is to choose the right option for a given sentence which requires\n",
       " commonsense reasoning.\n",
       " \tcitation: @InProceedings{ai2:winogrande,\n",
       " title = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},\n",
       " authors={Keisuke, Sakaguchi and Ronan, Le Bras and Chandra, Bhagavatula and Yejin, Choi\n",
       " },\n",
       " year={2019}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'winogrande', 'pretty_name': 'WinoGrande'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 90010\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: winogrande\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wiqa\n",
       " \tsha: ead0cc799ae4adc79524167ec72e827f8fd55872\n",
       " \tlastModified: 2022-07-01T11:57:31.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The WIQA dataset V1 has 39705 questions containing a perturbation and a possible effect in the context of a paragraph.\n",
       " The dataset is split into 29808 train questions, 6894 dev questions and 3003 test questions.\n",
       " \tcitation: @article{wiqa,\n",
       "       author    = {Niket Tandon and Bhavana Dalvi Mishra and Keisuke Sakaguchi and Antoine Bosselut and Peter Clark}\n",
       "       title     = {WIQA: A dataset for \"What if...\" reasoning over procedural text},\n",
       "       journal   = {arXiv:1909.04739v1},\n",
       "       year      = {2019},\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'wiqa', 'pretty_name': 'What-If Question Answering'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 30351\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: wiqa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wisesight1000\n",
       " \tsha: c3ee99e9a4828849d63d04e54ad67d837a589d20\n",
       " \tlastModified: 2022-07-01T11:57:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:n<1K', 'source_datasets:extended|wisesight_sentiment', 'task_categories:token-classification', 'task_ids:token-classification-other-word-tokenization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: `wisesight1000` contains Thai social media texts randomly drawn from the full `wisesight-sentiment`, tokenized by human annotators.\n",
       " Out of the labels `neg` (negative), `neu` (neutral), `pos` (positive), `q` (question), 250 samples each. Some texts are removed because\n",
       " they look like spam.Because these samples are representative of real world content, we believe having these annotaed samples will allow\n",
       " the community to robustly evaluate tokenization algorithms.\n",
       " \tcitation: @software{bact_2019_3457447,\n",
       "   author       = {Suriyawongkul, Arthit and\n",
       "                   Chuangsuwanich, Ekapol and\n",
       "                   Chormai, Pattarawat and\n",
       "                   Polpanumas, Charin},\n",
       "   title        = {PyThaiNLP/wisesight-sentiment: First release},\n",
       "   month        = sep,\n",
       "   year         = 2019,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {v1.0},\n",
       "   doi          = {10.5281/zenodo.3457447},\n",
       "   url          = {https://doi.org/10.5281/zenodo.3457447}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n<1K'], 'source_datasets': ['extended|wisesight_sentiment'], 'task_categories': ['token-classification'], 'task_ids': ['token-classification-other-word-tokenization'], 'paperswithcode_id': None, 'pretty_name': 'wisesight1000'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wisesight_sentiment\n",
       " \tsha: 4a0b15e6fb6bb96b6ea6d918ac694a5ef1357f1a\n",
       " \tlastModified: 2022-07-01T11:57:32.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:th', 'license:cc0-1.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wisesight Sentiment Corpus: Social media messages in Thai language with sentiment category (positive, neutral, negative, question)\n",
       " * Released to public domain under Creative Commons Zero v1.0 Universal license.\n",
       " * Category (Labels): {\"pos\": 0, \"neu\": 1, \"neg\": 2, \"q\": 3}\n",
       " * Size: 26,737 messages\n",
       " * Language: Central Thai\n",
       " * Style: Informal and conversational. With some news headlines and advertisement.\n",
       " * Time period: Around 2016 to early 2019. With small amount from other period.\n",
       " * Domains: Mixed. Majority are consumer products and services (restaurants, cosmetics, drinks, car, hotels), with some current affairs.\n",
       " * Privacy:\n",
       "     * Only messages that made available to the public on the internet (websites, blogs, social network sites).\n",
       "     * For Facebook, this means the public comments (everyone can see) that made on a public page.\n",
       "     * Private/protected messages and messages in groups, chat, and inbox are not included.\n",
       " * Alternations and modifications:\n",
       "     * Keep in mind that this corpus does not statistically represent anything in the language register.\n",
       "     * Large amount of messages are not in their original form. Personal data are removed or masked.\n",
       "     * Duplicated, leading, and trailing whitespaces are removed. Other punctuations, symbols, and emojis are kept intact.\n",
       "     (Mis)spellings are kept intact.\n",
       "     * Messages longer than 2,000 characters are removed.\n",
       "     * Long non-Thai messages are removed. Duplicated message (exact match) are removed.\n",
       " * More characteristics of the data can be explore: https://github.com/PyThaiNLP/wisesight-sentiment/blob/master/exploration.ipynb\n",
       " \tcitation: @software{bact_2019_3457447,\n",
       "   author       = {Suriyawongkul, Arthit and\n",
       "                   Chuangsuwanich, Ekapol and\n",
       "                   Chormai, Pattarawat and\n",
       "                   Polpanumas, Charin},\n",
       "   title        = {PyThaiNLP/wisesight-sentiment: First release},\n",
       "   month        = sep,\n",
       "   year         = 2019,\n",
       "   publisher    = {Zenodo},\n",
       "   version      = {v1.0},\n",
       "   doi          = {10.5281/zenodo.3457447},\n",
       "   url          = {https://doi.org/10.5281/zenodo.3457447}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['th'], 'license': ['cc0-1.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'WisesightSentiment', 'train-eval-index': [{'config': 'wisesight_sentiment', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'texts': 'text', 'category': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 528\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt14\n",
       " \tsha: 504f1215d35f6a8407a39984c4b4cd9a8f63970d\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:fr', 'language:hi', 'language:ru', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|giga_fren', 'source_datasets:extended|news_commentary', 'source_datasets:extended|un_multi', 'source_datasets:extended|hind_encorp', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2014:W14-33,\n",
       "   author    = {Bojar, Ondrej  and  Buck, Christian  and  Federmann, Christian  and  Haddow, Barry  and  Koehn, Philipp  and  Leveling, Johannes  and  Monz, Christof  and  Pecina, Pavel  and  Post, Matt  and  Saint-Amand, Herve  and  Soricut, Radu  and  Specia, Lucia  and  Tamchyna, Ale\\v{s}},\n",
       "   title     = {Findings of the 2014 Workshop on Statistical Machine Translation},\n",
       "   booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},\n",
       "   month     = {June},\n",
       "   year      = {2014},\n",
       "   address   = {Baltimore, Maryland, USA},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {12--58},\n",
       "   url       = {http://www.aclweb.org/anthology/W/W14/W14-3302}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'fr', 'hi', 'ru'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|giga_fren', 'extended|news_commentary', 'extended|un_multi', 'extended|hind_encorp'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT14', 'paperswithcode_id': 'wmt-2014'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8824\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: wmt-2014\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt15\n",
       " \tsha: 1e16d6f32091bf63a3c636dd5e55892a1f5fcbb2\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:fi', 'language:fr', 'language:ru', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|giga_fren', 'source_datasets:extended|news_commentary', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2015:WMT,\n",
       "   author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Haddow, Barry  and  Huck, Matthias  and  Hokamp, Chris  and  Koehn, Philipp  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Post, Matt  and  Scarton, Carolina  and  Specia, Lucia  and  Turchi, Marco},\n",
       "   title     = {Findings of the 2015 Workshop on Statistical Machine Translation},\n",
       "   booktitle = {Proceedings of the Tenth Workshop on Statistical Machine Translation},\n",
       "   month     = {September},\n",
       "   year      = {2015},\n",
       "   address   = {Lisbon, Portugal},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {1--46},\n",
       "   url       = {http://aclweb.org/anthology/W15-3001}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'fi', 'fr', 'ru'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|giga_fren', 'extended|news_commentary', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT15', 'paperswithcode_id': 'wmt-2015'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1183\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: wmt-2015\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt16\n",
       " \tsha: 52558ac6f417bc8859bfb439570412485521fe98\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:fi', 'language:ro', 'language:ru', 'language:tr', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|news_commentary', 'source_datasets:extended|setimes', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2016:WMT1,\n",
       "   author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Graham, Yvette  and  Haddow, Barry  and  Huck, Matthias  and  Jimeno Yepes, Antonio  and  Koehn, Philipp  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Neveol, Aurelie  and  Neves, Mariana  and  Popel, Martin  and  Post, Matt  and  Rubino, Raphael  and  Scarton, Carolina  and  Specia, Lucia  and  Turchi, Marco  and  Verspoor, Karin  and  Zampieri, Marcos},\n",
       "   title     = {Findings of the 2016 Conference on Machine Translation},\n",
       "   booktitle = {Proceedings of the First Conference on Machine Translation},\n",
       "   month     = {August},\n",
       "   year      = {2016},\n",
       "   address   = {Berlin, Germany},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {131--198},\n",
       "   url       = {http://www.aclweb.org/anthology/W/W16/W16-2301}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'fi', 'ro', 'ru', 'tr'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|news_commentary', 'extended|setimes', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT16', 'paperswithcode_id': 'wmt-2016'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 31081\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: wmt-2016\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt17\n",
       " \tsha: 246ab53e1c7411c25f2be9695df2b64be09e505a\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:fi', 'language:lv', 'language:ru', 'language:tr', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|news_commentary', 'source_datasets:extended|setimes', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2017:WMT1,\n",
       "   author    = {Bojar, Ond\\v{r}ej  and  Chatterjee, Rajen  and  Federmann, Christian  and  Graham, Yvette  and  Haddow, Barry  and  Huang, Shujian  and  Huck, Matthias  and  Koehn, Philipp  and  Liu, Qun  and  Logacheva, Varvara  and  Monz, Christof  and  Negri, Matteo  and  Post, Matt  and  Rubino, Raphael  and  Specia, Lucia  and  Turchi, Marco},\n",
       "   title     = {Findings of the 2017 Conference on Machine Translation (WMT17)},\n",
       "   booktitle = {Proceedings of the Second Conference on Machine Translation, Volume 2: Shared Task Papers},\n",
       "   month     = {September},\n",
       "   year      = {2017},\n",
       "   address   = {Copenhagen, Denmark},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {169--214},\n",
       "   url       = {http://www.aclweb.org/anthology/W17-4717}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'fi', 'lv', 'ru', 'tr', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|news_commentary', 'extended|setimes', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT17', 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2794\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt18\n",
       " \tsha: 50610a500eb94d37a46dd36e5a4a79130ea2a935\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:et', 'language:fi', 'language:kk', 'language:ru', 'language:tr', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|news_commentary', 'source_datasets:extended|opus_paracrawl', 'source_datasets:extended|setimes', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2018:WMT1,\n",
       "   author    = {Bojar, Ond\\v{r}ej  and  Federmann, Christian  and  Fishel, Mark\n",
       "     and Graham, Yvette  and  Haddow, Barry  and  Huck, Matthias  and\n",
       "     Koehn, Philipp  and  Monz, Christof},\n",
       "   title     = {Findings of the 2018 Conference on Machine Translation (WMT18)},\n",
       "   booktitle = {Proceedings of the Third Conference on Machine Translation,\n",
       "     Volume 2: Shared Task Papers},\n",
       "   month     = {October},\n",
       "   year      = {2018},\n",
       "   address   = {Belgium, Brussels},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {272--307},\n",
       "   url       = {http://www.aclweb.org/anthology/W18-6401}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'et', 'fi', 'kk', 'ru', 'tr', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|news_commentary', 'extended|opus_paracrawl', 'extended|setimes', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT18', 'paperswithcode_id': 'wmt-2018'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1588\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: wmt-2018\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt19\n",
       " \tsha: 2846b4fb70ab19b025a52906573e24e8d95cf5b9\n",
       " \tlastModified: 2022-08-23T10:01:01.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:cs', 'language:de', 'language:en', 'language:fi', 'language:fr', 'language:gu', 'language:kk', 'language:lt', 'language:ru', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|news_commentary', 'source_datasets:extended|opus_paracrawl', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @ONLINE {wmt19translate,\n",
       "     author = {Wikimedia Foundation},\n",
       "     title  = {ACL 2019 Fourth Conference on Machine Translation (WMT19), Shared Task: Machine Translation of News},\n",
       "     url    = {http://www.statmt.org/wmt19/translation-task.html}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['cs', 'de', 'en', 'fi', 'fr', 'gu', 'kk', 'lt', 'ru', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|news_commentary', 'extended|opus_paracrawl', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT19', 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5155\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt20_mlqe_task1\n",
       " \tsha: 6eab200c5ea71771e5359f05ce289cd85420dac1\n",
       " \tlastModified: 2022-08-11T12:57:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language:de', 'language:en', 'language:et', 'language:ne', 'language:ro', 'language:ru', 'language:si', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|reddit', 'source_datasets:extended|wikipedia', 'task_categories:translation', 'configs:en-de', 'configs:en-zh', 'configs:et-en', 'configs:ne-en', 'configs:ro-en', 'configs:ru-en', 'configs:si-en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This shared task (part of WMT20) will build on its previous editions\n",
       " to further examine automatic methods for estimating the quality\n",
       " of neural machine translation output at run-time, without relying\n",
       " on reference translations. As in previous years, we cover estimation\n",
       " at various levels. Important elements introduced this year include: a new\n",
       " task where sentences are annotated with Direct Assessment (DA)\n",
       " scores instead of labels based on post-editing; a new multilingual\n",
       " sentence-level dataset mainly from Wikipedia articles, where the\n",
       " source articles can be retrieved for document-wide context; the\n",
       " availability of NMT models to explore system-internal information for the task.\n",
       " \n",
       " Task 1 uses Wikipedia data for 6 language pairs that includes high-resource\n",
       " English--German (En-De) and English--Chinese (En-Zh), medium-resource\n",
       " Romanian--English (Ro-En) and Estonian--English (Et-En), and low-resource\n",
       " Sinhalese--English (Si-En) and Nepalese--English (Ne-En), as well as a\n",
       " dataset with a combination of Wikipedia articles and Reddit articles\n",
       " for Russian-English (En-Ru). The datasets were collected by translating\n",
       " sentences sampled from source language articles using state-of-the-art NMT\n",
       " models built using the fairseq toolkit and annotated with Direct Assessment (DA)\n",
       " scores by professional translators. Each sentence was annotated following the\n",
       " FLORES setup, which presents a form of DA, where at least three professional\n",
       " translators rate each sentence from 0-100 according to the perceived translation\n",
       " quality. DA scores are standardised using the z-score by rater. Participating systems\n",
       " are required to score sentences according to z-standardised DA scores.\n",
       " \tcitation: Not available.\n",
       " \tcardData: {'pretty_name': 'WMT20 - MultiLingual Quality Estimation (MLQE) Task1', 'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['found'], 'language': ['de', 'en', 'et', 'ne', 'ro', 'ru', 'si', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|reddit', 'extended|wikipedia'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None, 'configs': ['en-de', 'en-zh', 'et-en', 'ne-en', 'ro-en', 'ru-en', 'si-en']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1303\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt20_mlqe_task2\n",
       " \tsha: f410e08b07d9b38477fa80a29724f3009691133a\n",
       " \tlastModified: 2022-07-01T11:57:34.000Z\n",
       " \ttags: ['arxiv:1902.08646', 'annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language:de', 'language:en', 'language:zh', 'license:unknown', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|wikipedia', 'task_categories:translation', 'task_categories:text-classification', 'task_ids:text-classification-other-translation-quality-estimation', 'configs:en-de', 'configs:en-zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This shared task (part of WMT20) will build on its previous editions\n",
       " to further examine automatic methods for estimating the quality\n",
       " of neural machine translation output at run-time, without relying\n",
       " on reference translations. As in previous years, we cover estimation\n",
       " at various levels. Important elements introduced this year include: a new\n",
       " task where sentences are annotated with Direct Assessment (DA)\n",
       " scores instead of labels based on post-editing; a new multilingual\n",
       " sentence-level dataset mainly from Wikipedia articles, where the\n",
       " source articles can be retrieved for document-wide context; the\n",
       " availability of NMT models to explore system-internal information for the task.\n",
       " \n",
       " Task 2 evaluates the application of QE for post-editing purposes. It consists of predicting:\n",
       " - A/ Word-level tags. This is done both on source side (to detect which words caused errors)\n",
       " and target side (to detect mistranslated or missing words).\n",
       "   - A1/ Each token is tagged as either `OK` or `BAD`. Additionally,\n",
       "   each gap between two words is tagged as `BAD` if one or more\n",
       "   missing words should have been there, and `OK` otherwise. Note\n",
       "   that number of tags for each target sentence is 2*N+1, where\n",
       "   N is the number of tokens in the sentence.\n",
       "   - A2/ Tokens are tagged as `OK` if they were correctly\n",
       "   translated, and `BAD` otherwise. Gaps are not tagged.\n",
       " - B/ Sentence-level HTER scores. HTER (Human Translation Error Rate)\n",
       " is the ratio between the number of edits (insertions/deletions/replacements)\n",
       " needed and the reference translation length.\n",
       " \tcitation: Not available.\n",
       " \tcardData: {'pretty_name': 'WMT20 - MultiLingual Quality Estimation (MLQE) Task2', 'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['found'], 'language': ['de', 'en', 'zh'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|wikipedia'], 'task_categories': ['translation', 'text-classification'], 'task_ids': ['text-classification-other-translation-quality-estimation'], 'paperswithcode_id': None, 'configs': ['en-de', 'en-zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 477\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt20_mlqe_task3\n",
       " \tsha: c0018962e7fa6598042c6d3092742c4f66a883da\n",
       " \tlastModified: 2022-08-11T12:57:53.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:found', 'language:en', 'language:fr', 'license:unknown', 'multilinguality:translation', 'size_categories:1K<n<10K', 'source_datasets:extended|amazon_us_reviews', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: This shared task (part of WMT20) will build on its previous editions\n",
       " to further examine automatic methods for estimating the quality\n",
       " of neural machine translation output at run-time, without relying\n",
       " on reference translations. As in previous years, we cover estimation\n",
       " at various levels. Important elements introduced this year include: a new\n",
       " task where sentences are annotated with Direct Assessment (DA)\n",
       " scores instead of labels based on post-editing; a new multilingual\n",
       " sentence-level dataset mainly from Wikipedia articles, where the\n",
       " source articles can be retrieved for document-wide context; the\n",
       " availability of NMT models to explore system-internal information for the task.\n",
       " \n",
       " The goal of this task 3 is to predict document-level quality scores as well as fine-grained annotations.\n",
       " \tcitation: Not available.\n",
       " \tcardData: {'pretty_name': 'WMT20 - MultiLingual Quality Estimation (MLQE) Task3', 'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['found'], 'language': ['en', 'fr'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|amazon_us_reviews'], 'task_categories': ['translation'], 'task_ids': [], 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 320\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wmt_t2t\n",
       " \tsha: 081b63fa3100ea67d700512499c2533f5bb63a6c\n",
       " \tlastModified: 2022-08-23T10:01:06.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:de', 'language:en', 'license:unknown', 'multilinguality:translation', 'size_categories:10M<n<100M', 'source_datasets:extended|europarl_bilingual', 'source_datasets:extended|news_commentary', 'source_datasets:extended|opus_paracrawl', 'source_datasets:extended|un_multi', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{bojar-EtAl:2014:W14-33,\n",
       "   author    = {Bojar, Ondrej  and  Buck, Christian  and  Federmann, Christian  and  Haddow, Barry  and  Koehn, Philipp  and  Leveling, Johannes  and  Monz, Christof  and  Pecina, Pavel  and  Post, Matt  and  Saint-Amand, Herve  and  Soricut, Radu  and  Specia, Lucia  and  Tamchyna, Ale\\v{s}},\n",
       "   title     = {Findings of the 2014 Workshop on Statistical Machine Translation},\n",
       "   booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},\n",
       "   month     = {June},\n",
       "   year      = {2014},\n",
       "   address   = {Baltimore, Maryland, USA},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   pages     = {12--58},\n",
       "   url       = {http://www.aclweb.org/anthology/W/W14/W14-3302}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['de', 'en'], 'license': ['unknown'], 'multilinguality': ['translation'], 'size_categories': ['10M<n<100M'], 'source_datasets': ['extended|europarl_bilingual', 'extended|news_commentary', 'extended|opus_paracrawl', 'extended|un_multi'], 'task_categories': ['translation'], 'task_ids': [], 'pretty_name': 'WMT T2T', 'paperswithcode_id': None}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wnut_17\n",
       " \tsha: 4165ea1000fb133a906ed6220b1136fab6b6cc82\n",
       " \tlastModified: 2022-07-01T11:57:35.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WNUT 17: Emerging and Rare entity recognition\n",
       " \n",
       " This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\n",
       " Named entities form the basis of many modern approaches to other tasks (like event clustering and summarisation),\n",
       " but recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms.\n",
       " Take for example the tweet “so.. kktny in 30 mins?” - even human experts find entity kktny hard to detect and resolve.\n",
       " This task will evaluate the ability to detect and classify novel, emerging, singleton named entities in noisy text.\n",
       " \n",
       " The goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities.\n",
       " \tcitation: @inproceedings{derczynski-etal-2017-results,\n",
       "     title = \"Results of the {WNUT}2017 Shared Task on Novel and Emerging Entity Recognition\",\n",
       "     author = \"Derczynski, Leon  and\n",
       "       Nichols, Eric  and\n",
       "       van Erp, Marieke  and\n",
       "       Limsopatham, Nut\",\n",
       "     booktitle = \"Proceedings of the 3rd Workshop on Noisy User-generated Text\",\n",
       "     month = sep,\n",
       "     year = \"2017\",\n",
       "     address = \"Copenhagen, Denmark\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/W17-4418\",\n",
       "     doi = \"10.18653/v1/W17-4418\",\n",
       "     pages = \"140--147\",\n",
       "     abstract = \"This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\n",
       "                 Named entities form the basis of many modern approaches to other tasks (like event clustering and summarization),\n",
       "                 but recall on them is a real problem in noisy text - even among annotators.\n",
       "                 This drop tends to be due to novel entities and surface forms.\n",
       "                 Take for example the tweet {``}so.. kktny in 30 mins?!{''} {--} even human experts find the entity {`}kktny{'}\n",
       "                 hard to detect and resolve. The goal of this task is to provide a definition of emerging and of rare entities,\n",
       "                 and based on that, also datasets for detecting these entities. The task as described in this paper evaluated the\n",
       "                 ability of participating entries to detect and classify novel and emerging named entities in noisy text.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'wnut-2017-emerging-and-rare-entity', 'pretty_name': 'WNUT 17', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3100\n",
       " \tlikes: 7\n",
       " \tpaperswithcode_id: wnut-2017-emerging-and-rare-entity\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wongnai_reviews\n",
       " \tsha: 8ce485e6f0a1e1d554ca3f48a37d9788798d6e70\n",
       " \tlastModified: 2022-07-01T12:43:49.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:th', 'license:lgpl-3.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wongnai's review dataset contains restaurant reviews and ratings, mainly in Thai language.\n",
       " The reviews are in 5 classes ranging from 1 to 5 stars.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['th'], 'license': ['lgpl-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'WongnaiReviews'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 476\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: woz_dialogue\n",
       " \tsha: b5e561f6902a12edecabcbd962fd4de69b7c538c\n",
       " \tlastModified: 2022-08-11T12:57:54.000Z\n",
       " \ttags: ['arxiv:1604.04562', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:de', 'language:en', 'language:it', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_categories:token-classification', 'task_categories:text-classification', 'task_ids:dialogue-modeling', 'task_ids:multi-class-classification', 'task_ids:parsing', 'configs:de', 'configs:de_en', 'configs:en', 'configs:it', 'configs:it_en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Wizard-of-Oz (WOZ) is a dataset for training task-oriented dialogue systems. The dataset is designed around the task of finding a restaurant in the Cambridge, UK area. There are three informable slots (food, pricerange,area) that users can use to constrain the search and six requestable slots (address, phone, postcode plus the three informable slots) that the user can ask a value for once a restaurant has been offered.\n",
       " \tcitation: @misc{wen2017networkbased,\n",
       "       title={A Network-based End-to-End Trainable Task-oriented Dialogue System},\n",
       "       author={Tsung-Hsien Wen and David Vandyke and Nikola Mrksic and Milica Gasic and Lina M. Rojas-Barahona and Pei-Hao Su and Stefan Ultes and Steve Young},\n",
       "       year={2017},\n",
       "       eprint={1604.04562},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['de', 'en', 'it'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask', 'token-classification', 'text-classification'], 'task_ids': ['dialogue-modeling', 'multi-class-classification', 'parsing'], 'paperswithcode_id': 'wizard-of-oz', 'pretty_name': 'Wizard-of-Oz', 'configs': ['de', 'de_en', 'en', 'it', 'it_en']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 957\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: wizard-of-oz\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: wrbsc\n",
       " \tsha: 01b5d65e83f03711c3e0ff0ed8f69262d16b6dfd\n",
       " \tlastModified: 2022-07-01T11:57:36.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:pl', 'license:cc-by-sa-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:semantic-similarity-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: WUT Relations Between Sentences Corpus contains 2827 pairs of related sentences.\n",
       " Relationships are derived from Cross-document Structure Theory (CST), which enables multi-document summarization through identification of cross-document rhetorical relationships within a cluster of related documents.\n",
       " Every relation was marked by at least 3 annotators.\n",
       " \tcitation: @misc{11321/305,\n",
       "  title = {{WUT} Relations Between Sentences Corpus},\n",
       "  author = {Oleksy, Marcin and Fikus, Dominika and Wolski, Michal and Podbielska, Malgorzata and Turek, Agnieszka and Kędzia, Pawel},\n",
       "  url = {http://hdl.handle.net/11321/305},\n",
       "  note = {{CLARIN}-{PL} digital repository},\n",
       "  copyright = {Attribution-{ShareAlike} 3.0 Unported ({CC} {BY}-{SA} 3.0)},\n",
       "  year = {2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['pl'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['semantic-similarity-classification'], 'paperswithcode_id': None, 'pretty_name': 'wrbsc'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: x_stance\n",
       " \tsha: 6a1c8e5ed5e5e6787d2e797a766997894080ac5c\n",
       " \tlastModified: 2022-08-29T16:13:42.000Z\n",
       " \ttags: ['arxiv:2003.08385', 'annotations_creators:machine-generated', 'language:de', 'language:en', 'language:fr', 'language:it', 'language_creators:found', 'license:cc-by-nc-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-stance-detection']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions.\n",
       " \n",
       " It can be used to train and evaluate stance detection systems.\n",
       " \tcitation: @inproceedings{vamvas2020xstance,\n",
       "     author    = \"Vamvas, Jannis and Sennrich, Rico\",\n",
       "     title     = \"{X-Stance}: A Multilingual Multi-Target Dataset for Stance Detection\",\n",
       "     booktitle = \"Proceedings of the 5th Swiss Text Analytics Conference (SwissText) \\\\& 16th Conference on Natural Language Processing (KONVENS)\",\n",
       "     address   = \"Zurich, Switzerland\",\n",
       "     year      = \"2020\",\n",
       "     month     = \"jun\",\n",
       "     url       = \"http://ceur-ws.org/Vol-2624/paper9.pdf\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language': ['de', 'en', 'fr', 'it'], 'language_creators': ['found'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'x-stance', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-stance-detection'], 'paperswithcode_id': 'x-stance'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: x-stance\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xcopa\n",
       " \tsha: 4dd5a31b7f33d1782993f8f5e884b4e8e842abe3\n",
       " \tlastModified: 2022-07-01T11:57:37.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:et', 'language:ht', 'language:id', 'language:it', 'language:qu', 'language:sw', 'language:ta', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:unknown', 'source_datasets:extended|copa', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:   XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\n",
       " The Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\n",
       " languages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\n",
       " the globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages. All the details about the\n",
       " creation of XCOPA and the implementation of the baselines are available in the paper.\\n\n",
       " \tcitation:   @article{ponti2020xcopa,\n",
       "   title={{XCOPA: A} Multilingual Dataset for Causal Commonsense Reasoning},\n",
       "   author={Edoardo M. Ponti, Goran Glava\\v{s}, Olga Majewska, Qianchu Liu, Ivan Vuli\\'{c} and Anna Korhonen},\n",
       "   journal={arXiv preprint},\n",
       "   year={2020},\n",
       "   url={https://ducdauge.github.io/files/xcopa.pdf}\n",
       " }\n",
       " \n",
       " @inproceedings{roemmele2011choice,\n",
       "   title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},\n",
       "   author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},\n",
       "   booktitle={2011 AAAI Spring Symposium Series},\n",
       "   year={2011},\n",
       "   url={https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['et', 'ht', 'id', 'it', 'qu', 'sw', 'ta', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'XCOPA', 'size_categories': ['unknown'], 'source_datasets': ['extended|copa'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa'], 'paperswithcode_id': 'xcopa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5365\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: xcopa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xcsr\n",
       " \tsha: 30535c5ee459c019900fa7a2540d2f9eace0f33a\n",
       " \tlastModified: 2022-09-28T07:54:46.000Z\n",
       " \ttags: ['arxiv:2106.06937', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language_creators:machine-generated', 'language:ar', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:ja', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sw', 'language:ur', 'language:vi', 'language:zh', 'license:mit', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:extended|codah', 'source_datasets:extended|commonsense_qa', 'task_categories:question-answering', 'task_ids:multiple-choice-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.\n",
       " \tcitation: # X-CSR\n",
       " @inproceedings{lin-etal-2021-common,\n",
       "     title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n",
       "     author = \"Lin, Bill Yuchen  and\n",
       "       Lee, Seyeon  and\n",
       "       Qiao, Xiaoyang  and\n",
       "       Ren, Xiang\",\n",
       "     booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n",
       "     month = aug,\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.acl-long.102\",\n",
       "     doi = \"10.18653/v1/2021.acl-long.102\",\n",
       "     pages = \"1274--1287\",\n",
       " }\n",
       " \n",
       " # CSQA\n",
       " @inproceedings{Talmor2019commonsenseqaaq,\n",
       "     address = {Minneapolis, Minnesota},\n",
       "     author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n",
       "     booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n",
       "     doi = {10.18653/v1/N19-1421},\n",
       "     pages = {4149--4158},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n",
       "     url = {https://www.aclweb.org/anthology/N19-1421},\n",
       "     year = {2019}\n",
       " }\n",
       " \n",
       " # CODAH\n",
       " @inproceedings{Chen2019CODAHAA,\n",
       "     address = {Minneapolis, USA},\n",
       "     author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n",
       "     booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n",
       "     doi = {10.18653/v1/W19-2008},\n",
       "     pages = {63--69},\n",
       "     publisher = {Association for Computational Linguistics},\n",
       "     title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n",
       "     url = {https://www.aclweb.org/anthology/W19-2008},\n",
       "     year = {2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced', 'machine-generated'], 'language': ['ar', 'de', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pl', 'pt', 'ru', 'sw', 'ur', 'vi', 'zh'], 'license': ['mit'], 'multilinguality': ['multilingual'], 'pretty_name': 'X-CSR', 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|codah', 'extended|commonsense_qa'], 'task_categories': ['question-answering'], 'task_ids': ['multiple-choice-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 5159\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xed_en_fi\n",
       " \tsha: 6d4671f8e77e3d612082bd3aba268bb2ff309245\n",
       " \tlastModified: 2022-07-01T11:57:39.000Z\n",
       " \ttags: ['arxiv:2011.01612', 'annotations_creators:expert-generated', 'language_creators:found', 'language:en', 'language:fi', 'license:cc-by-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'size_categories:1K<n<10K', 'source_datasets:extended|other-OpenSubtitles2016', 'task_categories:text-classification', 'task_ids:intent-classification', 'task_ids:multi-class-classification', 'task_ids:multi-label-classification', 'task_ids:sentiment-classification', 'configs:en_annotated', 'configs:en_neutral', 'configs:fi_annotated', 'configs:fi_neutral']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A multilingual fine-grained emotion dataset. The dataset consists of human annotated Finnish (25k) and English sentences (30k). Plutchik’s\n",
       " core emotions are used to annotate the dataset with the addition of neutral to create a multilabel multiclass\n",
       " dataset. The dataset is carefully evaluated using language-specific BERT models and SVMs to\n",
       " show that XED performs on par with other similar datasets and is therefore a useful tool for\n",
       " sentiment analysis and emotion detection.\n",
       " \tcitation: @inproceedings{ohman2020xed,\n",
       "   title={XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection},\n",
       "   author={{\\\"O}hman, Emily and P{\\\"a}mies, Marc and Kajava, Kaisla and Tiedemann, J{\\\"o}rg},\n",
       "   booktitle={The 28th International Conference on Computational Linguistics (COLING 2020)},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['en', 'fi'], 'license': ['cc-by-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K', '1K<n<10K'], 'source_datasets': ['extended|other-OpenSubtitles2016'], 'task_categories': ['text-classification'], 'task_ids': ['intent-classification', 'multi-class-classification', 'multi-label-classification', 'sentiment-classification'], 'paperswithcode_id': 'xed', 'pretty_name': 'XedEnglishFinnish', 'configs': ['en_annotated', 'en_neutral', 'fi_annotated', 'fi_neutral']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 875\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: xed\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xglue\n",
       " \tsha: 7b554667b2755f2c5c000376576a99f6e0f7fc2f\n",
       " \tlastModified: 2022-07-01T12:43:49.000Z\n",
       " \ttags: ['arxiv:1907.09190', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'annotations_creators:found', 'annotations_creators:machine-generated', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:found', 'language_creators:machine-generated', 'language:ar', 'language:bg', 'language:de', 'language:el', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'language:sw', 'language:th', 'language:tr', 'language:ur', 'language:vi', 'language:zh', 'license:cc-by-nc-4.0', 'license:cc-by-sa-4.0', 'license:other', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:100K<n<1M', 'size_categories:10K<n<100K', 'source_datasets:extended|conll2003', 'source_datasets:extended|squad', 'source_datasets:extended|xnli', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:summarization', 'task_categories:text-classification', 'task_categories:text2text-generation', 'task_categories:token-classification', 'task_ids:acceptability-classification', 'task_ids:extractive-qa', 'task_ids:named-entity-recognition', 'task_ids:natural-language-inference', 'task_ids:news-articles-headline-generation', 'task_ids:open-domain-qa', 'task_ids:parsing', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text2text-generation-other-question-answering', 'task_ids:topic-classification', 'configs:mlqa', 'configs:nc', 'configs:ner', 'configs:ntg', 'configs:paws-x', 'configs:pos', 'configs:qadsm', 'configs:qam', 'configs:qg', 'configs:wpr', 'configs:xnli']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: XGLUE is a new benchmark dataset to evaluate the performance of cross-lingual pre-trained\n",
       " models with respect to cross-lingual natural language understanding and generation.\n",
       " The benchmark is composed of the following 11 tasks:\n",
       " - NER\n",
       " - POS Tagging (POS)\n",
       " - News Classification (NC)\n",
       " - MLQA\n",
       " - XNLI\n",
       " - PAWS-X\n",
       " - Query-Ad Matching (QADSM)\n",
       " - Web Page Ranking (WPR)\n",
       " - QA Matching (QAM)\n",
       " - Question Generation (QG)\n",
       " - News Title Generation (NTG)\n",
       " \n",
       " For more information, please take a look at https://microsoft.github.io/XGLUE/.\n",
       " \tcitation: @article{Liang2020XGLUEAN,\n",
       "   title={XGLUE: A New Benchmark Dataset for Cross-lingual Pre-training, Understanding and Generation},\n",
       "   author={Yaobo Liang and Nan Duan and Yeyun Gong and Ning Wu and Fenfei Guo and Weizhen Qi\n",
       "   and Ming Gong and Linjun Shou and Daxin Jiang and Guihong Cao and Xiaodong Fan and Ruofei\n",
       "   Zhang and Rahul Agrawal and Edward Cui and Sining Wei and Taroon Bharti and Ying Qiao\n",
       "   and Jiun-Hung Chen and Winnie Wu and Shuguang Liu and Fan Yang and Daniel Campos\n",
       "   and Rangan Majumder and Ming Zhou},\n",
       "   journal={arXiv},\n",
       "   year={2020},\n",
       "   volume={abs/2004.01401}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced', 'expert-generated', 'found', 'machine-generated'], 'language_creators': ['crowdsourced', 'expert-generated', 'found', 'machine-generated'], 'language': ['ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'hi', 'it', 'nl', 'pl', 'pt', 'ru', 'sw', 'th', 'tr', 'ur', 'vi', 'zh'], 'license': ['cc-by-nc-4.0', 'cc-by-sa-4.0', 'other'], 'license_details': 'Licence Universal Dependencies v2.5', 'multilinguality': ['multilingual', 'translation'], 'size_categories': ['100K<n<1M', '10K<n<100K'], 'source_datasets': ['extended|conll2003', 'extended|squad', 'extended|xnli', 'original'], 'task_categories': ['question-answering', 'summarization', 'text-classification', 'text2text-generation', 'token-classification'], 'task_ids': ['acceptability-classification', 'extractive-qa', 'named-entity-recognition', 'natural-language-inference', 'news-articles-headline-generation', 'open-domain-qa', 'parsing', 'text-classification-other-paraphrase-identification', 'text2text-generation-other-question-answering', 'topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'XGLUE', 'configs': ['mlqa', 'nc', 'ner', 'ntg', 'paws-x', 'pos', 'qadsm', 'qam', 'qg', 'wpr', 'xnli']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2654\n",
       " \tlikes: 9\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xnli\n",
       " \tsha: 7075d70ac92f010a213a6abe1d80b6ecc516f271\n",
       " \tlastModified: 2022-07-01T11:57:39.000Z\n",
       " \ttags: ['language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: XNLI is a subset of a few thousand examples from MNLI which has been translated\n",
       " into a 14 different languages (some low-ish resource). As with MNLI, the goal is\n",
       " to predict textual entailment (does sentence A imply/contradict/neither sentence\n",
       " B) and is a classification task (given two sentences, predict one of three\n",
       " labels).\n",
       " \tcitation: @InProceedings{conneau2018xnli,\n",
       "   author = {Conneau, Alexis\n",
       "                  and Rinott, Ruty\n",
       "                  and Lample, Guillaume\n",
       "                  and Williams, Adina\n",
       "                  and Bowman, Samuel R.\n",
       "                  and Schwenk, Holger\n",
       "                  and Stoyanov, Veselin},\n",
       "   title = {XNLI: Evaluating Cross-lingual Sentence Representations},\n",
       "   booktitle = {Proceedings of the 2018 Conference on Empirical Methods\n",
       "                in Natural Language Processing},\n",
       "   year = {2018},\n",
       "   publisher = {Association for Computational Linguistics},\n",
       "   location = {Brussels, Belgium},\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': 'xnli', 'pretty_name': 'Cross-lingual Natural Language Inference'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 39296\n",
       " \tlikes: 8\n",
       " \tpaperswithcode_id: xnli\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xor_tydi_qa\n",
       " \tsha: e471d3ce48eb55ab25c709886b773fcfa3c8e94f\n",
       " \tlastModified: 2022-07-01T11:57:40.000Z\n",
       " \ttags: ['arxiv:2010.11856', 'annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language_creators:found', 'language:ar', 'language:bn', 'language:fi', 'language:ja', 'language:ko', 'language:ru', 'language:te', 'license:mit', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'source_datasets:extended|tydiqa', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription:     XOR-TyDi QA brings together for the first time information-seeking questions,\n",
       "     open-retrieval QA, and multilingual QA to create a multilingual open-retrieval\n",
       "     QA dataset that enables cross-lingual answer retrieval. It consists of questions\n",
       "     written by information-seeking native speakers in 7 typologically diverse languages\n",
       "     and answer annotations that are retrieved from multilingual document collections.\n",
       "     There are three sub-tasks: XOR-Retrieve, XOR-EnglishSpan, and XOR-Full.\n",
       " \tcitation:     @misc{asai2020xor,\n",
       "       title={XOR QA: Cross-lingual Open-Retrieval Question Answering},\n",
       "       author={Akari Asai and Jungo Kasai and Jonathan H. Clark and Kenton Lee and Eunsol Choi and Hannaneh Hajishirzi},\n",
       "       year={2020},\n",
       "       eprint={2010.11856},\n",
       "       archivePrefix={arXiv},\n",
       "       primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated', 'found'], 'language': ['ar', 'bn', 'fi', 'ja', 'ko', 'ru', 'te'], 'license': ['mit'], 'multilinguality': ['multilingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original', 'extended|tydiqa'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': 'xor-tydi-qa', 'pretty_name': 'XOR QA'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 481\n",
       " \tlikes: 0\n",
       " \tpaperswithcode_id: xor-tydi-qa\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xquad\n",
       " \tsha: b8a513536cc654a09c9e6efa21acb83fede8926c\n",
       " \tlastModified: 2022-10-12T14:39:18.000Z\n",
       " \ttags: ['arxiv:1910.11856', 'annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:ar', 'language:de', 'language:el', 'language:en', 'language:es', 'language:hi', 'language:ro', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:unknown', 'source_datasets:extended|squad', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\n",
       " performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\n",
       " of SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\n",
       " Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and Romanian. Consequently, the dataset is entirely parallel\n",
       " across 12 languages.\n",
       " \tcitation: @article{Artetxe:etal:2019,\n",
       "       author    = {Mikel Artetxe and Sebastian Ruder and Dani Yogatama},\n",
       "       title     = {On the cross-lingual transferability of monolingual representations},\n",
       "       journal   = {CoRR},\n",
       "       volume    = {abs/1910.11856},\n",
       "       year      = {2019},\n",
       "       archivePrefix = {arXiv},\n",
       "       eprint    = {1910.11856}\n",
       " }\n",
       " \tcardData: {'pretty_name': 'XQuAD', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['ar', 'de', 'el', 'en', 'es', 'hi', 'ro', 'ru', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['unknown'], 'source_datasets': ['extended|squad'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'xquad'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8075\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: xquad\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xquad_r\n",
       " \tsha: 7c90f15975b29d7b7fce2589b3ad342c88391edd\n",
       " \tlastModified: 2022-09-12T10:09:10.000Z\n",
       " \ttags: ['arxiv:2004.05484', 'annotations_creators:expert-generated', 'language_creators:found', 'language:ar', 'language:de', 'language:el', 'language:en', 'language:es', 'language:hi', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:1K<n<10K', 'source_datasets:extended|squad', 'source_datasets:extended|xquad', 'task_categories:question-answering', 'task_ids:extractive-qa', 'configs:ar', 'configs:de', 'configs:el', 'configs:en', 'configs:es', 'configs:hi', 'configs:ru', 'configs:th', 'configs:tr', 'configs:vi', 'configs:zh']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: XQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive QA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset, where each question appears in 11 different languages and has 11 parallel correct answers across the languages.\n",
       " \tcitation: @article{roy2020lareqa,\n",
       "   title={LAReQA: Language-agnostic answer retrieval from a multilingual pool},\n",
       "   author={Roy, Uma and Constant, Noah and Al-Rfou, Rami and Barua, Aditya and Phillips, Aaron and Yang, Yinfei},\n",
       "   journal={arXiv preprint arXiv:2004.05484},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['ar', 'de', 'el', 'en', 'es', 'hi', 'ru', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|squad', 'extended|xquad'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa'], 'paperswithcode_id': 'xquad-r', 'pretty_name': 'LAReQA', 'configs': ['ar', 'de', 'el', 'en', 'es', 'hi', 'ru', 'th', 'tr', 'vi', 'zh']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3000\n",
       " \tlikes: 2\n",
       " \tpaperswithcode_id: xquad-r\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xsum\n",
       " \tsha: 2632270098fd344a89de25f10a32dfab873b8118\n",
       " \tlastModified: 2022-08-26T04:42:19.000Z\n",
       " \ttags: ['arxiv:1808.08745', 'annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:summarization', 'task_ids:news-articles-summarization']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Extreme Summarization (XSum) Dataset.\n",
       " \n",
       " There are three features:\n",
       "   - document: Input news article.\n",
       "   - summary: One sentence summary of the article.\n",
       "   - id: BBC ID of the article.\n",
       " \tcitation: @article{Narayan2018DontGM,\n",
       "   title={Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},\n",
       "   author={Shashi Narayan and Shay B. Cohen and Mirella Lapata},\n",
       "   journal={ArXiv},\n",
       "   year={2018},\n",
       "   volume={abs/1808.08745}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Extreme Summarization (XSum)', 'paperswithcode_id': 'xsum', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['news-articles-summarization'], 'train-eval-index': [{'config': 'default', 'task': 'summarization', 'task_id': 'summarization', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'document': 'text', 'summary': 'target'}, 'metrics': [{'type': 'rouge', 'name': 'Rouge'}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 49038\n",
       " \tlikes: 10\n",
       " \tpaperswithcode_id: xsum\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xsum_factuality\n",
       " \tsha: 7f82d94f177648c5fae7acb8826d7f576049604f\n",
       " \tlastModified: 2022-07-01T11:57:43.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:extended|other-xsum', 'task_categories:summarization', 'task_ids:summarization-other-hallucinations']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Neural abstractive summarization models are highly prone to hallucinate content that is unfaithful to the input\n",
       " document. The popular metric such as ROUGE fails to show the severity of the problem. The dataset consists of\n",
       " faithfulness and factuality annotations of abstractive summaries for the XSum dataset. We have crowdsourced 3 judgements\n",
       "  for each of 500 x 5 document-system pairs. This will be a valuable resource to the abstractive summarization community.\n",
       " \tcitation: @InProceedings{maynez_acl20,\n",
       "   author =      \"Joshua Maynez and Shashi Narayan and Bernd Bohnet and Ryan Thomas Mcdonald\",\n",
       "   title =       \"On Faithfulness and Factuality in Abstractive Summarization\",\n",
       "   booktitle =   \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "   year =        \"2020\",\n",
       "   pages = \"1906--1919\",\n",
       "   address = \"Online\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['extended|other-xsum'], 'task_categories': ['summarization'], 'task_ids': ['summarization-other-hallucinations'], 'paperswithcode_id': None, 'pretty_name': 'XSum Hallucination Annotations'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 494\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: xtreme\n",
       " \tsha: 6b0a3c0f85526d903a6f009c8657d0cf26e2afa3\n",
       " \tlastModified: 2022-07-27T14:39:15.000Z\n",
       " \ttags: ['arxiv:2003.11080', 'annotations_creators:found', 'language_creators:found', 'language:af', 'language:ar', 'language:bg', 'language:bn', 'language:de', 'language:el', 'language:en', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fr', 'language:he', 'language:hi', 'language:hu', 'language:id', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:ko', 'language:ml', 'language:mr', 'language:ms', 'language:my', 'language:nl', 'language:pt', 'language:ru', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tl', 'language:tr', 'language:ur', 'language:vi', 'language:yo', 'language:zh', 'language_bcp47:fa-IR', 'license:apache-2.0', 'license:cc-by-4.0', 'license:cc-by-2.0', 'license:cc-by-sa-4.0', 'license:other', 'license:cc-by-nc-4.0', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:n<1K', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'source_datasets:extended|xnli', 'source_datasets:extended|paws-x', 'source_datasets:extended|wikiann', 'source_datasets:extended|xquad', 'source_datasets:extended|mlqa', 'source_datasets:extended|tydiqa', 'source_datasets:extended|tatoeba', 'source_datasets:extended|squad', 'task_categories:multiple-choice', 'task_categories:question-answering', 'task_categories:token-classification', 'task_categories:text-classification', 'task_categories:text-retrieval', 'task_ids:multiple-choice-qa', 'task_ids:extractive-qa', 'task_ids:open-domain-qa', 'task_ids:natural-language-inference', 'task_ids:text-classification-other-paraphrase-identification', 'task_ids:text-retrieval-other-parallel-sentence-retrieval', 'task_ids:named-entity-recognition', 'task_ids:part-of-speech', 'configs:MLQA.ar.ar', 'configs:MLQA.ar.de', 'configs:MLQA.ar.en', 'configs:MLQA.ar.es', 'configs:MLQA.ar.hi', 'configs:MLQA.ar.vi', 'configs:MLQA.ar.zh', 'configs:MLQA.de.ar', 'configs:MLQA.de.de', 'configs:MLQA.de.en', 'configs:MLQA.de.es', 'configs:MLQA.de.hi', 'configs:MLQA.de.vi', 'configs:MLQA.de.zh', 'configs:MLQA.en.ar', 'configs:MLQA.en.de', 'configs:MLQA.en.en', 'configs:MLQA.en.es', 'configs:MLQA.en.hi', 'configs:MLQA.en.vi', 'configs:MLQA.en.zh', 'configs:MLQA.es.ar', 'configs:MLQA.es.de', 'configs:MLQA.es.en', 'configs:MLQA.es.es', 'configs:MLQA.es.hi', 'configs:MLQA.es.vi', 'configs:MLQA.es.zh', 'configs:MLQA.hi.ar', 'configs:MLQA.hi.de', 'configs:MLQA.hi.en', 'configs:MLQA.hi.es', 'configs:MLQA.hi.hi', 'configs:MLQA.hi.vi', 'configs:MLQA.hi.zh', 'configs:MLQA.vi.ar', 'configs:MLQA.vi.de', 'configs:MLQA.vi.en', 'configs:MLQA.vi.es', 'configs:MLQA.vi.hi', 'configs:MLQA.vi.vi', 'configs:MLQA.vi.zh', 'configs:MLQA.zh.ar', 'configs:MLQA.zh.de', 'configs:MLQA.zh.en', 'configs:MLQA.zh.es', 'configs:MLQA.zh.hi', 'configs:MLQA.zh.vi', 'configs:MLQA.zh.zh', 'configs:PAN-X.af', 'configs:PAN-X.ar', 'configs:PAN-X.bg', 'configs:PAN-X.bn', 'configs:PAN-X.de', 'configs:PAN-X.el', 'configs:PAN-X.en', 'configs:PAN-X.es', 'configs:PAN-X.et', 'configs:PAN-X.eu', 'configs:PAN-X.fa', 'configs:PAN-X.fi', 'configs:PAN-X.fr', 'configs:PAN-X.he', 'configs:PAN-X.hi', 'configs:PAN-X.hu', 'configs:PAN-X.id', 'configs:PAN-X.it', 'configs:PAN-X.ja', 'configs:PAN-X.jv', 'configs:PAN-X.ka', 'configs:PAN-X.kk', 'configs:PAN-X.ko', 'configs:PAN-X.ml', 'configs:PAN-X.mr', 'configs:PAN-X.ms', 'configs:PAN-X.my', 'configs:PAN-X.nl', 'configs:PAN-X.pt', 'configs:PAN-X.ru', 'configs:PAN-X.sw', 'configs:PAN-X.ta', 'configs:PAN-X.te', 'configs:PAN-X.th', 'configs:PAN-X.tl', 'configs:PAN-X.tr', 'configs:PAN-X.ur', 'configs:PAN-X.vi', 'configs:PAN-X.yo', 'configs:PAN-X.zh', 'configs:PAWS-X.de', 'configs:PAWS-X.en', 'configs:PAWS-X.es', 'configs:PAWS-X.fr', 'configs:PAWS-X.ja', 'configs:PAWS-X.ko', 'configs:PAWS-X.zh', 'configs:SQuAD', 'configs:XNLI', 'configs:XQuAD', 'configs:bucc18.de', 'configs:bucc18.fr', 'configs:bucc18.ru', 'configs:bucc18.zh', 'configs:tatoeba.afr', 'configs:tatoeba.ara', 'configs:tatoeba.ben', 'configs:tatoeba.bul', 'configs:tatoeba.cmn', 'configs:tatoeba.deu', 'configs:tatoeba.ell', 'configs:tatoeba.est', 'configs:tatoeba.eus', 'configs:tatoeba.fin', 'configs:tatoeba.fra', 'configs:tatoeba.heb', 'configs:tatoeba.hin', 'configs:tatoeba.hun', 'configs:tatoeba.ind', 'configs:tatoeba.ita', 'configs:tatoeba.jav', 'configs:tatoeba.jpn', 'configs:tatoeba.kat', 'configs:tatoeba.kaz', 'configs:tatoeba.kor', 'configs:tatoeba.mal', 'configs:tatoeba.mar', 'configs:tatoeba.nld', 'configs:tatoeba.pes', 'configs:tatoeba.por', 'configs:tatoeba.rus', 'configs:tatoeba.spa', 'configs:tatoeba.swh', 'configs:tatoeba.tam', 'configs:tatoeba.tel', 'configs:tatoeba.tgl', 'configs:tatoeba.tha', 'configs:tatoeba.tur', 'configs:tatoeba.urd', 'configs:tatoeba.vie', 'configs:tydiqa', 'configs:udpos.Afrikans', 'configs:udpos.Arabic', 'configs:udpos.Basque', 'configs:udpos.Bulgarian', 'configs:udpos.Chinese', 'configs:udpos.Dutch', 'configs:udpos.English', 'configs:udpos.Estonian', 'configs:udpos.Finnish', 'configs:udpos.French', 'configs:udpos.German', 'configs:udpos.Greek', 'configs:udpos.Hebrew', 'configs:udpos.Hindi', 'configs:udpos.Hungarian', 'configs:udpos.Indonesian', 'configs:udpos.Italian', 'configs:udpos.Japanese', 'configs:udpos.Kazakh', 'configs:udpos.Korean', 'configs:udpos.Marathi', 'configs:udpos.Persian', 'configs:udpos.Portuguese', 'configs:udpos.Russian', 'configs:udpos.Spanish', 'configs:udpos.Tagalog', 'configs:udpos.Tamil', 'configs:udpos.Telugu', 'configs:udpos.Thai', 'configs:udpos.Turkish', 'configs:udpos.Urdu', 'configs:udpos.Vietnamese', 'configs:udpos.Yoruba']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark is a benchmark for the evaluation of\n",
       " the cross-lingual generalization ability of pre-trained multilingual models. It covers 40 typologically diverse languages\n",
       " (spanning 12 language families) and includes nine tasks that collectively require reasoning about different levels of\n",
       " syntax and semantics. The languages in XTREME are selected to maximize language diversity, coverage in existing tasks,\n",
       " and availability of training data. Among these are many under-studied languages, such as the Dravidian languages Tamil\n",
       " (spoken in southern India, Sri Lanka, and Singapore), Telugu and Malayalam (spoken mainly in southern India), and the\n",
       " Niger-Congo languages Swahili and Yoruba, spoken in Africa.\n",
       " \tcitation: @article{hu2020xtreme,\n",
       "       author    = {Junjie Hu and Sebastian Ruder and Aditya Siddhant and Graham Neubig and Orhan Firat and Melvin Johnson},\n",
       "       title     = {XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization},\n",
       "       journal   = {CoRR},\n",
       "       volume    = {abs/2003.11080},\n",
       "       year      = {2020},\n",
       "       archivePrefix = {arXiv},\n",
       "       eprint    = {2003.11080}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh'], 'language_bcp47': ['fa-IR'], 'license': ['apache-2.0', 'cc-by-4.0', 'cc-by-2.0', 'cc-by-sa-4.0', 'other', 'cc-by-nc-4.0'], 'license_details': 'Licence Universal Dependencies v2.5', 'multilinguality': ['multilingual', 'translation'], 'pretty_name': 'XTREME', 'size_categories': ['n<1K', '1K<n<10K', '10K<n<100K', '100K<n<1M'], 'source_datasets': ['extended|xnli', 'extended|paws-x', 'extended|wikiann', 'extended|xquad', 'extended|mlqa', 'extended|tydiqa', 'extended|tatoeba', 'extended|squad'], 'task_categories': ['multiple-choice', 'question-answering', 'token-classification', 'text-classification', 'text-retrieval', 'token-classification'], 'task_ids': ['multiple-choice-qa', 'extractive-qa', 'open-domain-qa', 'natural-language-inference', 'text-classification-other-paraphrase-identification', 'text-retrieval-other-parallel-sentence-retrieval', 'named-entity-recognition', 'part-of-speech'], 'paperswithcode_id': 'xtreme', 'configs': ['MLQA.ar.ar', 'MLQA.ar.de', 'MLQA.ar.en', 'MLQA.ar.es', 'MLQA.ar.hi', 'MLQA.ar.vi', 'MLQA.ar.zh', 'MLQA.de.ar', 'MLQA.de.de', 'MLQA.de.en', 'MLQA.de.es', 'MLQA.de.hi', 'MLQA.de.vi', 'MLQA.de.zh', 'MLQA.en.ar', 'MLQA.en.de', 'MLQA.en.en', 'MLQA.en.es', 'MLQA.en.hi', 'MLQA.en.vi', 'MLQA.en.zh', 'MLQA.es.ar', 'MLQA.es.de', 'MLQA.es.en', 'MLQA.es.es', 'MLQA.es.hi', 'MLQA.es.vi', 'MLQA.es.zh', 'MLQA.hi.ar', 'MLQA.hi.de', 'MLQA.hi.en', 'MLQA.hi.es', 'MLQA.hi.hi', 'MLQA.hi.vi', 'MLQA.hi.zh', 'MLQA.vi.ar', 'MLQA.vi.de', 'MLQA.vi.en', 'MLQA.vi.es', 'MLQA.vi.hi', 'MLQA.vi.vi', 'MLQA.vi.zh', 'MLQA.zh.ar', 'MLQA.zh.de', 'MLQA.zh.en', 'MLQA.zh.es', 'MLQA.zh.hi', 'MLQA.zh.vi', 'MLQA.zh.zh', 'PAN-X.af', 'PAN-X.ar', 'PAN-X.bg', 'PAN-X.bn', 'PAN-X.de', 'PAN-X.el', 'PAN-X.en', 'PAN-X.es', 'PAN-X.et', 'PAN-X.eu', 'PAN-X.fa', 'PAN-X.fi', 'PAN-X.fr', 'PAN-X.he', 'PAN-X.hi', 'PAN-X.hu', 'PAN-X.id', 'PAN-X.it', 'PAN-X.ja', 'PAN-X.jv', 'PAN-X.ka', 'PAN-X.kk', 'PAN-X.ko', 'PAN-X.ml', 'PAN-X.mr', 'PAN-X.ms', 'PAN-X.my', 'PAN-X.nl', 'PAN-X.pt', 'PAN-X.ru', 'PAN-X.sw', 'PAN-X.ta', 'PAN-X.te', 'PAN-X.th', 'PAN-X.tl', 'PAN-X.tr', 'PAN-X.ur', 'PAN-X.vi', 'PAN-X.yo', 'PAN-X.zh', 'PAWS-X.de', 'PAWS-X.en', 'PAWS-X.es', 'PAWS-X.fr', 'PAWS-X.ja', 'PAWS-X.ko', 'PAWS-X.zh', 'SQuAD', 'XNLI', 'XQuAD', 'bucc18.de', 'bucc18.fr', 'bucc18.ru', 'bucc18.zh', 'tatoeba.afr', 'tatoeba.ara', 'tatoeba.ben', 'tatoeba.bul', 'tatoeba.cmn', 'tatoeba.deu', 'tatoeba.ell', 'tatoeba.est', 'tatoeba.eus', 'tatoeba.fin', 'tatoeba.fra', 'tatoeba.heb', 'tatoeba.hin', 'tatoeba.hun', 'tatoeba.ind', 'tatoeba.ita', 'tatoeba.jav', 'tatoeba.jpn', 'tatoeba.kat', 'tatoeba.kaz', 'tatoeba.kor', 'tatoeba.mal', 'tatoeba.mar', 'tatoeba.nld', 'tatoeba.pes', 'tatoeba.por', 'tatoeba.rus', 'tatoeba.spa', 'tatoeba.swh', 'tatoeba.tam', 'tatoeba.tel', 'tatoeba.tgl', 'tatoeba.tha', 'tatoeba.tur', 'tatoeba.urd', 'tatoeba.vie', 'tydiqa', 'udpos.Afrikans', 'udpos.Arabic', 'udpos.Basque', 'udpos.Bulgarian', 'udpos.Chinese', 'udpos.Dutch', 'udpos.English', 'udpos.Estonian', 'udpos.Finnish', 'udpos.French', 'udpos.German', 'udpos.Greek', 'udpos.Hebrew', 'udpos.Hindi', 'udpos.Hungarian', 'udpos.Indonesian', 'udpos.Italian', 'udpos.Japanese', 'udpos.Kazakh', 'udpos.Korean', 'udpos.Marathi', 'udpos.Persian', 'udpos.Portuguese', 'udpos.Russian', 'udpos.Spanish', 'udpos.Tagalog', 'udpos.Tamil', 'udpos.Telugu', 'udpos.Thai', 'udpos.Turkish', 'udpos.Urdu', 'udpos.Vietnamese', 'udpos.Yoruba']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 38709\n",
       " \tlikes: 12\n",
       " \tpaperswithcode_id: xtreme\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yahoo_answers_qa\n",
       " \tsha: 7379d20224e23c43aa533ae7e5aafc1f1505c9c1\n",
       " \tlastModified: 2022-08-11T12:57:55.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:extended|other-yahoo-webscope-l6', 'task_categories:question-answering', 'task_ids:open-domain-qa']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Yahoo Non-Factoid Question Dataset is derived from Yahoo's Webscope L6 collection using machine learning techiques such that the questions would contain non-factoid answers.The dataset contains 87,361 questions and their corresponding answers. Each question contains its best answer along with additional other answers submitted by users. Only the best answer was reviewed in determining the quality of the question-answer pair.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['extended|other-yahoo-webscope-l6'], 'task_categories': ['question-answering'], 'task_ids': ['open-domain-qa'], 'paperswithcode_id': None, 'pretty_name': 'YahooAnswersQa'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 523\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yahoo_answers_topics\n",
       " \tsha: 9920ecb23536ba745fd3e5b23177c450aa01df89\n",
       " \tlastModified: 2022-07-01T11:57:45.000Z\n",
       " \ttags: ['annotations_creators:found', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:extended|other-yahoo-answers-corpus', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Yahoo! Answers Topic Classification is text classification dataset. The dataset is the Yahoo! Answers corpus as of 10/25/2007. The Yahoo! Answers topic classification dataset is constructed using 10 largest main categories. From all the answers and other meta-information, this dataset only used the best answer content and the main category information.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['extended|other-yahoo-answers-corpus'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'YahooAnswersTopics', 'train-eval-index': [{'config': 'yahoo_answers_topics', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'question_content': 'text', 'topic': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 3030\n",
       " \tlikes: 8\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yelp_polarity\n",
       " \tsha: 5b9b89ca177500ecea301322d8f19786178930b8\n",
       " \tlastModified: 2022-07-01T11:57:46.000Z\n",
       " \ttags: ['arxiv:1509.01626', 'language:en']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Large Yelp Review Dataset.\n",
       " This is a dataset for binary sentiment classification. We provide a set of 560,000 highly polar yelp reviews for training, and 38,000 for testing. \n",
       " ORIGIN\n",
       " The Yelp reviews dataset consists of reviews from Yelp. It is extracted\n",
       " from the Yelp Dataset Challenge 2015 data. For more information, please\n",
       " refer to http://www.yelp.com/dataset_challenge\n",
       " \n",
       " The Yelp reviews polarity dataset is constructed by\n",
       " Xiang Zhang (xiang.zhang@nyu.edu) from the above dataset.\n",
       " It is first used as a text classification benchmark in the following paper:\n",
       " Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks\n",
       " for Text Classification. Advances in Neural Information Processing Systems 28\n",
       " (NIPS 2015).\n",
       " \n",
       " \n",
       " DESCRIPTION\n",
       " \n",
       " The Yelp reviews polarity dataset is constructed by considering stars 1 and 2\n",
       " negative, and 3 and 4 positive. For each polarity 280,000 training samples and\n",
       " 19,000 testing samples are take randomly. In total there are 560,000 trainig\n",
       " samples and 38,000 testing samples. Negative polarity is class 1,\n",
       " and positive class 2.\n",
       " \n",
       " The files train.csv and test.csv contain all the training samples as\n",
       " comma-sparated values. There are 2 columns in them, corresponding to class\n",
       " index (1 and 2) and review text. The review texts are escaped using double\n",
       " quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\").\n",
       " New lines are escaped by a backslash followed with an \"n\" character,\n",
       " that is \"\\n\".\n",
       " \tcitation: @article{zhangCharacterlevelConvolutionalNetworks2015,\n",
       "   archivePrefix = {arXiv},\n",
       "   eprinttype = {arxiv},\n",
       "   eprint = {1509.01626},\n",
       "   primaryClass = {cs},\n",
       "   title = {Character-Level {{Convolutional Networks}} for {{Text Classification}}},\n",
       "   abstract = {This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.},\n",
       "   journal = {arXiv:1509.01626 [cs]},\n",
       "   author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},\n",
       "   month = sep,\n",
       "   year = {2015},\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'paperswithcode_id': None, 'pretty_name': 'YelpPolarity', 'train-eval-index': [{'config': 'plain_text', 'task': 'text-classification', 'task_id': 'binary_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 binary', 'args': {'average': 'binary'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8479\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yelp_review_full\n",
       " \tsha: f9bdab7084ddf884342133a4374489699eeb745a\n",
       " \tlastModified: 2022-07-01T12:43:50.000Z\n",
       " \ttags: ['arxiv:1509.01626', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:other', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Yelp reviews dataset consists of reviews from Yelp. It is extracted from the Yelp Dataset Challenge 2015 data.\n",
       " The Yelp reviews full star dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the above dataset.\n",
       " It is first used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun.\n",
       " Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\n",
       " \tcitation: @inproceedings{zhang2015character,\n",
       "   title={Character-level convolutional networks for text classification},\n",
       "   author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},\n",
       "   booktitle={Advances in neural information processing systems},\n",
       "   pages={649--657},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['other'], 'license_details': 'yelp-licence', 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'YelpReviewFull', 'train-eval-index': [{'config': 'yelp_review_full', 'task': 'text-classification', 'task_id': 'multi_class_classification', 'splits': {'train_split': 'train', 'eval_split': 'test'}, 'col_mapping': {'text': 'text', 'label': 'target'}, 'metrics': [{'type': 'accuracy', 'name': 'Accuracy'}, {'type': 'f1', 'name': 'F1 macro', 'args': {'average': 'macro'}}, {'type': 'f1', 'name': 'F1 micro', 'args': {'average': 'micro'}}, {'type': 'f1', 'name': 'F1 weighted', 'args': {'average': 'weighted'}}, {'type': 'precision', 'name': 'Precision macro', 'args': {'average': 'macro'}}, {'type': 'precision', 'name': 'Precision micro', 'args': {'average': 'micro'}}, {'type': 'precision', 'name': 'Precision weighted', 'args': {'average': 'weighted'}}, {'type': 'recall', 'name': 'Recall macro', 'args': {'average': 'macro'}}, {'type': 'recall', 'name': 'Recall micro', 'args': {'average': 'micro'}}, {'type': 'recall', 'name': 'Recall weighted', 'args': {'average': 'weighted'}}]}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 35293\n",
       " \tlikes: 9\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yoruba_bbc_topics\n",
       " \tsha: 1f1758459e98852f9d22387c732c4aee3022628b\n",
       " \tlastModified: 2022-07-01T11:57:47.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:yo', 'license:unknown', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:topic-classification']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A collection of news article headlines in Yoruba from BBC Yoruba.\n",
       " Each headline is labeled with one of the following classes: africa,\n",
       " entertainment, health, nigeria, politics, sport or world.\n",
       " \n",
       " The dataset was presented in the paper:\n",
       " Hedderich, Adelani, Zhu, Alabi, Markus, Klakow: Transfer Learning and\n",
       " Distant Supervision for Multilingual Transformer Models: A Study on\n",
       " African Languages (EMNLP 2020).\n",
       " \tcitation: @inproceedings{hedderich-etal-2020-transfer,\n",
       "     title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages\",\n",
       "     author = \"Hedderich, Michael A.  and\n",
       "       Adelani, David  and\n",
       "       Zhu, Dawei  and\n",
       "       Alabi, Jesujoba  and\n",
       "       Markus, Udia  and\n",
       "       Klakow, Dietrich\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n",
       "     doi = \"10.18653/v1/2020.emnlp-main.204\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['yo'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['topic-classification'], 'paperswithcode_id': None, 'pretty_name': 'Yoruba Bbc News Topic Classification Dataset (YorubaBbcTopics)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yoruba_gv_ner\n",
       " \tsha: 4c56d87604a551075195f1156e09b693c6c7f695\n",
       " \tlastModified: 2022-07-01T12:43:51.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:yo', 'license:cc-by-3.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:token-classification', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: The Yoruba GV NER dataset is a labeled dataset for named entity recognition in Yoruba. The texts were obtained from\n",
       " Yoruba Global Voices News articles https://yo.globalvoices.org/ . We concentrate on\n",
       " four types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n",
       " \n",
       " The Yoruba GV NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\n",
       " there is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\n",
       " is the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\n",
       " of type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\n",
       " have tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n",
       " \n",
       " For more details, see https://www.aclweb.org/anthology/2020.lrec-1.335/\n",
       " \tcitation: @inproceedings{alabi-etal-2020-massive,\n",
       "     title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Yorùbá} and {T}wi\",\n",
       "     author = \"Alabi, Jesujoba  and\n",
       "       Amponsah-Kaakyire, Kwabena  and\n",
       "       Adelani, David  and\n",
       "       Espa{\\\\~n}a-Bonet, Cristina\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n",
       "     pages = \"2754--2762\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['yo'], 'license': ['cc-by-3.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['token-classification'], 'task_ids': ['named-entity-recognition'], 'paperswithcode_id': None, 'pretty_name': 'Yoruba GV NER Corpus'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yoruba_text_c3\n",
       " \tsha: 1df7b9ec411ebf08c04d7aa43e534f1e9dec580b\n",
       " \tlastModified: 2022-07-01T11:57:47.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:yo', 'license:cc-by-nc-4.0', 'multilinguality:monolingual', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:language-modeling', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Yoruba Text C3 is the largest Yoruba texts collected and used to train FastText embeddings in the\n",
       " YorubaTwi Embedding paper: https://www.aclweb.org/anthology/2020.lrec-1.335/\n",
       " \tcitation: @inproceedings{alabi-etal-2020-massive,\n",
       "     title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of Yoruba and {T}wi\",\n",
       "     author = \"Alabi, Jesujoba  and\n",
       "       Amponsah-Kaakyire, Kwabena  and\n",
       "       Adelani, David  and\n",
       "       Espa{\\\\~n}a-Bonet, Cristina\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n",
       "     pages = \"2754--2762\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['yo'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['text-generation', 'fill-mask'], 'task_ids': ['language-modeling', 'masked-language-modeling'], 'paperswithcode_id': None, 'pretty_name': 'Yorùbá Text C3'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: yoruba_wordsim353\n",
       " \tsha: 4954ec2050c67d93ca43cbc514644532b9c76f72\n",
       " \tlastModified: 2022-07-01T11:57:49.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:expert-generated', 'language:en', 'language:yo', 'license:unknown', 'multilinguality:multilingual', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-scoring', 'task_ids:semantic-similarity-scoring']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: A translation of the word pair similarity dataset wordsim-353 to Yorùbá.\n",
       " \n",
       " The dataset was presented in the paper\n",
       " Alabi et al.: Massive vs. Curated Embeddings for Low-Resourced\n",
       " Languages: the Case of Yorùbá and Twi (LREC 2020).\n",
       " \tcitation: @inproceedings{alabi-etal-2020-massive,\n",
       "     title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Y}or{\\\\`u}b{\\\\'a} and {T}wi\",\n",
       "     author = \"Alabi, Jesujoba  and\n",
       "       Amponsah-Kaakyire, Kwabena  and\n",
       "       Adelani, David  and\n",
       "       Espa{\\\\~n}a-Bonet, Cristina\",\n",
       "     booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n",
       "     month = may,\n",
       "     year = \"2020\",\n",
       "     address = \"Marseille, France\",\n",
       "     publisher = \"European Language Resources Association\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n",
       "     pages = \"2754--2762\",\n",
       "     language = \"English\",\n",
       "     ISBN = \"979-10-95546-34-4\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['expert-generated'], 'language': ['en', 'yo'], 'license': ['unknown'], 'multilinguality': ['multilingual'], 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-scoring', 'semantic-similarity-scoring'], 'paperswithcode_id': None, 'pretty_name': 'Wordsim-353 In Yorùbá (YorubaWordsim353)'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: youtube_caption_corrections\n",
       " \tsha: 3dfe779ed1ed551fb24a58948937fb224479f06a\n",
       " \tlastModified: 2022-07-01T11:57:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:other', 'task_categories:text-generation', 'task_categories:fill-mask', 'task_ids:other-other-token-classification-of-text-errors', 'task_ids:slot-filling']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: Dataset built from pairs of YouTube captions where both 'auto-generated' and\n",
       " 'manually-corrected' captions are available for a single specified language.\n",
       " This dataset labels two-way (e.g. ignoring single-sided insertions) same-length\n",
       " token differences in the `diff_type` column. The `default_seq` is composed of\n",
       " tokens from the 'auto-generated' captions. When a difference occurs between\n",
       " the 'auto-generated' vs 'manually-corrected' captions types, the `correction_seq`\n",
       " contains tokens from the 'manually-corrected' captions.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated', 'machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['other', 'text-generation', 'fill-mask'], 'task_ids': ['other-other-token-classification-of-text-errors', 'slot-filling'], 'paperswithcode_id': None, 'pretty_name': 'YouTube Caption Corrections'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: zest\n",
       " \tsha: 45e40f2f4de79ab8a2d66ccf8f9189bc3ef11796\n",
       " \tlastModified: 2022-07-01T11:57:50.000Z\n",
       " \ttags: ['arxiv:2011.08115', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:token-classification', 'task_ids:closed-domain-qa', 'task_ids:extractive-qa', 'task_ids:question-answering-other-yes-no-qa', 'task_ids:token-classification-other-output-structure']\n",
       " \tprivate: False\n",
       " \tauthor: None\n",
       " \tdescription: ZEST tests whether NLP systems can perform unseen tasks in a zero-shot way, given a natural language description of\n",
       " the task. It is an instantiation of our proposed framework \"learning from task descriptions\". The tasks include\n",
       " classification, typed entity extraction and relationship extraction, and each task is paired with 20 different\n",
       " annotated (input, output) examples. ZEST's structure allows us to systematically test whether models can generalize\n",
       " in five different ways.\n",
       " \tcitation: @inproceedings{weller-etal-2020-learning,\n",
       "     title = \"Learning from Task Descriptions\",\n",
       "     author = \"Weller, Orion  and\n",
       "       Lourie, Nicholas  and\n",
       "       Gardner, Matt  and\n",
       "       Peters, Matthew\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.105\",\n",
       "     pages = \"1361--1375\",\n",
       "     abstract = \"Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this frame- work with a new English language dataset, ZEST, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model{'}s ability to solve each task. Moreover, the dataset{'}s structure tests specific types of systematic generalization. We find that the state-of-the-art T5 model achieves a score of 12% on ZEST, leaving a significant challenge for NLP researchers.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'token-classification'], 'task_ids': ['closed-domain-qa', 'extractive-qa', 'question-answering-other-yes-no-qa', 'token-classification-other-output-structure'], 'paperswithcode_id': 'zest', 'pretty_name': 'ZEST'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 536\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: zest\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: 0n1xus/codexglue\n",
       " \tsha: e4604616235cdfa7398d489ba1f95d44a18d2f5d\n",
       " \tlastModified: 2021-11-18T08:45:46.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: 0n1xus\n",
       " \tdescription: CodeXGLUE is a benchmark dataset to foster machine learning research for program understanding and generation. \n",
       " CodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison.\n",
       " \tcitation: @article{Lu2021,\n",
       " author = {Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin B. and Drain, Dawn and Jiang, Daxin and Tang, Duyu and Li, Ge and Zhou, Lidong and Shou, Linjun and Zhou, Long and Tufano, Michele and Gong, Ming and Zhou, Ming and Duan, Nan and Sundaresan, Neel and Deng, Shao Kun and Fu, Shengyu and Liu, Shujie},\n",
       " year = {2021},\n",
       " booktitle = {arXiv},\n",
       " title = {CodeXGLUE - A Machine Learning Benchmark Dataset for Code Understanding and Generation}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 501\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: 0n1xus/pytorrent-standalone\n",
       " \tsha: 49b5f32829ffe8a88b67accac51d0512bc8a8f3b\n",
       " \tlastModified: 2021-12-02T06:13:15.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: 0n1xus\n",
       " \tdescription: pytorrent-standalone is a subset of the PyTorrent dataset, where only functions that does not depend on external libraries\n",
       " are kept.\n",
       " \tcitation: @article{Bahrami2021,\n",
       " author = {Bahrami, Mehdi and Shrikanth, N. C. and Ruangwan, Shade and Liu, Lei and Mizobuchi, Yuji and Fukuyori, Masahiro and Chen, Wei-Peng and Munakata, Kazuki and Menzies, Tim},\n",
       " year = {2021},\n",
       " journal = {arXiv},\n",
       " title = {PyTorrent: A Python Library Corpus for Large-scale Language Models}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AConsApart/anime_subtitles_DialoGPT\n",
       " \tsha: 4ec53f6fdadf8f87839ede82253149941581afcd\n",
       " \tlastModified: 2021-03-06T02:31:23.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AConsApart\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 172\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AHussain0418/day2_data\n",
       " \tsha: 0971c64036fb445cf3ad7eb6a103e9573bb2c649\n",
       " \tlastModified: 2022-01-05T18:16:53.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AHussain0418\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AHussain0418/day4data\n",
       " \tsha: 7cc5438c2ff33afea0c376162eaa3395b71a43fc\n",
       " \tlastModified: 2022-01-07T16:26:39.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AHussain0418\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AHussain0418/demo_data\n",
       " \tsha: 5b51c939d5c60ce0abd467849a0acb62d41ed8db\n",
       " \tlastModified: 2022-01-06T02:46:54.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AHussain0418\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AI-Sweden/SuperLim\n",
       " \tsha: bbe3044c8072ab2be55b19c2ebe468048075ebcc\n",
       " \tlastModified: 2022-03-03T10:30:23.000Z\n",
       " \ttags: ['languages:sv', 'multilinguality:monolingual', 'pretty_name:SuperLim', 'task_categories:question-answering', 'task_categories:text-classification', 'task_categories:sequence-modeling', 'task_categories:other']\n",
       " \tprivate: False\n",
       " \tauthor: AI-Sweden\n",
       " \tdescription: \\\n",
       " \tcitation: \\\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the online tagging app': 'https://huggingface.co/spaces/huggingface/datasets-tagging'}], 'languages': ['sv'], 'multilinguality': ['monolingual'], 'pretty_name': 'SuperLim', 'task_categories': ['question-answering', 'text-classification', 'sequence-modeling', 'other']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2032\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AI-it/khs_service_test\n",
       " \tsha: 3028b5bc556a1efbfbf2cef20c2dafe1eeb8d0e4\n",
       " \tlastModified: 2021-12-20T15:58:13.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AI-it\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: True\n",
       " \tdownloads: 14\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AI-it/korean-hate-speech\n",
       " \tsha: d58b8fc80437cfcbc56d5c4e07f8d2e2dd992787\n",
       " \tlastModified: 2021-12-20T03:00:00.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AI-it\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: True\n",
       " \tdownloads: 15\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ARKseal/YFCC14M_subset_webdataset\n",
       " \tsha: 9485c1cbaa12d0b1244d653dec04996947a974d1\n",
       " \tlastModified: 2021-11-27T22:47:47.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: ARKseal\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ARTeLab/fanpage\n",
       " \tsha: c8fe14be8fa86f2324ba3fdf22e79e511e1c0147\n",
       " \tlastModified: 2022-07-01T15:35:47.000Z\n",
       " \ttags: ['language:it', 'license:unknown', 'multilinguality:monolingual', 'size_categories:10K<n<100k', 'source_datasets:original', 'task_categories:summarization', 'task_ids:summarization']\n",
       " \tprivate: False\n",
       " \tauthor: ARTeLab\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['it'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100k'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['summarization']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 406\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ARTeLab/ilpost\n",
       " \tsha: 0242060d39b0ea1d5862026ab6eccf590aab604e\n",
       " \tlastModified: 2022-05-03T06:09:20.000Z\n",
       " \ttags: ['languages:it', 'multilinguality:monolingual', 'size_categories:10K<n<100k', 'task_categories:summarization', 'task_ids:summarization']\n",
       " \tprivate: False\n",
       " \tauthor: ARTeLab\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'languages': ['it'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100k'], 'task_categories': ['summarization'], 'task_ids': ['summarization']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ARTeLab/mlsum-it\n",
       " \tsha: 7f702158d25dca9e420a28b8249586d9bdabccf9\n",
       " \tlastModified: 2022-05-03T06:09:05.000Z\n",
       " \ttags: ['languages:it', 'multilinguality:monolingual', 'size_categories:10K<n<100k', 'task_categories:summarization', 'task_ids:summarization']\n",
       " \tprivate: False\n",
       " \tauthor: ARTeLab\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'languages': ['it'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100k'], 'task_categories': ['summarization'], 'task_ids': ['summarization']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ASCCCCCCCC/amazon_zh\n",
       " \tsha: f37c573d8d99bd0eff5c547282b990db5bc7a20e\n",
       " \tlastModified: 2022-02-17T02:16:59.000Z\n",
       " \ttags: ['license:apache-2.0']\n",
       " \tprivate: False\n",
       " \tauthor: ASCCCCCCCC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'license': 'apache-2.0'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ASCCCCCCCC/amazon_zh_simple\n",
       " \tsha: 14059f8980b8e8bc298293d160293d7ce6752c92\n",
       " \tlastModified: 2022-02-22T01:37:48.000Z\n",
       " \ttags: ['license:apache-2.0']\n",
       " \tprivate: False\n",
       " \tauthor: ASCCCCCCCC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'license': 'apache-2.0'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abdo1Kamr/Arabic_Hadith\n",
       " \tsha: 7af49f85461104c4e7172a55659d09ca423cd160\n",
       " \tlastModified: 2021-08-21T12:40:44.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Abdo1Kamr\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abirate/code_net_dataset\n",
       " \tsha: 6d7f48e0a6b9939fcb951c803934d020a3d10128\n",
       " \tlastModified: 2021-12-11T17:41:32.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Abirate\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abirate/code_net_dev_dataset\n",
       " \tsha: dccdbc024fbab4693941564e176c3876bc17267b\n",
       " \tlastModified: 2021-12-12T09:26:00.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Abirate\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abirate/code_net_test_final_dataset\n",
       " \tsha: 36a19fa48706f158fd7cc5dfa6e79cafb5bf3567\n",
       " \tlastModified: 2022-01-27T10:15:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Abirate\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abirate/english_quotes\n",
       " \tsha: 7c68c13c1f92ab3c1bd7395d74f1fadfb126f7da\n",
       " \tlastModified: 2021-12-23T20:31:58.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:crowdsourced', 'languages:en', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: Abirate\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'crowdsourced'], 'languages': ['en'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 350\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Abirate/french_book_reviews\n",
       " \tsha: 534725e03fec6f560dbe8166e8ae3825314a6290\n",
       " \tlastModified: 2022-08-25T19:26:48.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:crowdsourced', 'language:fr', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: Abirate\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'crowdsourced'], 'language': ['fr'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AdWeeb/DravidianMT\n",
       " \tsha: 2a70e0988dd3577c4a48ca1c86453a8d60d2397d\n",
       " \tlastModified: 2021-05-21T05:05:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AdWeeb\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Adnan/Urdu_News_Headlines\n",
       " \tsha: ff03997abd68557faa8338de04da6c318b8da8bc\n",
       " \tlastModified: 2021-03-01T08:39:32.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Adnan\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AhmadSawal/qa\n",
       " \tsha: e16101a55e2bbb9c8e1c8eacd5702cc1247ba2a7\n",
       " \tlastModified: 2022-01-26T20:57:27.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AhmadSawal\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 166\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AhmedSSoliman/CoNaLa\n",
       " \tsha: 08ecce2f116f895feb3f2a5a5b7beeef761ea68f\n",
       " \tlastModified: 2022-01-22T09:34:19.000Z\n",
       " \ttags: ['task_categories:Code Generation', 'task_categories:Translation', 'task_categories:Text2Text generation']\n",
       " \tprivate: False\n",
       " \tauthor: AhmedSSoliman\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'task_categories': ['Code Generation', 'Translation', 'Text2Text generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 550\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Aisha/BAAD16\n",
       " \tsha: fe1d58e18ee293283b3efd7c5dfe03f262e3a75c\n",
       " \tlastModified: 2022-07-01T15:29:28.000Z\n",
       " \ttags: ['arxiv:2001.05316', 'annotations_creators:found', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language_creators:crowdsourced', 'language:bn', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:BAAD16: Bangla Authorship Attribution Dataset (16 Authors)', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification', 'task_ids:authorship-attribution', 'task_ids:bangla literature', 'task_ids:bengali literature']\n",
       " \tprivate: False\n",
       " \tauthor: Aisha\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found', 'crowdsourced', 'expert-generated'], 'language_creators': ['found', 'crowdsourced'], 'language': ['bn'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'BAAD16: Bangla Authorship Attribution Dataset (16 Authors)', 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification', 'authorship-attribution', 'bangla literature', 'bengali literature']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Aisha/BAAD6\n",
       " \tsha: a4115a372b7a005b6711a95f9a641db0d2a1b8b5\n",
       " \tlastModified: 2022-07-01T15:42:30.000Z\n",
       " \ttags: ['annotations_creators:found', 'annotations_creators:crowdsourced', 'annotations_creators:expert-generated', 'language_creators:found', 'language_creators:crowdsourced', 'language:bn', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:BAAD6: Bangla Authorship Attribution Dataset (6 Authors)', 'size_categories:unknown', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification', 'task_ids:authorship-attribution', 'task_ids:bangla literature', 'task_ids:bengali literature']\n",
       " \tprivate: False\n",
       " \tauthor: Aisha\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found', 'crowdsourced', 'expert-generated'], 'language_creators': ['found', 'crowdsourced'], 'language': ['bn'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'BAAD6: Bangla Authorship Attribution Dataset (6 Authors)', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification', 'authorship-attribution', 'bangla literature', 'bengali literature']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Akila/ForgottenRealmsWikiDataset\n",
       " \tsha: f315e9a2743bfd88c7b6484a945be0158ed6d7e9\n",
       " \tlastModified: 2022-01-17T17:34:05.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Akila\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Akshith/aa\n",
       " \tsha: 62edae03cb5e5f8cc5aa257f42b7cc0f7bd9ad20\n",
       " \tlastModified: 2021-05-14T15:36:14.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Akshith\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 167\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Akshith/g_rock\n",
       " \tsha: 86ffc99693429a43106689c6881919ab343380f1\n",
       " \tlastModified: 2021-05-14T15:34:01.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Akshith\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 165\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Akshith/test\n",
       " \tsha: 862dd7d22ac5f6a035aeb743f3a7cec9df0da6ec\n",
       " \tlastModified: 2021-05-14T15:43:13.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Akshith\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlekseyDorkin/extended_tweet_emojis\n",
       " \tsha: 98cde29c651eaae29d53973bc150219621f5dfe5\n",
       " \tlastModified: 2021-11-18T11:02:29.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlekseyDorkin\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlekseyKorshuk/comedy-scripts\n",
       " \tsha: 6260f47b5cb584435b993c6b98087802e56dac49\n",
       " \tlastModified: 2022-02-11T14:50:39.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlekseyKorshuk\n",
       " \tdescription: This dataset is designed to generate lyrics with HuggingArtists.\n",
       " \tcitation: @InProceedings{huggingartists:dataset,\n",
       " title = {Lyrics dataset},\n",
       " author={Aleksey Korshuk\n",
       " },\n",
       " year={2021}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlekseyKorshuk/horror-scripts\n",
       " \tsha: d8ed6a4fd5933fc65a86c895caaa76afa813098d\n",
       " \tlastModified: 2022-02-10T18:26:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlekseyKorshuk\n",
       " \tdescription: This dataset is designed to generate lyrics with HuggingArtists.\n",
       " \tcitation: @InProceedings{huggingartists:dataset,\n",
       " title = {Lyrics dataset},\n",
       " author={Aleksey Korshuk\n",
       " },\n",
       " year={2021}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlexMaclean/all-deletion-compressions\n",
       " \tsha: 91cfe7fad3a7cab31c31520e0a05a7252dd10754\n",
       " \tlastModified: 2021-12-07T00:29:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlexMaclean\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlexMaclean/wikipedia-deletion-compressions\n",
       " \tsha: 3fb708e7417ff493282bf7ddfea6101f530d47a7\n",
       " \tlastModified: 2021-12-07T00:27:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlexMaclean\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlexZapolskii/zapolskii-amazon\n",
       " \tsha: 9fda7cad48bcda0c9f95c4e2e72c2966671f3f04\n",
       " \tlastModified: 2021-12-22T22:13:57.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlexZapolskii\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AlgoveraAI/CryptoPunks\n",
       " \tsha: c31fe59b441510cba533513a8d35b0d0126d1ced\n",
       " \tlastModified: 2022-02-28T15:25:44.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AlgoveraAI\n",
       " \tdescription: CryptoPunks is a non-fungible token (NFT) collection on the Ethereum blockchain. The dataset contains 10,000 CryptoPunk images, most of humans but also of three special types: Zombie (88), Ape (24) and Alien (9). They are provided with both clear backgrounds and teal backgrounds.\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Aliseyfi/event_token_type\n",
       " \tsha: 7a2eea4a5c436e8ea0e22d0b3f06802b134670c7\n",
       " \tlastModified: 2021-12-23T18:07:33.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Aliseyfi\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 167\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Alvenir/nst-da-16khz\n",
       " \tsha: 758333c328d446c1f24ce93320a60feecac3bc72\n",
       " \tlastModified: 2021-11-29T08:58:25.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Alvenir\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AndrewMcDowell/de_corpora_parliament_processed\n",
       " \tsha: 5d05efbb1beda881be339026c447e040769e78ec\n",
       " \tlastModified: 2022-02-04T15:45:27.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: AndrewMcDowell\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Annabelleabbott/real-fake-news-workshop\n",
       " \tsha: 14706a8c6b188bf27c75bd1414b05000ac450142\n",
       " \tlastModified: 2022-01-07T00:45:18.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Annabelleabbott\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Annielytics/DoctorsNotes\n",
       " \tsha: 89b6f3c8b63256d98e02bcf3f18d1de5f6764624\n",
       " \tlastModified: 2021-05-07T14:35:26.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Annielytics\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Anurag-Singh-creator/task\n",
       " \tsha: 3e7614a60dbe5266874e69fc7f639ca2e2b771a3\n",
       " \tlastModified: 2021-12-12T21:26:53.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Anurag-Singh-creator\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Anurag-Singh-creator/tasks\n",
       " \tsha: a53286221420c92d31b4af3b95d319ce865fc85c\n",
       " \tlastModified: 2021-12-12T20:16:49.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Anurag-Singh-creator\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 166\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ApiInferenceTest/asr_dummy\n",
       " \tsha: 45e764963b548106022c890db9b59eda69d4193a\n",
       " \tlastModified: 2022-02-14T11:18:56.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: ApiInferenceTest\n",
       " \tdescription: Self-supervised learning (SSL) has proven vital for advancing research in\n",
       " natural language processing (NLP) and computer vision (CV). The paradigm\n",
       " pretrains a shared model on large volumes of unlabeled data and achieves\n",
       " state-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\n",
       " speech processing community lacks a similar setup to systematically explore the\n",
       " paradigm. To bridge this gap, we introduce Speech processing Universal\n",
       " PERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\n",
       " performance of a shared model across a wide range of speech processing tasks\n",
       " with minimal architecture changes and labeled data. Among multiple usages of the\n",
       " shared model, we especially focus on extracting the representation learned from\n",
       " SSL due to its preferable re-usability. We present a simple framework to solve\n",
       " SUPERB tasks by learning task-specialized lightweight prediction heads on top of\n",
       " the frozen shared model. Our results demonstrate that the framework is promising\n",
       " as SSL representations show competitive generalizability and accessibility\n",
       " across SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a\n",
       " benchmark toolkit to fuel the research in representation learning and general\n",
       " speech processing.\n",
       " \n",
       " Note that in order to limit the required storage for preparing this dataset, the\n",
       " audio is stored in the .flac format and is not converted to a float32 array. To\n",
       " convert, the audio file to a float32 array, please make use of the `.map()`\n",
       " function as follows:\n",
       " \n",
       " \n",
       " ```python\n",
       " import soundfile as sf\n",
       " \n",
       " def map_to_array(batch):\n",
       "     speech_array, _ = sf.read(batch[\"file\"])\n",
       "     batch[\"speech\"] = speech_array\n",
       "     return batch\n",
       " \n",
       " dataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n",
       " ```\n",
       " \tcitation: @article{DBLP:journals/corr/abs-2105-01051,\n",
       "   author    = {Shu{-}Wen Yang and\n",
       "                Po{-}Han Chi and\n",
       "                Yung{-}Sung Chuang and\n",
       "                Cheng{-}I Jeff Lai and\n",
       "                Kushal Lakhotia and\n",
       "                Yist Y. Lin and\n",
       "                Andy T. Liu and\n",
       "                Jiatong Shi and\n",
       "                Xuankai Chang and\n",
       "                Guan{-}Ting Lin and\n",
       "                Tzu{-}Hsien Huang and\n",
       "                Wei{-}Cheng Tseng and\n",
       "                Ko{-}tik Lee and\n",
       "                Da{-}Rong Liu and\n",
       "                Zili Huang and\n",
       "                Shuyan Dong and\n",
       "                Shang{-}Wen Li and\n",
       "                Shinji Watanabe and\n",
       "                Abdelrahman Mohamed and\n",
       "                Hung{-}yi Lee},\n",
       "   title     = {{SUPERB:} Speech processing Universal PERformance Benchmark},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2105.01051},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2105.01051},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2105.01051},\n",
       "   timestamp = {Thu, 01 Jul 2021 13:30:22 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2105-01051.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 785\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Arnold/hausa_common_voice\n",
       " \tsha: a851e86f3029526f5e239beff1da3130fa9802f7\n",
       " \tlastModified: 2022-02-10T03:28:22.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Arnold\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: AryanLala/autonlp-data-Scientific_Title_Generator\n",
       " \tsha: 704cf00070272d949d97d8688f81809e95ed23d9\n",
       " \tlastModified: 2021-11-20T18:00:56.000Z\n",
       " \ttags: ['task_categories:conditional-text-generation']\n",
       " \tprivate: False\n",
       " \tauthor: AryanLala\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'task_categories': ['conditional-text-generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Atsushi/fungi_diagnostic_chars_comparison_japanese\n",
       " \tsha: 5130a51f560239d32fe84a0042bde1afd74fb06f\n",
       " \tlastModified: 2022-09-19T11:19:28.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:ja', 'license:cc-by-4.0', 'multilinguality:monolingual', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'size_categories:100K<n<1M']\n",
       " \tprivate: False\n",
       " \tauthor: Atsushi\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['ja'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification'], 'size_categories': ['100K<n<1M']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Atsushi/fungi_indexed_mycological_papers_japanese\n",
       " \tsha: a1b2fb78683fa6486a8b66f513095dfa2d1cbd37\n",
       " \tlastModified: 2022-09-19T11:18:30.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:ja', 'license:cc-by-4.0', 'multilinguality:monolingual', 'source_datasets:original', 'size_categories:1K<n<10K']\n",
       " \tprivate: False\n",
       " \tauthor: Atsushi\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['ja'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'source_datasets': ['original'], 'size_categories': ['1K<n<10K']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Atsushi/fungi_trait_circus_database\n",
       " \tsha: 5c9e513083cf5c97734c58db85236bd6b01172b8\n",
       " \tlastModified: 2022-08-13T07:42:33.000Z\n",
       " \ttags: ['annotations_creators:other', 'language:en', 'language:ja', 'multilinguality:multilingual', 'license:cc-by-4.0', 'source_datasets:original', 'size_categories:100K<n<1M']\n",
       " \tprivate: False\n",
       " \tauthor: Atsushi\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['other'], 'language': ['en', 'ja'], 'multilinguality': ['multilingual'], 'license': ['cc-by-4.0'], 'source_datasets': ['original'], 'size_categories': ['100K<n<1M']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Avishekavi/Avi\n",
       " \tsha: fa47fcb40d79624a3b89ecff6b947c40289304e0\n",
       " \tlastModified: 2021-03-29T18:59:18.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Avishekavi\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/SQAC\n",
       " \tsha: d00a3d8ba5e469a54ea7a3ddf52aebc7faf22e65\n",
       " \tlastModified: 2022-07-01T15:31:18.000Z\n",
       " \ttags: ['arxiv:2107.07253', 'arxiv:1606.05250', 'annotations_creators:expert-generated', 'language_creators:found', 'language:es', 'license:cc-by-sa-4.0', 'multilinguality:monolingual', 'pretty_name:Spanish Question Answering Corpus (SQAC)', 'size_categories:unknown', 'source_datasets:original', 'task_categories:question-answering', 'task_ids:extractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: This dataset contains 6,247 contexts and 18,817 questions with their answers, 1 to 5 for each fragment.\n",
       " \n",
       " The sources of the contexts are:\n",
       " \n",
       " * Encyclopedic articles from [Wikipedia in Spanish](https://es.wikipedia.org/), used under [CC-by-sa licence](https://creativecommons.org/licenses/by-sa/3.0/legalcode). \n",
       " \n",
       " * News from [Wikinews in Spanish](https://es.wikinews.org/), used under [CC-by licence](https://creativecommons.org/licenses/by/2.5/). \n",
       " \n",
       " * Text from the Spanish corpus [AnCora](http://clic.ub.edu/corpus/en), which is a mix from diferent newswire and literature sources, used under [CC-by licence] (https://creativecommons.org/licenses/by/4.0/legalcode). \n",
       " \n",
       " This dataset can be used to build extractive-QA.\n",
       " \tcitation: bibtex\n",
       " @article{DBLP:journals/corr/abs-2107-07253,\n",
       "   author    = {Asier Guti{\\'{e}}rrez{-}Fandi{\\~{n}}o and\n",
       "                Jordi Armengol{-}Estap{\\'{e}} and\n",
       "                Marc P{\\`{a}}mies and\n",
       "                Joan Llop{-}Palao and\n",
       "                Joaqu{\\'{\\i}}n Silveira{-}Ocampo and\n",
       "                Casimiro Pio Carrino and\n",
       "                Aitor Gonzalez{-}Agirre and\n",
       "                Carme Armentano{-}Oller and\n",
       "                Carlos Rodr{\\'{\\i}}guez Penagos and\n",
       "                Marta Villegas},\n",
       "   title     = {Spanish Language Models},\n",
       "   journal   = {CoRR},\n",
       "   volume    = {abs/2107.07253},\n",
       "   year      = {2021},\n",
       "   url       = {https://arxiv.org/abs/2107.07253},\n",
       "   archivePrefix = {arXiv},\n",
       "   eprint    = {2107.07253},\n",
       "   timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},\n",
       "   biburl    = {https://dblp.org/rec/journals/corr/abs-2107-07253.bib},\n",
       "   bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['es'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Spanish Question Answering Corpus (SQAC)', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['question-answering'], 'task_ids': ['extractive-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/ancora-ca-ner\n",
       " \tsha: 177bad09f9131a4670c09efebcdc13e7bbf6d546\n",
       " \tlastModified: 2021-12-01T11:07:44.000Z\n",
       " \ttags: ['languages:ca']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: AnCora Catalan NER.\n",
       "                   This is a dataset for Named Eentity Reacognition (NER) from Ancora corpus adapted for \n",
       "                   Machine Learning and Language Model evaluation purposes.\n",
       "                   Since multiwords (including Named Entites) in the original Ancora corpus are aggregated as \n",
       "                   a single lexical item using underscores (e.g. \"Ajuntament_de_Barcelona\") \n",
       "                   we splitted them to align with word-per-line format, and added conventional Begin-Inside-Outside (IOB)\n",
       "                    tags to mark and classify Named Entites. \n",
       "                    We did not filter out the different categories of NEs from Ancora (weak and strong). \n",
       "                    We did 6 minor edits by hand.\n",
       "                   AnCora corpus is used under [CC-by] (https://creativecommons.org/licenses/by/4.0/) licence.\n",
       "                   This dataset was developed by BSC TeMU as part of the AINA project, and to enrich the Catalan Language Understanding Benchmark (CLUB).\n",
       " \tcitation: \n",
       " \tcardData: {'languages': ['ca']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/sts-ca\n",
       " \tsha: 8a8ca699cc78f23b7c70fea2750474e64a86e6fe\n",
       " \tlastModified: 2021-12-01T11:09:16.000Z\n",
       " \ttags: ['languages:ca']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: Semantic Textual Similarity in Catalan.\n",
       "                   STS corpus is a benchmark for evaluating Semantic Text Similarity in Catalan.\n",
       "                   It consists of more than 3000 sentence pairs, annotated with the semantic similarity between them, \n",
       "                   using a scale from 0 (no similarity at all) to 5 (semantic equivalence). \n",
       "                   It is done manually by 4 different annotators following our guidelines based on previous work from the SemEval challenges (https://www.aclweb.org/anthology/S13-1004.pdf).\n",
       "                   The source data are scraped sentences from the Catalan Textual Corpus (https://doi.org/10.5281/zenodo.4519349), used under CC-by-SA-4.0 licence (https://creativecommons.org/licenses/by-sa/4.0/). The dataset is released under the same licence.\n",
       "                   This dataset was developed by BSC TeMU as part of the AINA project, and to enrich the Catalan Language Understanding Benchmark (CLUB).\n",
       "                   This is the version 1.0.2 of the dataset with the complete human and automatic annotations and the analysis scripts. It also has a more accurate license.\n",
       "                   This dataset can be used to build and score semantic similiarity models.\n",
       " \tcitation: Rodriguez-Penagos, Carlos Gerardo, Armentano-Oller, Carme, Gonzalez-Agirre, Aitor, & Gibert Bonet, Ona. (2021). \n",
       "                Semantic Textual Similarity in Catalan (Version 1.0.1) [Data set]. \n",
       "                Zenodo. http://doi.org/10.5281/zenodo.4761434\n",
       " \tcardData: {'languages': ['ca']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/tecla\n",
       " \tsha: acbdb92969cee15e31545814a8487649494f6d9f\n",
       " \tlastModified: 2021-12-01T11:08:09.000Z\n",
       " \ttags: ['languages:ca']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: TeCla: Text Classification Catalan dataset\n",
       "                    Catalan News corpus for Text classification, crawled from ACN (Catalan News Agency) site: www.acn.cat\n",
       "                    Corpus de notícies en català per a classificació textual, extret del web de l'Agència Catalana de Notícies - www.acn.cat\n",
       " \tcitation: Carrino, Casimiro Pio, Rodriguez-Penagos, Carlos Gerardo, & Armentano-Oller, Carme. (2021). \n",
       "                TeCla: Text Classification Catalan dataset (Version 1.0) [Data set]. \n",
       "                Zenodo. http://doi.org/10.5281/zenodo.4627198\n",
       " \tcardData: {'languages': ['ca']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/viquiquad\n",
       " \tsha: 5aaf5cb6cdc8a7909b2a8a06495405d84799238d\n",
       " \tlastModified: 2021-12-17T11:53:17.000Z\n",
       " \ttags: ['arxiv:1606.05250', 'languages:ca']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: ViquiQuAD: an extractive QA dataset from Catalan Wikipedia.\n",
       "                   This dataset contains 3111 contexts extracted from a set of 597 high quality original (no translations) \n",
       "                   articles in the Catalan Wikipedia \"Viquipèdia\" (ca.wikipedia.org), and 1 to 5 questions with their\n",
       "                   answer for each fragment. Viquipedia articles are used under CC-by-sa licence. \n",
       "                   This dataset can be used to build extractive-QA and Language Models.\n",
       "                   Funded by the Generalitat de Catalunya, Departament de Polítiques Digitals i Administració Pública (AINA),\n",
       "                   MT4ALL and Plan de Impulso de las Tecnologías del Lenguaje (Plan TL).\n",
       " \tcitation: Rodriguez-Penagos, Carlos Gerardo, & Armentano-Oller, Carme. (2021). \n",
       "                ViquiQuAD: an extractive QA dataset from Catalan Wikipedia (Version ViquiQuad_v.1.0.1) \n",
       "                [Data set]. Zenodo. http://doi.org/10.5281/zenodo.4761412\n",
       " \tcardData: {'languages': ['ca']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BSC-TeMU/xquad-ca\n",
       " \tsha: c03877b8517b019931931f75c21e2425fd4c51aa\n",
       " \tlastModified: 2021-12-01T11:08:54.000Z\n",
       " \ttags: ['arxiv:1910.11856', 'languages:ca']\n",
       " \tprivate: False\n",
       " \tauthor: BSC-TeMU\n",
       " \tdescription: Professional translation into Catalan of XQuAD dataset (https://github.com/deepmind/xquad).\n",
       "                   XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating \n",
       "                   cross-lingual question answering performance. \n",
       "                   The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from \n",
       "                   the development set of SQuAD v1.1 (Rajpurkar et al., 2016) together with \n",
       "                   their professional translations into ten languages: \n",
       "                   Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi. \n",
       "                   Rumanian was added later.\n",
       "                   We added the 13th language to the corpus using also professional native catalan translators.\n",
       "                   XQuAD and XQuAD-Ca datasets are released under CC-by-sa licence.\n",
       " \tcitation: Carlos Gerardo Rodriguez-Penagos, & Carme Armentano-Oller. (2021). XQuAD-ca [Data set].\n",
       "                 Zenodo. http://doi.org/10.5281/zenodo.4757559\n",
       " \tcardData: {'languages': ['ca']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Babelscape/rebel-dataset\n",
       " \tsha: 813b74704f4a257c4bf1ac803660df88f3a1faa4\n",
       " \tlastModified: 2022-07-01T15:37:13.000Z\n",
       " \ttags: ['arxiv:2005.00614', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:en', 'license:cc-by-nc-sa-4.0', 'multilinguality:monolingual', 'pretty_name:rebel-dataset', 'size_categories:unknown', 'source_datasets:original', 'task_categories:text-retrieval', 'task_categories:conditional-text-generation', 'task_ids:text-retrieval-other-relation-extraction']\n",
       " \tprivate: False\n",
       " \tauthor: Babelscape\n",
       " \tdescription: REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation\n",
       " \tcitation:     @inproceedings{huguet-cabot-navigli-2021-rebel,\n",
       "     title = \"REBEL: Relation Extraction By End-to-end Language generation\",\n",
       "     author = \"Huguet Cabot, Pere-Llu{\\'\\i}s  and\n",
       "       Navigli, Roberto\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2021\",\n",
       "     month = nov,\n",
       "     year = \"2021\",\n",
       "     address = \"Online and in the Barceló Bávaro Convention Centre, Punta Cana, Dominican Republic\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf\",\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['en'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'rebel-dataset', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['text-retrieval', 'conditional-text-generation'], 'task_ids': ['text-retrieval-other-relation-extraction']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 397\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Babelscape/wikineural\n",
       " \tsha: bee054b8523941f769c802539b30339eab1eadc4\n",
       " \tlastModified: 2022-07-11T08:11:14.000Z\n",
       " \ttags: ['arxiv:1810.04805', 'annotations_creators:machine-generated', 'language_creators:machine-generated', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:it', 'language:nl', 'language:pl', 'language:pt', 'language:ru', 'multilinguality:multilingual', 'license:cc-by-nc-sa-4.0', 'pretty_name:wikineural-dataset', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:named-entity-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: Babelscape\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['machine-generated'], 'language': ['de', 'en', 'es', 'fr', 'it', 'nl', 'pl', 'pt', 'ru'], 'multilinguality': ['multilingual'], 'license': ['cc-by-nc-sa-4.0'], 'pretty_name': 'wikineural-dataset', 'source_datasets': ['original'], 'task_categories': ['structure-prediction'], 'task_ids': ['named-entity-recognition']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 530\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BatuhanYilmaz/github-issues\n",
       " \tsha: d92b7c4c009681c1286a4db03de76fd4bfd8eed5\n",
       " \tlastModified: 2022-01-24T08:40:25.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: BatuhanYilmaz\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Baybars/parla_text_corpus\n",
       " \tsha: 8d2203a0c6c2c6a132e2234e666abd6153a342b4\n",
       " \tlastModified: 2022-01-21T17:27:00.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:various', 'languages:ca', 'licenses:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:ParlaTextCorpus', 'size_categories:100k<n<1M', 'source_datasets:found', 'task_categories:sequence-modeling', 'task_ids:language-modeling', 'tags:robust-speech-event']\n",
       " \tprivate: False\n",
       " \tauthor: Baybars\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['various'], 'languages': ['ca'], 'licenses': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'ParlaTextCorpus', 'size_categories': ['100k<n<1M'], 'source_datasets': ['found'], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling'], 'tags': ['robust-speech-event']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BeIR/beir-corpus\n",
       " \tsha: 8cebd1348b799bbe47f002f036b9da9a7ac32887\n",
       " \tlastModified: 2022-02-04T01:01:56.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-sa-4.0', 'multilinguality:monolingual', 'pretty_name:BEIR Benchmark', 'size_categories:1M<n<10M', 'size_categories:100k<n<1M', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'task_categories:text-retrieval', 'task_categories:zero-shot-retrieval', 'task_categories:information-retrieval', 'task_categories:zero-shot-information-retrieval', 'task_ids:passage-retrieval', 'task_ids:entity-linking-retrieval', 'task_ids:fact-checking-retrieval', 'task_ids:tweet-retrieval', 'task_ids:citation-prediction-retrieval', 'task_ids:duplication-question-retrieval', 'task_ids:argument-retrieval', 'task_ids:news-retrieval', 'task_ids:biomedical-information-retrieval', 'task_ids:question-answering-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: BeIR\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': [], 'language_creators': [], 'languages': ['en'], 'licenses': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'beir', 'pretty_name': 'BEIR Benchmark', 'size_categories': {'msmarco': ['1M<n<10M'], 'trec-covid': ['100k<n<1M'], 'nfcorpus': ['1K<n<10K'], 'nq': ['1M<n<10M'], 'hotpotqa': ['1M<n<10M'], 'fiqa': ['10K<n<100K'], 'arguana': ['1K<n<10K'], 'touche-2020': ['100K<n<1M'], 'cqadupstack': ['100K<n<1M'], 'quora': ['100K<n<1M'], 'dbpedia': ['1M<n<10M'], 'scidocs': ['10K<n<100K'], 'fever': ['1M<n<10M'], 'climate-fever': ['1M<n<10M'], 'scifact': ['1K<n<10K']}, 'source_datasets': [], 'task_categories': ['text-retrieval', 'zero-shot-retrieval', 'information-retrieval', 'zero-shot-information-retrieval'], 'task_ids': ['passage-retrieval', 'entity-linking-retrieval', 'fact-checking-retrieval', 'tweet-retrieval', 'citation-prediction-retrieval', 'duplication-question-retrieval', 'argument-retrieval', 'news-retrieval', 'biomedical-information-retrieval', 'question-answering-retrieval']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 482\n",
       " \tlikes: 1\n",
       " \tpaperswithcode_id: beir\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BeIR/beir\n",
       " \tsha: 152b8ec1d0a6c82fa0169e367bf0479f3fdcc3f0\n",
       " \tlastModified: 2022-02-04T00:59:41.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-sa-4.0', 'multilinguality:monolingual', 'pretty_name:BEIR Benchmark', 'size_categories:1M<n<10M', 'size_categories:100k<n<1M', 'size_categories:1K<n<10K', 'size_categories:10K<n<100K', 'size_categories:100K<n<1M', 'task_categories:text-retrieval', 'task_categories:zero-shot-retrieval', 'task_categories:information-retrieval', 'task_categories:zero-shot-information-retrieval', 'task_ids:passage-retrieval', 'task_ids:entity-linking-retrieval', 'task_ids:fact-checking-retrieval', 'task_ids:tweet-retrieval', 'task_ids:citation-prediction-retrieval', 'task_ids:duplication-question-retrieval', 'task_ids:argument-retrieval', 'task_ids:news-retrieval', 'task_ids:biomedical-information-retrieval', 'task_ids:question-answering-retrieval']\n",
       " \tprivate: False\n",
       " \tauthor: BeIR\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': [], 'language_creators': [], 'languages': ['en'], 'licenses': ['cc-by-sa-4.0'], 'multilinguality': ['monolingual'], 'paperswithcode_id': 'beir', 'pretty_name': 'BEIR Benchmark', 'size_categories': {'msmarco': ['1M<n<10M'], 'trec-covid': ['100k<n<1M'], 'nfcorpus': ['1K<n<10K'], 'nq': ['1M<n<10M'], 'hotpotqa': ['1M<n<10M'], 'fiqa': ['10K<n<100K'], 'arguana': ['1K<n<10K'], 'touche-2020': ['100K<n<1M'], 'cqadupstack': ['100K<n<1M'], 'quora': ['100K<n<1M'], 'dbpedia': ['1M<n<10M'], 'scidocs': ['10K<n<100K'], 'fever': ['1M<n<10M'], 'climate-fever': ['1M<n<10M'], 'scifact': ['1K<n<10K']}, 'source_datasets': [], 'task_categories': ['text-retrieval', 'zero-shot-retrieval', 'information-retrieval', 'zero-shot-information-retrieval'], 'task_ids': ['passage-retrieval', 'entity-linking-retrieval', 'fact-checking-retrieval', 'tweet-retrieval', 'citation-prediction-retrieval', 'duplication-question-retrieval', 'argument-retrieval', 'news-retrieval', 'biomedical-information-retrieval', 'question-answering-retrieval']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 662\n",
       " \tlikes: 3\n",
       " \tpaperswithcode_id: beir\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Lacito/pangloss\n",
       " \tsha: f80e65ea3922bfab04afe8f4a07a8ab16bd81553\n",
       " \tlastModified: 2022-09-06T18:02:34.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:jya', 'language:nru', 'language_bcp47:x-japh1234', 'language_bcp47:x-yong1288', 'language_details:jya consists of japh1234 (Glottolog code); nru consists of yong1288 (Glottolog code)', 'license:cc-by-nc-sa-4.0', 'multilinguality:multilingual', 'multilinguality:translation', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:automatic-speech-recognition', 'task_ids:speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: Lacito\n",
       " \tdescription: These datasets are extracts from the Pangloss collection and have\n",
       " been preprocessed for ASR experiments in Na and Japhug.\n",
       " \tcitation: None\n",
       " \tcardData: {'pretty_name': 'Pangloss', 'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['jya', 'nru'], 'language_bcp47': ['x-japh1234', 'x-yong1288'], 'language_details': 'jya consists of japh1234 (Glottolog code); nru consists of yong1288 (Glottolog code)', 'license': 'cc-by-nc-sa-4.0', 'multilinguality': ['multilingual', 'translation'], 'size_categories': {'yong1288': ['10K<n<100K'], 'japh1234': ['10K<n<100K']}, 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': ['speech-recognition']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Binbin/my_dataset\n",
       " \tsha: ea82fd6466858f33d40a413abf8b544409124440\n",
       " \tlastModified: 2021-03-22T01:15:48.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Binbin\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BlakesOrb6/Fred-Flintstone\n",
       " \tsha: 4dfce3ee76fb1372d649f3bff7677e091518a8a3\n",
       " \tlastModified: 2021-11-08T17:43:33.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: BlakesOrb6\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 165\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Bosio/pacman\n",
       " \tsha: bcf3032a4585127f8c43d78e2860b908287c2451\n",
       " \tlastModified: 2021-09-28T16:00:06.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Bosio\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Bosio/pacman_descriptions\n",
       " \tsha: af6537e9927a2726ac59922b43c0dca892058a74\n",
       " \tlastModified: 2021-09-29T14:05:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Bosio\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: BritishLibraryLabs/EThOS-PhD-metadata\n",
       " \tsha: 66bfd05a6720c6eb0d274779cec9b0632622c682\n",
       " \tlastModified: 2022-07-23T21:14:57.000Z\n",
       " \ttags: ['language:en', 'multilinguality:monolingual', 'pretty_name:EThOS PhD metadata', 'task_categories:text-classification', 'task_categories:fill-mask', 'task_ids:multi-label-classification', 'task_ids:masked-language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: BritishLibraryLabs\n",
       " \tdescription: The data in this collection comprises the bibliographic metadata for all UK doctoral theses listed in EThOS, the UK's national thesis service.\n",
       " We estimate the data covers around 98% of all PhDs ever awarded by UK Higher Education institutions, dating back to 1787.\n",
       " Thesis metadata from every PhD-awarding university in the UK is included.\n",
       " \tcitation: \\ \n",
       " @misc{british library_genre,\n",
       " title={UK Doctoral Thesis Metadata from EThOS},\n",
       " url={UK Doctoral Thesis Metadata from EThOS},\n",
       " author={{British Library} and  {Rosie, Heather}},\n",
       " year={2021}}\n",
       " \tcardData: {'annotations_creators': [], 'language': ['en'], 'language_creators': [], 'license': [], 'multilinguality': ['monolingual'], 'pretty_name': 'EThOS PhD metadata', 'size_categories': [], 'source_datasets': [], 'tags': [], 'task_categories': ['text-classification', 'fill-mask'], 'task_ids': ['multi-label-classification', 'masked-language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 489\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CAGER/rick\n",
       " \tsha: f002ce337df0b0f1fb96f87edd17b2ebe4a73963\n",
       " \tlastModified: 2021-07-09T02:05:44.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: CAGER\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CALM/arwiki\n",
       " \tsha: 36dcd9cf86cfc635866ec63d58ef5ee25885ac4d\n",
       " \tlastModified: 2022-08-01T16:37:23.000Z\n",
       " \ttags: ['pretty_name:Wikipedia Arabic dumps dataset.', 'language:ar', 'license:unknown', 'multilinguality:monolingual']\n",
       " \tprivate: False\n",
       " \tauthor: CALM\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'pretty_name': 'Wikipedia Arabic dumps dataset.', 'language': ['ar'], 'license': ['unknown'], 'multilinguality': ['monolingual']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CAiRE/ASCEND\n",
       " \tsha: 877a333c241b788fdfff2141c1e8c0ccaf87bb9f\n",
       " \tlastModified: 2022-10-06T14:21:30.000Z\n",
       " \ttags: ['arxiv:2112.06223', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'language:en', 'language:zh', 'license:cc-by-sa-4.0', 'multilinguality:multilingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:automatic-speech-recognition', 'task_ids:code-switching', 'task_ids:speech-recognition']\n",
       " \tprivate: False\n",
       " \tauthor: CAiRE\n",
       " \tdescription: ASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.\n",
       " \tcitation: @inproceedings{lovenia2021ascend,\n",
       "   title     = {ASCEND: A Spontaneous Chinese-English Dataset for Code-switching in Multi-turn Conversation},\n",
       "   author    = {Lovenia, Holy and Cahyawijaya, Samuel and Winata, Genta Indra and Xu, Peng and Yan, Xu and Liu, Zihan and Frieske, Rita and Yu, Tiezheng and Dai, Wenliang and Barezi, Elham J and others},\n",
       "   booktitle = {Proceedings of the International Conference on Language Resources and Evaluation, {LREC} 2022, 20-25 June 2022, Lu Palais du Pharo, France},\n",
       "   publisher = {European Language Resources Association},\n",
       "   year      = {2022},\n",
       "   pages = {}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'language': ['en', 'zh'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'ASCEND: A Spontaneous Chinese-English Dataset for Code-switching in Multi-turn Conversation', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['automatic-speech-recognition'], 'task_ids': ['code-switching', 'speech-recognition']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 545\n",
       " \tlikes: 5\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CShorten/KerasBERT\n",
       " \tsha: 563ad7cd6591c8a51a807ce073645e349ce92fa8\n",
       " \tlastModified: 2022-06-28T11:51:07.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: CShorten\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ChadxxxxHall/Inter-vision\n",
       " \tsha: ac7643af59bca366e7de8288c757b1326b3f121b\n",
       " \tlastModified: 2021-08-11T22:44:47.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: ChadxxxxHall\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Champion/vpc2020_clear_anon_speech\n",
       " \tsha: d0be437cfd0d5d653ffd582514f55cb1f039ba16\n",
       " \tlastModified: 2021-10-12T14:19:45.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Champion\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/a_re_gi\n",
       " \tsha: 37995e71a159af09ae5da884673ed04e00464a9b\n",
       " \tlastModified: 2021-08-31T08:46:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_1\n",
       " \tsha: e8f927222fa1340dc73cda228d037e770f118470\n",
       " \tlastModified: 2021-09-04T10:57:07.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_2\n",
       " \tsha: 7e87f8e337e0d5eae4d466d41516b789404794e1\n",
       " \tlastModified: 2021-09-04T11:04:11.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_3\n",
       " \tsha: d123b89d4c996700084cffda6ffe97fe2f5a7ee4\n",
       " \tlastModified: 2021-09-04T11:05:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_4\n",
       " \tsha: 20716e101ede213170be73317e3f819c2ed6ff72\n",
       " \tlastModified: 2021-09-04T11:06:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_5\n",
       " \tsha: cb7f4f16ad077e84e649090b4ff40f5f3b5587c8\n",
       " \tlastModified: 2021-09-04T11:07:26.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_6\n",
       " \tsha: 59d2b7d488c705775b6922312ebdaed8787ad393\n",
       " \tlastModified: 2021-09-04T11:08:02.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_7\n",
       " \tsha: f6d5b07c7563f926ac0aa24c021eb1f462c33ded\n",
       " \tlastModified: 2021-09-04T11:08:48.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_8\n",
       " \tsha: 8c1f22957445456bb5ca34c22a16fdd3c71aa625\n",
       " \tlastModified: 2021-09-04T11:09:53.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/region_9\n",
       " \tsha: 177541344356bbe545ee7ce7b2df23c6a34d8b92\n",
       " \tlastModified: 2021-09-04T11:09:23.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/regions\n",
       " \tsha: 2452726ac5e742c1dd74c0eeadd076492082a7b2\n",
       " \tlastModified: 2021-08-31T14:34:50.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Check/vverify\n",
       " \tsha: 671bd0b79adcab5abdfb8969d29acd82bcec587a\n",
       " \tlastModified: 2021-09-11T05:13:10.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Check\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cheranga/test\n",
       " \tsha: 0267de0892db58df76ab0ba08d07debeceb55aff\n",
       " \tlastModified: 2022-02-10T01:34:34.000Z\n",
       " \ttags: ['license:afl-3.0']\n",
       " \tprivate: False\n",
       " \tauthor: Cheranga\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'license': 'afl-3.0'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ChristophSchuhmann/MS_COCO_2017_URL_TEXT\n",
       " \tsha: e03f8abd98a208fd0da71e7b0c7af9b0c36d64b6\n",
       " \tlastModified: 2021-11-27T15:39:29.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: ChristophSchuhmann\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2273\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Chun/dataset\n",
       " \tsha: f496e251dd03afb88f8a19b8bdb47b6ae41a2408\n",
       " \tlastModified: 2021-08-24T08:16:33.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Chun\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Chuu/Vhh\n",
       " \tsha: bd167b2bceb72c2ac6e94104cfc213f2d6fcf9ee\n",
       " \tlastModified: 2021-11-25T11:15:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Chuu\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CodedotAI/code-clippy-tfrecords\n",
       " \tsha: 73dfc14d45938d224a7167fee1bac417d3e94252\n",
       " \tlastModified: 2021-12-07T21:40:32.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: CodedotAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CodedotAI/code_clippy\n",
       " \tsha: 9ab49d63034bf74a84769df261fea528f079440f\n",
       " \tlastModified: 2022-07-01T15:32:00.000Z\n",
       " \ttags: ['arxiv:2107.03374', 'annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:code', 'license:gpl-3.0', 'multilinguality:multilingual', 'pretty_name:Code Clippy', 'size_categories:unknown', 'source_datasets:original', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: CodedotAI\n",
       " \tdescription: This dataset was generated by selecting GitHub repositories from a large collection of repositories. These repositories were collected from https://seart-ghs.si.usi.ch/ and Github portion of [The Pile](https://github.com/EleutherAI/github-downloader) (performed on July 7th, 2021). The goal of this dataset is to provide a training set for pretraining large language models on code data for helping software engineering researchers better understand their impacts on software related tasks such as autocompletion of code. The dataset is split into train, validation, and test splits. There is a version containing duplicates (209GBs compressed) and ones where exact duplicates (132GBs compressed) are removed. Contains mostly JavaScript and Python code, but other programming languages are included as well to various degrees.\n",
       " \tcitation: @misc{cooper-2021-code-clippy-data,\n",
       "     author       = {Nathan Coooper, Artashes Arutiunian, Santiago Hincapié-Potes, Ben Trevett, Arun Raja, Erfan Hossami, Mrinal Mathur, and contributors},\n",
       "     title        = {{Code Clippy Data: A large dataset of code data from Github for research into code language models}},\n",
       "     month        = jul,\n",
       "     year         = 2021,\n",
       "     version      = {1.0},\n",
       "     publisher    = {GitHub},\n",
       "     url          = {https://github.com/ncoop57/gpt-code-clippy}\n",
       " }\n",
       " \tcardData: {'YAML tags': None, 'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['code'], 'license': ['gpl-3.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'Code Clippy', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 173\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CodedotAI/code_clippy_github\n",
       " \tsha: cf9f33dec640f45228f8f3f5e6a7899a37f5f83e\n",
       " \tlastModified: 2022-08-05T02:57:36.000Z\n",
       " \ttags: ['arxiv:2107.03374', 'language_creators:crowdsourced', 'language_creators:expert-generated', 'language:code', 'license:mit', 'multilinguality:multilingual', 'size_categories:unknown', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: CodedotAI\n",
       " \tdescription: The Code Clippy dataset consists of various public codebases from GitHub in 22 programming languages with 23 extensions     totalling about 16 TB of data when uncompressed. The dataset was created from the public GitHub dataset on Google BiqQuery.\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': [], 'language_creators': ['crowdsourced', 'expert-generated'], 'language': ['code'], 'license': ['mit'], 'multilinguality': ['multilingual'], 'pretty_name': 'code-clippy-github-code', 'size_categories': ['unknown'], 'source_datasets': [], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 174\n",
       " \tlikes: 7\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Crives/haha\n",
       " \tsha: 8f9dfdbed838c886787a56ba8b582fa82b268eba\n",
       " \tlastModified: 2022-02-22T09:40:35.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Crives\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cropinky/flatearther\n",
       " \tsha: 41d4a7c0dceb496a6a7441a80bb28e430cae670e\n",
       " \tlastModified: 2021-06-30T22:37:54.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Cropinky\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 166\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cropinky/rap_lyrics_english\n",
       " \tsha: 63ce731b2049c2d02e1c47a3ef15400c7e08d2e5\n",
       " \tlastModified: 2021-07-21T03:07:36.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Cropinky\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cropinky/wow_fishing_bobber\n",
       " \tsha: 49a1de0829240746a613c3e9a6d7a98e6527827f\n",
       " \tlastModified: 2021-06-30T22:14:04.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Cropinky\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cyberfish/pos_tagger\n",
       " \tsha: 81c2d1f3fc945fbc417173ce18aadf781efecd53\n",
       " \tlastModified: 2021-08-20T02:32:01.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Cyberfish\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Cyberfish/text_error_correction\n",
       " \tsha: 577a560fa4ee1bf8d32480eefa9e14f416022016\n",
       " \tlastModified: 2021-08-19T13:07:16.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Cyberfish\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: CyranoB/polarity\n",
       " \tsha: 35c80207fc7b7b03e5c940a7d173d33e8fdb3777\n",
       " \tlastModified: 2022-02-22T22:40:24.000Z\n",
       " \ttags: ['arxiv:1509.01626', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'languages:en', 'licenses:apache-2-0', 'multilinguality:monolingual', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification', 'pretty_name:Amazon Review Polarity']\n",
       " \tprivate: False\n",
       " \tauthor: CyranoB\n",
       " \tdescription: The Amazon reviews dataset consists of reviews from amazon.\n",
       " The data span a period of 18 years, including ~35 million reviews up to March 2013.\n",
       " Reviews include product and user information, ratings, and a plaintext review.\n",
       " \tcitation: @inproceedings{mcauley2013hidden,\n",
       "   title={Hidden factors and hidden topics: understanding rating dimensions with review text},\n",
       "   author={McAuley, Julian and Leskovec, Jure},\n",
       "   booktitle={Proceedings of the 7th ACM conference on Recommender systems},\n",
       "   pages={165--172},\n",
       "   year={2013}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'languages': ['en'], 'licenses': ['apache-2-0'], 'multilinguality': ['monolingual'], 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification'], 'paperswithcode_id': None, 'pretty_name': 'Amazon Review Polarity'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/angry-tweets\n",
       " \tsha: ba34e735abf46abc1e5d2675ac5c10e3fb9ff810\n",
       " \tlastModified: 2022-07-01T15:41:21.000Z\n",
       " \ttags: ['annotations_creators:crowdsourced', 'language_creators:found', 'language:da', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:AngryTweets', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['da'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'AngryTweets', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 705\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/dkhate\n",
       " \tsha: 83df8bfd010fe8ff932fc196aeab56f646f2d06a\n",
       " \tlastModified: 2022-05-31T07:49:19.000Z\n",
       " \ttags: ['arxiv:1908.04531', 'annotations_creators:expert-generated', 'language_creators:found', 'languages:da', 'licenses:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:DKHate', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:text-classification-other-hate-speech-classification', 'task_ids:hate-speech-detection', 'extra_gated_prompt:Content warning: This dataset contains harmful text (abusive language, hate speech).']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'languages': ['da'], 'licenses': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'DKHate', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['text-classification-other-hate-speech-classification', 'hate-speech-detection'], 'extra_gated_prompt': 'Content warning: This dataset contains harmful text (abusive language, hate speech).', 'paperswithcode_id': 'dkhate'}\n",
       " \tsiblings: None\n",
       " \tgated: True\n",
       " \tdownloads: 282\n",
       " \tlikes: 4\n",
       " \tpaperswithcode_id: dkhate\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/europarl\n",
       " \tsha: 705be67c4566ea3ae65476b5a9fa44361d3a2287\n",
       " \tlastModified: 2022-07-01T15:42:03.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:da', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:TwitterSent', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['da'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'TwitterSent', 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/lcc\n",
       " \tsha: 8cee426aac311cb33517ce16a2ccd79e90a7f299\n",
       " \tlastModified: 2022-07-01T15:44:15.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:da', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:TwitterSent', 'size_categories:n<1K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['da'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'TwitterSent', 'size_categories': ['n<1K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 499\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/partial-danish-gigaword-no-twitter\n",
       " \tsha: 693bbbbe289ee43c5a5ded5ab3c7e493843de9c0\n",
       " \tlastModified: 2022-07-01T15:28:28.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:da', 'language:da-bornholm', 'language:da-synnejyl', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:Danish Gigaword Corpus (no Twitter)', 'size_categories:unknown', 'source_datasets:original', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': None, 'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['da', 'da-bornholm', 'da-synnejyl'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'Danish Gigaword Corpus (no Twitter)', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/reddit-da-asr-preprocessed\n",
       " \tsha: 6823e304b9fa627f04b7af57c78ef3ac2dd498c2\n",
       " \tlastModified: 2022-02-15T19:17:08.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/reddit-da\n",
       " \tsha: 3ca56d3fd36fcd52c38472d7c9fca4fd73d16f70\n",
       " \tlastModified: 2022-07-01T15:44:02.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:da', 'license:mit', 'multilinguality:monolingual', 'pretty_name:Reddit-da', 'size_categories:1M<n<10M', 'source_datasets:original', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['da'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Reddit-da', 'size_categories': ['1M<n<10M'], 'source_datasets': ['original'], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DDSC/twitter-sent\n",
       " \tsha: 589ba98416d19168b59c26f992b4337815e55964\n",
       " \tlastModified: 2022-07-01T15:44:26.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:found', 'language:da', 'license:cc-by-4.0', 'multilinguality:monolingual', 'pretty_name:TwitterSent', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:sentiment-classification']\n",
       " \tprivate: False\n",
       " \tauthor: DDSC\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['found'], 'language': ['da'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'pretty_name': 'TwitterSent', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['sentiment-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DELith/github-issues\n",
       " \tsha: 84bc6bbc0493e3c0304b7a680129c43dce163492\n",
       " \tlastModified: 2021-11-21T15:58:45.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DELith\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DSCI511G1/COP26_Energy_Transition_Tweets\n",
       " \tsha: 730cc3b4b6b15c3f7a57494319b6476d84a5605c\n",
       " \tlastModified: 2021-12-06T17:53:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DSCI511G1\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DanL/scientific-challenges-and-directions-dataset\n",
       " \tsha: cb806b71bbb735b812bdfb57be080eea49d9fa4a\n",
       " \tlastModified: 2022-01-20T14:13:45.000Z\n",
       " \ttags: ['arxiv:2108.13751', 'arxiv:2004.10706', 'annotations_creators:expert-generated', 'languages:en', 'multilinguality:monolingual', 'source_datasets:CORD-19', 'task_categories:text-classification', 'task_ids:multi-label-classification']\n",
       " \tprivate: False\n",
       " \tauthor: DanL\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': None, 'annotations_creators': ['expert-generated'], 'language_creators': [], 'languages': ['en'], 'licenses': [], 'multilinguality': ['monolingual'], 'pretty_name': '', 'source_datasets': ['CORD-19'], 'task_categories': ['text-classification'], 'task_ids': ['multi-label-classification']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Daniele/dante-corpus\n",
       " \tsha: 107a08bf312451a432f6cd75ae38688b67f85646\n",
       " \tlastModified: 2021-11-12T11:44:16.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Daniele\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the online tagging app': 'https://huggingface.co/spaces/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Darren/data\n",
       " \tsha: c9b264f678262ddab733c3528bc64b74d58191dc\n",
       " \tlastModified: 2021-05-27T23:31:45.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Darren\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/accented_english\n",
       " \tsha: 14f9a0538f8c6dac63864d66801fc285c3159393\n",
       " \tlastModified: 2022-06-24T09:46:06.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/accented_mandarin\n",
       " \tsha: dbeb88563d80c9ad2896b8fc0a038f4db945192a\n",
       " \tlastModified: 2022-06-24T09:46:46.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/chinese_dialect\n",
       " \tsha: a3b3cc3f712507776384bb76b1a891cada70c796\n",
       " \tlastModified: 2022-06-24T09:46:30.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/mandarin_chinese\n",
       " \tsha: 14c08a5292003a506fb4355a47c9205cedfaa2a1\n",
       " \tlastModified: 2022-06-24T09:46:38.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/mixed_speech_chinese_english\n",
       " \tsha: 760b607ca2e788bde9240ce76fc95576adea53c8\n",
       " \tlastModified: 2022-06-24T09:46:22.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/multi_language\n",
       " \tsha: 66ac3d01e6ded0147dddaa279b57097149497dc6\n",
       " \tlastModified: 2022-06-24T09:45:56.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Datatang/multi_language_conversation\n",
       " \tsha: 045455c29adcdcf6f703786da9d45ad9eba242e2\n",
       " \tlastModified: 2022-06-24T09:46:13.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Datatang\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Davlan/conll2003_de_noMISC\n",
       " \tsha: 6c10edc191fed251d469ca7bb81010b38c5cee50\n",
       " \tlastModified: 2021-10-05T09:06:35.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Davlan\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Davlan/conll2003_noMISC\n",
       " \tsha: 56e730f1bbd9a40777ea5fbec12793e44f2a4999\n",
       " \tlastModified: 2022-02-03T19:00:25.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Davlan\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Davlan/masakhanerV1\n",
       " \tsha: 82a6371ab5f3e504dbb3f77623acb601c1ed3af9\n",
       " \tlastModified: 2021-09-18T19:13:11.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Davlan\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 165\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DelgadoPanadero/Pokemon\n",
       " \tsha: 89349b4f6b2b3dc5e3b4da9a505c969421da3e6c\n",
       " \tlastModified: 2022-01-03T10:10:40.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DelgadoPanadero\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DeskDown/ALTDataset\n",
       " \tsha: 8d33120c04ada67489ab862d4a8e1438a1114316\n",
       " \tlastModified: 2022-02-13T17:03:25.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DeskDown\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DeskDown/ALTDataset_en-to-fil-vi-id-ms-ja-khm\n",
       " \tsha: 27aeb98712ca9cded7d7fadd0027afdbe4f22746\n",
       " \tlastModified: 2022-01-03T22:31:36.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DeskDown\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 321\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DiFronzo/Human_Activity_Recognition\n",
       " \tsha: 578af74e6d9abf50e091ad2292a79dda85998e0f\n",
       " \tlastModified: 2022-02-08T11:18:07.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DiFronzo\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 325\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Dmitriy612/1\n",
       " \tsha: ed8e96f4eff8db56f3244118ad8e70b8bbbc1ee1\n",
       " \tlastModified: 2021-10-09T12:22:11.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Dmitriy612\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 166\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DoctorSlimm/yipee\n",
       " \tsha: 7925560fed8327d0f849ec8e6e0f14e50db116bf\n",
       " \tlastModified: 2021-10-31T16:09:49.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DoctorSlimm\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 163\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Doohae/klue-mrc-bm25\n",
       " \tsha: 0d0b5e8cb0712a451bbf16e5c776243e08434223\n",
       " \tlastModified: 2022-02-09T08:10:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Doohae\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Doohae/modern_music_re\n",
       " \tsha: 54e3bc2eb96a5f8c346ca715909f717f02eba22b\n",
       " \tlastModified: 2021-12-06T05:58:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Doohae\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DoyyingFace/github-embeddings-doy\n",
       " \tsha: b8fade32ab4ef7ed2c5a88c57865bc8c17e10cf1\n",
       " \tlastModified: 2022-01-20T04:19:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DoyyingFace\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DoyyingFace/github-issues-doy\n",
       " \tsha: e3045146168d223e8bc5642b536ce83280c4fa01\n",
       " \tlastModified: 2022-01-19T10:57:15.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DoyyingFace\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 165\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/as_opus100_processed\n",
       " \tsha: dd873e9cf51534859f0d792ccc36dc612ec15bd7\n",
       " \tlastModified: 2022-02-09T17:36:03.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 321\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/bg_opus100_processed\n",
       " \tsha: c6598454c58a057b113e669c972af6d1c1c1841c\n",
       " \tlastModified: 2022-02-09T07:33:17.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/br_opus100_processed\n",
       " \tsha: 2d20d98c1689f4ad81d763d2f79176bedbdcc29f\n",
       " \tlastModified: 2022-02-10T01:50:05.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/hi_opus100_processed\n",
       " \tsha: 614d99aa31a1c8055257a849f842137ae88629e9\n",
       " \tlastModified: 2022-02-09T18:34:07.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/kk_opus100_processed\n",
       " \tsha: 37e1e832f2a2095e03f0acfa0fe6a6310880f59d\n",
       " \tlastModified: 2022-02-09T08:23:36.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/mr_opus100_processed\n",
       " \tsha: 635dd36455402abafe104fc06d5308c32a1ab6bc\n",
       " \tlastModified: 2022-02-09T14:28:39.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/or_opus100_processed\n",
       " \tsha: 6d1f2af403c46e30d7421e6119b05e68ddda2afa\n",
       " \tlastModified: 2022-02-10T03:12:01.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 323\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/sl_opus100_processed\n",
       " \tsha: 993f39dff60594cf2ef0244f975a267368dcb35d\n",
       " \tlastModified: 2022-02-09T03:53:47.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: DrishtiSharma/sr_opus100_processed\n",
       " \tsha: 7cfa52f57eaec82e9c7f3cced33067285105486d\n",
       " \tlastModified: 2022-02-08T17:32:38.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: DrishtiSharma\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Dumiiii/common-voice-romaniarss\n",
       " \tsha: 2933270d52e548c9efd75451f085034d145c748c\n",
       " \tlastModified: 2022-01-11T11:29:09.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Dumiiii\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 322\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: EMBO/biolang\n",
       " \tsha: b85cac37ad447319a91ea886aa86b38aa9c00a14\n",
       " \tlastModified: 2022-07-20T07:01:04.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'language_creators:expert-generated', 'language:en', 'license:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:n>1M', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: EMBO\n",
       " \tdescription: This dataset is based on abstracts from the open access section of EuropePubMed Central to train language models in the domain of biology.\n",
       " \tcitation: @Unpublished{\n",
       "     huggingface: dataset,\n",
       "     title = {biolang},\n",
       "     authors={Thomas Lemberger, EMBO},\n",
       "     year={2021}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['machine-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['n>1M'], 'source_datasets': [], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 836\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: EMBO/sd-nlp\n",
       " \tsha: 08141a0784380474c69bc77fc13b5a08a17da245\n",
       " \tlastModified: 2022-07-20T11:03:50.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'languages:en', 'licenses:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'task_categories:text-classification', 'task_categories:structure-prediction', 'task_ids:multi-class-classification', 'task_ids:named-entity-recognition', 'task_ids:parsing']\n",
       " \tprivate: False\n",
       " \tauthor: EMBO\n",
       " \tdescription:     This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.\n",
       " \tcitation:     @Unpublished{\n",
       "         huggingface: dataset,\n",
       "         title = {SourceData NLP},\n",
       "         authors={Thomas Lemberger, EMBO},\n",
       "         year={2021}\n",
       "     }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'languages': ['en'], 'licenses': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['10K<n<100K'], 'source_datasets': [], 'task_categories': {'BORING': ['text-classification'], 'NER': ['structure-prediction'], 'PANELIZATION': ['structure-prediction'], 'ROLES': ['text-classification']}, 'task_ids': {'BORING': ['multi-class-classification'], 'NER': ['named-entity-recognition'], 'PANELIZATION': ['parsing'], 'ROLES': ['multi-class-classification']}}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 946\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: ESZER/H\n",
       " \tsha: a19929654f32b1f157b60f64f571d7c9e51b73f7\n",
       " \tlastModified: 2021-07-10T18:14:47.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: ESZER\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Emanuel/UD_Portuguese-Bosque\n",
       " \tsha: 609cc0be64d9763df8e3903b0dd1334ada90bd40\n",
       " \tlastModified: 2021-10-18T16:39:30.000Z\n",
       " \ttags: ['languages:pt']\n",
       " \tprivate: False\n",
       " \tauthor: Emanuel\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'languages': ['pt']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 326\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Emma121/testtest\n",
       " \tsha: c0d1f33ea5a48ac34bf46f33a810d29c468b2188\n",
       " \tlastModified: 2022-02-14T13:18:46.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Emma121\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 169\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Emon/sobuj\n",
       " \tsha: 111f199cb7527ca797e2e1cfcef282da5e21ff03\n",
       " \tlastModified: 2021-08-19T08:07:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Emon\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 167\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Enes3774/data\n",
       " \tsha: 0b90b2fe7a746c3dbaff1db761788887704637bc\n",
       " \tlastModified: 2021-08-15T19:43:29.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Enes3774\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Exr0n/wiki-entity-similarity\n",
       " \tsha: cbc67fdf71a5181de1aae304d98335276f236144\n",
       " \tlastModified: 2022-08-19T18:51:04.000Z\n",
       " \ttags: ['arxiv:2004.04906', 'arxiv:2202.13581', 'annotations_creators:found', 'language:en', 'language_creators:found', 'license:mit', 'multilinguality:monolingual', 'size_categories:10M<n<100M', 'source_datasets:original', 'tags:named entities', 'tags:similarity', 'tags:paraphrasing', 'tags:synonyms', 'tags:wikipedia']\n",
       " \tprivate: False\n",
       " \tauthor: Exr0n\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['found'], 'language': ['en'], 'language_creators': ['found'], 'license': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'Wiki Entity Similarity\\n', 'size_categories': ['10M<n<100M'], 'source_datasets': ['original'], 'tags': ['named entities', 'similarity', 'paraphrasing', 'synonyms', 'wikipedia'], 'task_categories': [], 'task_ids': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1099\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Eymen3455/xsum_tr\n",
       " \tsha: 5fe4b51b75e3979056b483f93922c3e5f6939065\n",
       " \tlastModified: 2021-02-25T11:32:10.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Eymen3455\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: FIG-Loneliness/FIG-Loneliness\n",
       " \tsha: 1d89c0235a300f314ddb4fd33d779d57eb24b63c\n",
       " \tlastModified: 2022-07-14T23:14:43.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: FIG-Loneliness\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: FL33TW00D/test-dataset\n",
       " \tsha: a07957b62bd5d6b91251d0119a28c0ab04fb8808\n",
       " \tlastModified: 2021-10-13T14:40:54.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: FL33TW00D\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: FRTNX/cosuju\n",
       " \tsha: 10630a174f51f76f6a5fff8ccd60a92d261f5c7b\n",
       " \tlastModified: 2021-03-29T09:01:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: FRTNX\n",
       " \tdescription: Court Summaries and Judgements (CoSuJu) Dataset\n",
       " \tcitation: @InProceedings{huggingface:dataset,\n",
       " title   = {CoSuJu 500+ Court Judegements and Summaries for Machine Text Summarization},\n",
       " authors = {Busani Ndlovu, Luke Jordan},\n",
       " year    = {2021}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 510\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: FRTNX/worldbank-projects\n",
       " \tsha: 1105a28c7e7fe92eaee97ec3b283155ff3f9986a\n",
       " \tlastModified: 2021-09-03T14:04:26.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: FRTNX\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Felix-ML/quoteli3\n",
       " \tsha: 5e7cd48d1b465aa0220e08f7e8ad41229e624bc7\n",
       " \tlastModified: 2021-06-28T09:55:11.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-4.0', 'multilinguality:monolingual', 'size_categories:1K<n<10K']\n",
       " \tprivate: False\n",
       " \tauthor: Felix-ML\n",
       " \tdescription: This dataset is a representation of Muzny et al.'s QuoteLi3 dataset as a Huggingface dataset. It can be best used for \n",
       " quote attribution.\n",
       " \tcitation: @inproceedings{muzny2017two,\n",
       "   title={A two-stage sieve approach for quote attribution},\n",
       "   author={Muzny, Grace and Fang, Michael and Chang, Angel and Jurafsky, Dan},\n",
       "   booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},\n",
       "   pages={460--470},\n",
       "   year={2017}\n",
       " }\n",
       " \tcardData: {'languages': ['en'], 'licenses': ['cc-by-4.0'], 'multilinguality': ['monolingual'], 'size_categories': ['1K<n<10K'], 'source_datasets': []}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 170\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Finnish-NLP/mc4_fi_cleaned\n",
       " \tsha: ca6d4a850d27ae1057eb2b709e517b6ff9f2b39e\n",
       " \tlastModified: 2022-07-02T12:46:08.000Z\n",
       " \ttags: ['language:fi', 'multilinguality:monolingual', 'pretty_name:mC4 Finnish Cleaned', 'size_categories:unknown', 'source_datasets:extended|mc4', 'task_categories:sequence-modeling', 'task_ids:language-modeling']\n",
       " \tprivate: False\n",
       " \tauthor: Finnish-NLP\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': [], 'language_creators': [], 'language': ['fi'], 'license': [], 'multilinguality': ['monolingual'], 'pretty_name': 'mC4 Finnish Cleaned', 'size_categories': ['unknown'], 'source_datasets': ['extended|mc4'], 'task_categories': ['sequence-modeling'], 'task_ids': ['language-modeling']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 413\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Firoj/HumAID\n",
       " \tsha: 6ae265697cb5e7d7bde15a79a51a25bae9b92758\n",
       " \tlastModified: 2022-05-18T04:45:03.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Firoj\n",
       " \tdescription: The HumAID Twitter dataset consists of several thousands of manually annotated tweets that has been collected during 19 major natural disaster events including earthquakes, hurricanes, wildfires, and floods, which happened from 2016 to 2019 across different parts of the World. The annotations in the provided datasets consists of following humanitarian categories. The dataset consists only english tweets and it is the largest dataset for crisis informatics so far.\n",
       " ** Humanitarian categories **\n",
       " - Caution and advice\n",
       " - Displaced people and evacuations\n",
       " - Dont know cant judge\n",
       " - Infrastructure and utility damage\n",
       " - Injured or dead people\n",
       " - Missing or found people\n",
       " - Not humanitarian\n",
       " - Other relevant information\n",
       " - Requests or urgent needs\n",
       " - Rescue volunteering or donation effort\n",
       " - Sympathy and support\n",
       " \tcitation: @inproceedings{humaid2020,\n",
       " Author = {Firoj Alam, Umair Qazi, Muhammad Imran, Ferda Ofli},\n",
       " booktitle={Proceedings of the Fifteenth International AAAI Conference on Web and Social Media},\n",
       " series={ICWSM~'21},\n",
       " Keywords = {Social Media, Crisis Computing, Tweet Text Classification, Disaster Response},\n",
       " Title = {HumAID: Human-Annotated Disaster Incidents Data from Twitter},\n",
       " Year = {2021},\n",
       " publisher={AAAI},\n",
       " address={Online},\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Francois/futures_es\n",
       " \tsha: 0fee8833a1fb80de15305e7a268583a3d8ded57c\n",
       " \tlastModified: 2021-07-29T17:19:50.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Francois\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 168\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/mnist-text-default\n",
       " \tsha: 79f97a8d8943cabb0127b0e97d6c25afdb6887fb\n",
       " \tlastModified: 2021-02-22T10:48:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: MNIST dataset adapted to a text-based representation.\n",
       " \n",
       " This allows testing interpolation quality for Transformer-VAEs.\n",
       " \n",
       " System is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n",
       " \n",
       " Works by quantising each MNIST pixel into one of 64 characters.\n",
       " Every sample has an up & down version to encourage the model to learn rotation invarient features.\n",
       " \n",
       " Use `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n",
       " \n",
       " Data format:\n",
       " - text: (30 x 28 tokens, 840 tokens total): Textual representation of MNIST digit, for example:\n",
       " ```\n",
       " 00 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 01 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 02 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 03 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 04 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 05 down ! ! ! ! ! ! ! ! ! ! ! ! ! % % % @ C L ' J a ^ @ ! ! ! !\n",
       " 06 down ! ! ! ! ! ! ! ! ( * 8 G K ` ` ` ` ` Y L ` ] Q 1 ! ! ! !\n",
       " 07 down ! ! ! ! ! ! ! - \\ ` ` ` ` ` ` ` ` _ 8 5 5 / * ! ! ! ! !\n",
       " 08 down ! ! ! ! ! ! ! % W ` ` ` ` ` R N ^ ] ! ! ! ! ! ! ! ! ! !\n",
       " 09 down ! ! ! ! ! ! ! ! 5 H ; ` ` T # ! + G ! ! ! ! ! ! ! ! ! !\n",
       " 10 down ! ! ! ! ! ! ! ! ! $ ! G ` 7 ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 11 down ! ! ! ! ! ! ! ! ! ! ! C ` P ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 12 down ! ! ! ! ! ! ! ! ! ! ! # P ` 2 ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 13 down ! ! ! ! ! ! ! ! ! ! ! ! ) ] Y I < ! ! ! ! ! ! ! ! ! ! !\n",
       " 14 down ! ! ! ! ! ! ! ! ! ! ! ! ! 5 ] ` ` > ' ! ! ! ! ! ! ! ! !\n",
       " 15 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! , O ` ` F ' ! ! ! ! ! ! ! !\n",
       " 16 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! % 8 ` ` O ! ! ! ! ! ! ! !\n",
       " 17 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! _ ` _ 1 ! ! ! ! ! ! !\n",
       " 18 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! , A N ` ` T ! ! ! ! ! ! ! !\n",
       " 19 down ! ! ! ! ! ! ! ! ! ! ! ! * F Z ` ` ` _ N ! ! ! ! ! ! ! !\n",
       " 20 down ! ! ! ! ! ! ! ! ! ! ' = X ` ` ` ` S 4 ! ! ! ! ! ! ! ! !\n",
       " 21 down ! ! ! ! ! ! ! ! & 1 V ` ` ` ` R 5 ! ! ! ! ! ! ! ! ! ! !\n",
       " 22 down ! ! ! ! ! ! % K W ` ` ` ` Q 5 # ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 23 down ! ! ! ! . L Y ` ` ` ` ^ B # ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 24 down ! ! ! ! C ` ` ` V B B % ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 25 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 26 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 27 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " ```\n",
       " - label: Just a number with the texts matching label.\n",
       " \tcitation: @dataset{dataset,\n",
       "     author = {Fraser Greenlee},\n",
       "     year = {2021},\n",
       "     month = {1},\n",
       "     pages = {},\n",
       "     title = {MNIST text dataset.},\n",
       "     doi = {}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 324\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/mnist-text-no-spaces\n",
       " \tsha: afa87a25d2d1e91a07e36508125359b66de9f909\n",
       " \tlastModified: 2021-02-05T16:03:35.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: MNIST dataset adapted to a text-based representation.\n",
       " \n",
       " This allows testing interpolation quality for Transformer-VAEs.\n",
       " \n",
       " System is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n",
       " \n",
       " Works by quantising each MNIST pixel into one of 64 characters.\n",
       " Every sample has an up & down version to encourage the model to learn rotation invarient features.\n",
       " \n",
       " Use `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n",
       " \n",
       " Removed spaces to get better BPE compression on sequences.\n",
       " **Should only be used with a trained tokenizer.**\n",
       " \n",
       " Data format:\n",
       " - text: (30 x 28 tokens, 840 tokens total): Textual representation of MNIST digit, for example:\n",
       " ```\n",
       " 00down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 01down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 02down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 03down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 04down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 05down!!!!!!!!!!!!!%%%@CL'Ja^@!!!!\n",
       " 06down!!!!!!!!(*8GK`````YL`]Q1!!!!\n",
       " 07down!!!!!!!-\\\\````````_855/*!!!!!\n",
       " 08down!!!!!!!%W`````RN^]!!!!!!!!!!\n",
       " 09down!!!!!!!!5H;``T#!+G!!!!!!!!!!\n",
       " 10down!!!!!!!!!$!G`7!!!!!!!!!!!!!!\n",
       " 11down!!!!!!!!!!!C`P!!!!!!!!!!!!!!\n",
       " 12down!!!!!!!!!!!#P`2!!!!!!!!!!!!!\n",
       " 13down!!!!!!!!!!!!)]YI<!!!!!!!!!!!\n",
       " 14down!!!!!!!!!!!!!5]``>'!!!!!!!!!\n",
       " 15down!!!!!!!!!!!!!!,O``F'!!!!!!!!\n",
       " 16down!!!!!!!!!!!!!!!%8``O!!!!!!!!\n",
       " 17down!!!!!!!!!!!!!!!!!_`_1!!!!!!!\n",
       " 18down!!!!!!!!!!!!!!,AN``T!!!!!!!!\n",
       " 19down!!!!!!!!!!!!*FZ```_N!!!!!!!!\n",
       " 20down!!!!!!!!!!'=X````S4!!!!!!!!!\n",
       " 21down!!!!!!!!&1V````R5!!!!!!!!!!!\n",
       " 22down!!!!!!%KW````Q5#!!!!!!!!!!!!\n",
       " 23down!!!!.LY````^B#!!!!!!!!!!!!!!\n",
       " 24down!!!!C```VBB%!!!!!!!!!!!!!!!!\n",
       " 25down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 26down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " 27down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       " ```\n",
       " - label: Just a number with the texts matching label.\n",
       " \tcitation: @dataset{dataset,\n",
       "     author = {Fraser Greenlee},\n",
       "     year = {2021},\n",
       "     month = {2},\n",
       "     pages = {},\n",
       "     title = {MNIST text dataset (no spaces).},\n",
       "     doi = {}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/mnist-text-small\n",
       " \tsha: da9c9262c1b62f55a948a194cba107448a7575c1\n",
       " \tlastModified: 2021-02-22T10:21:37.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: MNIST dataset adapted to a text-based representation.\n",
       " \n",
       " *Modified images to be ~1/4 the original area.*\n",
       " Done by taking a max pool.\n",
       " \n",
       " This allows testing interpolation quality for Transformer-VAEs.\n",
       " \n",
       " System is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n",
       " \n",
       " Works by quantising each MNIST pixel into one of 64 characters.\n",
       " Every sample has an up & down version to encourage the model to learn rotation invarient features.\n",
       " \n",
       " Use `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n",
       " \n",
       " Data format:\n",
       " - text: (16 x 14 tokens, 224 tokens total): Textual representation of MNIST digit, for example:\n",
       " ```\n",
       " 00 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 01 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " 02 down ! ! ! ! ! ! % % C L a ^ ! !\n",
       " 03 down ! ! ! - ` ` ` ` ` Y ` Q ! !\n",
       " 04 down ! ! ! % ` ` ` R ^ ! ! ! ! !\n",
       " 05 down ! ! ! ! $ G ` ! ! ! ! ! ! !\n",
       " 06 down ! ! ! ! ! # ` Y < ! ! ! ! !\n",
       " 07 down ! ! ! ! ! ! 5 ` ` F ! ! ! !\n",
       " 08 down ! ! ! ! ! ! ! % ` ` 1 ! ! !\n",
       " 09 down ! ! ! ! ! ! F ` ` ` ! ! ! !\n",
       " 10 down ! ! ! ! 1 ` ` ` ` 4 ! ! ! !\n",
       " 11 down ! ! L ` ` ` ` 5 ! ! ! ! ! !\n",
       " 12 down ! ! ` ` V B ! ! ! ! ! ! ! !\n",
       " 13 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
       " ```\n",
       " - label: Just a number with the texts matching label.\n",
       " \tcitation: @dataset{dataset,\n",
       "     author = {Fraser Greenlee},\n",
       "     year = {2021},\n",
       "     month = {1},\n",
       "     pages = {},\n",
       "     title = {MNIST small text dataset.},\n",
       "     doi = {}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/dream-coder\n",
       " \tsha: cd3a8930eecb7ea8d01fabd09353e70121223176\n",
       " \tlastModified: 2022-04-25T10:49:02.000Z\n",
       " \ttags: ['language:en', 'thumbnail:https://huggingface.co/datasets/Fraser/dream-coder/resolve/main/img.png', 'tags:program-synthesis', 'license:mit', 'datasets:program-synthesis']\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['en'], 'thumbnail': 'https://huggingface.co/datasets/Fraser/dream-coder/resolve/main/img.png', 'tags': ['program-synthesis'], 'license': 'mit', 'datasets': ['program-synthesis']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/python-lines\n",
       " \tsha: c1dd899291e00d83b4eecc9b1e02ae64b809ee2c\n",
       " \tlastModified: 2021-02-22T10:20:34.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: Dataset of single lines of Python code taken from the [CodeSearchNet](https://github.com/github/CodeSearchNet) dataset.\n",
       " \n",
       " Context\n",
       " \n",
       " This dataset allows checking the validity of Variational-Autoencoder latent spaces by testing what percentage of random/intermediate latent points can be greedily decoded into valid Python code.\n",
       " \n",
       " Content\n",
       " \n",
       " Each row has a parsable line of source code.\n",
       " {'text': '{python source code line}'}\n",
       " \n",
       " Most lines are < 100 characters while all are under 125 characters.\n",
       " \n",
       " Contains 2.6 million lines.\n",
       " \n",
       " All code is in parsable into a python3 ast.\n",
       " \tcitation: @dataset{dataset,\n",
       "     author = {Fraser Greenlee},\n",
       "     year = {2020},\n",
       "     month = {12},\n",
       "     pages = {},\n",
       "     title = {Python single line dataset.},\n",
       "     doi = {}\n",
       " }\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/python-state-changes\n",
       " \tsha: ef06b5d8cf560595e3812cff361f8c9be35714cd\n",
       " \tlastModified: 2022-10-11T17:04:35.000Z\n",
       " \ttags: ['language:code']\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: Python state changes from a single line of code.\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['code']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 482\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/short-jokes\n",
       " \tsha: 114769d1463bf9e45744be2b729b39dd06ded2c1\n",
       " \tlastModified: 2021-02-24T08:31:31.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: Copy of [Kaggle dataset](https://www.kaggle.com/abhinavmoudgil95/short-jokes), adding to Huggingface for ease of use.\n",
       " \n",
       " Description from Kaggle:\n",
       " \n",
       " Context\n",
       " \n",
       " Generating humor is a complex task in the domain of machine learning, and it requires the models to understand the deep semantic meaning of a joke in order to generate new ones. Such problems, however, are difficult to solve due to a number of reasons, one of which is the lack of a database that gives an elaborate list of jokes. Thus, a large corpus of over 0.2 million jokes has been collected by scraping several websites containing funny and short jokes.\n",
       " \n",
       " Visit my Github repository for more information regarding collection of data and the scripts used.\n",
       " \n",
       " Content\n",
       " \n",
       " This dataset is in the form of a csv file containing 231,657 jokes. Length of jokes ranges from 10 to 200 characters. Each line in the file contains a unique ID and joke.\n",
       " \n",
       " Disclaimer\n",
       " \n",
       " It has been attempted to keep the jokes as clean as possible. Since the data has been collected by scraping websites, it is possible that there may be a few jokes that are inappropriate or offensive to some people.\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 396\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Fraser/wiki_sentences\n",
       " \tsha: 7e4b5aadfd65fc31b5b0dd50f94f0857e040f0b1\n",
       " \tlastModified: 2021-07-21T07:43:08.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Fraser\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/ART\n",
       " \tsha: e9bea05e1d1441b4af92b2ca628e7609cb681674\n",
       " \tlastModified: 2022-09-03T18:26:45.000Z\n",
       " \ttags: ['arxiv:1908.05739', 'arxiv:1906.05317', 'annotations_creators:automatically-created', 'language_creators:unknown', 'language:en', 'license:apache-2.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:reasoning', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: the Abductive Natural Language Generation Dataset from AI2\n",
       " \tcitation: @InProceedings{anli,\n",
       "   author = {Chandra, Bhagavatula and Ronan, Le Bras and Chaitanya, Malaviya and Keisuke, Sakaguchi and Ari, Holtzman\n",
       "     and Hannah, Rashkin and Doug, Downey and Scott, Wen-tau Yih and Yejin, Choi},\n",
       "   title = {Abductive Commonsense Reasoning},\n",
       "   year = {2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['automatically-created'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['unknown'], 'pretty_name': 'ART', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['reasoning'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/BiSECT\n",
       " \tsha: 875b884d264ba3b0e7657432b8e963e1acefd723\n",
       " \tlastModified: 2022-09-02T21:58:17.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:de', 'language:en', 'language:fr', 'language:es', 'license:other', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:simplification', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: BiSECT is a Split and Rephrase corpus created via bilingual pivoting.\n",
       " \tcitation: @inproceedings{kim-etal-2021-bisect,\n",
       "     title = \"{B}i{SECT}: Learning to Split and Rephrase Sentences with Bitexts\",\n",
       "     author = \"Kim, Joongwon  and\n",
       "       Maddela, Mounica  and\n",
       "       Kriz, Reno  and\n",
       "       Xu, Wei  and\n",
       "       Callison-Burch, Chris\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = nov,\n",
       "     year = \"2021\",\n",
       "     address = \"Online and Punta Cana, Dominican Republic\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.emnlp-main.500\",\n",
       "     pages = \"6193--6209\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['de', 'en', 'fr', 'es'], 'license': ['other'], 'multilinguality': ['unknown'], 'pretty_name': 'BiSECT', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['simplification'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 892\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/CrossWOZ\n",
       " \tsha: 1a1b4d2cfc378228439774a2607a594161c500fa\n",
       " \tlastModified: 2022-09-03T18:26:47.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:zh', 'license:apache-2.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: CrossWOZ is the first large-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It contains 6K dialogue sessions and 102K utterances for 5 domains, including hotel, restaurant, attraction, metro, and taxi. Moreover, the corpus contains rich annotation of dialogue states and dialogue acts at both user and system sides.\n",
       " \tcitation: @article{zhu2020crosswoz,\n",
       "   author = {Qi Zhu and Kaili Huang and Zheng Zhang and Xiaoyan Zhu and Minlie Huang},\n",
       "   title = {Cross{WOZ}: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset},\n",
       "   journal = {Transactions of the Association for Computational Linguistics},\n",
       "   year = {2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['zh'], 'license': ['apache-2.0'], 'multilinguality': ['unknown'], 'pretty_name': 'CrossWOZ', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 328\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/OrangeSum\n",
       " \tsha: a31c7e3152cc0e15151549bf4f09d5a3438093ed\n",
       " \tlastModified: 2022-09-03T18:26:49.000Z\n",
       " \ttags: ['annotations_creators:unknown', 'language_creators:unknown', 'language:fr', 'license:other', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The OrangeSum dataset was inspired by the XSum dataset. It was created by scraping the \"Orange Actu\" website: https://actu.orange.fr/. Orange S.A. is a large French multinational telecommunications corporation, with 266M customers worldwide. Scraped pages cover almost a decade from Feb 2011 to Sep 2020. They belong to five main categories: France, world, politics, automotive, and society. The society category is itself divided into 8 subcategories: health, environment, people, culture, media, high-tech, unsual (\"insolite\" in French), and miscellaneous.\n",
       " \n",
       " Each article featured a single-sentence title as well as a very brief abstract, both professionally written by the author of the article. These two fields were extracted from each page, thus creating two summarization tasks: OrangeSum Title and OrangeSum Abstract.\n",
       " \tcitation: @inproceedings{kamal-eddine-etal-2021-barthez,\n",
       "     title = \"{BART}hez: a Skilled Pretrained {F}rench Sequence-to-Sequence Model\",\n",
       "     author = \"Kamal Eddine, Moussa  and\n",
       "       Tixier, Antoine  and\n",
       "       Vazirgiannis, Michalis\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = nov,\n",
       "     year = \"2021\",\n",
       "     address = \"Online and Punta Cana, Dominican Republic\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.emnlp-main.740\",\n",
       "     pages = \"9369--9390\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['unknown'], 'language_creators': ['unknown'], 'language': ['fr'], 'license': ['other'], 'multilinguality': ['unknown'], 'pretty_name': 'OrangeSum', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 601\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/RiSAWOZ\n",
       " \tsha: 44de907bff9ca671833067267f6ca52d3aa101ac\n",
       " \tlastModified: 2022-09-03T18:26:50.000Z\n",
       " \ttags: ['annotations_creators:crowd-sourced', 'language_creators:unknown', 'language:zh', 'license:cc-by-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets.Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively.\n",
       " \tcitation: @inproceedings{quan-etal-2020-risawoz,\n",
       "     title = \"{R}i{SAWOZ}: A Large-Scale Multi-Domain {W}izard-of-{O}z Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling\",\n",
       "     author = \"Quan, Jun  and\n",
       "       Zhang, Shian  and\n",
       "       Cao, Qian  and\n",
       "       Li, Zizhong  and\n",
       "       Xiong, Deyi\",\n",
       "     booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.emnlp-main.67\",\n",
       "     pages = \"930--940\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowd-sourced'], 'language_creators': ['unknown'], 'language': ['zh'], 'license': ['cc-by-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'RiSAWOZ', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 327\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/RotoWire_English-German\n",
       " \tsha: 2a59a372dabef05287edd6c5b1258757eaf2a938\n",
       " \tlastModified: 2022-09-03T18:26:52.000Z\n",
       " \ttags: ['annotations_creators:automatically-created', 'language_creators:unknown', 'language:en', 'language:de', 'license:cc-by-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: Dataset for the WNGT 2019 DGT shared task on \"Document-Level Generation and Translation”.\n",
       " \tcitation: @article{hayashi2019findings,\n",
       "   title={Findings of the Third Workshop on Neural Generation and Translation},\n",
       "   author={Hayashi, Hiroaki and Oda, Yusuke and Birch, Alexandra and Konstas, Ioannis and Finch, Andrew and Luong, Minh-Thang and Neubig, Graham and Sudoh, Katsuhito},\n",
       "   journal={EMNLP-IJCNLP 2019},\n",
       "   pages={1},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['automatically-created'], 'language_creators': ['unknown'], 'language': ['en', 'de'], 'license': ['cc-by-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'RotoWire_English-German', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/SIMPITIKI\n",
       " \tsha: 2d746beab26033fe6c1348c954ad7e40840133ba\n",
       " \tlastModified: 2022-09-03T18:26:54.000Z\n",
       " \ttags: ['annotations_creators:crowd-sourced', 'language_creators:unknown', 'language:it', 'license:cc-by-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:simplification', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: SIMPITIKI is a Simplification corpus for Italian and it consists of two sets of simplified pairs: the first one is harvested from the Italian Wikipedia in a semi-automatic way; the second one is manually annotated sentence-by-sentence from documents in the administrative domain.\n",
       " \tcitation: @article{tonelli2016simpitiki,\n",
       "   title={SIMPITIKI: a Simplification corpus for Italian},\n",
       "   author={Tonelli, Sara and Aprosio, Alessio Palmero and Saltori, Francesca},\n",
       "   journal={Proceedings of CLiC-it},\n",
       "   year={2016}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowd-sourced'], 'language_creators': ['unknown'], 'language': ['it'], 'license': ['cc-by-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'SIMPITIKI', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['simplification'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 178\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/SciDuet\n",
       " \tsha: 7dacf72c053678b4a0e4bfb3556fdbe15cc6c1eb\n",
       " \tlastModified: 2022-09-03T18:26:56.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:apache-2.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:text-to-slide', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: SciDuet is the first publicaly available dataset for the challenging task of document2slides generation,\n",
       " The dataset integrated into GEM is the ACL portion of the whole dataset described in \"https://aclanthology.org/2021.naacl-main.111.pdf\".\n",
       " It contains the full Dev and Test sets, and a portion of the Train dataset. \n",
       " We additionally create a challenge dataset in which the slide titles do not match with the \n",
       " section headers of the corresponding paper.\n",
       " Note that although we cannot release the whole training dataset due to copyright issues, researchers can still \n",
       " use our released data procurement code from https://github.com/IBM/document2slides\n",
       " to generate the training dataset from the online ICML/NeurIPS anthologies. \n",
       " In the released dataset, the original papers and slides (both are in PDF format) are carefully processed by a combination of PDF/Image processing tookits.\n",
       " The text contents from multiple slides that correspond to the same slide title are mreged.\n",
       " \tcitation: @inproceedings{sun-etal-2021-d2s,\n",
       "     title = \"{D}2{S}: Document-to-Slide Generation Via Query-Based Text Summarization\",\n",
       "     author = \"Sun, Edward  and\n",
       "       Hou, Yufang  and\n",
       "       Wang, Dakuo  and\n",
       "       Zhang, Yunfeng  and\n",
       "       Wang, Nancy X. R.\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n",
       "     month = June,\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.naacl-main.111\",\n",
       "     doi = \"10.18653/v1/2021.naacl-main.111\",\n",
       "     pages = \"1405--1418\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['unknown'], 'pretty_name': 'SciDuet', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['text-to-slide'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/Taskmaster\n",
       " \tsha: c1ca7f8040468ea252ab4e99f55eb827a5c43d94\n",
       " \tlastModified: 2022-09-03T18:26:57.000Z\n",
       " \ttags: ['arxiv:2012.12458', 'annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The Taskmaster-3 (aka TicketTalk) dataset consists of 23,789 movie ticketing dialogs\n",
       " (located in Taskmaster/TM-3-2020/data/). By \"movie ticketing\" we mean conversations\n",
       " where the customer's goal is to purchase tickets after deciding on theater, time,\n",
       " movie name, number of tickets, and date, or opt out of the transaction.\n",
       " The columns are gem_id, 0, 1 for serial numbering, 2 for the text dialog and id\n",
       " for the default id by the authors.\n",
       " \tcitation: @article{byrne2020tickettalk,\n",
       "   title={TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems},\n",
       "   author={Byrne, Bill and Krishnamoorthi, Karthik and Ganesh, Saravanan and Kale, Mihir Sanjay},\n",
       "   journal={arXiv preprint arXiv:2012.12458},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'Taskmaster', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/cochrane-simplification\n",
       " \tsha: 21a66d41c3730de50227fdf3e0f8cc354c16ee74\n",
       " \tlastModified: 2022-09-03T18:26:59.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:simplification', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: This dataset measures the ability for a model to simplify paragraphs of medical text through the omission non-salient information and simplification of medical jargon.\n",
       " \tcitation: @inproceedings{devaraj-etal-2021-paragraph,\n",
       "     title = \"Paragraph-level Simplification of Medical Texts\",\n",
       "     author = \"Devaraj, Ashwin  and\n",
       "       Marshall, Iain  and\n",
       "       Wallace, Byron  and\n",
       "       Li, Junyi Jessy\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n",
       "     month = jun,\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.naacl-main.395\",\n",
       "     doi = \"10.18653/v1/2021.naacl-main.395\",\n",
       "     pages = \"4972--4984\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'cochrane-simplification', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['simplification'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/common_gen\n",
       " \tsha: cbbe64474a35a0c6a3250c1297e72c423048d90c\n",
       " \tlastModified: 2022-09-03T18:27:00.000Z\n",
       " \ttags: ['arxiv:1911.03705', 'arxiv:1910.13461', 'arxiv:2009.12677', 'arxiv:2012.00366', 'arxiv:1910.10683', 'arxiv:2006.08315', 'annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:mit', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:reasoning', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: CommonGen is a constrained text generation task, associated with a benchmark\n",
       " dataset, to explicitly test machines for the ability of generative commonsense\n",
       " reasoning. Given a set of common concepts; the task is to generate a coherent\n",
       " sentence describing an everyday scenario using these concepts.\n",
       " \tcitation: @inproceedings{lin-etal-2020-commongen,\n",
       "     title = \"{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\n",
       "     author = \"Lin, Bill Yuchen  and\n",
       "       Zhou, Wangchunshu  and\n",
       "       Shen, Ming  and\n",
       "       Zhou, Pei  and\n",
       "       Bhagavatula, Chandra  and\n",
       "       Choi, Yejin  and\n",
       "       Ren, Xiang\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.165\",\n",
       "     pages = \"1823--1840\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['unknown'], 'pretty_name': 'common_gen', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['reasoning'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/conversational_weather\n",
       " \tsha: f1e057a90904e6c0627d85b89cde376f61e30c5c\n",
       " \tlastModified: 2022-09-03T18:27:02.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The Conversational Weather dataset is designed for generation of responses to weather queries based on a structured input data. The input allows specifying data attributes such as dates, times, locations, weather conditions, and errors, and also offers control over structure of response through discourse relations such as join, contrast, and justification.\n",
       " \tcitation: @inproceedings{balakrishnan-etal-2019-constrained,\n",
       "   title = \"Constrained Decoding for Neural {NLG} from Compositional Representations in Task-Oriented Dialogue\",\n",
       "   author = \"Balakrishnan, Anusha  and\n",
       "     Rao, Jinfeng  and\n",
       "     Upasani, Kartikeya  and\n",
       "     White, Michael  and\n",
       "     Subba, Rajen\",\n",
       "   booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "   month = jul,\n",
       "   year = \"2019\",\n",
       "   address = \"Florence, Italy\",\n",
       "   publisher = \"Association for Computational Linguistics\",\n",
       "   url = \"https://www.aclweb.org/anthology/P19-1080\",\n",
       "   doi = \"10.18653/v1/P19-1080\",\n",
       "   pages = \"831--844\"\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'conversational_weather', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 482\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/cs_restaurants\n",
       " \tsha: 5e46551fa681f170256de18e73ac951fc59eaae1\n",
       " \tlastModified: 2022-09-03T18:19:28.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:cs', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The task is generating responses in the context of a (hypothetical) dialogue\n",
       " system that provides information about restaurants. The input is a basic\n",
       " intent/dialogue act type and a list of slots (attributes) and their values.\n",
       " The output is a natural language sentence.\n",
       " \tcitation: @inproceedings{cs_restaurants,\n",
       " \taddress = {Tokyo, Japan},\n",
       " \ttitle = {Neural {Generation} for {Czech}: {Data} and {Baselines}},\n",
       " \tshorttitle = {Neural {Generation} for {Czech}},\n",
       " \turl = {https://www.aclweb.org/anthology/W19-8670/},\n",
       " \turldate = {2019-10-18},\n",
       " \tbooktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},\n",
       " \tauthor = {Dušek, Ondřej and Jurčíček, Filip},\n",
       " \tmonth = oct,\n",
       " \tyear = {2019},\n",
       " \tpages = {563--574},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['cs'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'cs_restaurants', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/dart\n",
       " \tsha: 353c5ec8ca0de8e22cc4b1af3ece17e33af835ca\n",
       " \tlastModified: 2022-09-03T18:27:07.000Z\n",
       " \ttags: ['arxiv:1910.13461', 'arxiv:1908.09022', 'arxiv:2007.02871', 'arxiv:1709.00103', 'arxiv:1706.09254', 'arxiv:1810.01170', 'annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:mit', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: DART is a large and open-domain structured DAta Record to Text generation corpus\n",
       " with high-quality sentence annotations with each input being a set of\n",
       " entity-relation triples following a tree-structured ontology. It consists of\n",
       " 82191 examples across different domains with each input being a semantic RDF\n",
       " triple set derived from data records in tables and the tree ontology of table\n",
       " schema, annotated with sentence description that covers all facts in the triple set.\n",
       " \tcitation: @inproceedings{nan-etal-2021-dart,\n",
       "     title = \"{DART}: Open-Domain Structured Data Record to Text Generation\",\n",
       "     author = \"Nan, Linyong  and\n",
       "       Radev, Dragomir  and\n",
       "       Zhang, Rui  and\n",
       "       Rau, Amrit  and\n",
       "       Sivaprasad, Abhinand  and\n",
       "       Hsieh, Chiachun  and\n",
       "       Tang, Xiangru  and\n",
       "       Vyas, Aadit  and\n",
       "       Verma, Neha  and\n",
       "       Krishna, Pranav  and\n",
       "       Liu, Yangxiaokang  and\n",
       "       Irwanto, Nadia  and\n",
       "       Pan, Jessica  and\n",
       "       Rahman, Faiaz  and\n",
       "       Zaidi, Ahmad  and\n",
       "       Mutuma, Mutethia  and\n",
       "       Tarabar, Yasin  and\n",
       "       Gupta, Ankit  and\n",
       "       Yu, Tao  and\n",
       "       Tan, Yi Chern  and\n",
       "       Lin, Xi Victoria  and\n",
       "       Xiong, Caiming  and\n",
       "       Socher, Richard  and\n",
       "       Rajani, Nazneen Fatema\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n",
       "     month = jun,\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.naacl-main.37\",\n",
       "     doi = \"10.18653/v1/2021.naacl-main.37\",\n",
       "     pages = \"432--447\",\n",
       "     abstract = \"We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['unknown'], 'pretty_name': 'dart', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 422\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/dstc10_track2_task2\n",
       " \tsha: b9b77f5cd3b965c4a9759e48665d1252b8c6c9c8\n",
       " \tlastModified: 2022-09-03T18:27:30.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:apache-2.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: \\\n",
       " \tcitation: @article{kim2020domain,\n",
       "   title={Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access},\n",
       "   author={Seokhwan Kim and Mihail Eric and Karthik Gopalakrishnan and Behnam Hedayatnia and Yang Liu and Dilek Hakkani-Tur},\n",
       "   journal={arXiv preprint arXiv:2006.03533}\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['apache-2.0'], 'multilinguality': ['unknown'], 'pretty_name': 'dstc10_track2_task2', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 334\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/e2e_nlg\n",
       " \tsha: 8d236576312dfe28580ad4ec8108b0c2b760d4f1\n",
       " \tlastModified: 2022-09-03T18:19:01.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The E2E dataset is designed for a limited-domain data-to-text task --\n",
       " generation of restaurant descriptions/recommendations based on up to 8 different\n",
       " attributes (name, area, price range etc.).\n",
       " \tcitation: @inproceedings{e2e_cleaned,\n",
       " \taddress = {Tokyo, Japan},\n",
       " \ttitle = {Semantic {Noise} {Matters} for {Neural} {Natural} {Language} {Generation}},\n",
       " \turl = {https://www.aclweb.org/anthology/W19-8652/},\n",
       " \tbooktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},\n",
       " \tauthor = {Dušek, Ondřej and Howcroft, David M and Rieser, Verena},\n",
       " \tyear = {2019},\n",
       " \tpages = {421--426},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'e2e_nlg', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 734\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/indonlg\n",
       " \tsha: 80f294e3a562b1ae29a45ee6acf2f0130a3d9619\n",
       " \tlastModified: 2022-06-29T16:35:12.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'languages:unknown', 'licenses:mit', 'multilinguality:unknown', 'pretty_name:indonlg', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The IndoNLG benchmark is a collection of resources for training, evaluating, and analyzing natural language generation systems for Indonesian, Javanese, and Sundanese.\n",
       " \tcitation: @inproceedings{cahyawijaya-etal-2021-indonlg,\n",
       "     title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n",
       "     author = \"Cahyawijaya, Samuel  and\n",
       "       Winata, Genta Indra  and\n",
       "       Wilie, Bryan  and\n",
       "       Vincentio, Karissa  and\n",
       "       Li, Xiaohong  and\n",
       "       Kuncoro, Adhiguna  and\n",
       "       Ruder, Sebastian  and\n",
       "       Lim, Zhi Yuan  and\n",
       "       Bahar, Syafri  and\n",
       "       Khodra, Masayu  and\n",
       "       Purwarianti, Ayu  and\n",
       "       Fung, Pascale\",\n",
       "     booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = nov,\n",
       "     year = \"2021\",\n",
       "     address = \"Online and Punta Cana, Dominican Republic\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.emnlp-main.699\",\n",
       "     pages = \"8875--8898\",\n",
       "     abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'languages': ['unknown'], 'licenses': ['mit'], 'multilinguality': ['unknown'], 'pretty_name': 'indonlg', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: True\n",
       " \tdownloads: 13\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/mlb_data_to_text\n",
       " \tsha: c109512d06043bde7b723c9871996e36d77adb7a\n",
       " \tlastModified: 2022-09-03T18:27:29.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:other', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The MLB dataset for data to text generation contains Major League Baseball games statistics and \n",
       " their human-written summaries.\n",
       " \tcitation: @inproceedings{puduppully-etal-2019-data,\n",
       "     title = \"Data-to-text Generation with Entity Modeling\",\n",
       "     author = \"Puduppully, Ratish  and\n",
       "       Dong, Li  and\n",
       "       Lapata, Mirella\",\n",
       "     booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2019\",\n",
       "     address = \"Florence, Italy\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/P19-1195\",\n",
       "     doi = \"10.18653/v1/P19-1195\",\n",
       "     pages = \"2023--2035\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['unknown'], 'pretty_name': 'mlb_data_to_text', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 351\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/mlsum\n",
       " \tsha: 432cc513d830d9b805d197693fb95ca69e6d0600\n",
       " \tlastModified: 2022-09-03T18:27:28.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:de', 'language:es', 'license:other', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: This is the MLSUM subset of the GEM benchmark. MLSUM is the first large-scale MultiLingual SUMmarization dataset.\n",
       " Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish.\n",
       " Together with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community.\n",
       " We report cross-lingual comparative analyses based on state-of-the-art systems.\n",
       " These highlight existing biases which motivate the use of a multi-lingual dataset.\n",
       " \tcitation: @article{scialom2020mlsum,\n",
       "   title={MLSUM: The Multilingual Summarization Corpus},\n",
       "   author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},\n",
       "   journal={arXiv preprint arXiv:2004.14900},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['de', 'es'], 'license': ['other'], 'multilinguality': ['unknown'], 'pretty_name': 'mlsum', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 488\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/opusparcus\n",
       " \tsha: 3cb27f45cb2c868d986cc4f614d1d397de7f021e\n",
       " \tlastModified: 2022-09-03T18:26:35.000Z\n",
       " \ttags: ['annotations_creators:expert-created', 'language_creators:unknown', 'language:de', 'language:en', 'language:fi', 'language:fr', 'language:ru', 'language:sv', 'license:cc-by-nc-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:paraphrasing', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: Opusparcus is a paraphrase corpus for six European languages: German,\n",
       " English, Finnish, French, Russian, and Swedish. The paraphrases are\n",
       " extracted from the OpenSubtitles2016 corpus, which contains subtitles\n",
       " from movies and TV shows.\n",
       " \tcitation: @InProceedings{creutz:lrec2018,\n",
       "   title = {Open Subtitles Paraphrase Corpus for Six Languages},\n",
       "   author={Mathias Creutz},\n",
       "   booktitle={Proceedings of the 11th edition of the Language Resources\n",
       "   and Evaluation Conference (LREC 2018)},\n",
       "   year={2018},\n",
       "   month = {May 7-12},\n",
       "   address = {Miyazaki, Japan},\n",
       "   editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri\n",
       "   and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti\n",
       "   Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and\n",
       "   Hélène Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis\n",
       "   and Takenobu Tokunaga},\n",
       "   publisher = {European Language Resources Association (ELRA)},\n",
       "   isbn = {979-10-95546-00-9},\n",
       "   language = {english},\n",
       "   url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/131.pdf}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-created'], 'language_creators': ['unknown'], 'language': ['de', 'en', 'fi', 'fr', 'ru', 'sv'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'opusparcus', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['paraphrasing'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 8532\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/references\n",
       " \tsha: 97e4c5cebd637f24fa1319b5fbea008b8bd7f04b\n",
       " \tlastModified: 2022-06-23T19:32:57.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 329\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/schema_guided_dialog\n",
       " \tsha: 9cb9d9b92e9299e3b120296619b5ca4381fcc136\n",
       " \tlastModified: 2022-09-03T18:27:10.000Z\n",
       " \ttags: ['arxiv:1909.05855', 'arxiv:2004.15006', 'arxiv:2002.01359', 'annotations_creators:crowd-sourced', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:dialog-response-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The Schema-Guided Dialogue (SGD) dataset contains 18K multi-domain task-oriented\n",
       " dialogues between a human and a virtual assistant, which covers 17 domains\n",
       " ranging from banks and events to media, calendar, travel, and weather. The\n",
       " language presents in the datset is only English. The SGD dataset provides a\n",
       " challenging testbed for a number of tasks in task-oriented dialogue, including\n",
       " language understanding, slot filling, dialogue state tracking and response\n",
       " generation. For the creation of the SGD dataset, they developed a multi-domain\n",
       " dialogue simulator that generates dialogue outlines over an arbitrary combination\n",
       " of APIs, dialogue states and system actions. Then, they used a crowd-sourcing\n",
       " procedure to paraphrase these outlines to natural language utterances. This novel\n",
       " crowd-sourcing procedure preserves all annotations obtained from the simulator and\n",
       " does not require any extra annotations after dialogue collection.\n",
       " \tcitation: @inproceedings{rastogi2020towards,\n",
       "   title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},\n",
       "   author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},\n",
       "   booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
       "   volume={34},\n",
       "   number={05},\n",
       "   pages={8689--8696},\n",
       "   year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowd-sourced'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'schema_guided_dialog', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['dialog-response-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/sportsett_basketball\n",
       " \tsha: 4dc398138dc1dca2ed7ed75b80828f8e12ecfa92\n",
       " \tlastModified: 2022-09-03T18:26:42.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:mit', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: SportSett:Basketball dataset for Data-to-Text Generation contains NBA games stats aligned with their human written summaries.\n",
       " \tcitation: @inproceedings{thomson-etal-2020-sportsett,\n",
       "     title = \"{S}port{S}ett:Basketball - A robust and maintainable data-set for Natural Language Generation\",\n",
       "     author = \"Thomson, Craig  and\n",
       "       Reiter, Ehud  and\n",
       "       Sripada, Somayajulu\",\n",
       "     booktitle = \"Proceedings of the Workshop on Intelligent Information Processing and Natural Language Generation\",\n",
       "     month = sep,\n",
       "     year = \"2020\",\n",
       "     address = \"Santiago de Compostela, Spain\",\n",
       "     publisher = \"Association for Computational Lingustics\",\n",
       "     url = \"https://aclanthology.org/2020.intellang-1.4\",\n",
       "     pages = \"32--40\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['mit'], 'multilinguality': ['unknown'], 'pretty_name': 'sportsett_basketball', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/squad_v2\n",
       " \tsha: d469483865e7677f15c8ffcfbd6a3845dc941404\n",
       " \tlastModified: 2022-09-03T18:27:26.000Z\n",
       " \ttags: ['arxiv:1806.03822', 'annotations_creators:crowd-sourced', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:question-generation', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription:  SQuAD2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers\n",
       "  to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but\n",
       "  also determine when no answer is supported by the paragraph and abstain from answering.\n",
       " \tcitation: @article{2016arXiv160605250R,\n",
       "        author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
       "                  Konstantin and {Liang}, Percy},\n",
       "         title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
       "       journal = {arXiv e-prints},\n",
       "          year = 2016,\n",
       "           eid = {arXiv:1606.05250},\n",
       "         pages = {arXiv:1606.05250},\n",
       " archivePrefix = {arXiv},\n",
       "        eprint = {1606.05250},\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowd-sourced'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'squad_v2', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['question-generation'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 928\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/surface_realisation_st_2020\n",
       " \tsha: 95e0a25d0d3138eff56b7d1a87369f47c65cd8f1\n",
       " \tlastModified: 2022-09-02T21:58:03.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:ar', 'language:zh', 'language:en', 'language:fr', 'language:hi', 'language:id', 'language:ja', 'language:ko', 'language:pt', 'language:ru', 'language:es', 'license:cc-by-2.5', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['ar', 'zh', 'en', 'fr', 'hi', 'id', 'ja', 'ko', 'pt', 'ru', 'es'], 'license': ['cc-by-2.5'], 'multilinguality': ['unknown'], 'pretty_name': 'surface_realisation_st_2020', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/totto\n",
       " \tsha: dee70745aa3274bdbd1670d5303df7d62cee3e28\n",
       " \tlastModified: 2022-09-03T18:27:25.000Z\n",
       " \ttags: ['arxiv:1603.07771', 'arxiv:2007.02871', 'arxiv:2005.10433', 'annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: ToTTo is an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description.\n",
       " \tcitation: \\@inproceedings{parikh2020totto,\n",
       " title={{ToTTo}: A Controlled Table-To-Text Generation Dataset},\n",
       " author={Parikh, Ankur P and Wang, Xuezhi and Gehrmann, Sebastian and Faruqui, Manaal and Dhingra, Bhuwan and Yang, Diyi and Das, Dipanjan},\n",
       " booktitle={Proceedings of EMNLP},\n",
       " year={2020}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['unknown'], 'pretty_name': 'totto', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 360\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/turku_hockey_data2text\n",
       " \tsha: c16d34bb5e22bd81c428c01cad64282730235357\n",
       " \tlastModified: 2022-09-03T18:27:23.000Z\n",
       " \ttags: ['annotations_creators:expert-created', 'language_creators:unknown', 'language:fi', 'license:cc-by-nc-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: The Turku Hockey Data2Text corpus was developed as a benchmark for evaluating template-free, machine learning methods on Finnish news generation in the area of ice hockey reporting. This dataset is a collection of 3,454 ice hockey games, each including game statistics and a news article describing the game. Each game includes manual alignment of events (such as goals or penalties) and sentences describing the specific event in natural language extracted from the news article. The corpus includes 12,827 annotated events. The natural language passages are manually curated not to include any information not derivable from the input data or world knowledge.\n",
       " \tcitation: @inproceedings{kanerva2019newsgen,\n",
       "   Title = {Template-free Data-to-Text Generation of Finnish Sports News},\n",
       "   Author = {Jenna Kanerva and Samuel R{\\\"o}nnqvist and Riina Kekki and Tapio Salakoski and Filip Ginter},\n",
       "   booktitle = {Proceedings of the 22nd Nordic Conference on Computational Linguistics (NoDaLiDa’19)},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-created'], 'language_creators': ['unknown'], 'language': ['fi'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'turku_hockey_data2text', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 512\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/turku_paraphrase_corpus\n",
       " \tsha: 61f423ae4fb3374b58680c787bd3f71673029fd7\n",
       " \tlastModified: 2022-09-03T18:27:21.000Z\n",
       " \ttags: ['annotations_creators:expert-created', 'language_creators:unknown', 'language:fi', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:paraphrasing', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: Turku Paraphrase Corpus is a dataset of 104,645 manually annotated Finnish paraphrases. The vast majority of the data is classified as a paraphrase either in the given context, or universally.\n",
       " \tcitation: @inproceedings{kanerva-etal-2021-finnish,\n",
       "   title = {Finnish Paraphrase Corpus},\n",
       "   author = {Kanerva, Jenna and Ginter, Filip and Chang, Li-Hsin and Rastas, Iiro and Skantsi, Valtteri and Kilpeläinen, Jemina and Kupari, Hanna-Mari and Saarni, Jenna and Sevón, Maija and Tarkka, Otto},\n",
       "   booktitle = {Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa'21)},\n",
       "   year = {2021},\n",
       "   publisher = {Linköping University Electronic Press, Sweden},\n",
       "   url = {https://aclanthology.org/2021.nodalida-main.29},\n",
       "   pages = {288--298}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-created'], 'language_creators': ['unknown'], 'language': ['fi'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'turku_paraphrase_corpus', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['paraphrasing'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 684\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/viggo\n",
       " \tsha: 4c3b5b13f0a19113fc6c2edd6c60d5c0a21db316\n",
       " \tlastModified: 2022-09-03T18:27:22.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: ViGGO was designed for the task of data-to-text generation in chatbots (as opposed to task-oriented dialogue systems), with target responses being more conversational than information-seeking, yet constrained to the information presented in a meaning representation. The dataset, being relatively small and clean, can also serve for demonstrating transfer learning capabilities of neural models.\n",
       " \tcitation: @inproceedings{juraska-etal-2019-viggo,\n",
       "     title = \"{V}i{GGO}: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation\",\n",
       "     author = \"Juraska, Juraj  and\n",
       "       Bowden, Kevin  and\n",
       "       Walker, Marilyn\",\n",
       "     booktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\n",
       "     month = oct # \"{--}\" # nov,\n",
       "     year = \"2019\",\n",
       "     address = \"Tokyo, Japan\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/W19-8623\",\n",
       "     doi = \"10.18653/v1/W19-8623\",\n",
       "     pages = \"164--172\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'viggo', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/web_nlg\n",
       " \tsha: ef0e834df6eaa73953a35956011ac1b234b10e9a\n",
       " \tlastModified: 2022-09-03T18:26:40.000Z\n",
       " \ttags: ['annotations_creators:unknown', 'language_creators:unknown', 'language:en', 'license:cc-by-nc-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:data-to-text', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: WebNLG is a bi-lingual dataset (English, Russian) of parallel DBpedia triple sets\n",
       " and short texts that cover about 450 different DBpedia properties. The WebNLG data\n",
       " was originally created to promote the development of RDF verbalisers able to\n",
       " generate short text and to handle micro-planning (i.e., sentence segmentation and\n",
       " ordering, referring expression generation, aggregation); the goal of the task is\n",
       " to generate texts starting from 1 to 7 input triples which have entities in common\n",
       " (so the input is actually a connected Knowledge Graph). The dataset contains about\n",
       " 17,000 triple sets and 45,000 crowdsourced texts in English, and 7,000 triples sets\n",
       " and 19,000 crowdsourced texts in Russian. A challenging test set section with\n",
       " entities and/or properties that have not been seen at training time is available.\n",
       " \tcitation: @inproceedings{castro-ferreira20:bilin-bi-direc-webnl-shared,\n",
       "   title={The 2020 Bilingual, Bi-Directional WebNLG+ Shared Task Overview and Evaluation Results (WebNLG+ 2020)},\n",
       "   author={Castro Ferreira, Thiago and\n",
       "                   Gardent, Claire and\n",
       " \t\t  Ilinykh, Nikolai and\n",
       " \t\t  van der Lee, Chris and\n",
       " \t\t  Mille, Simon and\n",
       " \t\t  Moussallem, Diego and\n",
       " \t\t  Shimorina, Anastasia},\n",
       "   booktitle = {Proceedings of the 3rd WebNLG Workshop on Natural Language Generation from the Semantic Web (WebNLG+ 2020)},\n",
       "     pages = \"55--76\",\n",
       "   year = \t 2020,\n",
       "   address = \t {Dublin, Ireland (Virtual)},\n",
       "   publisher = {Association for Computational Linguistics}}\n",
       " \tcardData: {'annotations_creators': ['unknown'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-nc-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'web_nlg', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['data-to-text'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1268\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/wiki_auto_asset_turk\n",
       " \tsha: 2c4bbcfa70307fda96066a7e04813174de0fee33\n",
       " \tlastModified: 2022-09-03T18:27:19.000Z\n",
       " \ttags: ['arxiv:1910.02677', 'arxiv:2005.00352', 'annotations_creators:crowd-sourced', 'language_creators:unknown', 'language:en', 'license:other', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:simplification', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: WikiAuto provides a set of aligned sentences from English Wikipedia and Simple\n",
       " English Wikipedia as a resource to train sentence simplification systems.\n",
       " \n",
       " The authors first crowd-sourced a set of manual alignments between sentences in\n",
       " a subset of the Simple English Wikipedia and their corresponding versions in\n",
       " English Wikipedia (this corresponds to the manual config in this version of the\n",
       " dataset), then trained a neural CRF system to predict these alignments.\n",
       " \n",
       " The trained alignment prediction model was then applied to the other articles in\n",
       " Simple English Wikipedia with an English counterpart to create a larger corpus\n",
       " of aligned sentences (corresponding to the auto and auto_acl configs here).\n",
       " \tcitation: @inproceedings{jiang-etal-2020-neural,\n",
       "     title = \"Neural {CRF} Model for Sentence Alignment in Text Simplification\",\n",
       "     author = \"Jiang, Chao  and\n",
       "       Maddela, Mounica  and\n",
       "       Lan, Wuwei  and\n",
       "       Zhong, Yang  and\n",
       "       Xu, Wei\",\n",
       "     booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n",
       "     month = jul,\n",
       "     year = \"2020\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://www.aclweb.org/anthology/2020.acl-main.709\",\n",
       "     doi = \"10.18653/v1/2020.acl-main.709\",\n",
       "     pages = \"7943--7960\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['crowd-sourced'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['other'], 'multilinguality': ['unknown'], 'pretty_name': 'wiki_auto_asset_turk', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['simplification'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 1045\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/wiki_cat_sum\n",
       " \tsha: 740b92e5b00080ade20c3b34032cc7d79e5ceaeb\n",
       " \tlastModified: 2022-09-03T18:26:44.000Z\n",
       " \ttags: ['arxiv:1906.04687', 'arxiv:1801.10198', 'arxiv:2009.07032', 'annotations_creators:automatically-created', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-3.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: Summarise the most important facts of a given entity in the Film, Company, and Animal domains from a cluster of related documents.\n",
       " \tcitation: @inproceedings{perez2019generating,\n",
       "   title={Generating Summaries with Topic Templates and Structured Convolutional Decoders},\n",
       "   author={Perez-Beltrachini, Laura and Liu, Yang and Lapata, Mirella},\n",
       "   booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n",
       "   pages={5107--5116},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['automatically-created'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-3.0'], 'multilinguality': ['unknown'], 'pretty_name': 'wiki_cat_sum', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 705\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/wiki_lingua\n",
       " \tsha: cd4eb0b2e468442afbda737e261546255f4e59e4\n",
       " \tlastModified: 2022-08-25T17:31:46.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:ar', 'language:cs', 'language:de', 'language:en', 'language:es', 'language:fr', 'language:hi', 'language:id', 'language:it', 'language:ja', 'language:ko', 'language:nl', 'language:pt', 'language:ru', 'language:th', 'language:tr', 'language:vi', 'language:zh', 'license:cc-by-3.0', 'multilinguality:multilingual', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: WikiLingua is a large-scale multilingual dataset for the evaluation of\n",
       " crosslingual abstractive summarization systems. The dataset includes ~770k\n",
       " article and summary pairs in 18 languages from WikiHow. The gold-standard\n",
       " article-summary alignments across languages was done by aligning the images\n",
       " that are used to describe each how-to step in an article.\n",
       " \tcitation: @article{ladhak-wiki-2020,\n",
       "   title   = {WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\n",
       "   authors = {Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\n",
       "   journal = {arXiv preprint arXiv:2010.03093},\n",
       "   year    = {2020},\n",
       "   url     = {https://arxiv.org/abs/2010.03093}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['ar', 'cs', 'de', 'en', 'es', 'fr', 'hi', 'id', 'it', 'ja', 'ko', 'nl', 'pt', 'ru', 'th', 'tr', 'vi', 'zh'], 'license': ['cc-by-3.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'wiki_lingua', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 53845\n",
       " \tlikes: 4\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/xlsum\n",
       " \tsha: 1f20af436bc42b0bfbfc8e5bd651b74e4b121b35\n",
       " \tlastModified: 2022-09-19T12:32:04.000Z\n",
       " \ttags: ['arxiv:1607.01759', 'annotations_creators:none', 'language_creators:unknown', 'language:unknown', 'license:cc-by-nc-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally\n",
       " annotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics.\n",
       " The dataset covers 45 languages ranging from low to high-resource, for many of which no\n",
       " public dataset is currently available. XL-Sum is highly abstractive, concise,\n",
       " and of high quality, as indicated by human and intrinsic evaluation.\n",
       " \tcitation: @inproceedings{hasan-etal-2021-xl,\n",
       "     title = \"{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\",\n",
       "     author = \"Hasan, Tahmid  and\n",
       "       Bhattacharjee, Abhik  and\n",
       "       Islam, Md. Saiful  and\n",
       "       Mubasshir, Kazi  and\n",
       "       Li, Yuan-Fang  and\n",
       "       Kang, Yong-Bin  and\n",
       "       Rahman, M. Sohel  and\n",
       "       Shahriyar, Rifat\",\n",
       "     booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n",
       "     month = aug,\n",
       "     year = \"2021\",\n",
       "     address = \"Online\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2021.findings-acl.413\",\n",
       "     pages = \"4693--4703\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['unknown'], 'license': ['cc-by-nc-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'xlsum', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 7773\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM/xsum\n",
       " \tsha: 74afe8fee986906fc348858854369968e04407b4\n",
       " \tlastModified: 2022-09-03T18:26:38.000Z\n",
       " \ttags: ['annotations_creators:none', 'language_creators:unknown', 'language:en', 'license:cc-by-sa-4.0', 'multilinguality:unknown', 'size_categories:unknown', 'source_datasets:original', 'task_categories:summarization', 'task_ids:unknown']\n",
       " \tprivate: False\n",
       " \tauthor: GEM\n",
       " \tdescription: This is the XSUM subset of the GEM benchmark.\n",
       " \tcitation: @inproceedings{narayan-etal-2018-dont,\n",
       "     title = \"Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization\",\n",
       "     author = \"Narayan, Shashi  and\n",
       "       Cohen, Shay B.  and\n",
       "       Lapata, Mirella\",\n",
       "     booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
       "     month = oct # \"-\" # nov,\n",
       "     year = \"2018\",\n",
       "     address = \"Brussels, Belgium\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/D18-1206\",\n",
       "     doi = \"10.18653/v1/D18-1206\",\n",
       "     pages = \"1797--1807\",\n",
       "     abstract = \"We introduce {``}extreme summarization{''}, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question {``}What is the article about?{''}. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article{'}s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['none'], 'language_creators': ['unknown'], 'language': ['en'], 'license': ['cc-by-sa-4.0'], 'multilinguality': ['unknown'], 'pretty_name': 'xsum', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['summarization'], 'task_ids': ['unknown']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 2113\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM-submissions/GEM__bart_base_schema_guided_dialog__1645547915\n",
       " \tsha: 2652b476ad41e11512d3f377cc5f7a5be04daffe\n",
       " \tlastModified: 2022-02-22T16:38:38.000Z\n",
       " \ttags: ['benchmark:gem', 'type:prediction', 'submission_name:BART_BASE_schema_guided_dialog']\n",
       " \tprivate: False\n",
       " \tauthor: GEM-submissions\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'benchmark': 'gem', 'type': 'prediction', 'submission_name': 'BART_BASE_schema_guided_dialog'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645558682\n",
       " \tsha: 3162f569ba2d639018f912b3f7692823d3b1148a\n",
       " \tlastModified: 2022-02-22T19:38:08.000Z\n",
       " \ttags: ['benchmark:gem', 'type:prediction', 'submission_name:Hugging Face test T5-base.outputs.json 36bf2a59']\n",
       " \tprivate: False\n",
       " \tauthor: GEM-submissions\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'benchmark': 'gem', 'type': 'prediction', 'submission_name': 'Hugging Face test T5-base.outputs.json 36bf2a59'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645559101\n",
       " \tsha: 3b0d72d19fba40c0727b4c079aa3bda0fec7df73\n",
       " \tlastModified: 2022-02-22T19:45:04.000Z\n",
       " \ttags: ['benchmark:gem', 'type:prediction', 'submission_name:Hugging Face test T5-base.outputs.json 36bf2a59']\n",
       " \tprivate: False\n",
       " \tauthor: GEM-submissions\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'benchmark': 'gem', 'type': 'prediction', 'submission_name': 'Hugging Face test T5-base.outputs.json 36bf2a59'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM-submissions/ratishsp\n",
       " \tsha: d98b4675a0211bea520e386f012d8e379405007f\n",
       " \tlastModified: 2022-02-11T16:04:09.000Z\n",
       " \ttags: ['benchmark:gem', 'type:prediction', 'submission_name:Template']\n",
       " \tprivate: False\n",
       " \tauthor: GEM-submissions\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'benchmark': 'gem', 'type': 'prediction', 'submission_name': 'Template'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GEM-submissions/submission-scores\n",
       " \tsha: ed901ce72b72a1355922f5e752748dce10c0594d\n",
       " \tlastModified: 2022-10-14T07:16:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: GEM-submissions\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 335\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GV05/shlomit_speech\n",
       " \tsha: ae49076cce96772abc9c8c9fde5492f54e310147\n",
       " \tlastModified: 2022-02-03T18:44:14.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: GV05\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 332\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Gabriel/quora_swe\n",
       " \tsha: a463a96d548996a9fe0faa3e7bc93fcc8ff826cf\n",
       " \tlastModified: 2022-08-13T09:04:02.000Z\n",
       " \ttags: ['language:sv', 'license:mit', 'size_categories:10K<n<100K', 'task_categories:question-pairing', 'task_categories:Information Retrieval', 'task_categories:Semantic Search', 'task_categories:Evaluation of language models', 'task_ids:semantic']\n",
       " \tprivate: False\n",
       " \tauthor: Gabriel\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['sv'], 'license': ['mit'], 'size_categories': ['10K<n<100K'], 'task_categories': ['question-pairing', 'Information Retrieval', 'Semantic Search', 'Evaluation of language models'], 'task_ids': ['semantic']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 333\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GalacticAI/Noirset\n",
       " \tsha: 13d5e4dfe7597ae9b3e0cdd943e1b45aec1f0d21\n",
       " \tlastModified: 2021-06-30T00:59:28.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: GalacticAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 174\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Gauravadlakha1509/new_one\n",
       " \tsha: ab65249db39707bddc4543cbb99544c0b935ad11\n",
       " \tlastModified: 2021-09-20T06:39:46.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Gauravadlakha1509\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GeoffVdr/cv8_trainval_processed\n",
       " \tsha: a83ef9793538b9aa02ae625155353227187c780d\n",
       " \tlastModified: 2022-01-31T15:10:08.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: GeoffVdr\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 173\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GonzaloA/fake_news\n",
       " \tsha: d653ddbf8eecee268bf6bc6e2fb2d0433704fedf\n",
       " \tlastModified: 2022-07-04T18:09:58.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:found', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'size_categories:30k<n<50k', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:fact-checking', 'task_ids:intent-classification', 'pretty_name:GonzaloA / Fake News']\n",
       " \tprivate: False\n",
       " \tauthor: GonzaloA\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['found'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'size_categories': ['30k<n<50k'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['fact-checking', 'intent-classification'], 'pretty_name': 'GonzaloA / Fake News'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 408\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/gqa-lxmert\n",
       " \tsha: b109ee6ac14dfef91dcf4fa6ea3a0723c294dbe2\n",
       " \tlastModified: 2022-03-23T13:54:11.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-4-0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: GQA is a new dataset for real-world visual reasoning and compositional question answering,\n",
       " seeking to address key shortcomings of previous visual question answering (VQA) datasets.\n",
       " \tcitation: @inproceedings{hudson2019gqa,\n",
       "   title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},\n",
       "   author={Hudson, Drew A and Manning, Christopher D},\n",
       "   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n",
       "   pages={6700--6709},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'languages': ['en'], 'licenses': ['cc-by-4-0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 346\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/gqa\n",
       " \tsha: 776b578ba67abdbe58b697714b6d794d3686a214\n",
       " \tlastModified: 2022-03-23T13:52:25.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-4-0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: GQA is a new dataset for real-world visual reasoning and compositional question answering,\n",
       " seeking to address key shortcomings of previous visual question answering (VQA) datasets.\n",
       " \tcitation: @inproceedings{hudson2019gqa,\n",
       "   title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},\n",
       "   author={Hudson, Drew A and Manning, Christopher D},\n",
       "   booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n",
       "   pages={6700--6709},\n",
       "   year={2019}\n",
       " }\n",
       " \tcardData: {'languages': ['en'], 'licenses': ['cc-by-4-0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 361\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/vqa-lxmert\n",
       " \tsha: 485df719abad6b7b2a10eeb36c14cf0c993fc4b4\n",
       " \tlastModified: 2022-03-23T13:53:56.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-4-0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: VQA is a new dataset containing open-ended questions about images. \n",
       " These questions require an understanding of vision, language and commonsense knowledge to answer.\n",
       " \tcitation: @inproceedings{antol2015vqa,\n",
       "   title={Vqa: Visual question answering},\n",
       "   author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},\n",
       "   booktitle={Proceedings of the IEEE international conference on computer vision},\n",
       "   pages={2425--2433},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'languages': ['en'], 'licenses': ['cc-by-4-0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/vqa\n",
       " \tsha: 63d299b7e792bcdb20a90e62a8c5a6385ddc0ba1\n",
       " \tlastModified: 2022-03-23T13:53:39.000Z\n",
       " \ttags: ['languages:en', 'licenses:cc-by-4-0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: VQA is a new dataset containing open-ended questions about images. \n",
       " These questions require an understanding of vision, language and commonsense knowledge to answer.\n",
       " \tcitation: @inproceedings{antol2015vqa,\n",
       "   title={Vqa: Visual question answering},\n",
       "   author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},\n",
       "   booktitle={Proceedings of the IEEE international conference on computer vision},\n",
       "   pages={2425--2433},\n",
       "   year={2015}\n",
       " }\n",
       " \tcardData: {'languages': ['en'], 'licenses': ['cc-by-4-0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 341\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/wikipedia-bert-128\n",
       " \tsha: d5e4c9b09eccf298c2d90f27d360a459e48ba344\n",
       " \tlastModified: 2022-09-07T14:42:32.000Z\n",
       " \ttags: ['language:en', 'license:cc-by-sa-3.0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['en'], 'license': ['cc-by-sa-3.0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 744\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Graphcore/wikipedia-bert-512\n",
       " \tsha: 6beac0eaa412cabb4b8dba22df241683da1d9921\n",
       " \tlastModified: 2022-09-07T14:43:02.000Z\n",
       " \ttags: ['language:en', 'license:cc-by-sa-3.0']\n",
       " \tprivate: False\n",
       " \tauthor: Graphcore\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'language': ['en'], 'license': ['cc-by-sa-3.0']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 448\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GroNLP/ik-nlp-22_pestyle\n",
       " \tsha: a1e3fce2b9b0dcfcda73d2ed9df90727155f9290\n",
       " \tlastModified: 2022-02-03T15:07:03.000Z\n",
       " \ttags: ['annotations_creators:machine-generated', 'annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'languages:it', 'licenses:private', 'multilinguality:translation', 'pretty_name:iknlp22-pestyle', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:translation']\n",
       " \tprivate: False\n",
       " \tauthor: GroNLP\n",
       " \tdescription: This dataset contains a sample of sentences taken from the FLORES-101 dataset that were either translated \n",
       " from scratch or post-edited from an existing automatic translation by three human translators. \n",
       " Translation were performed for the English-Italian language pair, and translators' behavioral data \n",
       " (keystrokes, pauses, editing times) were collected using the PET platform.\n",
       " \tcitation: No citation information available.\n",
       " \tcardData: {'annotations_creators': ['machine-generated', 'expert-generated'], 'language_creators': ['found'], 'languages': ['en', 'it'], 'licenses': ['private'], 'multilinguality': ['translation'], 'pretty_name': 'iknlp22-pestyle', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['translation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GroNLP/ik-nlp-22_slp\n",
       " \tsha: e42022b22a0598ebfc93c45c1b5531a1fd93f271\n",
       " \tlastModified: 2022-07-01T15:39:55.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language:en', 'license:unknown', 'multilinguality:monolingual', 'pretty_name:slp3ed-iknlp2022', 'size_categories:1K<n<10K', 'source_datasets:original', 'task_categories:question-answering', 'task_categories:text-retrieval', 'task_categories:summarization', 'task_categories:question-generation']\n",
       " \tprivate: False\n",
       " \tauthor: GroNLP\n",
       " \tdescription: Paragraphs from the Speech and Language Processing book (3ed) by Jurafsky and Martin extracted semi-automatically\n",
       " from Chapters 2 to 11 of the original book draft.\n",
       " \tcitation: @book{slp3ed-iknlp2022,\n",
       "     author = {Jurafsky, Daniel and Martin, James},\n",
       "     year = {2021},\n",
       "     month = {12},\n",
       "     pages = {1--235, 1--19},\n",
       "     title = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},\n",
       "     volume = {3}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated'], 'language': ['en'], 'license': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'slp3ed-iknlp2022', 'size_categories': ['1K<n<10K'], 'source_datasets': ['original'], 'task_categories': ['question-answering', 'text-retrieval', 'summarization', 'question-generation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 507\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GroNLP/ik-nlp-22_transqe\n",
       " \tsha: 27be6f2c17e30ad223dedb5e283a18b6edfde02d\n",
       " \tlastModified: 2022-07-01T15:40:10.000Z\n",
       " \ttags: ['annotations_creators:expert-generated', 'language_creators:expert-generated', 'language_creators:machine-generated', 'language:en', 'language:nl', 'license:apache-2.0', 'multilinguality:translation', 'pretty_name:iknlp22-transqe', 'size_categories:unknown', 'source_datasets:extended|esnli', 'task_categories:text-classification', 'task_ids:natural-language-inference', 'task_ids:text-classification-other-quality-estimation']\n",
       " \tprivate: False\n",
       " \tauthor: GroNLP\n",
       " \tdescription: The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\n",
       " include human-annotated natural language explanations of the entailment\n",
       " relations. This version includes an automatic translation to Dutch and two quality estimation annotations\n",
       " for each translated field.\n",
       " \tcitation: @incollection{NIPS2018_8163,\n",
       " title = {e-SNLI: Natural Language Inference with Natural Language Explanations},\n",
       " author = {Camburu, Oana-Maria and Rockt\\\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},\n",
       " booktitle = {Advances in Neural Information Processing Systems 31},\n",
       " editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\n",
       " pages = {9539--9549},\n",
       " year = {2018},\n",
       " publisher = {Curran Associates, Inc.},\n",
       " url = {http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf}\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['expert-generated', 'machine-generated'], 'language': ['en', 'nl'], 'license': ['apache-2.0'], 'multilinguality': ['translation'], 'pretty_name': 'iknlp22-transqe', 'size_categories': ['unknown'], 'source_datasets': ['extended|esnli'], 'task_categories': ['text-classification'], 'task_ids': ['natural-language-inference', 'text-classification-other-quality-estimation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: GroNLP/ik-nlp-22_winemag\n",
       " \tsha: 90eb39f35fc64e556fc17f06d4137a4a69ec3297\n",
       " \tlastModified: 2022-02-13T11:03:27.000Z\n",
       " \ttags: ['license:cc-by-sa-4.0']\n",
       " \tprivate: False\n",
       " \tauthor: GroNLP\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'license': 'cc-by-sa-4.0'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 330\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Gwangho/NCBI-Sars-Cov-2\n",
       " \tsha: e75dde2f176061fc8730ab49ce097000367ce22a\n",
       " \tlastModified: 2021-07-03T06:26:03.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Gwangho\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 175\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HHousen/ParaSCI\n",
       " \tsha: 5bbaa2ae85bfd49ac6ec872314d49a3b195a2f2b\n",
       " \tlastModified: 2021-11-24T03:38:25.000Z\n",
       " \ttags: ['arxiv:2101.08382']\n",
       " \tprivate: False\n",
       " \tauthor: HHousen\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 349\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HHousen/msrp\n",
       " \tsha: 6b1694b6e20f25bd1236dd68ae3201b71a85d424\n",
       " \tlastModified: 2022-01-01T03:30:43.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HHousen\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HHousen/quora\n",
       " \tsha: 992115389a20fb16c43da344d4feae9cd396bf43\n",
       " \tlastModified: 2021-11-21T02:11:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HHousen\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 331\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HUPD/hupd\n",
       " \tsha: 8e86bd54818f5b2b7b3fb4fc8db89a4878cf382a\n",
       " \tlastModified: 2022-08-09T15:20:06.000Z\n",
       " \ttags: ['arxiv:2207.04043', 'language:en', 'license:cc-by-sa-4.0', 'task_categories:masked-language-modeling', 'task_categories:summarization', 'task_categories:text-classification', 'task_categories:named-entity-recognition', 'task_categories:multi-class classification', 'task_categories:topic-classification', 'task_categories:classification', 'task_categories:patents', 'task_ids:masked-language-modeling', 'task_ids:summarization', 'task_ids:text-classification', 'task_ids:named-entity-recognition', 'task_ids:multi-class classification', 'task_ids:topic-classification', 'task_ids:classification', 'task_ids:patents']\n",
       " \tprivate: False\n",
       " \tauthor: HUPD\n",
       " \tdescription: The Harvard USPTO Patent Dataset (HUPD) is a large-scale, well-structured, and multi-purpose corpus \n",
       " of English-language patent applications filed to the United States Patent and Trademark Office (USPTO) \n",
       " between 2004 and 2018. With more than 4.5 million patent documents, HUPD is two to three times larger \n",
       " than comparable corpora. Unlike other NLP patent datasets, HUPD contains the inventor-submitted versions \n",
       " of patent applications, not the final versions of granted patents, allowing us to study patentability at \n",
       " the time of filing using NLP methods for the first time.\n",
       " \tcitation: @InProceedings{suzgun2021:hupd,\n",
       " title = {The Harvard USPTO Patent Dataset},\n",
       " authors={Mirac Suzgun and Suproteem Sarkar and Luke Melas-Kyriazi and Scott Kominers and Stuart Shieber},\n",
       " year={2021}\n",
       " }\n",
       " \tcardData: {'language': ['en'], 'license': ['cc-by-sa-4.0'], 'task_categories': ['masked-language-modeling', 'summarization', 'text-classification', 'named-entity-recognition', 'multi-class classification', 'topic-classification', 'classification', 'patents'], 'task_ids': ['masked-language-modeling', 'summarization', 'text-classification', 'named-entity-recognition', 'multi-class classification', 'topic-classification', 'classification', 'patents'], 'pretty_name': 'HUPD'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 556\n",
       " \tlikes: 8\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Halilyesilceng/autonlp-data-nameEntityRecognition\n",
       " \tsha: ae38fb811b5e1c418da3e65a256f625c78a29e8b\n",
       " \tlastModified: 2021-03-30T23:41:25.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Halilyesilceng\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 183\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HarleyQ/WitcherDialogue\n",
       " \tsha: 2e7d85ebef0840dc73708f104f2baa2dc660452f\n",
       " \tlastModified: 2021-06-02T16:15:44.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HarleyQ\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 180\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HarrisDePerceptron/sv_corpora_parliament_processed\n",
       " \tsha: 3dab36fe95dc28a7ef07239f7ace73ef4c97ca0a\n",
       " \tlastModified: 2022-02-06T22:08:17.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HarrisDePerceptron\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HarrisDePerceptron/ur_corpora_pib\n",
       " \tsha: 633d1915a5dfe168f3215b3404f610452f33bf45\n",
       " \tlastModified: 2022-02-08T10:30:32.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HarrisDePerceptron\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 341\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Harveenchadha/bol-models\n",
       " \tsha: 5ce018508a7ce16c14e5a73d994daff438fcdc2d\n",
       " \tlastModified: 2021-09-17T05:51:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Harveenchadha\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 180\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Harveenchadha/indic-voice\n",
       " \tsha: e0c8257950fec26d809f20e154a69224422ccf85\n",
       " \tlastModified: 2022-01-25T12:28:15.000Z\n",
       " \ttags: ['pretty_name:Indic Voice', 'annotations_creators:crowdsourced', 'language_creators:crowdsourced', 'languages:hi', 'languages:mr', 'languages:or', 'languages:ta', 'languages:te', 'languages:gu', 'multilinguality:multilingual', 'task_categories:speech-processing', 'task_ids:automatic-speech-recognition', 'tags:robust-speech-event']\n",
       " \tprivate: False\n",
       " \tauthor: Harveenchadha\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'pretty_name': 'Indic Voice', 'annotations_creators': ['crowdsourced'], 'language_creators': ['crowdsourced'], 'languages': ['hi', 'mr', 'or', 'ta', 'te', 'gu'], 'multilinguality': ['multilingual'], 'task_categories': ['speech-processing'], 'task_ids': ['automatic-speech-recognition'], 'tags': ['robust-speech-event']}\n",
       " \tsiblings: None\n",
       " \tgated: True\n",
       " \tdownloads: 28\n",
       " \tlikes: 2\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HarveyBWest/mybot\n",
       " \tsha: 6ba068d35eff5b785262fcc01b7a58706d4f97e9\n",
       " \tlastModified: 2021-07-03T13:22:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HarveyBWest\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 183\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Hellisotherpeople/DebateSum\n",
       " \tsha: c785ded74922db1129635cca166a9d80bec0c359\n",
       " \tlastModified: 2021-09-22T13:39:44.000Z\n",
       " \ttags: ['arxiv:2011.07251', 'annotations_creators:expert-generated', 'language_creators:crowdsourced', 'languages:en-US', 'licenses:mit', 'multilinguality:monolingual', 'pretty_name:DebateSum: A large-scale argument mining and summarization dataset', 'size_categories:100K<n<1M', 'source_datasets:original', 'task_categories:conditional-text-generation', 'task_categories:text-retrieval', 'task_categories:question-answering', 'task_ids:summarization', 'task_ids:document-retrieval', 'task_ids:extractive-qa', 'task_ids:abstractive-qa']\n",
       " \tprivate: False\n",
       " \tauthor: Hellisotherpeople\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'annotations_creators': ['expert-generated'], 'language_creators': ['crowdsourced'], 'languages': ['en-US'], 'licenses': ['mit'], 'multilinguality': ['monolingual'], 'pretty_name': 'DebateSum: A large-scale argument mining and summarization dataset', 'size_categories': ['100K<n<1M'], 'source_datasets': ['original'], 'task_categories': ['conditional-text-generation', 'text-retrieval', 'question-answering'], 'task_ids': ['summarization', 'document-retrieval', 'extractive-qa', 'abstractive-qa']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 354\n",
       " \tlikes: 3\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Helsinki-NLP/tatoeba_mt\n",
       " \tsha: 65f56198b10fa5bd6d331ebdf02a39e4162c382b\n",
       " \tlastModified: 2022-09-05T09:33:44.000Z\n",
       " \ttags: ['annotations_creators:no-annotation', 'language_creators:crowdsourced', 'language:af', 'language:ar', 'language:az', 'language:be', 'language:bg', 'language:bn', 'language:br', 'language:bs', 'language:ca', 'language:ch', 'language:cs', 'language:cv', 'language:cy', 'language:da', 'language:de', 'language:el', 'language:en', 'language:eo', 'language:es', 'language:et', 'language:eu', 'language:fa', 'language:fi', 'language:fo', 'language:fr', 'language:fy', 'language:ga', 'language:gd', 'language:gl', 'language:gn', 'language:he', 'language:hi', 'language:hr', 'language:hu', 'language:hy', 'language:ia', 'language:id', 'language:ie', 'language:io', 'language:is', 'language:it', 'language:ja', 'language:jv', 'language:ka', 'language:kk', 'language:km', 'language:ko', 'language:ku', 'language:kw', 'language:la', 'language:lb', 'language:lt', 'language:lv', 'language:mi', 'language:mk', 'language:ml', 'language:mn', 'language:mr', 'language:ms', 'language:mt', 'language:my', 'language:nb', 'language:nl', 'language:nn', 'language:no', 'language:oc', 'language:pl', 'language:pt', 'language:qu', 'language:rn', 'language:ro', 'language:ru', 'language:sh', 'language:sl', 'language:sq', 'language:sr', 'language:sv', 'language:sw', 'language:ta', 'language:te', 'language:th', 'language:tk', 'language:tl', 'language:tr', 'language:tt', 'language:ug', 'language:uk', 'language:ur', 'language:uz', 'language:vi', 'language:vo', 'language:yi', 'language:zh', 'license:cc-by-2.0', 'multilinguality:translation', 'size_categories:unknown', 'source_datasets:original', 'task_categories:conditional-text-generation', 'task_ids:machine-translation']\n",
       " \tprivate: False\n",
       " \tauthor: Helsinki-NLP\n",
       " \tdescription: The Tatoeba Translation Challenge is a multilingual data set of\n",
       " machine translation benchmarks derived from user-contributed\n",
       " translations collected by [Tatoeba.org](https://tatoeba.org/) and\n",
       " provided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\n",
       " dataset includes test and development data sorted by language pair. It\n",
       " includes test sets for hundreds of language pairs and is continuously\n",
       " updated. Please, check the version number tag to refer to the release\n",
       " that your are using.\n",
       " \tcitation: @inproceedings{tiedemann-2020-tatoeba,\n",
       "     title = \"The {T}atoeba {T}ranslation {C}hallenge {--} {R}ealistic Data Sets for Low Resource and Multilingual {MT}\",\n",
       "     author = {Tiedemann, J{\\\"o}rg},\n",
       "     booktitle = \"Proceedings of the Fifth Conference on Machine Translation\",\n",
       "     month = nov,\n",
       "     year = \"2020\",\n",
       "     publisher = \"Association for Computational Linguistics\",\n",
       "     url = \"https://aclanthology.org/2020.wmt-1.139\",\n",
       "     pages = \"1174--1182\",\n",
       " }\n",
       " \tcardData: {'annotations_creators': ['no-annotation'], 'language_creators': ['crowdsourced'], 'language': ['af', 'ar', 'az', 'be', 'bg', 'bn', 'br', 'bs', 'ca', 'ch', 'cs', 'cv', 'cy', 'da', 'de', 'el', 'en', 'eo', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fy', 'ga', 'gd', 'gl', 'gn', 'he', 'hi', 'hr', 'hu', 'hy', 'ia', 'id', 'ie', 'io', 'is', 'it', 'ja', 'jv', 'ka', 'kk', 'km', 'ko', 'ku', 'kw', 'la', 'lb', 'lt', 'lv', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'nb', 'nl', 'nn', 'no', 'oc', 'pl', 'pt', 'qu', 'rn', 'ro', 'ru', 'sh', 'sl', 'sq', 'sr', 'sv', 'sw', 'ta', 'te', 'th', 'tk', 'tl', 'tr', 'tt', 'ug', 'uk', 'ur', 'uz', 'vi', 'vo', 'yi', 'zh'], 'license': ['cc-by-2.0'], 'multilinguality': ['translation'], 'pretty_name': 'The Tatoeba Translation Challenge', 'size_categories': ['unknown'], 'source_datasets': ['original'], 'task_categories': ['conditional-text-generation'], 'task_ids': ['machine-translation']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 129414\n",
       " \tlikes: 12\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HenryAI/KerasAPIReference.txt\n",
       " \tsha: 945bea40d4783692fca28bb4fed101a57b922a2f\n",
       " \tlastModified: 2021-12-15T15:55:07.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HenryAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 342\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HenryAI/KerasBERTv1-Data\n",
       " \tsha: 80f81242d8d1cf1163018eab3b0237c8a12fcadd\n",
       " \tlastModified: 2021-12-15T16:05:48.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HenryAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HenryAI/KerasCodeExamples.txt\n",
       " \tsha: 2dd5beae4e31f10590a4860025d26edf36ac8512\n",
       " \tlastModified: 2021-12-15T15:57:06.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HenryAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 340\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: HenryAI/KerasDeveloperGuides.txt\n",
       " \tsha: 8d270a68da1c0eedee946f5d7dc3261aab36237c\n",
       " \tlastModified: 2021-12-15T15:56:47.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: HenryAI\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 181\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Huertas97/autonlp-data-mami-semeval-20-21\n",
       " \tsha: d9d47ea79a409ccbeb15d64ffb3bd0621376551a\n",
       " \tlastModified: 2021-10-21T08:03:52.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Huertas97\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 341\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Husain/intent-classification-en-fr\n",
       " \tsha: a6f1a20bd258f025dfa33e9e22ce4679b098e85a\n",
       " \tlastModified: 2021-07-28T13:06:35.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Husain\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 183\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: IFSTalfredoswald/MBTI\n",
       " \tsha: 16f3d2dbe10c17fed80f76ac6f757edacce7d82d\n",
       " \tlastModified: 2021-10-25T10:40:02.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: IFSTalfredoswald\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: {'YAML tags': [{'copy-paste the tags obtained with the tagging app': 'https://github.com/huggingface/datasets-tagging'}]}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Iftoo95/Arabic_Sentiment_and_Topics\n",
       " \tsha: d858e3bf6145217b36e151636805daa733a77eb2\n",
       " \tlastModified: 2021-11-20T14:50:45.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Iftoo95\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 178\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: IlyaGusev/gazeta\n",
       " \tsha: b65bdcd9e867b0b02da8773c70b0003a31e7e166\n",
       " \tlastModified: 2021-12-15T12:53:53.000Z\n",
       " \ttags: ['arxiv:2006.11063', 'annotations_creators:expert-generated', 'annotations_creators:found', 'language_creators:expert-generated', 'language_creators:found', 'languages:ru', 'languages:ru-RU', 'licenses:unknown', 'multilinguality:monolingual', 'pretty_name:Gazeta', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:conditional-text-generation', 'task_ids:summarization']\n",
       " \tprivate: False\n",
       " \tauthor: IlyaGusev\n",
       " \tdescription: None\n",
       " \tcitation: @InProceedings{10.1007/978-3-030-59082-6_9,\n",
       "     author=\"Gusev, Ilya\",\n",
       "     editor=\"Filchenkov, Andrey and Kauttonen, Janne and Pivovarova, Lidia\",\n",
       "     title=\"Dataset for Automatic Summarization of Russian News\",\n",
       "     booktitle=\"Artificial Intelligence and Natural Language\",\n",
       "     year=\"2020\",\n",
       "     publisher=\"Springer International Publishing\",\n",
       "     address=\"Cham\",\n",
       "     pages=\"122--134\",\n",
       "     isbn=\"978-3-030-59082-6\"\n",
       " }\n",
       " \tcardData: {'YAML tags': None, 'annotations_creators': ['expert-generated', 'found'], 'language_creators': ['expert-generated', 'found'], 'languages': ['ru', 'ru-RU'], 'licenses': ['unknown'], 'multilinguality': ['monolingual'], 'pretty_name': 'Gazeta', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['conditional-text-generation'], 'task_ids': ['summarization'], 'paperswithcode_id': 'gazeta'}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 423\n",
       " \tlikes: 5\n",
       " \tpaperswithcode_id: gazeta\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: IlyaGusev/headline_cause\n",
       " \tsha: e08a8d7b563cfc8ea9d0b5de51770105766cf219\n",
       " \tlastModified: 2022-07-28T10:13:45.000Z\n",
       " \ttags: ['arxiv:2108.12626', 'annotations_creators:crowdsourced', 'language_creators:found', 'language:ru', 'language:en', 'license:cc0-1.0', 'multilinguality:multilingual', 'pretty_name:HeadlineCause', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:text-classification', 'task_ids:multi-class-classification', 'task_ids:causal-reasoning']\n",
       " \tprivate: False\n",
       " \tauthor: IlyaGusev\n",
       " \tdescription: None\n",
       " \tcitation: @misc{gusev2021headlinecause,\n",
       "     title={HeadlineCause: A Dataset of News Headlines for Detecting Casualties},\n",
       "     author={Ilya Gusev and Alexey Tikhonov},\n",
       "     year={2021},\n",
       "     eprint={2108.12626},\n",
       "     archivePrefix={arXiv},\n",
       "     primaryClass={cs.CL}\n",
       " }\n",
       " \tcardData: {'YAML tags': None, 'annotations_creators': ['crowdsourced'], 'language_creators': ['found'], 'language': ['ru', 'en'], 'license': ['cc0-1.0'], 'multilinguality': ['multilingual'], 'pretty_name': 'HeadlineCause', 'size_categories': ['10K<n<100K'], 'source_datasets': ['original'], 'task_categories': ['text-classification'], 'task_ids': ['multi-class-classification', 'causal-reasoning']}\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 808\n",
       " \tlikes: 1\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Intel/WEC-Eng\n",
       " \tsha: e9a0f74a6fc2ec7a12ce66299dcffc693d2bf0d9\n",
       " \tlastModified: 2021-10-04T11:21:48.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Intel\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: IsaacBot/GP-Sentiment\n",
       " \tsha: e78032a21bfce3b9acc3a031df23cf27540353ae\n",
       " \tlastModified: 2022-02-22T18:15:59.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: IsaacBot\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 386\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Ishwar/Senti\n",
       " \tsha: dbcb8b0b3beca6fdbcbbb3d1aac0eb792c68e6b5\n",
       " \tlastModified: 2021-10-31T10:03:41.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Ishwar\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 338\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Iskaj/dutch_corpora_parliament_processed\n",
       " \tsha: ed61af7c59e4f040796d8ca85c4f7d7d09f46ff7\n",
       " \tlastModified: 2022-01-27T11:42:10.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Iskaj\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 339\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: JIWON/nil_dataset\n",
       " \tsha: b56c5975aceb95215cf62f0df0957290796f2038\n",
       " \tlastModified: 2022-02-07T00:34:03.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: JIWON\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 182\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: JIsanan/war-ceb-wikipedia\n",
       " \tsha: dad97e25cbb6fdbcf419d63d1bdbfa998978da60\n",
       " \tlastModified: 2021-10-24T01:48:04.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: JIsanan\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/TED2020_kor\n",
       " \tsha: 7afe7334bd7522452d36eaa131a6c3cfc2d78ae4\n",
       " \tlastModified: 2021-11-07T19:45:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 343\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/TED2020_vi\n",
       " \tsha: aa5d105dd93ae17ade7786b73c926ac27d244b40\n",
       " \tlastModified: 2021-11-07T19:42:16.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 337\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/TED2020vi_kor\n",
       " \tsha: 9764d8bff784eaa15a7f60ecef973159ffa0acd1\n",
       " \tlastModified: 2021-11-07T17:21:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 338\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/demo\n",
       " \tsha: b8a9661cebd3a0373d79cae8cea62e749d2b3e98\n",
       " \tlastModified: 2021-11-07T16:25:20.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 338\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/eng_vi_demo\n",
       " \tsha: 883c56da0d75793e701bbd89fcae7aeb55b436af\n",
       " \tlastModified: 2021-11-07T14:26:53.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 177\n",
       " \tlikes: 0\n",
       " },\n",
       " DatasetInfo: {\n",
       " \tid: Jack0508/test\n",
       " \tsha: 3026170f842d8531c65c6e02a0ac3b73b001b127\n",
       " \tlastModified: 2021-11-07T18:03:21.000Z\n",
       " \ttags: []\n",
       " \tprivate: False\n",
       " \tauthor: Jack0508\n",
       " \tdescription: None\n",
       " \tcitation: None\n",
       " \tcardData: None\n",
       " \tsiblings: None\n",
       " \tgated: False\n",
       " \tdownloads: 338\n",
       " \tlikes: 0\n",
       " },\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_list = list_datasets(with_details=True)\n",
    "datasets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abba994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration binary\n",
      "Found cached dataset empathetic_dialogues (C:/Users/Davide/.cache/huggingface/datasets/empathetic_dialogues/binary/0.1.0/09bbeed3882a67db98c73952fb3c1c9a85af83dc78f81454c2454382fd03f6cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bce1091b6e43358f1f2307e988f0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('empathetic_dialogues','binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0715821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'],\n",
       "        num_rows: 76673\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'],\n",
       "        num_rows: 12030\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'],\n",
       "        num_rows: 10943\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1312bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='pandas', columns=['conv_id',  'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', \n",
    "                                    'selfeval', 'tags']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fae6bd",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5cbec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = dataset['train'][0]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e421ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f12c3b02384c62af6fb751d28f50ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1, len(dataset['train']))):\n",
    "    df_train = df_train.append(dataset['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9829702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"dataset/HuggingFace Datasets/empathetic_dialogues_Train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7ce047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12424_conv:24848</td>\n",
       "      <td>5</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I found some pictures of my grandma in the att...</td>\n",
       "      <td>389</td>\n",
       "      <td>Yeah reminds me of the good old days.  I miss ...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>1</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>294</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>2</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>389</td>\n",
       "      <td>Oh hey that's awesome!  That is awesome right?</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>3</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>294</td>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12424_conv:24849</td>\n",
       "      <td>4</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>389</td>\n",
       "      <td>That is awesome!!!! Congratulations!</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76673 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 conv_id  utterance_idx      context  \\\n",
       "0           hit:0_conv:1              1  sentimental   \n",
       "0           hit:0_conv:1              2  sentimental   \n",
       "0           hit:0_conv:1              3  sentimental   \n",
       "0           hit:0_conv:1              4  sentimental   \n",
       "0           hit:0_conv:1              5  sentimental   \n",
       "..                   ...            ...          ...   \n",
       "0   hit:12424_conv:24848              5  sentimental   \n",
       "0   hit:12424_conv:24849              1    surprised   \n",
       "0   hit:12424_conv:24849              2    surprised   \n",
       "0   hit:12424_conv:24849              3    surprised   \n",
       "0   hit:12424_conv:24849              4    surprised   \n",
       "\n",
       "                                               prompt  speaker_idx  \\\n",
       "0   I remember going to the fireworks with my best...            1   \n",
       "0   I remember going to the fireworks with my best...            0   \n",
       "0   I remember going to the fireworks with my best...            1   \n",
       "0   I remember going to the fireworks with my best...            0   \n",
       "0   I remember going to the fireworks with my best...            1   \n",
       "..                                                ...          ...   \n",
       "0   I found some pictures of my grandma in the att...          389   \n",
       "0   I woke up this morning to my wife telling me s...          294   \n",
       "0   I woke up this morning to my wife telling me s...          389   \n",
       "0   I woke up this morning to my wife telling me s...          294   \n",
       "0   I woke up this morning to my wife telling me s...          389   \n",
       "\n",
       "                                            utterance     selfeval tags  \n",
       "0   I remember going to see the fireworks with my ...  5|5|5_2|2|5       \n",
       "0   Was this a friend you were in love with_comma_...  5|5|5_2|2|5       \n",
       "0                 This was a best friend. I miss her.  5|5|5_2|2|5       \n",
       "0                                 Where has she gone?  5|5|5_2|2|5       \n",
       "0                                  We no longer talk.  5|5|5_2|2|5       \n",
       "..                                                ...          ...  ...  \n",
       "0   Yeah reminds me of the good old days.  I miss ...  5|5|5_5|5|5       \n",
       "0   I woke up this morning to my wife telling me s...  5|5|5_5|5|5       \n",
       "0      Oh hey that's awesome!  That is awesome right?  5|5|5_5|5|5       \n",
       "0   It is soooo awesome.  We have been wanting a b...  5|5|5_5|5|5       \n",
       "0                That is awesome!!!! Congratulations!  5|5|5_5|5|5       \n",
       "\n",
       "[76673 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bfdd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f3d98d",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f502a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>1</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx    context  \\\n",
       "0  hit:3_conv:6              1  terrified   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  Today_comma_as i was leaving for work in the m...            6   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  Today_comma_as i was leaving for work in the m...  4|5|5_5|5|5       "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation = dataset['validation'][0]\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69dd613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eeb75062f547078f6f87ea8794f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1, len(dataset['validation']))):\n",
    "    df_validation = df_validation.append(dataset['validation'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722506e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv(\"dataset/HuggingFace Datasets/empathetic_dialogues_Validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d8de8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>1</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>2</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>Are you fine now?</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>3</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>Yeah_comma_i'm doing alright now_comma_ but wi...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>4</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>Cool :) Is your car damaged a lot?</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>&lt;IRREGULAR_COLON_FORMAT&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>5</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>The car was badly damaged_comma_i veered outsi...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12361_conv:24722</td>\n",
       "      <td>4</td>\n",
       "      <td>prepared</td>\n",
       "      <td>One time I studied all night for my final exam!</td>\n",
       "      <td>46</td>\n",
       "      <td>tha is really cool what was your grade</td>\n",
       "      <td>4|4|5_4|4|3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12392_conv:24785</td>\n",
       "      <td>1</td>\n",
       "      <td>furious</td>\n",
       "      <td>One of my coworkers has been arguing with his ...</td>\n",
       "      <td>791</td>\n",
       "      <td>One of my coworkers has been arguing with his ...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12392_conv:24785</td>\n",
       "      <td>2</td>\n",
       "      <td>furious</td>\n",
       "      <td>One of my coworkers has been arguing with his ...</td>\n",
       "      <td>829</td>\n",
       "      <td>What are they arguing about?</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12392_conv:24785</td>\n",
       "      <td>3</td>\n",
       "      <td>furious</td>\n",
       "      <td>One of my coworkers has been arguing with his ...</td>\n",
       "      <td>791</td>\n",
       "      <td>Everything and anything. It's annoying_comma_ ...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12392_conv:24785</td>\n",
       "      <td>4</td>\n",
       "      <td>furious</td>\n",
       "      <td>One of my coworkers has been arguing with his ...</td>\n",
       "      <td>829</td>\n",
       "      <td>That's so ridiculous!</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12030 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 conv_id  utterance_idx    context  \\\n",
       "0           hit:3_conv:6              1  terrified   \n",
       "0           hit:3_conv:6              2  terrified   \n",
       "0           hit:3_conv:6              3  terrified   \n",
       "0           hit:3_conv:6              4  terrified   \n",
       "0           hit:3_conv:6              5  terrified   \n",
       "..                   ...            ...        ...   \n",
       "0   hit:12361_conv:24722              4   prepared   \n",
       "0   hit:12392_conv:24785              1    furious   \n",
       "0   hit:12392_conv:24785              2    furious   \n",
       "0   hit:12392_conv:24785              3    furious   \n",
       "0   hit:12392_conv:24785              4    furious   \n",
       "\n",
       "                                               prompt  speaker_idx  \\\n",
       "0   Today_comma_as i was leaving for work in the m...            6   \n",
       "0   Today_comma_as i was leaving for work in the m...            7   \n",
       "0   Today_comma_as i was leaving for work in the m...            6   \n",
       "0   Today_comma_as i was leaving for work in the m...            7   \n",
       "0   Today_comma_as i was leaving for work in the m...            6   \n",
       "..                                                ...          ...   \n",
       "0     One time I studied all night for my final exam!           46   \n",
       "0   One of my coworkers has been arguing with his ...          791   \n",
       "0   One of my coworkers has been arguing with his ...          829   \n",
       "0   One of my coworkers has been arguing with his ...          791   \n",
       "0   One of my coworkers has been arguing with his ...          829   \n",
       "\n",
       "                                            utterance     selfeval  \\\n",
       "0   Today_comma_as i was leaving for work in the m...  4|5|5_5|5|5   \n",
       "0                                   Are you fine now?  4|5|5_5|5|5   \n",
       "0   Yeah_comma_i'm doing alright now_comma_ but wi...  4|5|5_5|5|5   \n",
       "0                  Cool :) Is your car damaged a lot?  4|5|5_5|5|5   \n",
       "0   The car was badly damaged_comma_i veered outsi...  4|5|5_5|5|5   \n",
       "..                                                ...          ...   \n",
       "0              tha is really cool what was your grade  4|4|5_4|4|3   \n",
       "0   One of my coworkers has been arguing with his ...  4|5|5_5|5|5   \n",
       "0                        What are they arguing about?  4|5|5_5|5|5   \n",
       "0   Everything and anything. It's annoying_comma_ ...  4|5|5_5|5|5   \n",
       "0                               That's so ridiculous!  4|5|5_5|5|5   \n",
       "\n",
       "                        tags  \n",
       "0                             \n",
       "0                             \n",
       "0                             \n",
       "0   <IRREGULAR_COLON_FORMAT>  \n",
       "0                             \n",
       "..                       ...  \n",
       "0                             \n",
       "0                             \n",
       "0                             \n",
       "0                             \n",
       "0                             \n",
       "\n",
       "[12030 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175755d",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aac2efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>1</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yeah about 10 years ago I had a horrifying exp...</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx context  \\\n",
       "0  hit:0_conv:0              1  guilty   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I felt guilty when I was driving home one nigh...            0   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  Yeah about 10 years ago I had a horrifying exp...  2|2|5_5|5|5       "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = dataset['test'][0]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906eb235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83de47733944475e8dfcb8e474cd85b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1, len(dataset['test']))):\n",
    "    df_test = df_test.append(dataset['test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c100be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"dataset/HuggingFace Datasets/empathetic_dialogues_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5808dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>1</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yeah about 10 years ago I had a horrifying exp...</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>2</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Did you suffer any injuries?</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>3</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>0</td>\n",
       "      <td>No I wasn't hit. It turned out they were drunk...</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>4</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why did you feel guilty? People really shouldn...</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>5</td>\n",
       "      <td>guilty</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know I was new to driving and hadn't e...</td>\n",
       "      <td>2|2|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12416_conv:24832</td>\n",
       "      <td>4</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>I saw a huge cockroach outside my house today....</td>\n",
       "      <td>46</td>\n",
       "      <td>I live in Texas to so i know those feels</td>\n",
       "      <td>5|5|5_4|3|4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>1</td>\n",
       "      <td>anxious</td>\n",
       "      <td>I have a big test on Monday. I am so nervous_c...</td>\n",
       "      <td>481</td>\n",
       "      <td>I have a big test on Monday_comma_ I am so ner...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>2</td>\n",
       "      <td>anxious</td>\n",
       "      <td>I have a big test on Monday. I am so nervous_c...</td>\n",
       "      <td>375</td>\n",
       "      <td>What is the test on?</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>3</td>\n",
       "      <td>anxious</td>\n",
       "      <td>I have a big test on Monday. I am so nervous_c...</td>\n",
       "      <td>481</td>\n",
       "      <td>It's for my Chemistry class. I haven't slept m...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>4</td>\n",
       "      <td>anxious</td>\n",
       "      <td>I have a big test on Monday. I am so nervous_c...</td>\n",
       "      <td>375</td>\n",
       "      <td>Chemistry is quite difficult_comma_have you st...</td>\n",
       "      <td>5|5|5_5|5|5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10943 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 conv_id  utterance_idx    context  \\\n",
       "0           hit:0_conv:0              1     guilty   \n",
       "0           hit:0_conv:0              2     guilty   \n",
       "0           hit:0_conv:0              3     guilty   \n",
       "0           hit:0_conv:0              4     guilty   \n",
       "0           hit:0_conv:0              5     guilty   \n",
       "..                   ...            ...        ...   \n",
       "0   hit:12416_conv:24832              4  disgusted   \n",
       "0   hit:12423_conv:24847              1    anxious   \n",
       "0   hit:12423_conv:24847              2    anxious   \n",
       "0   hit:12423_conv:24847              3    anxious   \n",
       "0   hit:12423_conv:24847              4    anxious   \n",
       "\n",
       "                                               prompt  speaker_idx  \\\n",
       "0   I felt guilty when I was driving home one nigh...            0   \n",
       "0   I felt guilty when I was driving home one nigh...            1   \n",
       "0   I felt guilty when I was driving home one nigh...            0   \n",
       "0   I felt guilty when I was driving home one nigh...            1   \n",
       "0   I felt guilty when I was driving home one nigh...            0   \n",
       "..                                                ...          ...   \n",
       "0   I saw a huge cockroach outside my house today....           46   \n",
       "0   I have a big test on Monday. I am so nervous_c...          481   \n",
       "0   I have a big test on Monday. I am so nervous_c...          375   \n",
       "0   I have a big test on Monday. I am so nervous_c...          481   \n",
       "0   I have a big test on Monday. I am so nervous_c...          375   \n",
       "\n",
       "                                            utterance     selfeval tags  \n",
       "0   Yeah about 10 years ago I had a horrifying exp...  2|2|5_5|5|5       \n",
       "0                        Did you suffer any injuries?  2|2|5_5|5|5       \n",
       "0   No I wasn't hit. It turned out they were drunk...  2|2|5_5|5|5       \n",
       "0   Why did you feel guilty? People really shouldn...  2|2|5_5|5|5       \n",
       "0   I don't know I was new to driving and hadn't e...  2|2|5_5|5|5       \n",
       "..                                                ...          ...  ...  \n",
       "0            I live in Texas to so i know those feels  5|5|5_4|3|4       \n",
       "0   I have a big test on Monday_comma_ I am so ner...  5|5|5_5|5|5       \n",
       "0                                What is the test on?  5|5|5_5|5|5       \n",
       "0   It's for my Chemistry class. I haven't slept m...  5|5|5_5|5|5       \n",
       "0   Chemistry is quite difficult_comma_have you st...  5|5|5_5|5|5       \n",
       "\n",
       "[10943 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8be46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f4f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a83cc334",
   "metadata": {},
   "source": [
    "#### Final Dataframe V.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71503ab1",
   "metadata": {},
   "source": [
    "Previous final df + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f8c33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ = df_train[[\"prompt\", \"utterance\"]]\n",
    "df_train_.rename({\"prompt\":\"sentence_1\", \"utterance\":\"sentence_2\"}, axis=1, inplace=True)\n",
    "df_validation_ = df_validation[[\"prompt\", \"utterance\"]]\n",
    "df_validation_.rename({\"prompt\":\"sentence_1\", \"utterance\":\"sentence_2\"}, axis=1, inplace=True)\n",
    "df_test_ = df_test[[\"prompt\", \"utterance\"]]\n",
    "df_test_.rename({\"prompt\":\"sentence_1\", \"utterance\":\"sentence_2\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "297b95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_['sentence_1'] =  df_train_['sentence_1'].apply(lambda x: re.sub('_comma_',',', str(x)))\n",
    "df_train_['sentence_2'] =  df_train_['sentence_2'].apply(lambda x: re.sub('_comma_',',', str(x)))\n",
    "df_validation_['sentence_1'] =  df_validation_['sentence_1'].apply(lambda x: re.sub('_comma_',',', str(x)))\n",
    "df_validation_['sentence_2'] =  df_validation_['sentence_2'].apply(lambda x: re.sub('_comma_',',', str(x)))\n",
    "df_test_['sentence_1'] =  df_test_['sentence_1'].apply(lambda x: re.sub('_comma_',',', str(x)))\n",
    "df_test_['sentence_2'] =  df_test_['sentence_2'].apply(lambda x: re.sub('_comma_',',', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f3073b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/processed_df.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54bad148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>Can you prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Can you prove you are self-aware please</td>\n",
       "      <td>That is an difficult question, can you prove t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>Can you prove you are self aware please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>Can you prove you have a conscious please</td>\n",
       "      <td>That is an interesting question, can you prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>prove you have a conscious</td>\n",
       "      <td>That depends, can you prove that you are?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence_1  \\\n",
       "0                        hi, how are you doing?   \n",
       "1                 i'm fine. how about yourself?   \n",
       "2           i'm pretty good. thanks for asking.   \n",
       "3             no problem. so how have you been?   \n",
       "4              i've been great. what about you?   \n",
       "...                                         ...   \n",
       "4080         Can you prove you have a conscious   \n",
       "4081    Can you prove you are self-aware please   \n",
       "4082    Can you prove you are self aware please   \n",
       "4083  Can you prove you have a conscious please   \n",
       "4084                 prove you have a conscious   \n",
       "\n",
       "                                             sentence_2  \n",
       "0                         i'm fine. how about yourself?  \n",
       "1                   i'm pretty good. thanks for asking.  \n",
       "2                     no problem. so how have you been?  \n",
       "3                      i've been great. what about you?  \n",
       "4              i've been good. i'm in school right now.  \n",
       "...                                                 ...  \n",
       "4080          That depends, can you prove that you are?  \n",
       "4081  That is an difficult question, can you prove t...  \n",
       "4082  That is an interesting question, can you prove...  \n",
       "4083  That is an interesting question, can you prove...  \n",
       "4084          That depends, can you prove that you are?  \n",
       "\n",
       "[4085 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb514fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw a huge cockroach outside my house today....</td>\n",
       "      <td>I live in Texas to so i know those feels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>I have a big test on Monday, I am so nervous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>What is the test on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>It's for my Chemistry class. I haven't slept m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>Chemistry is quite difficult,have you studied ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence_1  \\\n",
       "0                              hi, how are you doing?   \n",
       "1                       i'm fine. how about yourself?   \n",
       "2                 i'm pretty good. thanks for asking.   \n",
       "3                   no problem. so how have you been?   \n",
       "4                    i've been great. what about you?   \n",
       "..                                                ...   \n",
       "0   I saw a huge cockroach outside my house today....   \n",
       "0   I have a big test on Monday. I am so nervous, ...   \n",
       "0   I have a big test on Monday. I am so nervous, ...   \n",
       "0   I have a big test on Monday. I am so nervous, ...   \n",
       "0   I have a big test on Monday. I am so nervous, ...   \n",
       "\n",
       "                                           sentence_2  \n",
       "0                       i'm fine. how about yourself?  \n",
       "1                 i'm pretty good. thanks for asking.  \n",
       "2                   no problem. so how have you been?  \n",
       "3                    i've been great. what about you?  \n",
       "4            i've been good. i'm in school right now.  \n",
       "..                                                ...  \n",
       "0            I live in Texas to so i know those feels  \n",
       "0       I have a big test on Monday, I am so nervous.  \n",
       "0                                What is the test on?  \n",
       "0   It's for my Chemistry class. I haven't slept m...  \n",
       "0   Chemistry is quite difficult,have you studied ...  \n",
       "\n",
       "[103731 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_v2 = pd.concat([df, df_train_, df_validation_, df_test_])\n",
    "display(df_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1c233a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.to_csv(\"dataset/processed_df_V2.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7ea8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
